Search.setIndex({"alltitles": {"(1) \u5b89\u88c5 Toolkit \u5f00\u53d1\u5957\u4ef6": [[14, "toolkit"]], "(2) \u5b89\u88c5 Kernels \u7b97\u5b50\u5305": [[14, "kernels"]], "(3) \u5b89\u88c5 NNAL \u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5e93\uff08\u53ef\u9009\uff09": [[14, "nnal"]], "1. Classification Reranker": [[120, "classification-reranker"]], "1. Colocate (Internal) Mode": [[150, "colocate-internal-mode"]], "1. Colocate(Internal) Mode": [[89, "colocate-internal-mode"]], "1. Create Your Model Implementation": [[36, "create-your-model-implementation"]], "1. Create a Patch Configuration": [[39, "create-a-patch-configuration"]], "1. Define Your Custom Preprocessor": [[37, "define-your-custom-preprocessor"]], "1. FSDP Support - Native Integration": [[46, "fsdp-support-native-integration"]], "1. Fine-grained Collection in Rollout Phase": [[172, "fine-grained-collection-in-rollout-phase"]], "1. KL Divergence": [[142, "kl-divergence"]], "1. KL \u6563\u5ea6\uff08KL Divergence\uff09": [[81, "kl-kl-divergence"]], "1. Rollout \u9636\u6bb5\u7cbe\u7ec6\u5316\u91c7\u96c6": [[173, "rollout"]], "1. Truncate": [[142, "truncate"]], "1. Truncate\uff08\u622a\u65ad\uff09": [[81, "truncate"]], "1. accuracy": [[87, "accuracy"], [148, "accuracy"]], "1. \u4f7f\u7528 Docker Build \u6784\u5efa": [[14, "docker-build"]], "1. \u4f7f\u7528DeepSpeed\u591a\u5361\u5e76\u884c\u8bad\u7ec3": [[188, "id2"]], "1. \u4f7f\u7528\u811a\u672c\u4e0b\u8f7d": [[256, "id2"]], "1. \u5206\u7c7b\u5f0fReranker": [[59, "id2"]], "1. \u5355\u5361\u8bad\u7ec3": [[219, "id2"]], "1. \u5378\u8f7d": [[185, "id6"]], "1. \u5b89\u88c5 LLaMA-Factory \u548c transformers": [[8, "llama-factory-transformers"]], "1. \u5b89\u88c5DeepSpeed": [[187, "deepspeed"]], "1. \u62c9\u53d6\u955c\u50cf": [[14, "id6"]], "1. \u6570\u636e\u5e76\u884c": [[215, "id2"]], "1. \u6570\u636e\u96c6\u4e0e\u6743\u91cd": [[170, "id2"]], "1. \u7248\u672c\u53ca\u4e0b\u8f7d\u94fe\u63a5": [[14, "id3"]], "1. \u7cfb\u7edf\u8981\u6c42": [[185, "id2"]], "1. \u9009\u62e9\u9700\u8981\u5b89\u88c5\u7684 PyTorch \u7248\u672c": [[218, "pytorch"]], "1. \u957f\u8017\u65f6\u4efb\u52a1\u4e0e\u8d44\u6e90\u7a7a\u6ce1\u5206\u6790": [[177, "id6"]], "1.1 DDP": [[215, "ddp"]], "1.1 \u524d\u7f6e\u68c0\u67e5": [[185, "id3"]], "1.2 FSDP": [[215, "fsdp"]], "1.2 \u8f6f\u4ef6\u8981\u6c42": [[185, "id4"]], "1.host bound\u8bca\u65ad": [[177, "host-bound"]], "1.\u6a21\u578b\u6570\u636e\u51c6\u5907": [[178, "id4"], [179, "id4"]], "2. Async(External) Mode": [[89, "async-external-mode"], [150, "async-external-mode"]], "2. Define Patches": [[39, "define-patches"]], "2. Fine-grained Collection in compute_log_prob (Actor & Ref) Phase": [[172, "fine-grained-collection-in-compute-log-prob-actor-ref-phase"]], "2. Generative Reranker": [[120, "generative-reranker"]], "2. Mask": [[142, "mask"]], "2. Mask\uff08\u5c4f\u853d\uff09": [[81, "mask"]], "2. Perplexity (PPL)": [[81, "perplexity-ppl"], [142, "perplexity-ppl"]], "2. Register Your Model": [[36, "register-your-model"]], "2. Sequence Parallelism Support": [[46, "sequence-parallelism-support"]], "2. Use Your Preprocessor": [[37, "use-your-preprocessor"]], "2. compute_log_prob (Actor & Ref) \u9636\u6bb5\u7cbe\u7ec6\u5316\u91c7\u96c6": [[173, "compute-log-prob-actor-ref"]], "2. format": [[87, "format"], [148, "format"]], "2. \u4f7f\u7528 Docker Compose \u6784\u5efa": [[14, "docker-compose"]], "2. \u4f7f\u7528DeepSpeed\u591a\u5361\u5e76\u884c\u8bad\u7ec3": [[219, "deepspeed"]], "2. \u542f\u52a8\u5bb9\u5668": [[14, "id7"]], "2. \u5728\u5355\u5f20 GPU \u4e0a\u8bad\u7ec3 GPT-OSS\uff08\u8981\u6c42\u663e\u5b58 > 44 GB, \u652f\u6301\u591a GPU\uff09": [[8, "gpu-gpt-oss-44-gb-gpu"]], "2. \u5b89\u88c5 PyTorch": [[218, "id2"]], "2. \u5de5\u4f5c\u6d41 YAML \u6a21\u677f": [[170, "yaml"]], "2. \u624b\u52a8\u4e0b\u8f7d": [[256, "id3"]], "2. \u73af\u5883\u5b89\u88c5": [[185, "id5"]], "2. \u751f\u6210\u5f0fReranker": [[59, "id3"]], "2. \u8bad\u7ec3\u7ed3\u679c\u67e5\u770b": [[188, "id3"]], "2. \u8d1f\u8f7d\u5747\u8861\u5206\u6790": [[177, "id7"]], "2. \u901a\u8fc7\u6e90\u7801\u5b89\u88c5": [[187, "id3"]], "2. \u9a71\u52a8\u53ca\u56fa\u4ef6": [[14, "id4"]], "2.1 Language Model Part - Simple Position Embedding Slicing": [[46, "language-model-part-simple-position-embedding-slicing"]], "2.2 Vision Transformer (ViT) Part - Padding and Slicing": [[46, "vision-transformer-vit-part-padding-and-slicing"]], "2.3 ViT-LM Connection Part": [[46, "vit-lm-connection-part"]], "2.4 Special Case: Deepstack Visual Embeddings": [[46, "special-case-deepstack-visual-embeddings"]], "2.\u7ec4\u7f51\u5408\u7406\u6027\u5206\u6790": [[177, "id13"]], "2.\u8bad\u7ec3": [[179, "id7"]], "3. Add Supporting Imports": [[39, "add-supporting-imports"]], "3. CANN": [[14, "cann"]], "3. Expert Parallelism (EP) Support": [[46, "expert-parallelism-ep-support"]], "3. Fine-grained Collection in update_policy (Actor & Critic) Phase": [[172, "fine-grained-collection-in-update-policy-actor-critic-phase"]], "3. Model Configuration": [[36, "model-configuration"]], "3. Use in Your Config": [[37, "use-in-your-config"]], "3. cosine": [[87, "cosine"], [148, "cosine"]], "3. update_policy (Actor & Critic) \u9636\u6bb5\u7cbe\u7ec6\u5316\u91c7\u96c6": [[173, "update-policy-actor-critic"]], "3. \u03c7\u00b2 Divergence (Chi-squared Divergence)": [[142, "divergence-chi-squared-divergence"]], "3. \u03c7\u00b2 \u6563\u5ea6\uff08Chi-squared Divergence\uff09": [[81, "chi-squared-divergence"]], "3. \u4f7f\u7528Transformers\u8fdb\u884c\u6a21\u578b\u5fae\u8c03": [[219, "transformers"]], "3. \u5408\u5e76 LoRA \u6743\u91cd": [[8, "lora"]], "3. \u6dfb\u52a0\u5355\u5143\u6d4b\u8bd5": [[170, "id3"]], "3. \u6dfb\u52a0\u7aef\u5230\u7aef\u6d4b\u8bd5\u811a\u672c": [[170, "id4"]], "3. \u81ea\u884c\u8f6c\u6362\u6a21\u578b": [[256, "id4"]], "3. \u8fdb\u5165\u5bb9\u5668": [[14, "id8"]], "3. \u96c6\u7fa4\u6574\u4f53\u6027\u80fd\u5206\u6790": [[177, "id8"]], "3. \u9884\u7f16\u8bd1DeepSpeed\u7b97\u5b50\uff08\u53ef\u9009\uff09": [[187, "id4"]], "3. \u9a8c\u8bc1\u5b89\u88c5\u7ed3\u679c": [[218, "id4"]], "3.1 Define Parallel Plan": [[46, "define-parallel-plan"]], "3.2 Enable Fused MoE Forward": [[46, "enable-fused-moe-forward"]], "3.\u6a21\u578b\u8bc4\u4f30": [[179, "id8"]], "3.\u7b97\u5b50\u6027\u80fd\u521d\u8bca": [[177, "id14"]], "30-Minute Self-Awareness Fine-Tuning": [[117, "minute-self-awareness-fine-tuning"]], "30\u5206\u949f\u81ea\u6211\u8ba4\u77e5\u5fae\u8c03": [[56, "id4"]], "3\u6b65\u5b9e\u73b0 GPT-OSS \u7684 LoRA \u5fae\u8c03": [[8, "gpt-oss-lora"]], "4. Effective Sample Size (ESS)": [[81, "effective-sample-size-ess"], [142, "effective-sample-size-ess"]], "4. Generate Code": [[39, "generate-code"]], "4. Loading Your Model": [[36, "loading-your-model"]], "4. Remove CPU-GPU Synchronization for Better Performance": [[46, "remove-cpu-gpu-synchronization-for-better-performance"]], "4. repetition": [[87, "repetition"], [148, "repetition"]], "4. torch-npu": [[14, "torch-npu"]], "4. \u4f7f\u7528Diffusers\u8fdb\u884c\u6a21\u578b\u5fae\u8c03": [[219, "diffusers"]], "4. \u5b89\u88c5\u9a8c\u8bc1": [[187, "id5"]], "4. \u6d4b\u8bd5\u7b56\u7565\u5efa\u8bae": [[170, "id5"]], "4.1 Vision Attention Optimization": [[46, "vision-attention-optimization"]], "4.1 \u642c\u8fd0\u6548\u7387\u4eb2\u548c\u7684shape": [[177, "id15"]], "4.2 Language Model Attention Optimization": [[46, "language-model-attention-optimization"]], "4.2 \u8d1f\u8f7d\u5747\u8861\u4eb2\u548c\u7684shape": [[177, "id16"]], "4.\u4eb2\u548cshape\u8c03\u6574": [[177, "shape"]], "5. IS Weight Statistics": [[142, "is-weight-statistics"]], "5. IS \u6743\u91cd\u7edf\u8ba1": [[81, "is"]], "5. Register Your Model": [[46, "register-your-model"]], "5. soft overlong punishment": [[87, "soft-overlong-punishment"], [148, "soft-overlong-punishment"]], "5. \u9a8c\u8bc1\u5b89\u88c5": [[14, "id5"]], "ACLgraph+FULL_DECODE_ONLY": [[181, "aclgraph-full-decode-only"]], "AICpu\u673a\u5236\u5c55\u5f00": [[181, "aicpu"]], "AIV": [[181, "aiv"]], "API": [[38, "api"]], "API Reference": [[37, "api-reference"]], "API \u6587\u6863": [[214, null]], "AQLM": [[16, "aqlm"]], "AWQ": [[16, "awq"]], "Accelerate": [[182, null]], "Accelerate \u4e0b\u8f7d\u5b89\u88c5": [[183, "accelerate"]], "Accessing additional dataset information in scheduler": [[147, "accessing-additional-dataset-information-in-scheduler"]], "Acknowledgements": [[35, "acknowledgements"], [46, "acknowledgements"]], "AdaLoRA": [[67, "adalora"], [128, "adalora"]], "Adapter Strategy Implemented": [[41, "adapter-strategy-implemented"]], "Add into the Main Forward Pass": [[46, "add-into-the-main-forward-pass"]], "Adding a New Model to VeOmni": [[36, null]], "Additional Helper Functions": [[46, "additional-helper-functions"]], "Advanced": [[110, "advanced"], [120, "advanced"]], "Advanced Guide: Fine-grained Collection": [[172, "advanced-guide-fine-grained-collection"]], "Advanced Usage": [[37, "advanced-usage"], [39, "advanced-usage"], [44, "advanced-usage"]], "Advanced topics": [[147, "advanced-topics"]], "Agent Format": [[121, "agent-format"]], "Agent Support": [[127, null]], "Agent\u652f\u6301": [[66, null]], "Agent\u683c\u5f0f": [[60, "agent"]], "Algorithm Overview": [[133, "algorithm-overview"], [134, "algorithm-overview"], [137, "algorithm-overview"], [138, "algorithm-overview"], [150, "algorithm-overview"]], "Align the Inference results of the verl and vLLM frameworks on Ascend devices(zh)": [[171, null]], "Alpaca": [[19, "alpaca"]], "Apollo": [[7, "apollo"]], "ApolloArguments": [[7, "id18"]], "App Arguments": [[128, "app-arguments"]], "App\u53c2\u6570": [[67, "app"]], "Architecture": [[37, "architecture"]], "Arguments": [[43, "arguments"]], "Arguments API Reference": [[42, null]], "Ascend Dockerfile Build Guidance": [[176, null]], "Ascend NPU": [[98, null], [159, null]], "Ascend Quickstart": [[174, null]], "Ascend Quickstart with SGLang Backend": [[175, null]], "Ascend Retool Best Practice": [[178, null]], "Ascend SGLang Best Practice": [[179, null]], "Ascend relevant Environment variables": [[33, "ascend-relevant-environment-variables"]], "Async Reward Functions": [[148, "async-reward-functions"]], "Asynchronous Ulysses": [[38, "asynchronous-ulysses"]], "Atomic Arguments": [[128, "atomic-arguments"]], "AutoModelForCausalLM": [[246, "automodelforcausallm"]], "BAdam": [[7, "badam"], [18, "badam"]], "BAdamArgument": [[7, "id19"], [18, "id11"]], "BNPO (Batch Normalized Policy Optimization)": [[84, "bnpo-batch-normalized-policy-optimization"], [145, "bnpo-batch-normalized-policy-optimization"]], "BOFT": [[67, "boft"], [128, "boft"]], "Background": [[40, "background"], [81, "background"], [142, "background"]], "Background and Challenges": [[172, "background-and-challenges"]], "Background and Motivation": [[139, "background-and-motivation"]], "Background of dyn_bsz": [[45, "background-of-dyn-bsz"]], "Background of rmpad_with_pos_ids": [[45, "background-of-rmpad-with-pos-ids"]], "Background: Why Not Monkey Patching?": [[39, "background-why-not-monkey-patching"]], "Base Arguments": [[128, "base-arguments"]], "Basic Assumptions of GRPO": [[142, "basic-assumptions-of-grpo"]], "Basic Modules": [[43, null]], "Basic Usage": [[44, "basic-usage"]], "Batch-related Parameters": [[161, "batch-related-parameters"]], "Before/After Examples": [[110, "before-after-examples"]], "Benchmark": [[105, "benchmark"], [166, "benchmark"]], "Best Practices": [[37, "best-practices"], [140, "best-practices"], [144, "best-practices"]], "Best Practices for Rapidly Training Vision-Language (VL) Models": [[119, null]], "Best Practices for Registering Multimodal Models": [[114, null]], "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning": [[80, null], [141, null]], "Build the docs": [[26, "build-the-docs"]], "Built-in Reward Functions": [[148, "built-in-reward-functions"]], "C++\u63a8\u7406\u793a\u4f8b": [[204, "c"]], "CHORD-\u00b5": [[72, "id3"]], "CHORD-\u03bc": [[133, "chord"]], "CHORD-\u03c6 (Token-level weighting)": [[133, "chord-token-level-weighting"]], "CHORD-\u03d5\uff08Token \u7ea7\u52a0\u6743\uff09": [[72, "chord-token"]], "CISPO": [[84, "cispo"], [145, "cispo"]], "CISPO \u7684\u89e3\u51b3\u65b9\u6848": [[73, "cispo"]], "CISPO's Solution": [[134, "cispo-s-solution"]], "CLI Reference": [[39, "cli-reference"]], "CPO": [[92, "cpo"], [153, "cpo"]], "CPU_AFFINITY_CONF": [[34, "cpu-affinity-conf"]], "CUDA \u5b89\u88c5": [[22, "cuda"], [22, "id2"]], "Callback Mechanism": [[123, "callback-mechanism"]], "Capability Introduction": [[129, "capability-introduction"], [156, "capability-introduction"]], "Channel Loss": [[121, "channel-loss"]], "Chat Template": [[43, "chat-template"]], "Checkpoint Conversion": [[44, null]], "Class Replacement": [[39, "class-replacement"]], "ClevrCount Task": [[113, "clevrcount-task"]], "ClevrCount \u4efb\u52a1": [[52, "clevrcount"]], "Client Side": [[151, "client-side"], [152, "client-side"]], "Clip Higher": [[74, "clip-higher"], [135, "clip-higher"]], "Clipped Importance Sampling Policy Optimization (CISPO)": [[73, null], [134, null]], "Cluster Support": [[150, "cluster-support"]], "Code Modification": [[159, "code-modification"]], "Code Training with GRPO": [[112, null]], "Collate Function": [[43, "collate-function"]], "Colocate \u6a21\u5f0f\u4e0b\u7684\u663e\u5b58\u4f18\u5316\u65b9\u6848": [[89, "colocate"]], "Command Line Arguments": [[160, null]], "Command Line Parameters": [[128, null]], "Command-Line Arguments": [[44, "command-line-arguments"]], "Common Patch Scenarios": [[39, "common-patch-scenarios"]], "Communication Analysis": [[38, "communication-analysis"]], "Comparing Generated vs Original Code": [[39, "comparing-generated-vs-original-code"]], "Complete GRPO Experiment Process": [[111, null]], "Complete Multimodal GRPO Experiment Workflow": [[113, null]], "Completion Examples at Different Steps": [[111, "completion-examples-at-different-steps"]], "Concept of Reinforced Fine-Tuning": [[155, "concept-of-reinforced-fine-tuning"]], "Conditional Preprocessing": [[37, "conditional-preprocessing"]], "Config File (config.json) Update": [[119, "config-file-config-json-update"]], "Configuration": [[109, "configuration"], [172, "configuration"]], "Configuration (data and batch sizes)": [[133, "configuration-data-and-batch-sizes"]], "Configuring Proper Prefetching": [[35, "configuring-proper-prefetching"]], "Consequences of Mixed Sharding Strategy": [[35, "consequences-of-mixed-sharding-strategy"]], "Contributing": [[39, "contributing"]], "Convenience Functions": [[37, "convenience-functions"]], "Convert DCP Checkpoint to HuggingFace Format": [[44, "convert-dcp-checkpoint-to-huggingface-format"]], "Convert with Custom Output Directory": [[44, "convert-with-custom-output-directory"]], "Converting HF to Mcore": [[163, "converting-hf-to-mcore"]], "Converting MCore to HF": [[163, "converting-mcore-to-hf"]], "Core Design": [[39, "core-design"]], "Current Limitations": [[161, "current-limitations"]], "Current Support Status": [[116, "current-support-status"]], "Custom Dataset": [[121, null]], "Custom Datasets": [[43, "custom-datasets"]], "Custom Evaluation Datasets": [[129, "custom-evaluation-datasets"]], "Custom Loss Function": [[43, "custom-loss-function"]], "Custom Model": [[122, null]], "Custom Preprocessor Registry": [[37, null]], "Custom Reward Function": [[148, "custom-reward-function"]], "Custom Reward Models": [[149, "custom-reward-models"]], "Customising the interaction logic": [[147, "customising-the-interaction-logic"]], "Customize Shard Size": [[44, "customize-shard-size"]], "Customizing Agent Template": [[123, "customizing-agent-template"]], "Customizing Loss": [[123, "customizing-loss"]], "Customizing Loss Scale": [[123, "customizing-loss-scale"]], "Customizing Metrics": [[123, "customizing-metrics"]], "Customizing Optimizers": [[123, "customizing-optimizers"]], "Customizing PRM or ORM": [[156, "customizing-prm-or-orm"]], "Customizing Tuners": [[123, "customizing-tuners"]], "DAPO": [[84, "dapo"], [145, "dapo"]], "DAPO multi model optimization practice": [[180, null]], "DAPO \u4ecb\u7ecd": [[180, "dapo"]], "DAPO: An Open-Source LLM Reinforcement Learning System at Scale": [[74, null], [135, null]], "DPO": [[17, "dpo"], [92, "dpo"], [153, "dpo"]], "DPO Parameters": [[160, "dpo-parameters"]], "DPO \u8bad\u7ec3": [[15, "dpo"]], "DPO/ORPO/CPO/SimPO/RM": [[60, "dpo-orpo-cpo-simpo-rm"], [121, "dpo-orpo-cpo-simpo-rm"]], "DPO\u53c2\u6570": [[99, "dpo"]], "DR-GRPO": [[84, "dr-grpo"], [145, "dr-grpo"]], "Data Arguments": [[128, "data-arguments"]], "Data Parallel Training": [[116, "data-parallel-training"]], "Data Preparation": [[117, "data-preparation"], [117, "id1"]], "Data Transform (Preprocess)": [[43, "data-transform-preprocess"]], "Data Type Conversion": [[44, "data-type-conversion"]], "Data configuration arguments": [[42, "data-configuration-arguments"]], "DataArguments": [[7, "id21"]], "DataLoader": [[43, "dataloader"]], "Dataset": [[43, "dataset"], [153, "dataset"]], "Dataset Format": [[110, "dataset-format"], [120, "dataset-format"], [127, "dataset-format"]], "Dataset Registration": [[121, "dataset-registration"]], "Datasets": [[157, "datasets"]], "Declarations": [[34, "declarations"]], "DeepEyes: Incentivizing \"Thinking with Images\" via Reinforcement Learning": [[79, null], [140, null]], "DeepSpeed": [[9, "deepspeed"], [186, null]], "DeepSpeed \u914d\u7f6e\u6587\u4ef6": [[9, "id20"]], "DeepSpeed-Ulysses": [[38, "deepspeed-ulysses"]], "Deepspeed Training": [[116, "deepspeed-training"]], "Deepspeed\u8bad\u7ec3": [[55, "deepspeed"]], "Dense Model": [[165, "dense-model"]], "Dense Models": [[118, "dense-models"], [164, "dense-models"]], "Dense\u6a21\u578b": [[57, "dense"], [103, "dense"], [104, "dense"]], "Deoloyment": [[119, "deoloyment"]], "Deployment": [[116, "deployment"], [127, "deployment"], [131, "deployment"], [151, "deployment"]], "Deployment (Fine-Tuned Model)": [[152, "deployment-fine-tuned-model"]], "Deployment Arguments": [[128, "deployment-arguments"]], "Deployment with native Transformers": [[116, "deployment-with-native-transformers"]], "Deployment with vLLM-ascend": [[116, "deployment-with-vllm-ascend"]], "Design Goals": [[41, "design-goals"]], "Design Overview": [[35, "design-overview"]], "Design Principles": [[39, "design-principles"]], "Deviation After Introducing vLLM": [[142, "deviation-after-introducing-vllm"]], "Difference 1: How the Advantage Baseline Is Constructed": [[138, "difference-1-how-the-advantage-baseline-is-constructed"]], "Difference 1: Statistics Used for Normalization": [[137, "difference-1-statistics-used-for-normalization"]], "Difference 2: How KL Regularization Is Applied": [[138, "difference-2-how-kl-regularization-is-applied"]], "Difference 2: KL Divergence Regularization": [[137, "difference-2-kl-divergence-regularization"]], "Diffusers": [[1, null]], "Diffusers \u5b89\u88c5": [[2, "diffusers"]], "Disabling collection": [[172, "disabling-collection"]], "Discrete Mode Collection": [[172, "discrete-mode-collection"]], "Divergence Metrics": [[132, "divergence-metrics"]], "DoRA": [[18, "dora"]], "DockerFile\u955c\u50cf\u6784\u5efa & \u4f7f\u7528": [[174, "dockerfile"]], "Dockerfile\u6784\u5efa\u955c\u50cf\u811a\u672c\u6e05\u5355": [[176, "dockerfile"]], "Download Qwen3 VL model": [[30, "download-qwen3-vl-model"]], "Download Qwen3 model": [[27, "download-qwen3-model"]], "Download Qwen3-Omni-MoE model": [[29, "download-qwen3-omni-moe-model"]], "Download dataset": [[27, "download-dataset"], [30, "download-dataset"]], "Download model": [[31, "download-model"]], "Download multisource dataset": [[29, "download-multisource-dataset"]], "Drivers\uff0cFirmware \u548c CANN": [[197, "drivers-firmware-cann"]], "Dummy ViT Forward for VLMs": [[46, "dummy-vit-forward-for-vlms"]], "Duplicate Registration Warning": [[37, "duplicate-registration-warning"]], "Dynamic Sampling": [[74, "dynamic-sampling"], [135, "dynamic-sampling"]], "EETQ": [[16, "eetq"]], "EP+FSDP2 for Large-scale MoE Model Training": [[35, null]], "Elastic": [[48, null], [109, null]], "Embedding": [[60, "embedding"], [121, "embedding"]], "Embedding Training": [[110, null]], "Embedding\u8bad\u7ec3": [[49, null]], "Enable": [[159, "enable"]], "Enabling Async Ulysses": [[38, "enabling-async-ulysses"], [38, "id1"]], "Enabling Importance Sampling Correction": [[142, "enabling-importance-sampling-correction"]], "End-to-End Example: Qwen2-VL Training Pipeline": [[37, "end-to-end-example-qwen2-vl-training-pipeline"]], "End-to-End collection": [[172, "end-to-end-collection"]], "Environment Installation": [[116, "environment-installation"]], "Environment Preparation": [[116, "environment-preparation"], [129, "environment-preparation"], [152, "environment-preparation"]], "Environment Setup": [[114, "environment-setup"], [117, "environment-setup"], [118, "environment-setup"], [156, "environment-setup"], [166, "environment-setup"]], "Environment Variables": [[7, "id31"], [34, "environment-variables"]], "Environment Viewing": [[116, "environment-viewing"]], "EvalArguments": [[7, "id27"], [20, "id4"]], "Evaluation": [[119, "evaluation"], [129, null], [129, "id1"], [131, "evaluation"]], "Evaluation Arguments": [[128, "evaluation-arguments"]], "Evaluation During Training": [[129, "evaluation-during-training"]], "Example": [[159, "example"]], "Example 1: Multi-turn VQA Conversation Preprocessor": [[37, "example-1-multi-turn-vqa-conversation-preprocessor"]], "Example 2: Image generation Preprocessor": [[37, "example-2-image-generation-preprocessor"]], "Example 3: Registering Multiple Names": [[37, "example-3-registering-multiple-names"]], "Example: Qwen3 GPU Patches": [[39, "example-qwen3-gpu-patches"]], "Examples": [[37, "examples"], [44, "examples"], [172, "examples"]], "Existing Approaches and Their Trade-offs": [[39, "existing-approaches-and-their-trade-offs"]], "Expected Runtime Behavior": [[41, "expected-runtime-behavior"]], "Experimental Observations": [[111, "experimental-observations"], [113, "experimental-observations"], [113, "id4"], [113, "id9"]], "Experimental Results": [[155, "experimental-results"]], "Expert Parallelism Details": [[35, "expert-parallelism-details"]], "Export Arguments": [[128, "export-arguments"]], "Export Parameters": [[160, "export-parameters"]], "Export and Push": [[130, null]], "ExportArguments": [[7, "id26"]], "External Class References": [[39, "external-class-references"]], "External Deployment": [[149, "external-deployment"]], "Extra Dependency": [[22, "extra-dependency"]], "FAQ": [[89, "faq"], [150, "faq"], [216, null]], "FSDP": [[9, "fsdp"], [9, "id34"], [9, "id37"]], "FSDP2": [[9, "fsdp2"]], "FSDP2 Details": [[35, "fsdp2-details"]], "Feature Support": [[161, "feature-support"]], "Features": [[37, "features"]], "File Structure": [[37, "file-structure"]], "Fine-tuning": [[116, "fine-tuning"], [152, "fine-tuning"]], "FinetuningArguments": [[7, "id14"]], "FlashAttention": [[6, "flashattention"]], "FlashAttention-2": [[22, "flashattention-2"]], "Format for Contrastive/Online Contrastive Loss": [[110, "format-for-contrastive-online-contrastive-loss"]], "Format for Cosine Similarity Loss": [[110, "format-for-cosine-similarity-loss"]], "Format for InfoNCE": [[110, "format-for-infonce"]], "Forward KL": [[132, "forward-kl"]], "Forward KL and Reverse KL": [[132, "forward-kl-and-reverse-kl"]], "Forward KL \u4e0e Reverse KL": [[71, "forward-kl-reverse-kl"]], "Forward KL\uff08\u524d\u5411 KL\uff09": [[71, "forward-kl-kl"]], "Four Correction Modes": [[142, "four-correction-modes"]], "FourierFt": [[67, "fourierft"], [128, "fourierft"]], "Freeze": [[7, "freeze"], [18, "freeze"]], "FreezeArguments": [[7, "id17"], [18, "id8"]], "Frequently-asked-questions": [[131, null]], "Full": [[104, "full"], [165, "full"]], "Full Arguments": [[128, "full-arguments"]], "Full Parameter Fine-tuning": [[18, "full-parameter-fine-tuning"]], "Function Replacement": [[39, "function-replacement"]], "Future Work: Align with Transformers v5 Weight Formatting": [[40, "future-work-align-with-transformers-v5-weight-formatting"]], "GKD": [[60, "gkd"], [71, null], [100, null], [121, "gkd"], [132, null], [161, null]], "GKD Arguments": [[128, "gkd-arguments"]], "GKD Parameters": [[160, "gkd-parameters"]], "GKD \u7279\u6709\u53c2\u6570": [[100, "id4"]], "GKD-specific Parameters": [[161, "gkd-specific-parameters"]], "GKD\u53c2\u6570": [[67, "gkd"], [99, "gkd"]], "GPT-OSS": [[8, null]], "GPTQ": [[16, "gptq"]], "GRPO": [[84, "grpo"], [89, null], [92, "grpo"], [101, null], [145, "grpo"], [150, null], [153, "grpo"]], "GRPO Arguments": [[128, "grpo-arguments"]], "GRPO Parameters": [[160, "grpo-parameters"]], "GRPO Training Experiment Log": [[113, "grpo-training-experiment-log"], [113, "id2"], [113, "id7"]], "GRPO Training Experiment Record": [[111, "grpo-training-experiment-record"]], "GRPO \u7684\u57fa\u672c\u5047\u8bbe": [[81, "grpo"]], "GRPO\u4ee3\u7801\u8bad\u7ec3": [[51, null]], "GRPO\u53c2\u6570": [[67, "grpo"], [99, "grpo"]], "GRPO\u5b8c\u6574\u5b9e\u9a8c\u6d41\u7a0b": [[50, null]], "GRPO\u8bad\u7ec3\u5b9e\u9a8c\u8bb0\u5f55": [[50, "id3"], [52, "id3"], [52, "id8"], [52, "id13"]], "GYM Environment Training": [[144, null]], "GYM\u73af\u5883\u8bad\u7ec3": [[83, null]], "GaLore": [[7, "galore"], [67, "galore"], [128, "galore"]], "GaLoreArguments": [[7, "id20"], [18, "id10"]], "Galore": [[18, "galore"]], "Generalized Jensen-Shannon Divergence (Generalized JSD)": [[132, "generalized-jensen-shannon-divergence-generalized-jsd"]], "Generated Output Format": [[39, "generated-output-format"]], "GeneratingArguments": [[7, "id28"]], "Generation Arguments": [[128, "generation-arguments"]], "Geometric QA Task": [[113, "geometric-qa-task"]], "Geometric QA\u4efb\u52a1": [[52, "geometric-qa"]], "Get Started with Ascend NPU": [[34, null]], "Global collection control": [[172, "global-collection-control"]], "Grounding": [[121, "grounding"]], "Group Sequence Policy Optimization": [[75, null]], "Group Sequence Policy Optimization (GSPO)": [[136, null]], "Gym Interface": [[144, "gym-interface"]], "Gym\u63a5\u53e3": [[83, "id1"]], "HF\u8f6c\u6362Mcore": [[102, "hfmcore"]], "HOST\u5c55\u5f00": [[181, "host"]], "HQQ": [[16, "hqq"]], "Handling Multiple Formats": [[37, "handling-multiple-formats"]], "How to Start": [[109, "how-to-start"]], "How to Use": [[39, "how-to-use"]], "HuggingFace": [[245, "huggingface"]], "Implementation Details": [[134, "implementation-details"], [140, "implementation-details"], [143, "implementation-details"]], "Implementation Methods": [[120, "implementation-methods"]], "Importance Sampling Correction": [[142, "importance-sampling-correction"]], "Important Parameters": [[138, "important-parameters"]], "In veomni/models/transformers/__init__.py": [[46, "in-veomni-models-transformers-init-py"]], "In your model file": [[46, "in-your-model-file"]], "Include Model Assets (Config & Tokenizer)": [[44, "include-model-assets-config-tokenizer"]], "Inference": [[110, "inference"], [116, "inference"], [117, "inference"], [118, "inference"], [119, "inference"], [127, "inference"], [131, "inference"], [151, "inference"], [163, "inference"], [163, "id2"]], "Inference (Fine-Tuned Model)": [[152, "inference-fine-tuned-model"]], "Inference / Deployment / Evaluation": [[119, "inference-deployment-evaluation"]], "Inference Alignment": [[114, "inference-alignment"]], "Inference Arguments": [[128, "inference-arguments"]], "Inference and Deployment": [[151, null]], "Inference configuration arguments": [[42, "inference-configuration-arguments"]], "Init Modification": [[39, "init-modification"]], "Install with uv or pip": [[32, "install-with-uv-or-pip"], [33, "install-with-uv-or-pip"]], "Installation": [[34, "installation"], [116, "installation"], [124, "installation"]], "Installation with Ascend NPU": [[33, null]], "Installation with Nvidia GPU": [[32, null]], "Installing Dependencies": [[109, "installing-dependencies"]], "Installing msprobe": [[159, "installing-msprobe"]], "Integration Arguments": [[128, "integration-arguments"]], "Interface List": [[158, "interface-list"]], "Internal Plugin": [[149, "internal-plugin"]], "KL Divergence (Kullback-Leibler Divergence)": [[132, "kl-divergence-kullback-leibler-divergence"]], "KL \u6563\u5ea6\uff08Kullback-Leibler Divergence\uff09": [[71, "kl-kullback-leibler-divergence"]], "KTO": [[17, "kto"], [60, "kto"], [92, "kto"], [121, "kto"], [153, "kto"]], "KTO Parameters": [[160, "kto-parameters"]], "KTO \u6570\u636e\u96c6": [[19, "kto"]], "KTO\u53c2\u6570": [[99, "kto"]], "Key Challenge: Padding and Grid Handling": [[46, "key-challenge-padding-and-grid-handling"]], "Key Conversion Details": [[44, "key-conversion-details"]], "Key Parameter Descriptions": [[137, "key-parameter-descriptions"]], "Key Updates": [[34, "key-updates"]], "LISA": [[67, "lisa"], [128, "lisa"]], "LLAMAPRO": [[67, "llamapro"], [128, "llamapro"]], "LLM \u63a8\u7406": [[197, "llm"]], "LLM \u6a21\u578b\u670d\u52a1": [[197, "id12"]], "LLaMA Pro": [[10, "llama-pro"]], "LLaMA-Factory": [[4, null]], "LLaMA-Factory \u5b89\u88c5": [[22, "llama-factory"]], "LLaMA-Factory \u6821\u9a8c": [[22, "id3"]], "LLaMA-Factory \u9ad8\u7ea7\u9009\u9879": [[22, "id4"]], "LLaMA-Factory\u5b89\u88c5": [[13, "llama-factory"]], "LLaVA-Video-178K": [[29, "llava-video-178k"]], "LM-Evalution-Harness": [[198, null]], "LMDeploy": [[195, null]], "LMDeploy Arguments": [[128, "lmdeploy-arguments"]], "LMDeploy\u53c2\u6570": [[67, "lmdeploy"]], "Large Language Models": [[157, "large-language-models"]], "Learn More": [[124, "learn-more"]], "Liger Kernel": [[6, "liger-kernel"]], "Limitations": [[39, "limitations"]], "Linux": [[22, "linux"]], "Listwise Loss Functions": [[120, "listwise-loss-functions"]], "Listwise\u635f\u5931\u51fd\u6570": [[59, "listwise"]], "Llama.cpp": [[192, null]], "LlamaBoard": [[12, "llamaboard"]], "LoRA": [[7, "lora"], [18, "lora"], [67, "lora"], [104, "lora"], [128, "lora"], [165, "lora"]], "LoRA Export": [[164, "lora-export"]], "LoRA Training": [[163, null], [163, "id1"]], "LoRA \u5408\u5e76": [[23, null]], "LoRA+": [[18, "id5"]], "LoRA-GA": [[67, "lora-ga"], [128, "lora-ga"]], "LoRA\u5bfc\u51fa": [[103, "lora"]], "LoRA\u8bad\u7ec3": [[102, null], [102, "id2"]], "Local \u52a0\u8f7d\u5185\u6838\u793a\u4f8b": [[191, "local"]], "Logging Diagnostic Metrics Only": [[142, "logging-diagnostic-metrics-only"]], "Long-Sequence Training Using Ulysses": [[38, null]], "LoraArguments": [[7, "id15"], [18, "id9"]], "Loss": [[110, "loss"]], "Loss Function": [[132, "loss-function"], [145, "loss-function"]], "Loss Function Types": [[120, "loss-function-types"]], "Loss Types": [[84, null], [145, null]], "Loss mask": [[147, "loss-mask"]], "MCore\u8f6c\u6362HF": [[102, "mcorehf"]], "MLflow": [[12, "mlflow"]], "Mcore Bridge": [[103, null], [164, null]], "Mcore-Bridge [Recommended]": [[163, "mcore-bridge-recommended"], [166, "mcore-bridge-recommended"]], "Mcore-Bridge\u3010\u63a8\u8350\u3011": [[102, "mcore-bridge"], [105, "mcore-bridge"]], "Megatron GRPO": [[162, null]], "Megatron Parameters": [[160, "megatron-parameters"]], "Megatron-SWIFT": [[56, "megatron-swift"], [117, "megatron-swift"]], "Megatron-SWIFT Wechat Group": [[166, "megatron-swift-wechat-group"]], "Megatron-SWIFT\u5fae\u4fe1\u7fa4": [[105, "megatron-swift"]], "Megatron\u53c2\u6570": [[99, "megatron"]], "MemFabric Adaptor \u5b89\u88c5": [[230, "memfabric-adaptor"]], "Memory Control": [[156, "memory-control"]], "Memory Efficiency": [[44, "memory-efficiency"]], "Memory Optimization Solutions in Colocate Mode": [[150, "memory-optimization-solutions-in-colocate-mode"]], "Merge Arguments": [[128, "merge-arguments"]], "Merge LoRA": [[69, "merge-lora"], [91, "merge-lora"], [130, "merge-lora"], [152, "merge-lora"]], "Merge-LoRA": [[102, "merge-lora"], [163, "merge-lora"]], "Meta\u5b98\u65b9": [[245, "meta"]], "Method Override": [[39, "method-override"]], "Metrics": [[81, "metrics"], [142, "metrics"]], "Mirror": [[125, "mirror"]], "Missing Model Assets": [[44, "missing-model-assets"]], "MoE Model": [[165, "moe-model"]], "MoE Models": [[118, "moe-models"], [164, "moe-models"]], "Mode 1: On-Policy Learning": [[132, "mode-1-on-policy-learning"], [161, "mode-1-on-policy-learning"]], "Mode 1: On-Policy \u5b66\u4e60": [[71, "mode-1-on-policy"], [100, "mode-1-on-policy"]], "Mode 2: Sequential KD (Not Yet Supported)": [[161, "mode-2-sequential-kd-not-yet-supported"]], "Mode 2: Sequential KD (seq_kd=True and on-policy not triggered)": [[132, "mode-2-sequential-kd-seq-kd-true-and-on-policy-not-triggered"]], "Mode 2: Sequential KD\uff08seq_kd=True \u4e14\u672a\u89e6\u53d1 on-policy\uff09": [[71, "mode-2-sequential-kd-seq-kd-true-on-policy"]], "Mode 2: Sequential KD\uff08\u5f53\u524d\u6682\u4e0d\u652f\u6301\uff09": [[100, "mode-2-sequential-kd"]], "Mode 3: Off-Policy Learning": [[161, "mode-3-off-policy-learning"]], "Mode 3: Off-Policy \u5b66\u4e60": [[100, "mode-3-off-policy"]], "Mode 3: Offline Learning (other cases)": [[132, "mode-3-offline-learning-other-cases"]], "Mode 3: \u79bb\u7ebf\u5b66\u4e60\uff08\u5176\u4ed6\u60c5\u51b5\uff09": [[71, "mode-3"]], "Mode Selection Logic": [[132, "mode-selection-logic"]], "Model Arguments": [[128, "model-arguments"]], "Model Initialization": [[43, "model-initialization"]], "Model Modification": [[119, "model-modification"]], "Model Registration": [[114, "model-registration"], [122, "model-registration"]], "Model Weight Initialization and Replacement": [[119, "model-weight-initialization-and-replacement"]], "Model and Optimizer": [[43, "model-and-optimizer"]], "Model configuration arguments": [[42, "model-configuration-arguments"]], "ModelArguments": [[7, "id22"]], "Modeling Code Generation": [[39, null]], "Models": [[157, "models"]], "Moe\u6a21\u578b": [[57, "moe"], [103, "moe"], [104, "moe"]], "More Best Practices": [[115, null]], "Motivation": [[35, "motivation"]], "Multi-Task Training": [[146, null]], "Multi-turn Training": [[147, null]], "MultiTurnScheduler": [[147, "multiturnscheduler"]], "Multimodal": [[121, "multimodal"]], "Multimodal Data Override": [[147, "multimodal-data-override"]], "Multimodal Models": [[165, null]], "Multimodal Open R1 Dataset Experiment": [[113, "multimodal-open-r1-dataset-experiment"]], "Multimodal Open R1 \u6570\u636e\u96c6\u5b9e\u9a8c": [[52, "multimodal-open-r1"]], "Multimodal large models": [[157, "multimodal-large-models"]], "Multiple-Choice Question Format (MCQ)": [[129, "multiple-choice-question-format-mcq"]], "NLG \u8bc4\u4f30": [[20, "nlg"]], "NPU Accuracy Data Collection": [[159, "npu-accuracy-data-collection"]], "NPU Performance Data Collection": [[159, "npu-performance-data-collection"]], "NPU Qwen3-32B GSPO Optimization Practice": [[181, null]], "NPU Support": [[116, null]], "NPU WeChat Group": [[116, "npu-wechat-group"]], "NPU \u6027\u80fd\u6570\u636e\u91c7\u96c6": [[98, "npu"]], "NPU \u7cbe\u5ea6\u6570\u636e\u91c7\u96c6": [[98, "id1"]], "NPU-CI \u6dfb\u52a0\u6307\u5bfc": [[170, null]], "NPU\u5b89\u88c5\u53ca\u914d\u7f6e": [[14, null]], "NPU\u5fae\u4fe1\u7fa4": [[55, "id12"]], "NPU\u63a8\u7406": [[13, null]], "NPU\u652f\u6301": [[55, null]], "NPU\u8bad\u7ec3": [[15, null]], "NPU\u8c03\u4f18\u53c2\u8003\u6587\u7ae0": [[181, "npu"]], "NativeDDP": [[9, "nativeddp"]], "NativeDDP, DeepSpeed": [[9, "nativeddp-deepspeed"], [9, "id36"]], "No Model Weights Found": [[44, "no-model-weights-found"]], "Notebook Environment": [[125, "notebook-environment"]], "Notebook\u73af\u5883": [[64, "notebook"]], "Notes": [[41, "notes"], [144, "notes"], [148, "notes"]], "OFTQ": [[16, "oftq"]], "ONNX Runtime": [[202, null]], "ONNX Runtime \u5b89\u88c5": [[203, "onnx-runtime"]], "ORM": [[62, "orm"]], "ORM (Outcome Reward Model)": [[123, "orm-outcome-reward-model"]], "ORPO": [[92, "orpo"], [153, "orpo"]], "Off-Policy Sequence Masking": [[81, "off-policy-sequence-masking"], [142, "off-policy-sequence-masking"]], "On-Policy Distillation": [[71, "on-policy-distillation"], [132, "on-policy-distillation"]], "On-Policy RL Meets Off-Policy Experts: Harmonizing SFT and RL via Dynamic Weighting (CHORD)": [[72, null], [133, null]], "Open the docs with your browser": [[26, "open-the-docs-with-your-browser"]], "OpenAI\u683c\u5f0f": [[19, "openai"]], "OpenCV": [[211, null]], "OpenCV \u5b89\u88c5": [[212, "opencv"]], "OpenCompass": [[208, null]], "OpenCompass \u5b89\u88c5": [[209, "opencompass"]], "OpenEuler \u64cd\u4f5c\u7cfb\u7edf": [[181, "openeuler"]], "Optimizer and LR Scheduler": [[43, "optimizer-and-lr-scheduler"]], "Other Environment Variables": [[128, "other-environment-variables"]], "Out of Memory": [[44, "out-of-memory"]], "Output Format": [[44, "output-format"]], "Overlong Filtering": [[74, "overlong-filtering"], [135, "overlong-filtering"]], "Overview": [[37, "overview"], [44, "overview"], [46, "overview"]], "PPO": [[17, "ppo"], [92, "ppo"], [153, "ppo"]], "PPO Arguments": [[128, "ppo-arguments"]], "PPO/GRPO": [[60, "ppo-grpo"], [121, "ppo-grpo"]], "PPO\u53c2\u6570": [[67, "ppo"]], "PREPROCESSOR_REGISTRY.register(name: str)": [[37, "preprocessor-registry-register-name-str"]], "PRM": [[62, "prm"]], "PRM (Process Reward Model)": [[123, "prm-process-reward-model"]], "PTQ": [[16, "ptq"]], "PYTORCH_NPU_ALLOC_CONF": [[34, "pytorch-npu-alloc-conf"]], "Padding packed inputs (pad_packed_input)": [[45, "padding-packed-inputs-pad-packed-input"]], "Parallel State": [[43, "parallel-state"]], "Parallelism Setup": [[35, "parallelism-setup"]], "Parallelization your model": [[43, "parallelization-your-model"]], "Parameter Comparison": [[162, "parameter-comparison"]], "Parameter Configuration": [[134, "parameter-configuration"], [137, "parameter-configuration"], [138, "parameter-configuration"]], "Parameter Settings": [[132, "parameter-settings"], [135, "parameter-settings"], [139, "parameter-settings"], [154, "parameter-settings"]], "Parameters": [[161, "parameters"]], "Patch Types Reference": [[39, "patch-types-reference"]], "Performance Benefits": [[38, "performance-benefits"]], "Performance data collection based on FSDP or MindSpeed(Megatron) on Ascend devices(en)": [[172, null]], "Performance data collection based on FSDP or MindSpeed(Megatron) on Ascend devices(zh)": [[173, null]], "PiSSA": [[18, "pissa"]], "Pluginization": [[123, null]], "Pointwise Loss Functions": [[120, "pointwise-loss-functions"]], "Pointwise\u635f\u5931\u51fd\u6570": [[59, "pointwise"]], "Post-training": [[17, "post-training"]], "Practical Example": [[156, "practical-example"]], "Pre-training": [[17, "pre-training"], [121, "pre-training"], [152, "pre-training"]], "Pre-training and Fine-tuning": [[152, null]], "Prepare CANN": [[33, "prepare-cann"]], "Prepare Dataset": [[31, "prepare-dataset"]], "Preprocessor Format": [[37, "preprocessor-format"]], "Preprocessor Not Found Error": [[37, "preprocessor-not-found-error"]], "Principle": [[142, "principle"]], "Principle Introduction": [[140, "principle-introduction"], [143, "principle-introduction"]], "Problem Background": [[41, "problem-background"]], "ProcessorArguments": [[7, "id23"]], "Profiler": [[43, "profiler"]], "Programmatic Generation": [[39, "programmatic-generation"]], "Project Structure": [[39, "project-structure"]], "Push Model": [[130, "push-model"]], "PyTorch": [[217, null]], "PyTorch Distributed Checkpoint (DCP) Support": [[35, "pytorch-distributed-checkpoint-dcp-support"]], "Python \u73af\u5883\u521b\u5efa": [[2, "python"], [206, "python"], [209, "python"], [212, "python"], [221, "python"], [230, "python"], [233, "python"], [239, "python"], [252, "python"]], "Q100: Can trust_remote_code be set when using VLLM for GRPO training?": [[131, "q100-can-trust-remote-code-be-set-when-using-vllm-for-grpo-training"]], "Q100: \u8bf7\u95eegrpo\u4f7f\u7528vllm\u8fdb\u884c\u63a8\u7406\uff0cvllm\u53ef\u4ee5\u8bbe\u7f6etrust_rwmote_code\u5417\uff1f": [[70, "q100-grpovllm-vllmtrust-rwmote-code"]], "Q101: For large dataset pretraining using streaming and packing, is there a way to calculate total steps based on epochs, batch size etc when setting max_steps?": [[131, "q101-for-large-dataset-pretraining-using-streaming-and-packing-is-there-a-way-to-calculate-total-steps-based-on-epochs-batch-size-etc-when-setting-max-steps"]], "Q101: \u8bf7\u6559\u4e00\u4e0b\uff0cpretrain\u9636\u6bb5\u6570\u636e\u96c6\u6bd4\u8f83\u5927\uff0c\u7528\u4e86streaming\u6d41\u5f0f\u548cpacking\u6253\u5305\u6570\u636e\uff0c\u8fd9\u65f6\u5019\u9700\u8981\u8bbe\u7f6e max_steps\uff0c\u6709\u6ca1\u6709\u53c2\u6570\u6216\u8005\u547d\u4ee4\u53ef\u4ee5\u6839\u636eepochs\u3001bs\u7b49\u53c2\u6570\u8ba1\u7b97\u6253\u5305\u540e\u7684\u603b\u7684steps\u5417\uff1f": [[70, "q101-pretrain-streamingpacking-max-steps-epochsbssteps"]], "Q102: Unsloth training error: \"assert(type(target modules) in (list,tuple,))\" when using --target_modules all-linear": [[131, "q102-unsloth-training-error-assert-type-target-modules-in-list-tuple-when-using-target-modules-all-linear"]], "Q102: unsloth\u8bad\u7ec3\uff0c\u62a5\u9519\uff1aassert(type(target modules) in (list,tuple,))\u3002\u914d\u7f6e\u7684\u53c2\u6570\u662f--target modules all-linear": [[70, "q102-unsloth-assert-type-target-modules-in-list-tuple-target-modules-all-linear"]], "Q103: Does Swift support multi-label classification now?": [[131, "q103-does-swift-support-multi-label-classification-now"]], "Q103: Swift\u73b0\u5728\u652f\u6301\u591a\u6807\u7b7e\u5206\u7c7b\u4e48\uff1f": [[70, "q103-swift"]], "Q104: How does flash_attn handle packing - separately or merged?": [[131, "q104-how-does-flash-attn-handle-packing-separately-or-merged"]], "Q104: \u8bf7\u95eepacking\u4e2dflash_attn\u662f\u5206\u5f00\u5904\u7406\u7684\u8fd8\u662f\u5408\u5e76\u5904\u7406\u7684\uff1f": [[70, "q104-packingflash-attn"]], "Q105: For qwen2.5-omni, does setting --freeze_vit false mean both the visual encoder and the audio encoder are enabled? Is there a way to enable only the audio encoder without enabling the visual encoder?": [[131, "q105-for-qwen2-5-omni-does-setting-freeze-vit-false-mean-both-the-visual-encoder-and-the-audio-encoder-are-enabled-is-there-a-way-to-enable-only-the-audio-encoder-without-enabling-the-visual-encoder"]], "Q105: \u8bf7\u95ee\u5bf9\u4e8eqwen2.5-omni\u6765\u8bf4--freeze_vit false\u610f\u5473\u8fd9\u89c6\u89c9\u7f16\u7801\u5668\u548c\u97f3\u9891\u7f16\u7801\u5668\u90fd\u6253\u5f00\u4e86\uff0c\u6709\u4ec0\u4e48\u529e\u6cd5\u53ef\u4ee5\u53ea\u6253\u5f00\u97f3\u9891\u7f16\u7801\u5668\u4e0d\u6253\u5f00\u89c6\u89c9\u7f16\u7801\u5668\u5417\uff1f": [[70, "q105-qwen2-5-omni-freeze-vit-false"]], "Q106: Does swift currently support sequence parallelism for those reinforcement learning training methods?": [[131, "q106-does-swift-currently-support-sequence-parallelism-for-those-reinforcement-learning-training-methods"]], "Q106: \u8bf7\u95ee\u73b0\u5728swift\u7684\u5f3a\u5316\u5b66\u4e60\u90a3\u51e0\u79cd\u8bad\u7ec3\u65b9\u6cd5\u652f\u6301\u5e8f\u5217\u5e76\u884c\u4e48\uff1f": [[70, "q106-swift"]], "Q107: After using lora sft, is tokenizer.json not saved?": [[131, "q107-after-using-lora-sft-is-tokenizer-json-not-saved"]], "Q107: \u4f7f\u7528 lora sft\u4e4b\u540e\u662f\u4e0d\u4f1a\u50a8\u5b58tokenizer.json\u5417": [[70, "q107-lora-sfttokenizer-json"]], "Q108: Can the reward_model and reward_funcs of GRPO be used together?": [[131, "q108-can-the-reward-model-and-reward-funcs-of-grpo-be-used-together"]], "Q108: GRPO \u7684reward_model \u548c reward_funcs\u53ef\u4ee5\u4e00\u8d77\u7528\u5417\uff1f": [[70, "q108-grpo-reward-model-reward-funcs"]], "Q109: I want to ask if there is a parameter that can be adjusted to avoid introducing the KL term in GRPO?": [[131, "q109-i-want-to-ask-if-there-is-a-parameter-that-can-be-adjusted-to-avoid-introducing-the-kl-term-in-grpo"]], "Q109: \u60f3\u8bf7\u6559\u4e00\u4e0b\uff0c\u5728\u8fdb\u884cGRPO\u65f6\u4e0d\u6253\u7b97\u5f15\u5165KL\u9879\uff0c\u6709\u76f8\u5173\u7684\u53c2\u6570\u53ef\u4ee5\u8c03\u6574\u5417\uff1f": [[70, "q109-grpokl"]], "Q10: Can I control the number of dataset entries during evaluation? It takes over an hour to evaluate an MMLU, which is too slow.": [[131, "q10-can-i-control-the-number-of-dataset-entries-during-evaluation-it-takes-over-an-hour-to-evaluate-an-mmlu-which-is-too-slow"]], "Q10: Does Swift support pre-training? I only see SFT.": [[131, "q10-does-swift-support-pre-training-i-only-see-sft"]], "Q10: Getting the error assert factor in rope_scaling with vllm?": [[131, "q10-getting-the-error-assert-factor-in-rope-scaling-with-vllm"]], "Q10: When deploying qwen2-vl, I encounter an error about the vllm version not being correct?": [[131, "q10-when-deploying-qwen2-vl-i-encounter-an-error-about-the-vllm-version-not-being-correct"]], "Q10: qwen2-vl\u90e8\u7f72\u65f6\u62a5\u9519\u5982\u4e0b\uff0c\u662fvllm\u7684\u7248\u672c\u4e0d\u5bf9\u4e48\uff1f": [[70, "q10-qwen2-vl-vllm"]], "Q10: swift\u652f\u6301\u9884\u8bad\u7ec3\u5417\uff0c\u6211\u770b\u53ea\u6709sft\uff1f": [[70, "q10-swift-sft"]], "Q10: vllm\u4f1a\u62a5\u9519\uff0cassert factor in rope_scaling": [[70, "q10-vllm-assert-factor-in-rope-scaling"]], "Q10: \u8bc4\u4f30\u7684\u65f6\u5019\u53ef\u4e0d\u53ef\u4ee5\u63a7\u5236\u6570\u636e\u96c6\u6761\u6570\uff1f\u8bc4\u4f30\u4e00\u4e2ammlu\u9700\u8981\u4e00\u4e2a\u591a\u5c0f\u65f6\uff0c\u4e5f\u592a\u6162\u4e86\u3002": [[70, "q10-mmlu"]], "Q110: When doing GRPO, how can I access the original labels in the orm custom reward function? I printed the messages field in kwargs, and the value of assistant's content in each item is replaced by the generated result.": [[131, "q110-when-doing-grpo-how-can-i-access-the-original-labels-in-the-orm-custom-reward-function-i-printed-the-messages-field-in-kwargs-and-the-value-of-assistant-s-content-in-each-item-is-replaced-by-the-generated-result"]], "Q110: \u8bf7\u6559\u4e00\u4e2a\u95ee\u9898\uff0c\u505agrpo\u7684\u65f6\u5019\uff0c\u5982\u4f55\u5728orm\u7684\u81ea\u5b9a\u4e49\u5956\u52b1\u51fd\u6570\u4e2d\u83b7\u53d6\u539f\u59cb\u6807\u7b7e\u5462\uff1f\u6211\u6253\u5370\u4e86kwargs\u7684messages\u5b57\u6bb5\uff0c\u91cc\u9762\u7684\u6bcf\u4e00\u9879\u7684assistant\u7684content\u7684\u503c\u5df2\u7ecf\u88ab\u66ff\u6362\u6210\u751f\u6210\u7684\u7ed3\u679c\u4e86": [[70, "q110-grpo-orm-kwargsmessages-assistantcontent"]], "Q111: If you use the default num_iterations=1, does clip become ineffective? The clip higher in dapo is also useless. I see that veRL has a micro batch setting to update the policy model in small batches for the clip term to take effect. In ms-swift, it seems mini batch only does gradient accumulation according to the source code?": [[131, "q111-if-you-use-the-default-num-iterations-1-does-clip-become-ineffective-the-clip-higher-in-dapo-is-also-useless-i-see-that-verl-has-a-micro-batch-setting-to-update-the-policy-model-in-small-batches-for-the-clip-term-to-take-effect-in-ms-swift-it-seems-mini-batch-only-does-gradient-accumulation-according-to-the-source-code"]], "Q111: \u9ed8\u8ba4\u53ea\u7528 num_iterations=1 \u7684\u8bdd\uff0cclip \u5c31\u5931\u53bb\u4f5c\u7528\u4e86\u5427\uff1fdapo \u7684 clip higher \u4e5f\u6ca1\u7528\u3002\u6211\u770b veRL \u6709\u4e2a micro batch \u53ef\u4ee5\u8bbe\u7f6e\u5355\u8f6e\u5c0f\u6279\u6b21\u66f4\u65b0 policy model \u6765\u4f7f\u5f97 clip \u9879\u751f\u6548\uff0cms-swift \u7684 mini batch \u770b\u6e90\u7801\u8c8c\u4f3c\u53ea\u662f\u505a\u4e86\u68af\u5ea6\u7d2f\u52a0\uff1f": [[70, "q111-num-iterations-1-clip-dapo-clip-higher-verl-micro-batch-policy-model-clip-ms-swift-mini-batch"]], "Q112: Does qwen2.5-omni training support full parameter training, and does it support talker training?": [[131, "q112-does-qwen2-5-omni-training-support-full-parameter-training-and-does-it-support-talker-training"]], "Q112: \u8bf7\u95eeqwen2.5-omni\u7684\u8bad\u7ec3\u652f\u6301\u5168\u53c2\u8bad\u7ec3\u5417\uff0c\u662f\u5426\u652f\u6301talker\u7684\u8bad\u7ec3\uff1f": [[70, "q112-qwen2-5-omni-talker"]], "Q113: Can sequence parallel be enabled at the same time as the liger kernel?": [[131, "q113-can-sequence-parallel-be-enabled-at-the-same-time-as-the-liger-kernel"]], "Q113: \u8bf7\u95ee\uff0csequence parallel\u662f\u5426\u53ef\u4ee5\u548cliger kernel\u540c\u65f6\u542f\u7528\u5440\uff1f": [[70, "q113-sequence-parallelliger-kernel"]], "Q114: What are the requirements for rm and policy in ppo training?": [[131, "q114-what-are-the-requirements-for-rm-and-policy-in-ppo-training"]], "Q114: \u8bf7\u95eeppo\u8bad\u7ec3rm\u548cpolicy\u6709\u4ec0\u4e48\u8981\u6c42\u5462\uff1f": [[70, "q114-ppormpolicy"]], "Q115: I want to use the 3.2 1B model for fine-tuning because llama3.1 doesn't have models smaller than 8B. Can I still use the Llama-3.1 reward model?": [[131, "q115-i-want-to-use-the-3-2-1b-model-for-fine-tuning-because-llama3-1-doesn-t-have-models-smaller-than-8b-can-i-still-use-the-llama-3-1-reward-model"]], "Q115: \u8fd8\u60f3\u95ee\u4e00\u4e0b\uff0c\u7531\u4e8ellama3.1\u6ca1\u6709\u5c0f\u4e8e8B\u7684\u6a21\u578b\uff0c\u56e0\u6b64\u6211\u60f3\u75283.2 1B\u7684\u7684\u6765\u5fae\u8c03\uff0c\u90a3\u4e48\u8fd8\u80fd\u7528Llama-3.1\u8fd9\u4e2a\u5956\u52b1\u6a21\u578b\u5417\uff1f": [[70, "q115-llama3-18b-3-2-1b-llama-3-1"]], "Q116: Can swift cache a mapped version of data for troubleshooting training data issues?": [[131, "q116-can-swift-cache-a-mapped-version-of-data-for-troubleshooting-training-data-issues"]], "Q116: \u8bf7\u95eeswift\u662f\u5426\u80fd\u7f13\u5b58\u4e00\u4efdmappiing\u4e4b\u540e\u7684\u6570\u636e\uff1f\u65b9\u4fbf\u6392\u67e5\u8bad\u7ec3\u6570\u636e\u7684\u95ee\u9898": [[70, "q116-swiftmappiing"]], "Q117: Why is there a warning: none of the inputs have requires_grad=True during full parameter training?": [[131, "q117-why-is-there-a-warning-none-of-the-inputs-have-requires-grad-true-during-full-parameter-training"]], "Q117: \u5168\u53c2\u6570\u8bad\u7ec3\u4e3a\u5565\u4f1a\u6709warning: none of the inputs have requires_grad=True?": [[70, "q117-warning-none-of-the-inputs-have-requires-grad-true"]], "Q118: Does qwen2.5vl ulysses currently support sdpa?": [[131, "q118-does-qwen2-5vl-ulysses-currently-support-sdpa"]], "Q118: \u73b0\u5728qwen2.5vl ulysses\u652f\u6301sdpa\u5417\uff1f": [[70, "q118-qwen2-5vl-ulyssessdpa"]], "Q119: Is the image list format for videos now supported? The format is as follows:": [[131, "q119-is-the-image-list-format-for-videos-now-supported-the-format-is-as-follows"]], "Q119: \u8bf7\u95ee\u8fd9\u56fe\u7247\u5217\u8868\u5f62\u5f0f\u7684videos\u73b0\u5728\u652f\u6301\u4e86\u5417\uff1f\u683c\u5f0f\u5982\u4e0b": [[70, "q119-videos"]], "Q11: Does vllm require the models to be merged before calling them during inference?": [[131, "q11-does-vllm-require-the-models-to-be-merged-before-calling-them-during-inference"]], "Q11: For models fine-tuned with LoRA, should I merge them into one model for resuming training, or can I specify the original model and LoRA block by path directly?": [[131, "q11-for-models-fine-tuned-with-lora-should-i-merge-them-into-one-model-for-resuming-training-or-can-i-specify-the-original-model-and-lora-block-by-path-directly"]], "Q11: When evaluating, isn't it just having the model output an answer once and checking if it's correct? Is there a way to record or see the complete answer each time?": [[131, "q11-when-evaluating-isn-t-it-just-having-the-model-output-an-answer-once-and-checking-if-it-s-correct-is-there-a-way-to-record-or-see-the-complete-answer-each-time"]], "Q11: When using Swift deploy for inference, I want to output token probabilities. I added logprobs True, but it outputs null. What's the reason?": [[131, "q11-when-using-swift-deploy-for-inference-i-want-to-output-token-probabilities-i-added-logprobs-true-but-it-outputs-null-what-s-the-reason"]], "Q11: vllm\u4f5c\u4e3a\u63a8\u7406\u540e\u7aef\u7684\u8bdd\uff0c\u6a21\u578b\u5fc5\u987b\u5408\u5e76\u4ee5\u540e\u624d\u80fd\u8c03\u7528\u5417\uff1f": [[70, "q11-vllm"]], "Q11: \u60f3\u8bf7\u95ee\u4e00\u4e0b\uff0c\u8bc4\u6d4b\u65f6\u4e0d\u662f\u76f8\u5f53\u4e8e\u8ba9\u6a21\u578b\u8f93\u51fa\u4e00\u6b21\u56de\u7b54\u7136\u540e\u68c0\u67e5\u7b54\u6848\u5bf9\u4e0d\u5bf9\u5417\uff0c\u6709\u6ca1\u6709\u529e\u6cd5\u53ef\u4ee5\u8bb0\u5f55\u6216\u770b\u5230\u6bcf\u6b21\u5b8c\u6574\u7684\u56de\u7b54\u5462\uff1f": [[70, "q11"]], "Q11: \u60f3\u95ee\u4e00\u4e0b\u7528lora\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u5982\u679c\u60f3\u65ad\u70b9\u7eed\u8bad\u7684\u8bdd\uff0c\u662f\u5e94\u8be5\u5148\u628a\u5b83\u5408\u6210\u4e00\u6574\u4e2a\u6a21\u578b\u5417\uff0c\u8fd8\u662f\u53ef\u4ee5\u4e0d\u5408\u8d77\u6765\uff0c\u76f4\u63a5\u901a\u8fc7\u8def\u5f84\u6765\u6307\u5b9a\u539f\u6a21\u578b\u548clora\u5757": [[70, "q11-lora-lora"]], "Q11: \u6211\u7528swift deploy\u505a\u63a8\u7406\u7684\u65f6\u5019\uff0c\u60f3\u8ba9\u4ed6\u8f93\u51fatoken\u7684\u6982\u7387\uff0c\u6211\u52a0\u4e86logprobs True\uff0c\u4f46\u662f\u5b83\u8f93\u51fanull\uff0c\u8fd9\u4e2a\u662f\u4ec0\u4e48\u539f\u56e0\u5462\uff1f": [[70, "q11-swift-deploy-token-logprobs-true-null"]], "Q120: In the grpo script, does save_steps refer to step or global step? The local training shows a global step of 18, while wandb shows a step of 628.": [[131, "q120-in-the-grpo-script-does-save-steps-refer-to-step-or-global-step-the-local-training-shows-a-global-step-of-18-while-wandb-shows-a-step-of-628"]], "Q120: \u8bf7\u6559\u4e00\u4e2a\u95ee\u9898\uff0cgrpo\u811a\u672c\u4e2d\u7684save_steps\u6307\u7684\u662fstep\u8fd8\u662fglobal step\uff1f\u76ee\u524d\u672c\u5730\u8bad\u7ec3\u663e\u793a\u7684global step\u662f18\uff0c wandb\u4e0a\u663e\u793a\u7684step\u662f628\u3002": [[70, "q120-grposave-stepsstepglobal-step-global-step18-wandbstep628"]], "Q121: Can use_logits_to_keep be used on large multimodal models now?": [[131, "q121-can-use-logits-to-keep-be-used-on-large-multimodal-models-now"]], "Q121: use_logits_to_keep \u73b0\u5728\u591a\u6a21\u6001\u5927\u6a21\u578b\u4e0a\u53ef\u4ee5\u7528\u5417\uff1f": [[70, "q121-use-logits-to-keep"]], "Q122: Why does memory increase significantly multiple times during training, even after 50 or 100 steps?": [[131, "q122-why-does-memory-increase-significantly-multiple-times-during-training-even-after-50-or-100-steps"]], "Q122: \u8bf7\u95ee\u4e00\u4e0b\u4e3a\u4ec0\u4e48\u8bad\u7ec3\u5230\u4f1a\u6709\u597d\u51e0\u6b21\u663e\u5b58\u5927\u5e45\u5ea6\u589e\u52a0\uff0c\u5df2\u7ecf50step\u6216\u8005100step": [[70, "q122-50step100step"]], "Q123: With the packing_cache parameter set, I am encountering errors when training on multiple machines, even after setting the folder path. Are there any special requirements?": [[131, "q123-with-the-packing-cache-parameter-set-i-am-encountering-errors-when-training-on-multiple-machines-even-after-setting-the-folder-path-are-there-any-special-requirements"]], "Q123: \u8bf7\u95eepacking_cache\u8fd9\u4e2a\u53c2\u6570\u8bbe\u7f6e\uff0c\u591a\u673a\u8bad\u7ec3\uff0c\u6211\u8bbe\u7f6e\u4e86\u6587\u4ef6\u5939\u5730\u5740\u540e\u8fd8\u662f\u4f1a\u62a5\u9519\uff0c\u8fd9\u6709\u5565\u7279\u6b8a\u8981\u6c42\u5417?": [[70, "q123-packing-cache"]], "Q124: For Qwen3, are there differences in datasets and parameter settings between non-thinking and thinking modes?": [[131, "q124-for-qwen3-are-there-differences-in-datasets-and-parameter-settings-between-non-thinking-and-thinking-modes"]], "Q124: Qwen3\u975ethinking\u6a21\u5f0f\u548cthinking\u6a21\u5f0f\uff0c\u6570\u636e\u96c6\u548c\u53c2\u6570\u8bbe\u7f6e\u6709\u4ec0\u4e48\u4e0d\u540c\u5417\uff1f": [[70, "q124-qwen3thinkingthinking"]], "Q125: How do I configure resuming training from a checkpoint in megatron-swift?": [[131, "q125-how-do-i-configure-resuming-training-from-a-checkpoint-in-megatron-swift"]], "Q125: \u8bf7\u95eemegatron-swift\u5982\u4f55\u914d\u7f6e\u65ad\u70b9\u7eed\u8bad\uff1f": [[70, "q125-megatron-swift"]], "Q126: Has anyone encountered the following error while reproducing Kimi-VL-A3B-Instruct?": [[131, "q126-has-anyone-encountered-the-following-error-while-reproducing-kimi-vl-a3b-instruct"]], "Q126: \u6709\u6ca1\u6709\u4eba\u5728\u590d\u73b0Kimi-VL-A3B-Instruct\u7684\u65f6\u5019\u51fa\u73b0\u4e86\u5982\u4e0b\u7684\u62a5\u9519\uff1f": [[70, "q126-kimi-vl-a3b-instruct"]], "Q127: When training qwenvl2.5, how can I ensure the bounding box coordinates are correct after setting max_pixels? How does Swift handle this?": [[131, "q127-when-training-qwenvl2-5-how-can-i-ensure-the-bounding-box-coordinates-are-correct-after-setting-max-pixels-how-does-swift-handle-this"]], "Q127: \u60f3\u95ee\u4e0b\u8bad\u7ec3qwenvl2.5\u7684\u65f6\u5019\uff0c\u600e\u4e48\u4fdd\u8bc1\u8bbe\u5b9amax_pixels\u540e\u68c0\u6d4b\u6846\u7684\u5750\u6807\u662f\u5bf9\u7684\uff1f\u8fd9\u90e8\u5206swift\u662f\u600e\u4e48\u5904\u7406\u7684\uff1f": [[70, "q127-qwenvl2-5-max-pixels-swift"]], "Q128: I have a question. I want to return a solution field in my dataset. I've written a preprocessing function, but the dataset only returns messages and images, not solution. How can I fix this?": [[131, "q128-i-have-a-question-i-want-to-return-a-solution-field-in-my-dataset-i-ve-written-a-preprocessing-function-but-the-dataset-only-returns-messages-and-images-not-solution-how-can-i-fix-this"]], "Q128: \u95ee\u4e00\u4e2a\u95ee\u9898\uff0c\u6211\u60f3\u5728dataset\u4e2d\u8fd4\u56desolution \u5b57\u6bb5\uff0c\u6240\u4ee5\u6211\u5199\u4e86preprocess\uff0c\u4f46\u662fdataset\u53ea\u8fd4\u56demessages\u548cimages\uff0c\u6ca1\u8fd4\u56desolution\u8fd9\u8be5\u5982\u4f55\u4fee\u6539\u5462\uff1f": [[70, "q128-datasetsolution-preprocess-datasetmessagesimages-solution"]], "Q129: I'm getting an error when merging LoRA parameters. My current peft version is 0.11.0. Is this error because I need to upgrade it?": [[131, "q129-i-m-getting-an-error-when-merging-lora-parameters-my-current-peft-version-is-0-11-0-is-this-error-because-i-need-to-upgrade-it"]], "Q129: \u8bf7\u95ee\u4e0b\uff0clora\u53c2\u6570\u5408\u5e76\u62a5\u9519\uff0c\u76ee\u524dpeft\u662f0.11.0\uff0c\u8fd9\u4e2a\u662f\u56e0\u4e3apeft\u7248\u672c\u9700\u8981\u5347\u7ea7\u5417": [[70, "q129-lora-peft0-11-0-peft"]], "Q12: Can we set request timeout time for Swift3.0 deployment inference? What happens if the image URL is invalid?": [[131, "q12-can-we-set-request-timeout-time-for-swift3-0-deployment-inference-what-happens-if-the-image-url-is-invalid"]], "Q12: How to use CPU when performing inference with Python scripts?": [[131, "q12-how-to-use-cpu-when-performing-inference-with-python-scripts"]], "Q12: I want to stress test my model using evalscope and would like to use a prompt.txt file format. What should the format of this file look like?": [[131, "q12-i-want-to-stress-test-my-model-using-evalscope-and-would-like-to-use-a-prompt-txt-file-format-what-should-the-format-of-this-file-look-like"]], "Q12: I would like to control the location where the original model weights downloaded from the internet are stored. How can I place the original model in a specific folder?": [[131, "q12-i-would-like-to-control-the-location-where-the-original-model-weights-downloaded-from-the-internet-are-stored-how-can-i-place-the-original-model-in-a-specific-folder"]], "Q12: swift3.0 \u90e8\u7f72\u63a8\u7406\uff0c\u53ef\u4ee5\u8bbe\u7f6e\u8bf7\u6c42\u7684\u8d85\u65f6\u65f6\u95f4\u4e48\uff1f\u5982\u679c\u56fe\u7247url\u975e\u6cd5\uff0c\u4f1a\u7b49\u5728\u90a3\u91cc": [[70, "q12-swift3-0-url"]], "Q12: \u6211\u60f3\u63a7\u5236\u4e00\u4e0b\u4ece\u7f51\u4e0a\u4e0b\u8f7d\u4e0b\u6765\u7684\u539f\u59cb\u6a21\u578b\u6743\u91cd\u7684\u4f4d\u7f6e\uff0c\u600e\u4e48\u624d\u80fd\u505a\u5230\u628a\u539f\u59cb\u7684\u6a21\u578b\u653e\u5728\u6307\u5b9a\u7684\u6587\u4ef6\u5939\u91cc\u5462\uff1f": [[70, "q12"]], "Q12: \u6211\u60f3\u7528evalscope\u538b\u6d4b\u4e00\u4e0b\u6211\u7684\u6a21\u578b\uff0c\u60f3\u91c7\u7528prompt.txt\u6587\u4ef6\u7684\u5f62\u5f0f\uff0c\u8fd9\u4e2a\u6587\u4ef6\u5185\u5bb9\u7684\u683c\u5f0f\u5e94\u8be5\u662f\u4ec0\u4e48\u6837\u5b50\u7684\u5440\uff1f": [[70, "q12-evalscope-prompt-txt"]], "Q12: \u8bf7\u95ee\u5728\u4f7f\u7528python\u811a\u672c\u63a8\u7406\u65f6\uff0c\u5982\u4f55\u4f7f\u7528cpu?": [[70, "q12-python-cpu"]], "Q130: Does it currently support multi-turn DPO?": [[131, "q130-does-it-currently-support-multi-turn-dpo"]], "Q130: \u8bf7\u95ee\u73b0\u5728\u652f\u6301\u591a\u8f6e\u7684DPO\u5417\uff1f": [[70, "q130-dpo"]], "Q131: I have a question. I've run the dataset registration process before. After that, I modified the action_preprocessor code, but the data seems to be unchanged, as if my modifications were ignored. What should I do?": [[131, "q131-i-have-a-question-i-ve-run-the-dataset-registration-process-before-after-that-i-modified-the-action-preprocessor-code-but-the-data-seems-to-be-unchanged-as-if-my-modifications-were-ignored-what-should-i-do"]], "Q131: \u60f3\u95ee\u4e0b\uff0c\u6211\u4e4b\u524d\u8fd0\u884c\u8fc7\u4e00\u6b21\u6ce8\u518c\u6570\u636e\u96c6\u4e86\uff0c\u540e\u9762\u4fee\u6539\u4e86action_preprocessor\u7684\u4ee3\u7801\uff0c\u4f46\u662f\u6570\u636e\u8fd8\u662f\u548c\u539f\u6765\u7684\u4e00\u6837\uff0c\u50cf\u662f\u5ffd\u7565\u4e86\u6211\u7684\u4fee\u6539\uff1f": [[70, "q131-action-preprocessor"]], "Q132: Is there a conflict between sequence_parallel_size and a custom loss function? I added some debug print statements in my custom loss, but after enabling sequence_parallel_size, nothing is printed, and there are no errors. The SFT training runs normally, so I'm concerned it might be automatically using another library.": [[131, "q132-is-there-a-conflict-between-sequence-parallel-size-and-a-custom-loss-function-i-added-some-debug-print-statements-in-my-custom-loss-but-after-enabling-sequence-parallel-size-nothing-is-printed-and-there-are-no-errors-the-sft-training-runs-normally-so-i-m-concerned-it-might-be-automatically-using-another-library"]], "Q132: \u8bf7\u95eesequence_parallel_size\u548c\u81ea\u5b9a\u4e49loss\u51b2\u7a81\u5417\uff1f\u6211\u5728\u81ea\u5b9a\u4e49loss\u91cc\u9762\u6253\u5370\u4e86\u4e00\u4e9bdebug\u4fe1\u606f\uff0c\u4f46\u662f\u53d1\u73b0\u5f00\u542f\u4e86sequence_parallel_size \u8fc7\u540e\u5c31\u6ca1\u6709\u4fe1\u606f\u88ab\u6253\u5370\u51fa\u6765\u4e86\uff0c\u4e5f\u6ca1\u6709\u62a5\u9519\uff0csft\u8bad\u7ec3\u662f\u6b63\u5e38\u7684\uff0c\u62c5\u5fc3\u662f\u81ea\u52a8\u8c03\u4e86\u4ec0\u4e48\u522b\u7684\u5e93\u3002": [[70, "q132-sequence-parallel-sizeloss-lossdebug-sequence-parallel-size-sft"]], "Q133: In Swift's PT (pre-training) mode, when an <image> token is passed, is it not masked, meaning it contributes to the loss calculation?": [[131, "q133-in-swift-s-pt-pre-training-mode-when-an-image-token-is-passed-is-it-not-masked-meaning-it-contributes-to-the-loss-calculation"]], "Q133: swift pt\u8fd9\u79cd\u8bad\u7ec3\u65b9\u5f0f\uff0c\u5982\u679c\u4f20\u5165\u4e86<image>\uff0c<image>\u662f\u4e0d\u662f\u6ca1\u6709\u88ab\u5c4f\u853d\uff0c\u6bcf\u4e2atoken\u4e5f\u53c2\u4e0e\u635f\u5931\u8ba1\u7b97\uff1f": [[70, "q133-swift-pt-image-image-token"]], "Q134: I have a question about multimodal pre-training with packing. It seems my GPU memory usage increases slightly after each pytorch allocator cache flushes since last step, leading to an OOM (Out of Memory) error after many steps. What should I do?": [[131, "q134-i-have-a-question-about-multimodal-pre-training-with-packing-it-seems-my-gpu-memory-usage-increases-slightly-after-each-pytorch-allocator-cache-flushes-since-last-step-leading-to-an-oom-out-of-memory-error-after-many-steps-what-should-i-do"]], "Q134: \u60f3\u95ee\u4e00\u4e2a\u95ee\u9898\uff0c\u591a\u6a21\u6001packing\u9884\u8bad\u7ec3\u6bcf\u6b21pytorch allocator cache flushes since last step\u540e\uff0c\u663e\u5b58\u4f7f\u7528\u597d\u50cf\u5c31\u4f1a\u589e\u957f\u4e00\u70b9\uff0c\u6b65\u6570\u591a\u4e86\u5bb9\u6613oom": [[70, "q134-packingpytorch-allocator-cache-flushes-since-last-step-oom"]], "Q135: How can I use focal loss during training? Where can I find the list of currently supported loss types?": [[131, "q135-how-can-i-use-focal-loss-during-training-where-can-i-find-the-list-of-currently-supported-loss-types"]], "Q135: \u5982\u4f55\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528focal loss\uff1f\u5f53\u524d\u652f\u6301\u7684loss\u79cd\u7c7b\u54ea\u91cc\u6709\uff1f": [[70, "q135-focal-loss-loss"]], "Q136: When pipeline_parallel_size is set for rollout, it seems that the world_size value cannot be retrieved in TRL and vLLM.": [[131, "q136-when-pipeline-parallel-size-is-set-for-rollout-it-seems-that-the-world-size-value-cannot-be-retrieved-in-trl-and-vllm"]], "Q136: rollout\u8bbe\u7f6e\u4e86pipeline parallel size\uff0c\u8c8c\u4f3ctrl\u548cvllm\u91cc\u83b7\u53d6\u4e0d\u5230word size\u8fd9\u4e2a\u503c\u3002": [[70, "q136-rolloutpipeline-parallel-size-trlvllmword-size"]], "Q137: Does SFT for qwen2audio support packing?": [[131, "q137-does-sft-for-qwen2audio-support-packing"]], "Q137: \u8bf7\u95eeqwen2audio\u7684sft\u652f\u6301packing\u5417\uff1f": [[70, "q137-qwen2audiosftpacking"]], "Q138: Does GSPO training support the top_entropy_quantile parameter? After setting --importance_sampling_level sequence, can we still optimize for the top x% of tokens based on the entropy distribution?": [[131, "q138-does-gspo-training-support-the-top-entropy-quantile-parameter-after-setting-importance-sampling-level-sequence-can-we-still-optimize-for-the-top-x-of-tokens-based-on-the-entropy-distribution"]], "Q138: \u8bf7\u95eegspo\u8bad\u7ec3\u652f\u6301\u4f20\u5165\u53c2\u6570top_entropy_quantile\u5417\uff1f\u4f20\u5165\u4e86--importance_sampling_level sequence\u540e\uff0c\u8fd8\u80fd\u5b9e\u73b0\u5bf9\u71b5\u5206\u5e03\u524dx%\u7684token\u7684\u4f18\u5316\u5417\uff1f": [[70, "q138-gspotop-entropy-quantile-importance-sampling-level-sequence-x-token"]], "Q139: For GKD training, do the model_type for the student and teacher models have to be the same? Can one be a dense model and the other an MoE model?": [[131, "q139-for-gkd-training-do-the-model-type-for-the-student-and-teacher-models-have-to-be-the-same-can-one-be-a-dense-model-and-the-other-an-moe-model"]], "Q139: gkd\u8bad\u7ec3student model\u548cteacher model\u7684model_type\u9700\u8981\u4e00\u81f4\u5417\uff0c\u4e00\u4e2adense\u4e00\u4e2amoe\u53ef\u4ee5\u5417?": [[70, "q139-gkdstudent-modelteacher-modelmodel-type-densemoe"]], "Q13: Has anyone encountered the error RuntimeError: \"triu_tril_cuda_template\" not implemented for'BFloat16'?": [[131, "q13-has-anyone-encountered-the-error-runtimeerror-triu-tril-cuda-template-not-implemented-for-bfloat16"]], "Q13: How should I use the 'parallel' and 'number' parameters when conducting model inference performance testing using evalscope perf?": [[131, "q13-how-should-i-use-the-parallel-and-number-parameters-when-conducting-model-inference-performance-testing-using-evalscope-perf"]], "Q13: Why can't I get streaming generation with Swift deployed models? I've set stream to True on both server and client side, but it's still not streaming": [[131, "q13-why-can-t-i-get-streaming-generation-with-swift-deployed-models-i-ve-set-stream-to-true-on-both-server-and-client-side-but-it-s-still-not-streaming"]], "Q13: swift\u90e8\u7f72\u7684\u6a21\u578b\u600e\u4e48\u6ca1\u6cd5\u6d41\u5f0f\u751f\u6210\u554a\uff1f\u670d\u52a1\u7aef\u7684stream\u8bbe\u4e3aTrue\u4e86\uff0c\u5ba2\u6237\u7aef\u7684stream\u4e5f\u8bbe\u4e3aTrue\u4e86\uff0c\u4f46\u5b83\u5c31\u662f\u6ca1\u6cd5\u6d41\u5f0f\u751f\u6210": [[70, "q13-swift-streamtrue-streamtrue"]], "Q13: \u4f7f\u7528evalscope perf\u8fdb\u884c\u6a21\u578b\u63a8\u7406\u6027\u80fd\u538b\u6d4b\uff0cparallel\u548cnumber\u8fd9\u4e24\u4e2a\u53c2\u6570\u600e\u6837\u4f7f\u7528\u5462\uff1f": [[70, "q13-evalscope-perf-parallelnumber"]], "Q13: \u6709\u4eba\u9047\u5230\u8fc7\u8fd9\u4e2a\u95ee\u9898\u5417?RuntimeError: \"triu_tril_cuda_template\" not implemented for'BFloat16'": [[70, "q13-runtimeerror-triu-tril-cuda-template-not-implemented-for-bfloat16"]], "Q140: On devices that don't support Flash Attention, what is the default attention implementation? The documentation states the default is none.": [[131, "q140-on-devices-that-don-t-support-flash-attention-what-is-the-default-attention-implementation-the-documentation-states-the-default-is-none"]], "Q140: \u8bf7\u95ee\u5728\u4e0d\u652f\u6301flash attention\u7684\u8bbe\u5907\u4e0aattention implemation\u9ed8\u8ba4\u662f\u4ec0\u4e48\u5462\uff1f\u6587\u6863\u4e2d\u9ed8\u8ba4\u662fnone": [[70, "q140-flash-attentionattention-implemation-none"]], "Q141: Is the freeze_parameters_ratio calculated starting from the attention layers?": [[131, "q141-is-the-freeze-parameters-ratio-calculated-starting-from-the-attention-layers"]], "Q141: freeze_parameters_ratio\u53c2\u6570\u662f\u4ece\u6ce8\u610f\u529b\u5c42\u5f00\u59cb\u7b97\u7684\u5417\uff1f": [[70, "q141-freeze-parameters-ratio"]], "Q142: After LoRA fine-tuning, is it not possible to subsequently perform DPO or GRPO training on the same adapter?": [[131, "q142-after-lora-fine-tuning-is-it-not-possible-to-subsequently-perform-dpo-or-grpo-training-on-the-same-adapter"]], "Q142: \u8bf7\u95ee\uff0clora\u5fae\u8c03\u540e\uff0c\u4e0d\u652f\u6301\u5728adapter\u4e0a\u7ee7\u7eed\u505adpo\u6216\u8005grpo\u8bad\u7ec3\u5417\uff1f": [[70, "q142-lora-adapterdpogrpo"]], "Q143: For a multi-modal dataset, I'd like to perform dynamic data augmentation after the data is loaded, such as randomly adding noise. Which parts should I inherit or override to implement custom dynamic data augmentation?": [[131, "q143-for-a-multi-modal-dataset-i-d-like-to-perform-dynamic-data-augmentation-after-the-data-is-loaded-such-as-randomly-adding-noise-which-parts-should-i-inherit-or-override-to-implement-custom-dynamic-data-augmentation"]], "Q143: \u591a\u6a21\u6001\u6570\u636e\u96c6\u5e0c\u671b\u5728\u52a0\u8f7d\u6570\u636e\u4e4b\u540e\u505a\u52a8\u6001\u6570\u636e\u589e\u5f3a\uff0c\u4f8b\u5982\uff0c\u7ed9\u8f93\u5165\u6570\u636e\u968f\u673a\u6dfb\u52a0\u566a\u58f0\u3002\u8bf7\u95ee\u8981\u81ea\u5b9a\u4e49\u52a8\u6001\u6570\u636e\u589e\u5f3a\uff0c\u9700\u8981\u7ee7\u627f\u6216\u91cd\u5199\u54ea\u4e9b\u90e8\u5206\u5462\uff1f": [[70, "q143"]], "Q144: Does PPO training support gradient clipping?": [[131, "q144-does-ppo-training-support-gradient-clipping"]], "Q144: ppo\u8bad\u7ec3\u652f\u6301\u68af\u5ea6\u88c1\u526a\u5417\uff1f": [[70, "q144-ppo"]], "Q145: Is it not possible to enable the Liger kernel and padding-free simultaneously during the GRPO phase?": [[131, "q145-is-it-not-possible-to-enable-the-liger-kernel-and-padding-free-simultaneously-during-the-grpo-phase"]], "Q145: \u8bf7\u95eeliger kernel\u548cpadding free\u6ca1\u6cd5\u5728grpo\u9636\u6bb5\u4e00\u8d77\u5f00\u5417\uff1f": [[70, "q145-liger-kernelpadding-freegrpo"]], "Q146: In the command-line arguments for Swift SFT, are LoRA training and the --trainable_parameters argument compatible? For instance, I want to use LoRA to train the language model while also adding a score head to the final layer and training it.": [[131, "q146-in-the-command-line-arguments-for-swift-sft-are-lora-training-and-the-trainable-parameters-argument-compatible-for-instance-i-want-to-use-lora-to-train-the-language-model-while-also-adding-a-score-head-to-the-final-layer-and-training-it"]], "Q146: \u8bf7\u95ee\uff0cswift sft\u7684\u547d\u4ee4\u884c\u53c2\u6570\u91cc\u9762\uff0c\u4f7f\u7528lora\u8bad\u7ec3\u548c--trainable_parameters\u53c2\u6570\u662f\u517c\u5bb9\u7684\u5417\uff1f\u5c31\u662f\u7528lora\u8bad\u7ec3language model\uff0c\u7136\u540e\u540c\u65f6\u5728\u6700\u540e\u4e00\u5c42\u52a0\u4e2ascore head\u4e00\u8d77\u8bad\u7ec3\u3002": [[70, "q146-swift-sft-lora-trainable-parameters-loralanguage-model-score-head"]], "Q147: During multi-node, multi-GPU training, is it normal that only the main node produces logs?": [[131, "q147-during-multi-node-multi-gpu-training-is-it-normal-that-only-the-main-node-produces-logs"]], "Q147: \u591a\u673a\u591a\u5361\u8bad\u7ec3\uff0c\u53ea\u6709\u4e3b\u8282\u70b9\u6709\u65e5\u5fd7\uff0c\u662f\u6b63\u5e38\u7684\u5417\uff1f": [[70, "q147"]], "Q148: Can Swift support setting a minimum learning rate? I feel like it decreases too much in the end.": [[131, "q148-can-swift-support-setting-a-minimum-learning-rate-i-feel-like-it-decreases-too-much-in-the-end"]], "Q148: swift\u80fd\u591f\u652f\u6301\u8bbe\u7f6e\u6700\u5c0f\u7684learning rate\u5417\uff0c\u611f\u89c9\u6700\u540e\u51cf\u5230\u592a\u5c0f\u4e86": [[70, "q148-swiftlearning-rate"]], "Q149: I've set split_dataset_ratio, but there's no validation process for the validation set even by the end of training. Is there a configuration I missed?": [[131, "q149-i-ve-set-split-dataset-ratio-but-there-s-no-validation-process-for-the-validation-set-even-by-the-end-of-training-is-there-a-configuration-i-missed"]], "Q149: \u8bbe\u7f6e\u4e86split_dataset_ratio\uff0c\u4f46\u662f\u4e00\u76f4\u5230\u8bad\u7ec3\u7ed3\u675f\u4e5f\u6ca1\u6709\u9a8c\u8bc1\u96c6\u7684\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u662f\u54ea\u91cc\u6ca1\u914d\u7f6e\u597d\u5417\uff1f": [[70, "q149-split-dataset-ratio"]], "Q14: After deploying a multimodal model with Swift, is there an example of passing PIL.Image from the client?": [[131, "q14-after-deploying-a-multimodal-model-with-swift-is-there-an-example-of-passing-pil-image-from-the-client"]], "Q14: Does qwen2-audio support streaming inference?": [[131, "q14-does-qwen2-audio-support-streaming-inference"]], "Q14: In swift eval, the model stops generating after 1024 tokens. How can I modify this? Setting --max_new_tokens 5000 doesn't seem to work.": [[131, "q14-in-swift-eval-the-model-stops-generating-after-1024-tokens-how-can-i-modify-this-setting-max-new-tokens-5000-doesn-t-seem-to-work"]], "Q14: Is there a complete tutorial and command line for fine-tuning Qwen-2-VL?": [[131, "q14-is-there-a-complete-tutorial-and-command-line-for-fine-tuning-qwen-2-vl"]], "Q14: qwen2-audio\u652f\u6301\u6d41\u5f0f\u63a8\u7406\u5417\uff1f": [[70, "q14-qwen2-audio"]], "Q14: swift\u90e8\u7f72\u597d\u591a\u6a21\u6001\u6a21\u578b\u4e4b\u540e\uff0c\u5ba2\u6237\u7aef\u4f20PIL.Image\uff0c\u6709\u793a\u4f8b\u6ca1?": [[70, "q14-swift-pil-image"]], "Q14: \u6709\u5fae\u8c03qwen-2-vl\u7684\u5b8c\u6574\u7684\u6559\u7a0b\u548c\u547d\u4ee4\u884c\u5417\uff1f": [[70, "q14-qwen-2-vl"]], "Q14: \u95ee\u4e00\u4e0b\u8bc4\u4f30swift eval\u91cc\uff0c\u6a21\u578b\u6700\u591a\u751f\u62101024token\u5c31\u7ed3\u675f\u4e86\uff0c\u8fd9\u4e2a\u5982\u4f55\u4fee\u6539\uff1f\u8bbe\u7f6e--max_new_tokens 5000\uff0c\u770b\u8d77\u6765\u6ca1\u8d77\u4f5c\u7528": [[70, "q14-swift-eval-1024token-max-new-tokens-5000"]], "Q150: Does GRPO support channel_loss?": [[131, "q150-does-grpo-support-channel-loss"]], "Q150: grpo\u652f\u6301channel_loss\u5417": [[70, "q150-grpochannel-loss"]], "Q151: Is there a way to pass through a task_id in GRPO? I want to distinguish between different tasks in the training set.": [[131, "q151-is-there-a-way-to-pass-through-a-task-id-in-grpo-i-want-to-distinguish-between-different-tasks-in-the-training-set"]], "Q151: \u8bf7\u95eegrpo\u6709\u4ec0\u4e48\u529e\u6cd5\u900f\u4f20task_id\u5417\uff1f\u60f3\u533a\u522b\u8bad\u7ec3\u96c6\u7684\u4e0d\u540ctask\u3002": [[70, "q151-grpotask-id-task"]], "Q152: Is it currently supported to configure GRPO and SFT using a YAML file?": [[131, "q152-is-it-currently-supported-to-configure-grpo-and-sft-using-a-yaml-file"]], "Q152: \u76ee\u524d\u652f\u6301\u7528yaml\u6587\u4ef6\u914d\u7f6egrpo\u548csft\u5417\uff1f": [[70, "q152-yamlgrposft"]], "Q153: Does Swift support multi-node distributed training?": [[131, "q153-does-swift-support-multi-node-distributed-training"]], "Q153: swift\u652f\u6301\u591a\u8282\u70b9\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u5417\uff1f": [[70, "q153-swift"]], "Q154: When fine-tuning a VLM with several tasks together, the video sampling rules are different for each task. Does MS-Swift support this? And where can I configure it?": [[131, "q154-when-fine-tuning-a-vlm-with-several-tasks-together-the-video-sampling-rules-are-different-for-each-task-does-ms-swift-support-this-and-where-can-i-configure-it"]], "Q154: \u51e0\u4e2a\u4efb\u52a1\u4e00\u8d77finetune vlm\uff0c\u4e0d\u540c\u4efb\u52a1\u89c6\u9891\u91c7\u6837\u89c4\u5219\u4e0d\u4e00\u81f4\uff0cms swift\u662f\u5426\u652f\u6301\uff1f\u5728\u54ea\u91cc\u914d\u7f6e\uff1f": [[70, "q154-finetune-vlm-ms-swift"]], "Q155: Excuse me, does GKD currently support using different tokenizers for the teacher and student models?": [[131, "q155-excuse-me-does-gkd-currently-support-using-different-tokenizers-for-the-teacher-and-student-models"]], "Q155: \u8bf7\u6559gkd\u73b0\u5728\u652f\u6301\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578btokenizer\u4e0d\u4e00\u6837\u5417\uff1f": [[70, "q155-gkdtokenizer"]], "Q156: Excuse me, are use_liger_kernel and log_entropy currently not supported to be used together?": [[131, "q156-excuse-me-are-use-liger-kernel-and-log-entropy-currently-not-supported-to-be-used-together"]], "Q156: \u8bf7\u95ee\u73b0\u5728\u662f\u4e0d\u652f\u6301use_liger_kernel\u548clog_entropy\u4e00\u8d77\u7528\u5417\uff1f": [[70, "q156-use-liger-kernellog-entropy"]], "Q157: When training GRPO, why isn't there an entropy curve during monitoring?": [[131, "q157-when-training-grpo-why-isn-t-there-an-entropy-curve-during-monitoring"]], "Q157: \u8bad\u7ec3grpo\u7684\u65f6\u5019\uff0c\u8fdb\u884c\u89c2\u5bdf\u7684\u65f6\u5019\uff0c\u600e\u4e48\u6ca1\u6709\u71b5\u8fd9\u4e2a\u66f2\u7ebf\u5440": [[70, "q157-grpo"]], "Q158: In Swift, where is the location in the code that reads an image and converts it into a tensor?": [[131, "q158-in-swift-where-is-the-location-in-the-code-that-reads-an-image-and-converts-it-into-a-tensor"]], "Q158: swift\u91cc\u628a\u56fe\u50cf\u8bfb\u8fdb\u6765\u8f6c\u6362\u6210tensor\u7684\u4f4d\u7f6e\u5728\u54ea\u91cc\uff1f": [[70, "q158-swifttensor"]], "Q159: I have a question. My original dataset has 'question' and 'answer' columns. After mapping them via the command line with --columns {\"question\": \"query\", \"answer\": \"response\"}, the reward function reports a 'column not found' error whether I use 'answer' or 'response'. How can I pass the dataset columns through to the reward function?": [[131, "q159-i-have-a-question-my-original-dataset-has-question-and-answer-columns-after-mapping-them-via-the-command-line-with-columns-question-query-answer-response-the-reward-function-reports-a-column-not-found-error-whether-i-use-answer-or-response-how-can-i-pass-the-dataset-columns-through-to-the-reward-function"]], "Q159: \u95ee\u4e00\u4e0b\uff0c\u539f\u59cb\u6570\u636e\u96c6\u5305\u542bquestion\u548canswer\u4e24\u5217\uff0c\u547d\u4ee4\u884c\u505a\u6620\u5c04\u4e4b\u540e--columns {\"question\": \"query\", \"answer\": \"response\"}\uff0c\u5956\u52b1\u51fd\u6570\u65e0\u8bba\u662f\u7528answer\u8fd8\u662fresponse\u90fd\u4f1a\u62a5\u9519\u6ca1\u6709\u5217\u3002\u600e\u4e48\u6837\u624d\u80fd\u628a\u6570\u636e\u96c6\u7684\u5217\u900f\u4f20\u8fdb\u53bb\u5462\uff1f": [[70, "q159-questionanswer-columns-question-query-answer-response-answerresponse"]], "Q15: Are there any tricks supported for fine-tuning multi-modal large models, similar to the LLM's neftune?": [[131, "q15-are-there-any-tricks-supported-for-fine-tuning-multi-modal-large-models-similar-to-the-llm-s-neftune"]], "Q15: Does evalscope currently support benchmarks like AIME and MATH-500 for deepseek-r1?": [[131, "q15-does-evalscope-currently-support-benchmarks-like-aime-and-math-500-for-deepseek-r1"]], "Q15: When deploying, which parameter should be set to output multiple results in a single response?": [[131, "q15-when-deploying-which-parameter-should-be-set-to-output-multiple-results-in-a-single-response"]], "Q15: Where to set do_sample for multi-modal inference using inference client?": [[131, "q15-where-to-set-do-sample-for-multi-modal-inference-using-inference-client"]], "Q15: inference client\u63a8\u7406\u591a\u6a21\u6001\uff0cdo_sample\u5728\u54ea\u91cc\u8bbe\u7f6e\uff1f": [[70, "q15-inference-client-do-sample"]], "Q15: \u591a\u6a21\u6001\u5927\u6a21\u578b\u5fae\u8c03\u6709\u4ec0\u4e48\u652f\u6301\u7684trick\u5417\uff0c\u7c7b\u4f3cllm\u7684neftune?": [[70, "q15-trick-llmneftune"]], "Q15: \u8bf7\u95ee deploy\u90e8\u7f72\u65f6\u5019\uff0c\u8bbe\u7f6e\u4ec0\u4e48\u53c2\u6570\u53ef\u4ee5\u5b9e\u73b0\u4e00\u6b21\u8f93\u51fa\uff0c\u8f93\u51fa\u591a\u4e2a\u7ed3\u679c\u5462\uff1f": [[70, "q15-deploy"]], "Q15: \u8bf7\u95eeevalscope\u73b0\u5728\u652f\u6301deepseek-r1 \u7684\u76f8\u5173benchmark\u5417\uff1fAIME\u3001MATH-500\u8fd9\u6837": [[70, "q15-evalscopedeepseek-r1-benchmark-aimemath-500"]], "Q160: I have a question about fine-tuning the qwen3-30b-a3b MoE model with LoRA in MS-Swift. The aux_loss barely changes, even when I set aux_loss_coef to 1.": [[131, "q160-i-have-a-question-about-fine-tuning-the-qwen3-30b-a3b-moe-model-with-lora-in-ms-swift-the-aux-loss-barely-changes-even-when-i-set-aux-loss-coef-to-1"]], "Q160: \u60f3\u95ee\u4e0b\uff0cms-swift\u5bf9qwen3-30b-a3b\u7684moe\u6a21\u578blora\u5fae\u8c03\uff0caux-loss\u57fa\u672c\u6ca1\u53d8\u5316\uff0c\u5373\u4f7f\u8bbe\u7f6eaux-loss-coef\u4e3a1\u4e5f\u6ca1\u53d8\u5316\u3002": [[70, "q160-ms-swiftqwen3-30b-a3bmoelora-aux-loss-aux-loss-coef1"]], "Q161: With the script below, is it possible to save checkpoints per epoch?": [[131, "q161-with-the-script-below-is-it-possible-to-save-checkpoints-per-epoch"]], "Q161: \u4e0b\u9762\u7684\u811a\u672c\uff0c\u53ef\u4ee5\u6309epoch\u4fdd\u5b58checkpoint\u5417\uff1f": [[70, "q161-epochcheckpoint"]], "Q162: I encountered this error. How can I fix it? Installing Apex didn't help.": [[131, "q162-i-encountered-this-error-how-can-i-fix-it-installing-apex-didn-t-help"]], "Q162: \u8bf7\u95ee\u4e0b\uff0c\u9047\u5230\u8fd9\u4e2a\u62a5\u9519\uff0c\u600e\u4e48\u5904\u7406\uff1f\u5b89\u88c5\u4e86apex\u4e5f\u4e0d\u884c": [[70, "q162-apex"]], "Q163: For MoE LoRA training, if target_modules is set to all-linear, does this include the router modules?": [[131, "q163-for-moe-lora-training-if-target-modules-is-set-to-all-linear-does-this-include-the-router-modules"]], "Q163: moe\u7684lora\u8bad\u7ec3\uff0ctarget_modules\u53c2\u6570\u8bbe\u7f6e\u4e86all-linear\uff0c\u662f\u5305\u62ec\u4e86\u8def\u7531\u5668\u6a21\u5757\u5417\uff1f": [[70, "q163-moelora-target-modulesall-linear"]], "Q164: For GRPO training, does the colocate mode not support use_async_engine?": [[131, "q164-for-grpo-training-does-the-colocate-mode-not-support-use-async-engine"]], "Q164: grpo\u8bad\u7ec3colocate\u6a21\u5f0f\u4e0d\u652f\u6301use_async_engine\u5417\uff1f": [[70, "q164-grpocolocateuse-async-engine"]], "Q165: Can a model trained with QLoRA be merged?": [[131, "q165-can-a-model-trained-with-qlora-be-merged"]], "Q165: qlora\u8bad\u7ec3\u540e\u7684\u6a21\u578b\u53ef\u4ee5merge\u5417\uff1f": [[70, "q165-qloramerge"]], "Q16: Does ms-swift support batch processing for large models?": [[131, "q16-does-ms-swift-support-batch-processing-for-large-models"]], "Q16: I'm getting this error when using a local path for gpqa evaluation in evalscope: ValueError: BuildingConfig 'gpqa_extended' not found. Available: ['default']": [[131, "q16-i-m-getting-this-error-when-using-a-local-path-for-gpqa-evaluation-in-evalscope-valueerror-buildingconfig-gpqa-extended-not-found-available-default"]], "Q16: The accuracy from eval during training and the accuracy computed from re-inference with the saved checkpoint are not consistent.": [[131, "q16-the-accuracy-from-eval-during-training-and-the-accuracy-computed-from-re-inference-with-the-saved-checkpoint-are-not-consistent"]], "Q16: When deploying using swift deploy with the parameter --infer_backend vllm, the performance was nearly 10 points worse compared to deploying directly with vllm: vllm serve. Does anyone know the reason for this?": [[131, "q16-when-deploying-using-swift-deploy-with-the-parameter-infer-backend-vllm-the-performance-was-nearly-10-points-worse-compared-to-deploying-directly-with-vllm-vllm-serve-does-anyone-know-the-reason-for-this"]], "Q16: ms-swift\u652f\u6301\u5927\u6a21\u578b\u6279\u5904\u7406\u4e0d\uff1f": [[70, "q16-ms-swift"]], "Q16: \u60f3\u95ee\u4e00\u4e0bevalscope\u6d4b\u8bc4gpqa\u4f7f\u7528\u672c\u5730\u8def\u5f84\u62a5\u9519\uff1a ValueError: BuildingConfig 'gpqa_extended' not found. Available: ['default']": [[70, "q16-evalscopegpqa-valueerror-buildingconfig-gpqa-extended-not-found-available-default"]], "Q16: \u6bd4\u4f7f\u7528 swift deploy \u90e8\u7f72\uff0c\u6307\u5b9a\u53c2\u6570\u4e3a --infer_backend vllm\uff0c\u76f4\u63a5\u4f7f\u7528 vllm \u90e8\u7f72\uff1avllm serve\u00a0\uff0c\u6548\u679c\u5dee\u4e86\u63a5\u8fd110\u4e2a\u70b9\uff0c\u6709\u4eba\u77e5\u9053\u4ec0\u4e48\u539f\u56e0\u4e0d\uff1f": [[70, "q16-swift-deploy-infer-backend-vllm-vllm-vllm-serve-10"]], "Q16: \u8bad\u7ec3\u8fc7\u7a0b\u4e2deval\u5f97\u5230\u7684acc\u548c\u5bf9\u5e94\u4fdd\u5b58\u7684ckpt\u53bb\u91cd\u65b0\u63a8\u7406\u4e00\u904d\u8ba1\u7b97\u5f97\u5230\u7684acc\u4e0d\u662f\u4e00\u81f4\u7684": [[70, "q16-evalaccckptacc"]], "Q17: How can I disable the deep thinking mode of qwem3 in the deployment command?": [[131, "q17-how-can-i-disable-the-deep-thinking-mode-of-qwem3-in-the-deployment-command"]], "Q17: Official Magic Mirror image and Swift environment.": [[131, "q17-official-magic-mirror-image-and-swift-environment"]], "Q17: When evaluating the arc dataset with evalscope, I get this error. What's the reason? I'm using the local data path method.": [[131, "q17-when-evaluating-the-arc-dataset-with-evalscope-i-get-this-error-what-s-the-reason-i-m-using-the-local-data-path-method"]], "Q17: When quantizing models with ms-swift, there is an insufficient memory display. Can we reduce resource usage during quantization, even if it's slower?": [[131, "q17-when-quantizing-models-with-ms-swift-there-is-an-insufficient-memory-display-can-we-reduce-resource-usage-during-quantization-even-if-it-s-slower"]], "Q17: ms-swift\u91cf\u5316\u6a21\u578b\u7684\u65f6\u5019\uff0c\u663e\u793a\u5185\u5b58\u4e0d\u8db3\uff0c\u53ef\u4ee5\u5728\u91cf\u5316\u7684\u65f6\u5019\u5c11\u5360\u7528\u4e00\u4e9b\u8d44\u6e90\u5417\uff0c\u6162\u4e00\u70b9\u6ca1\u5173\u7cfb\u3002": [[70, "q17-ms-swift"]], "Q17: \u7528evalscope\u8bc4\u6d4barc\u6570\u636e\u96c6\u7684\u65f6\u5019\uff0c\u62a5\u8fd9\u4e2a\u9519\u8bef\uff0c\u8fd9\u662f\u4ec0\u4e48\u539f\u56e0\u5462\uff0c\u7528\u7684\u662f\u52a0\u8f7d\u672c\u5730\u6570\u636e\u8def\u5f84\u65b9\u5f0f": [[70, "q17-evalscopearc"]], "Q17: \u90e8\u7f72\u547d\u4ee4\u600e\u4e48\u5173\u95edqwem3\u7684\u6df1\u5ea6\u601d\u8003\u6a21\u5f0f\uff1f": [[70, "q17-qwem3"]], "Q17: \u9b54\u642d\u5b98\u65b9\u955c\u50cf\u4e0eswift\u73af\u5883": [[70, "q17-swift"]], "Q18: Command line for multi-machine multi-card training.": [[131, "q18-command-line-for-multi-machine-multi-card-training"]], "Q18: Does Swift support quantization for multi-modal models?": [[131, "q18-does-swift-support-quantization-for-multi-modal-models"]], "Q18: How can I load downloaded datasets locally when using opencompass backend for evaluation?": [[131, "q18-how-can-i-load-downloaded-datasets-locally-when-using-opencompass-backend-for-evaluation"]], "Q18: When I use ms-swift for vllm deployment inference, it is much slower compared to native vllm. Is this a problem with the swift framework?": [[131, "q18-when-i-use-ms-swift-for-vllm-deployment-inference-it-is-much-slower-compared-to-native-vllm-is-this-a-problem-with-the-swift-framework"]], "Q18: swift\u652f\u6301\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u91cf\u5316\u5417\uff1f": [[70, "q18-swift"]], "Q18: \u591a\u673a\u591a\u5361\u8bad\u7ec3\u547d\u4ee4\u884c": [[70, "q18"]], "Q18: \u8bf7\u6559\u4e00\u4e0b\uff0c\u60f3\u4f7f\u7528opencompass\u7684\u540e\u7aef\u8bc4\u6d4b\uff0c\u5982\u4f55\u4ece\u672c\u5730\u52a0\u8f7d\u4e0b\u8f7d\u597d\u7684\u6570\u636e\u96c6\uff1f": [[70, "q18-opencompass"]], "Q18: \u8bf7\u95ee\uff0c\u6211\u7528ms-swift\u7684vllm\u90e8\u7f72\u63a8\u7406\uff0c\u6bd4\u539f\u751fvllm\u8981\u6162\u5f88\u591a\uff0c\u8fd9\u4e2a\u662fswift\u6846\u67b6\u7684\u95ee\u9898\u561b\uff1f": [[70, "q18-ms-swiftvllm-vllm-swift"]], "Q19: Does swift eval with --eval_backend OpenCompass not support custom datasets?": [[131, "q19-does-swift-eval-with-eval-backend-opencompass-not-support-custom-datasets"]], "Q19: Encountering the following error while using GPTQ, what is the cause?": [[131, "q19-encountering-the-following-error-while-using-gptq-what-is-the-cause"]], "Q19: How to choose a template?": [[131, "q19-how-to-choose-a-template"]], "Q19: If a Swift deployment is accelerated with vLLM, can I specify the proportion of GPU memory to be used on different cards individually?": [[131, "q19-if-a-swift-deployment-is-accelerated-with-vllm-can-i-specify-the-proportion-of-gpu-memory-to-be-used-on-different-cards-individually"]], "Q19: swift eval \u6765\u8bc4\u4f30\u6a21\u578b\uff0c--eval_backend OpenCompass\u4e0d\u652f\u6301\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5417\uff1f": [[70, "q19-swift-eval-eval-backend-opencompass"]], "Q19: \u4f7f\u7528GPTQ\u62a5\u9519\u5982\u4e0b\uff0c\u8bf7\u95ee\u662f\u5565\u539f\u56e0\uff1f": [[70, "q19-gptq"]], "Q19: \u5982\u4f55\u9009\u62e9template?": [[70, "q19-template"]], "Q19: \u5982\u679cswift\u90e8\u7f72\u7528vllm\u52a0\u901f\uff0c\u80fd\u5206\u522b\u6307\u5b9a\u4e0d\u540c\u5361\u4e0a\u4f7f\u7528\u663e\u5b58\u7684\u6bd4\u4f8b\u5417\uff1f": [[70, "q19-swiftvllm"]], "Q1: How to deploy a trained model?": [[131, "q1-how-to-deploy-a-trained-model"]], "Q1: Is there documentation for Swift inference?": [[131, "q1-is-there-documentation-for-swift-inference"]], "Q1: Swift\u5fae\u8c03\u652f\u6301\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u6709\u54ea\u4e9b\uff1f": [[70, "q1-swift"]], "Q1: What evaluation datasets are supported by Swift?": [[131, "q1-what-evaluation-datasets-are-supported-by-swift"]], "Q1: What models and datasets are supported for fine-tuning in Swift?": [[131, "q1-what-models-and-datasets-are-supported-for-fine-tuning-in-swift"]], "Q1: swift\u652f\u6301\u7684\u8bc4\u6d4b\u96c6\u6709\u54ea\u4e9b\uff1f": [[70, "id8"]], "Q1: \u5982\u4f55\u90e8\u7f72\u8bad\u7ec3\u540e\u7684\u6a21\u578b\uff1f": [[70, "q1"]], "Q1:swift\u63a8\u7406\u6709\u6587\u6863\u5417\uff1f": [[70, "id4"]], "Q20: After a model is saved, it seems it can't be loaded by vLLM. It throws an error about a missing \"model.language_model.embed_tokens.weight\". Is there a solution?": [[131, "q20-after-a-model-is-saved-it-seems-it-can-t-be-loaded-by-vllm-it-throws-an-error-about-a-missing-model-language-model-embed-tokens-weight-is-there-a-solution"]], "Q20: How can I specify where to save evaluation results during swift infer? I can't find where the results are saved.": [[131, "q20-how-can-i-specify-where-to-save-evaluation-results-during-swift-infer-i-can-t-find-where-the-results-are-saved"]], "Q20: How to use torchrun and swift sft for multi-card training?": [[131, "q20-how-to-use-torchrun-and-swift-sft-for-multi-card-training"]], "Q20: When I run the RAGAS evaluation task from the evalscope official documentation locally on a single A100, it takes 10 minutes to run the two examples in the documentation. Is this normal? Are there ways to optimize the running speed?": [[131, "q20-when-i-run-the-ragas-evaluation-task-from-the-evalscope-official-documentation-locally-on-a-single-a100-it-takes-10-minutes-to-run-the-two-examples-in-the-documentation-is-this-normal-are-there-ways-to-optimize-the-running-speed"]], "Q20: swift infer\u5982\u4f55\u5c06\u8bc4\u4f30\u7684\u7ed3\u679c\u4fdd\u5b58\u5230\u6307\u5b9a\u6587\u4ef6\u5462 \u6bcf\u6b21\u90fd\u4e0d\u77e5\u9053\u4fdd\u5b58\u5230\u54ea\u91cc\u4e86": [[70, "q20-swift-infer"]], "Q20: \u591a\u5361\u8bad\u7ec3torchrun\u548cswift sft\u5982\u4f55\u4f7f\u7528\uff1f": [[70, "q20-torchrunswift-sft"]], "Q20: \u6211\u5728\u672c\u5730\u7528\u5355\u5f20A100\u8fd0\u884c\u6a21\u578b\u6765\u505aevalscope\u5b98\u65b9\u6587\u6863\u91cc\u7684RAGAS\u8bc4\u6d4b\u4efb\u52a1\u65f6\uff0c\u8dd1\u6587\u6863\u4e2d\u7684\u4e24\u4e2a\u6837\u4f8b\u82b1\u8d39\u4e8610\u5206\u949f\u7684\u65f6\u95f4\uff0c\u8bf7\u95ee\u8fd9\u662f\u6b63\u5e38\u7684\u4e48\uff1f\u6709\u6ca1\u6709\u4ec0\u4e48\u529e\u6cd5\u53ef\u4ee5\u4f18\u5316\u8fd0\u884c\u901f\u5ea6\u3002": [[70, "q20-a100evalscoperagas-10"]], "Q20: \u6a21\u578b\u4fdd\u5b58\u540e\uff0c\u597d\u50cf\u65e0\u6cd5\u88abvllm\u8bfb\u53d6\uff0c\u4f1a\u62a5\u9519\u6ca1\u6709\u201cmodel.language_model.embed_tokens.weight\u201d\uff0c\u6709\u89e3\u6cd5\u5417\uff1f": [[70, "q20-vllm-model-language-model-embed-tokens-weight"]], "Q21: AWQ\u91cf\u5316yi-vl-6b\u51fa\u9519\u5982\u4e0b\uff1a": [[70, "q21-awqyi-vl-6b"]], "Q21: I get an error while using AWQ quantized yi-vl-6b:": [[131, "q21-i-get-an-error-while-using-awq-quantized-yi-vl-6b"]], "Q21: I have a question about my SFT dataset being too large; tokenizing takes a long time. Is there a solution?": [[131, "q21-i-have-a-question-about-my-sft-dataset-being-too-large-tokenizing-takes-a-long-time-is-there-a-solution"]], "Q21: I'm using evalscope to evaluate RAG, but I also want to use the API method to call the embedded model. Is this supported? I don't see it mentioned in the documentation.": [[131, "q21-i-m-using-evalscope-to-evaluate-rag-but-i-also-want-to-use-the-api-method-to-call-the-embedded-model-is-this-supported-i-don-t-see-it-mentioned-in-the-documentation"]], "Q21: Regarding the system prompt, you can specify it via the --system parameter, prepend it to each data entry in the dataset, or define it in the template. Is it sufficient to use just one of these methods? And are they all treated the same way by the model?": [[131, "q21-regarding-the-system-prompt-you-can-specify-it-via-the-system-parameter-prepend-it-to-each-data-entry-in-the-dataset-or-define-it-in-the-template-is-it-sufficient-to-use-just-one-of-these-methods-and-are-they-all-treated-the-same-way-by-the-model"]], "Q21: \u6709\u4e2a\u95ee\u9898\uff0c\u56e0\u4e3a\u6211\u7684sft\u6570\u636e\u96c6\u592a\u5927\u4e86\uff0c\u7136\u540e\u6bcf\u6b21tokenize\u90fd\u9700\u8981\u5f88\u4e45\uff0c\u6709\u89e3\u51b3\u65b9\u6848\u5417\uff1f": [[70, "q21-sft-tokenize"]], "Q21: \u7528evalscope\u8bc4\u6d4bRAG\uff0c\u4f46\u662f\u5d4c\u5165\u5f0f\u6a21\u578b\u6211\u4e5f\u60f3\u7528 API \u65b9\u5f0f\u8c03\u7528\uff0c\u652f\u6301\u5417\uff1f\u6211\u770b\u6587\u6863\u4e0a\u6ca1\u6709\u5199": [[70, "q21-evalscoperag-api"]], "Q21: \u901a\u8fc7--system\u53c2\u6570\u6307\u5b9asystem prompt\u4e0e\u6570\u636e\u96c6\u4e2d\u6bcf\u4e2a\u6570\u636e\u524d\u52a0system prompt\u4ee5\u53catemplate\u7684system prompt\u662f\u4e0d\u662f\u6709\u4e00\u4e2a\u5c31\u884c\uff1f\u8fd9\u4e9b\u65b9\u5f0f\u5bf9\u6a21\u578b\u6765\u8bf4\uff0c\u662f\u4e0d\u662f\u4e00\u6837\u7684\uff1f": [[70, "q21-systemsystem-promptsystem-prompttemplatesystem-prompt"]], "Q22: After deploying a model using the Swift Transformers engine, inference is not parallelized, and data is not distributed to other GPUs. Everything is running on the first GPU.": [[131, "q22-after-deploying-a-model-using-the-swift-transformers-engine-inference-is-not-parallelized-and-data-is-not-distributed-to-other-gpus-everything-is-running-on-the-first-gpu"]], "Q22: I would like to ask about using swift export to perform GPTQ INT4 quantization on the qwen2.5 72B model with a max model length of 32768, which is the default value. The calibration dataset provided has 128 samples, but an error occurred during quantization. The error log is: \"factorization could not be completed because the input is not positive-definite (the leading minor of order 18145 is not positive-definite).\" What is the cause?": [[131, "q22-i-would-like-to-ask-about-using-swift-export-to-perform-gptq-int4-quantization-on-the-qwen2-5-72b-model-with-a-max-model-length-of-32768-which-is-the-default-value-the-calibration-dataset-provided-has-128-samples-but-an-error-occurred-during-quantization-the-error-log-is-factorization-could-not-be-completed-because-the-input-is-not-positive-definite-the-leading-minor-of-order-18145-is-not-positive-definite-what-is-the-cause"]], "Q22: When testing a locally trained model using evalscope, the output for the test data is very simple, but the data was constructed in an inferential way during model training, leading to lower test results. How can evalscope be used to test only the data within xxx from the model's output?": [[131, "q22-when-testing-a-locally-trained-model-using-evalscope-the-output-for-the-test-data-is-very-simple-but-the-data-was-constructed-in-an-inferential-way-during-model-training-leading-to-lower-test-results-how-can-evalscope-be-used-to-test-only-the-data-within-xxx-from-the-model-s-output"]], "Q22: When two datasets are simply appended together in the training set, does the model shuffle internally during training, or does it take data in order to train?": [[131, "q22-when-two-datasets-are-simply-appended-together-in-the-training-set-does-the-model-shuffle-internally-during-training-or-does-it-take-data-in-order-to-train"]], "Q22: swift transformers engine\u90e8\u7f72\u6a21\u578b\u540e\uff0c\u63a8\u7406\u65e0\u6cd5\u5e76\u884c\uff0c\u6570\u636e\u4e5f\u6ca1\u529e\u6cd5\u5206\u914d\u5230\u5176\u4ed6\u663e\u5361\u4e0a\uff0c\u7528\u7684\u5168\u662f\u7b2c\u4e00\u5f20\u5361\u3002": [[70, "q22-swift-transformers-engine"]], "Q22: \u4f7f\u7528evalscpoe\u6d4b\u8bd5\u672c\u5730\u8bad\u7ec3\u540e\u7684\u6a21\u578b\uff0c\u6d4b\u8bd5\u6570\u636e\u8f93\u51fa\u662f\u5f88\u7b80\u5355\u7684\uff0c\u4f46\u662f\u8bad\u7ec3\u6a21\u578b\u7684\u65f6\u5019\u6570\u636e\u6784\u9020\u7684\u662f\u63a8\u7406\u7684\u65b9\u5f0f\uff0c\u8fd9\u6837\u6d4b\u8bd5\u7ed3\u679c\u5c31\u6bd4\u8f83\u4f4e\uff0c\u8bf7\u95eeevalscope\u600e\u4e48\u4ec5\u4ec5\u4f7f\u7528\u6a21\u578b\u8f93\u51fa\u91cc<answer>xxx</answer>\u91cc\u7684\u6570\u636e\u6d4b\u8bd5\uff1f": [[70, "q22-evalscpoe-evalscope-answer-xxx-answer"]], "Q22: \u60f3\u95ee\u4e00\u4e0b\u7528swift export\u5bf9qwen2.5 72B\u6a21\u578b\u8fdb\u884cgptq int4\u91cf\u5316\uff0cmax model length=32768\u7528\u7684\u662f\u9ed8\u8ba4\u503c\uff0c\u7ed9\u7684\u6821\u51c6\u6570\u636e\u96c6\u6709128\u4e2a\u6837\u672c\uff0c\u4f46\u662f\u91cf\u5316\u7684\u65f6\u5019\u62a5\u9519\u4e86\uff0c\u62a5\u9519\u65e5\u5fd7\u662f\uff1afactorization could not be completed because the input is not positive-definite(the leading minor of order 18145 is not pisitive-definite)\u3002\u662f\u4ec0\u4e48\u539f\u56e0\uff1f": [[70, "q22-swift-exportqwen2-5-72bgptq-int4-max-model-length-32768-128-factorization-could-not-be-completed-because-the-input-is-not-positive-definite-the-leading-minor-of-order-18145-is-not-pisitive-definite"]], "Q22: \u8bad\u7ec3\u65f6\uff0c\u5982\u679c\u4e24\u4e2a\u6570\u636e\u96c6\u76f4\u63a5\u8ffd\u52a0\u4e00\u8d77\u653e\u5728\u8bad\u7ec3\u96c6\u4e2d\uff0c\u6a21\u578b\u5728\u8bad\u7ec3\u7684\u65f6\u5019\u5185\u90e8\u4f1a\u6709shuffle\u7684\u6d41\u7a0b\u5417\uff1f\u8fd8\u662f\u6309\u987a\u5e8f\u53d6\u6570\u636e\u53bb\u8bad\u7ec3\uff1f": [[70, "q22-shuffle"]], "Q23: Can batch inference only be done through custom code? Can't it be done like SFT with script parameters?": [[131, "q23-can-batch-inference-only-be-done-through-custom-code-can-t-it-be-done-like-sft-with-script-parameters"]], "Q23: Evalscope can natively generate reports, but other backends like OpenCompass do not support report visualization, correct?": [[131, "q23-evalscope-can-natively-generate-reports-but-other-backends-like-opencompass-do-not-support-report-visualization-correct"]], "Q23: For a model deployed with swift deploy, how can I disable the \"thinking\" status on the client side? Adding it to the extra_body of the request doesn't work.": [[131, "q23-for-a-model-deployed-with-swift-deploy-how-can-i-disable-the-thinking-status-on-the-client-side-adding-it-to-the-extra-body-of-the-request-doesn-t-work"]], "Q23: If the model is on two cards and the data is not parallelized, deepspeed will throw an error. How to handle this?": [[131, "q23-if-the-model-is-on-two-cards-and-the-data-is-not-parallelized-deepspeed-will-throw-an-error-how-to-handle-this"]], "Q23: evalscope\u539f\u751f\u662f\u53ef\u4ee5\u751f\u6210\u62a5\u544a\u7684 \u5176\u4ed6\u540e\u7aef\u5982opencompass\u662f\u4e0d\u652f\u6301\u751f\u6210\u62a5\u544a\u53ef\u89c6\u5316\u662f\u5417\uff1f": [[70, "q23-evalscope-opencompass"]], "Q23: swift deploy\u90e8\u7f72\u7684\u6a21\u578b\uff0c\u600e\u4e48\u5728\u5ba2\u6237\u7aef\u7981\u6b62thinking\uff1f\u6211\u5728\u8bf7\u6c42\u7684\u65f6\u5019\u52a0\u4e86extra body\u4e5f\u4e0d\u884c\u3002": [[70, "q23-swift-deploy-thinking-extra-body"]], "Q23: \u5982\u679c\u6a21\u578b\u4e24\u5f20\u5361\uff0c\u6570\u636e\u4e0d\u5f00\u5e76\u884c\uff0cdeepspeed\u5c31\u4f1a\u51fa\u73b0\u62a5\u9519\uff0c\u600e\u4e48\u5904\u7406\u5462\uff1f": [[70, "q23-deepspeed"]], "Q23: \u8bf7\u95ee\u6279\u91cf\u63a8\u7406\u662f\u53ea\u80fd\u81ea\u5df1\u7f16\u5199\u4ee3\u7801\u8fd0\u884c\u5417\uff1f\u4e0d\u53ef\u4ee5\u6309\u7167 sft \u90a3\u6837\u586b\u811a\u672c\u53c2\u6570\u7801": [[70, "q23-sft"]], "Q24: Could you explain what causes the following error when using ifeval for evaluation?": [[131, "q24-could-you-explain-what-causes-the-following-error-when-using-ifeval-for-evaluation"]], "Q24: How to reduce GPU memory usage when training VLM models?": [[131, "q24-how-to-reduce-gpu-memory-usage-when-training-vlm-models"]], "Q24: What's the default temperature value when using swift app for inference?": [[131, "q24-what-s-the-default-temperature-value-when-using-swift-app-for-inference"]], "Q24: vlm\u6a21\u578b\u8bad\u7ec3\u5982\u4f55\u51cf\u5c11\u663e\u5b58\u4f7f\u7528\uff1f": [[70, "q24-vlm"]], "Q24: \u8bf7\u95ee\u4e00\u4e0b\u8bc4\u6d4bifeval\u62a5\u8fd9\u4e2a\u9519\u662f\u4ec0\u4e48\u539f\u56e0\uff1f": [[70, "q24-ifeval"]], "Q24: \u95ee\u4e00\u4e0b\uff0cswift app\u63a8\u7406\u65f6\uff0ctemperature\u9ed8\u8ba4\u662f\u591a\u5c11\u7684\uff1f": [[70, "q24-swift-app-temperature"]], "Q25: Can export and quantization be done using multiple GPUs?": [[131, "q25-can-export-and-quantization-be-done-using-multiple-gpus"]], "Q25: For a model that doesn't have a matching model_type, can I customize the special_tokens and chat_template during SFT?": [[131, "q25-for-a-model-that-doesn-t-have-a-matching-model-type-can-i-customize-the-special-tokens-and-chat-template-during-sft"]], "Q25: When evaluating with eval_backend='OpenCompass', how can I specify the path to offline datasets?": [[131, "q25-when-evaluating-with-eval-backend-opencompass-how-can-i-specify-the-path-to-offline-datasets"]], "Q25: \u6ca1\u6709\u9002\u914dmodel_type\u7684\u6a21\u578b\uff0csft\u65f6\u53ef\u4ee5\u81ea\u5b9a\u4e49special_tokens\u548cchat_template\u5417\uff1f": [[70, "q25-model-type-sftspecial-tokenschat-template"]], "Q25: \u8bf7\u95ee\u8bc4\u6d4b\u65f6eval_backend='OpenCompass'\uff0c\u600e\u4e48\u6307\u5b9a\u79bb\u7ebf\u6570\u636e\u96c6\u8def\u5f84\uff1f": [[70, "q25-eval-backend-opencompass"]], "Q25: \u8bf7\u95ee\uff0c\u5bfc\u51fa\u548c\u91cf\u5316\u7684\u65f6\u5019\u53ef\u4ee5\u591a\u5361\u5417\uff1f": [[70, "q25"]], "Q26: Can I use DPO to train Qwen2-VL in a Python script?": [[131, "q26-can-i-use-dpo-to-train-qwen2-vl-in-a-python-script"]], "Q26: What causes the following error when using evalscope?": [[131, "q26-what-causes-the-following-error-when-using-evalscope"]], "Q26: When using swift export with a custom template_type, does it permanently change the template_type? If we use swift export --template_type custom, does it change the model's template?": [[131, "q26-when-using-swift-export-with-a-custom-template-type-does-it-permanently-change-the-template-type-if-we-use-swift-export-template-type-custom-does-it-change-the-model-s-template"]], "Q26: swift export\u7684\u65f6\u5019\u4f20\u5165\u81ea\u5b9a\u4e49\u7684template_type,\u662f\u4e0d\u662f\u5c31\u53ef\u4ee5\u6c38\u4e45\u6539\u6389template_type\u4e86\uff1f\u5982\u679cswift export --template_type \u81ea\u5b9a\u4e49,\u662f\u4e0d\u662f\u5c31\u53ef\u4ee5\u628a\u6a21\u578b\u5bf9\u5e94\u7684template\u6539\u6389": [[70, "q26-swift-exporttemplate-type-template-type-swift-export-template-type-template"]], "Q26: \u53ef\u4ee5\u5728python\u811a\u672c\u91cc\u9762\u7528DPO\u53bb\u8bad\u7ec3qwen2-vl\u5417\uff1f": [[70, "q26-pythondpoqwen2-vl"]], "Q26: \u7528evalscope\u62a5\u8fd9\u4e2a\u9519\u662f\u4ec0\u4e48\u539f\u56e0": [[70, "q26-evalscope"]], "Q27: AWQ quantization for Qwen2VL gives error: TypeError: Qwen2VLForConditionalGeneration.init() got an unexpected keyword argument 'use_cache'": [[131, "q27-awq-quantization-for-qwen2vl-gives-error-typeerror-qwen2vlforconditionalgeneration-init-got-an-unexpected-keyword-argument-use-cache"]], "Q27: Can I pre-train with pure text before fine-tuning on a VQA dataset for MLLM?": [[131, "q27-can-i-pre-train-with-pure-text-before-fine-tuning-on-a-vqa-dataset-for-mllm"]], "Q27: Why is there no issue with plain text, but when testing multi-modal data, even though we specify the path, it still fails to detect the dataset and attempts to download it?": [[131, "q27-why-is-there-no-issue-with-plain-text-but-when-testing-multi-modal-data-even-though-we-specify-the-path-it-still-fails-to-detect-the-dataset-and-attempts-to-download-it"]], "Q27: awq\u91cf\u5316Qwen2VL\u62a5\u9519\uff1aTypeError: Qwen2VLForConditionalGeneration.init() got an unexpected keyword argument 'use_cache'": [[70, "q27-awqqwen2vl-typeerror-qwen2vlforconditionalgeneration-init-got-an-unexpected-keyword-argument-use-cache"]], "Q27: \u4e3a\u5565\u7eaf\u6587\u672c\u6ca1\u95ee\u9898\uff0c\u6d4b\u591a\u6a21\u6001\u6211\u4eec\u6307\u5b9a\u8def\u5f84\u4e86\uff0c\u4f46\u4ed6\u8fd8\u662f\u68c0\u6d4b\u4e0d\u5230\u6570\u636e\u96c6\uff0c\u4f1a\u53bb\u4e0b\u8f7d\uff1f": [[70, "q27"]], "Q27: \u8bf7\u95ee\u8bad\u7ec3MLLM\u65f6\uff0c\u53ef\u5426\u5148\u8fdb\u884c\u7eaf\u6587\u672c\u7684\u9884\u8bad\u7ec3\uff0c\u7136\u540e\u63a5\u5165VQA\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\u5462\uff1f": [[70, "q27-mllm-vqa"]], "Q28: Could you explain how the score in evalscope is calculated? Is there any documentation about this part?": [[131, "q28-could-you-explain-how-the-score-in-evalscope-is-calculated-is-there-any-documentation-about-this-part"]], "Q28: For DDP inference, does max_batch_size in infer refer to batch size per GPU or total batch size?": [[131, "q28-for-ddp-inference-does-max-batch-size-in-infer-refer-to-batch-size-per-gpu-or-total-batch-size"]], "Q28: When conducting DPO training based on the qwen2 SFT model on a V100 machine, the training shows NaN?": [[131, "q28-when-conducting-dpo-training-based-on-the-qwen2-sft-model-on-a-v100-machine-the-training-shows-nan"]], "Q28: ddp \u63a8\u7406\uff0cinfer\u91cc\u9762\u7684\u8fd9\u4e2amax_batch_size\uff0c\u662f\u6307\u6bcf\u5f20\u5361\u7684batch_size\u8fd8\u662f\u603b\u7684batch_size": [[70, "q28-ddp-infermax-batch-size-batch-sizebatch-size"]], "Q28: \u57fa\u4e8eqwen2\u7684sft\u6a21\u578b\u8fdb\u884cdpo\u8bad\u7ec3\uff0cv100\u7684\u673a\u5668\uff0c\u8bad\u7ec3\u65f6\u90fd\u662fNan\u5462\uff1f": [[70, "q28-qwen2sftdpo-v100-nan"]], "Q28: \u8bf7\u6559\u4e0b\uff0cevalscope\u7684score\u662f\u5982\u4f55\u8ba1\u7b97\u7684\uff0c\u8fd9\u90e8\u5206\u6709\u6587\u6863\u8bf4\u660e\u5417\uff1f": [[70, "q28-evalscopescore"]], "Q29: Does Swift support distillation?": [[131, "q29-does-swift-support-distillation"]], "Q29: Does swift.inference now support messages format input? It seems to only support query format currently. The answer contains part of the prompt, how should I modify the inference to complete the answer?": [[131, "q29-does-swift-inference-now-support-messages-format-input-it-seems-to-only-support-query-format-currently-the-answer-contains-part-of-the-prompt-how-should-i-modify-the-inference-to-complete-the-answer"]], "Q29: When using swift eval for benchmark evaluation, can I specify an llm as a judge and how should I pass in the parameters?": [[131, "q29-when-using-swift-eval-for-benchmark-evaluation-can-i-specify-an-llm-as-a-judge-and-how-should-i-pass-in-the-parameters"]], "Q29: \u60f3\u95ee\u4e00\u4e0b\uff0cswift\uff0c\u80fd\u652f\u6301\u84b8\u998f\u5417\uff1f": [[70, "q29-swift"]], "Q29: \u8bf7\u95eeswift.inference\u73b0\u5728\u652f\u6301messages\u683c\u5f0f\u7684\u8f93\u5165\u5417\uff1f\u73b0\u5728\u770b\u5230\u597d\u50cf\u53ea\u80fd\u7528query\u683c\u5f0f\uff0c\u5f97\u5230response\u3002\u6570\u636eanswer\u91cc\u9762\u5df2\u7ecf\u5305\u542b\u4e86\u90e8\u5206prompt\uff0c\u5e0c\u671b\u8865\u5168answer\uff0c\u5e94\u8be5\u600e\u4e48\u4fee\u6539inference": [[70, "q29-swift-inferencemessages-query-responseanswerprompt-answer-inference"]], "Q29: \u8bf7\u95ee\u4e00\u4e0bswift eval\u505abenchmark\u8bc4\u6d4b\u7684\u65f6\u5019\uff0c\u662f\u5426\u53ef\u4ee5\u6307\u5b9allm\u4f5c\u4e3ajudge, \u53c2\u6570\u5e94\u8be5\u600e\u4e48\u4f20\u8fdb\u53bb\uff1f": [[70, "q29-swift-evalbenchmark-llmjudge"]], "Q2: How to use a custom evaluation dataset?": [[131, "q2-how-to-use-a-custom-evaluation-dataset"]], "Q2: How to use the trained model for inference with a dataset?": [[131, "q2-how-to-use-the-trained-model-for-inference-with-a-dataset"]], "Q2: How to use vllm for multi-card deployment?": [[131, "q2-how-to-use-vllm-for-multi-card-deployment"]], "Q2: What data formats are supported when training with custom datasets?": [[131, "q2-what-data-formats-are-supported-when-training-with-custom-datasets"]], "Q2: \u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u8bad\u7ec3\u65f6\u652f\u6301\u7684\u6570\u636e\u683c\u5f0f\u6709\u54ea\u4e9b\uff1f": [[70, "q2"]], "Q2: \u5982\u4f55\u4f7f\u7528vllm\u90e8\u7f72\u8fdb\u884c\u591a\u5361\u90e8\u7f72\uff1f": [[70, "q2-vllm"]], "Q2: \u5982\u4f55\u4f7f\u7528\u81ea\u5b9a\u4e49\u8bc4\u6d4b\u96c6\uff1f": [[70, "id9"]], "Q2: \u8bad\u7ec3\u540e\u7684\u6a21\u578b\u5982\u4f55\u4f7f\u7528\u6570\u636e\u96c6\u63a8\u7406\uff1f": [[70, "id5"]], "Q30: How can I make swift infer write results to result_path in real-time instead of writing everything at once at the end?": [[131, "q30-how-can-i-make-swift-infer-write-results-to-result-path-in-real-time-instead-of-writing-everything-at-once-at-the-end"]], "Q30: How can I remove the CoT (Chain-of-Thought) from the model's response before evaluation when using the vlmevalkit backend?": [[131, "q30-how-can-i-remove-the-cot-chain-of-thought-from-the-model-s-response-before-evaluation-when-using-the-vlmevalkit-backend"]], "Q30: How many checkpoints are saved by default after training?": [[131, "q30-how-many-checkpoints-are-saved-by-default-after-training"]], "Q30: \u5f53\u524d\u8bad\u7ec3\u5b8c\u9ed8\u8ba4\u4fdd\u5b58\u591a\u5c11\u4e2acheckpoint\uff1f": [[70, "q30-checkpoint"]], "Q30: \u8bf7\u95eeswift infer\u7684\u65f6\u5019\uff0c\u5982\u4f55\u8ba9\u7ed3\u679c\u5b9e\u65f6\u5199\u5165result_path\uff0c\u800c\u4e0d\u662f\u6700\u540e\u4e00\u6b21\u6027\u5199\u5165\u5462\uff1f": [[70, "q30-swift-infer-result-path"]], "Q30: \u8bf7\u95ee\uff0c\u601d\u8003\u6a21\u578b\u600e\u4e48\u5728response\u4e2d\u53bb\u6389CoT\u518d\u8fdb\u884c\u8bc4\u6d4b\uff1fvlmevalkit\u540e\u7aef": [[70, "q30-responsecot-vlmevalkit"]], "Q31: For embedding evaluation, the first run automatically downloads the dataset. Is it possible to download it manually and then specify a local directory?": [[131, "q31-for-embedding-evaluation-the-first-run-automatically-downloads-the-dataset-is-it-possible-to-download-it-manually-and-then-specify-a-local-directory"]], "Q31: Grounding\u4efb\u52a1\u4e2d\u901a\u7528\u6570\u636e\u683c\u5f0f\u652f\u6301\u4e00\u4e2a\u7c7b\u522b\u6709\u591a\u4e2a\u5b9e\u4f8b\u5417\uff1f": [[70, "q31-grounding"]], "Q31: In grounding tasks, does the universal data format support multiple instances for one category?": [[131, "q31-in-grounding-tasks-does-the-universal-data-format-support-multiple-instances-for-one-category"]], "Q31: When I trained and did inference in Swift it worked, but after merge_lora when using Ollama's API the effect disappeared.": [[131, "q31-when-i-trained-and-did-inference-in-swift-it-worked-but-after-merge-lora-when-using-ollama-s-api-the-effect-disappeared"]], "Q31: \u6211\u5728swift\u8bad\u7ec3\u63a8\u7406\u7684\u65f6\u5019\u662f\u6709\u6548\u679c\u7684\uff0c\u4f46\u662f\u7528merge_lora\u540e\u518d\u901a\u8fc7ollama\u7684api\u5f00\u63a5\u53e3\u7684\u65f6\u5019\u6548\u679c\u5c31\u6ca1\u4e86": [[70, "q31-swift-merge-loraollamaapi"]], "Q31: \u8bf7\u95eeembedding\u8bc4\u6d4b\uff0c\u7b2c\u4e00\u6b21\u8fd0\u884c\u4f1a\u53bb\u5b98\u65b9\u4e0b\u8f7d\u6570\u636e\u96c6\u3002\u53ef\u4ee5\u4e0b\u8f7d\u540e\u6307\u5b9a\u76ee\u5f55\u5417\uff1f": [[70, "q31-embedding"]], "Q32: How can I define custom evaluation metrics?": [[131, "q32-how-can-i-define-custom-evaluation-metrics"]], "Q32: Which parameter should I set if I need to continue inference under a specific prefix during model inference?": [[131, "q32-which-parameter-should-i-set-if-i-need-to-continue-inference-under-a-specific-prefix-during-model-inference"]], "Q32: Why am I getting the error that numpy.object cannot be found?": [[131, "q32-why-am-i-getting-the-error-that-numpy-object-cannot-be-found"]], "Q32: \u6a21\u578b\u63a8\u7406\u7684\u65f6\u5019\u5982\u679c\u9700\u8981\u5728\u7279\u5b9a\u524d\u7f00\u4e0b\u7ee7\u7eed\u63a8\u7406\u7684\u8bdd\u662f\u8bbe\u7f6e\u54ea\u4e2a\u53c2\u6570\uff1f": [[70, "q32"]], "Q32: \u8bf7\u95ee\u600e\u4e48\u81ea\u5b9a\u4e49\u8bc4\u6d4b\u6307\u6807\uff1f": [[70, "id10"]], "Q32: \u8fd9\u4e2a\u9519\u8bef\u4e3a\u4ec0\u4e48\u4f1a\u51fa\u73b0\u5728\u8fd9\uff0cnumpy.object\u627e\u4e0d\u5230\u5728\u54ea\uff1f": [[70, "q32-numpy-object"]], "Q33: Does the Swift framework support sequence parallelism now?": [[131, "q33-does-the-swift-framework-support-sequence-parallelism-now"]], "Q33: For MMVet evaluation, a judge model needs to be configured. I followed this document to set it up, but I'm getting an error. Does the judge model's name have to be one of these three?": [[131, "q33-for-mmvet-evaluation-a-judge-model-needs-to-be-configured-i-followed-this-document-to-set-it-up-but-i-m-getting-an-error-does-the-judge-model-s-name-have-to-be-one-of-these-three"]], "Q33: How do I fix this error that keeps appearing?": [[131, "q33-how-do-i-fix-this-error-that-keeps-appearing"]], "Q33: mmvet\u8bc4\u6d4b\u9700\u8981\u914d\u7f6ejudge model\uff0c\u6309\u8fd9\u4e2a\u6587\u6863\u914d\u7f6ejudge model\uff0c\u88c1\u5224\u6a21\u578b\u7684\u540d\u79f0\u4e00\u5b9a\u8981\u662f\u8fd9\u4e09\u4e2a\u91cc\u9762\u7684\u5417\uff1f": [[70, "q33-mmvetjudge-model-judge-model"]], "Q33: swift\u6846\u67b6\u80fd\u652f\u6301\u5e8f\u5217\u5e76\u884c\u4e86\u5417\uff1f": [[70, "q33-swift"]], "Q33: \u4e00\u76f4\u62a5\u8fd9\u4e2a\u9519\u600e\u4e48\u6539\u5440\uff1f": [[70, "q33"]], "Q34: Inference error, ImportError: cannot import name 'shard_checkpoint' from 'transformers.modeling_utils' (/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py)": [[131, "q34-inference-error-importerror-cannot-import-name-shard-checkpoint-from-transformers-modeling-utils-usr-local-lib-python3-10-dist-packages-transformers-modeling-utils-py"]], "Q34: What could be the reason for uneven GPU memory allocation across multiple cards when running eval?": [[131, "q34-what-could-be-the-reason-for-uneven-gpu-memory-allocation-across-multiple-cards-when-running-eval"]], "Q34: When fine-tuning qwen2-1.5B on a V100, I see loss': 0.0, 'acc': 0.0, 'grad_norm': nan. What is the issue?": [[131, "q34-when-fine-tuning-qwen2-1-5b-on-a-v100-i-see-loss-0-0-acc-0-0-grad-norm-nan-what-is-the-issue"]], "Q34: \u63a8\u7406\u62a5\u9519\uff0cImportError: cannot import name 'shard_checkpoint' from 'transformers.modeling_utils' (/usr/local/lib/python3.10/dist-packages/transformers/modeling_utilspy\uff09": [[70, "q34-importerror-cannot-import-name-shard-checkpoint-from-transformers-modeling-utils-usr-local-lib-python3-10-dist-packages-transformers-modeling-utilspy"]], "Q34: \u7528v100\u5fae\u8c03qwen2-1.5B\u65f6\uff0closs': 0.0, 'acc': 0.0, 'grad_norm': nan\uff0c\u662f\u4ec0\u4e48\u95ee\u9898\u5462?": [[70, "q34-v100qwen2-1-5b-loss-0-0-acc-0-0-grad-norm-nan"]], "Q34: \u8bf7\u95ee\u5728\u6267\u884ceval\u7684\u65f6\u5019\u51fa\u73b0\u4e86\u591a\u5361\u663e\u5b58\u5206\u914d\u4e0d\u5747\u662f\u4ec0\u4e48\u539f\u56e0\uff1f": [[70, "q34-eval"]], "Q35: Is it possible to fully fine-tune GPTQ quantized models?": [[131, "q35-is-it-possible-to-fully-fine-tune-gptq-quantized-models"]], "Q35: When using evalscope for evaluation, how can I control the input to have a fixed token length?": [[131, "q35-when-using-evalscope-for-evaluation-how-can-i-control-the-input-to-have-a-fixed-token-length"]], "Q35: When using swift sample, it seems that batch processing is not supported? It appears to sample examples one by one in a loop, which is somewhat slow.": [[131, "q35-when-using-swift-sample-it-seems-that-batch-processing-is-not-supported-it-appears-to-sample-examples-one-by-one-in-a-loop-which-is-somewhat-slow"]], "Q35: gptq\u91cf\u5316\u6a21\u578b\uff0c\u80fd\u5168\u53c2\u6570\u5fae\u8c03\u5417\uff1f": [[70, "q35-gptq"]], "Q35: swift sample\u7684\u65f6\u5019\uff0c\u597d\u50cf\u4e0d\u652f\u6301batch\uff1f\u597d\u50cf\u662ffor\u5faa\u73af\u4e00\u4e2a\u4e2a\u4f8b\u5b50sample\uff0c\u6709\u70b9\u6162": [[70, "q35-swift-sample-batch-forsample"]], "Q35: \u8bf7\u95ee\uff0c\u4f7f\u7528evalscope\u8bc4\u6d4b \u5982\u4f55\u63a7\u5236input token\u4e3a\u56fa\u5b9a\u957f\u5ea6\uff1f": [[70, "q35-evalscope-input-token"]], "Q36: Does Swift support inference for embedding models?": [[131, "q36-does-swift-support-inference-for-embedding-models"]], "Q36: What parameters should I set for fine-tuning using QLoRA on glm4-chat?": [[131, "q36-what-parameters-should-i-set-for-fine-tuning-using-qlora-on-glm4-chat"]], "Q36: Why can't evalscope app find the report, even though there are corresponding records in the outputs directory?": [[131, "q36-why-can-t-evalscope-app-find-the-report-even-though-there-are-corresponding-records-in-the-outputs-directory"]], "Q36: evalscope app\u627e\u4e0d\u5230\u62a5\u544a\u662f\u600e\u4e48\u56de\u4e8b\uff0coutputs\u76ee\u5f55\u4e0b\u660e\u660e\u6709\u5bf9\u5e94\u7684\u8bb0\u5f55": [[70, "q36-evalscope-app-outputs"]], "Q36: \u8bf7\u95eeswift\u652f\u6301embedding\u6a21\u578b\u7684\u63a8\u7406\u5417\uff1f": [[70, "q36-swiftembedding"]], "Q36: \u8bf7\u95ee\u5982\u679c\u60f3\u7528qlora\u7684\u65b9\u5f0f\u5fae\u8c03\u7684\u8bdd\u5e94\u8be5\u5982\u4f55\u8bbe\u7f6e\u53c2\u6570\u5462?glm4-chat": [[70, "q36-qlora-glm4-chat"]], "Q37: Does the swift framework support model or tensor parallelism for inference? There is no OOM during training, but OOM occurs during inference.": [[131, "q37-does-the-swift-framework-support-model-or-tensor-parallelism-for-inference-there-is-no-oom-during-training-but-oom-occurs-during-inference"]], "Q37: How do I expand my vocabulary within the Swift framework?": [[131, "q37-how-do-i-expand-my-vocabulary-within-the-swift-framework"]], "Q37: Where can I see what extra fields, besides the question itself, are included in the query sent during a Swift evaluation?": [[131, "q37-where-can-i-see-what-extra-fields-besides-the-question-itself-are-included-in-the-query-sent-during-a-swift-evaluation"]], "Q37: swift\u6846\u67b6\u63a8\u7406\u652f\u6301\u6a21\u578b\u6216\u8005\u5f20\u91cf\u5e76\u884c\u4e48\uff1f\u8bad\u7ec3\u4e0d\u4f1aoom\uff0c\u63a8\u7406\u65f6\u5019\u62a5oom\u4e86": [[70, "q37-swift-oom-oom"]], "Q37: \u8bf7\u6559\u4e00\u4e2a\u95ee\u9898\uff0c\u6211\u5e94\u8be5\u5982\u4f55\u5728swift\u6846\u67b6\u4e0b\u6269\u5145\u6211\u7684\u8bcd\u8868\u5462\uff1f": [[70, "q37-swift"]], "Q37: \u8bf7\u95ee\u54ea\u91cc\u53ef\u4ee5\u770b\u5230swift\u8bc4\u6d4b\u7684\u65f6\u5019\u9001\u5165\u7684query\u9664\u4e86\u95ee\u9898\u4e4b\u5916\u8fd8\u6709\u54ea\u4e9b\u989d\u5916\u7684\u5b57\u6bb5\u5462\uff1f": [[70, "q37-swiftquery"]], "Q38: Can I directly use models with the same name from Hugging Face?": [[131, "q38-can-i-directly-use-models-with-the-same-name-from-hugging-face"]], "Q38: Does streaming inference support DDP?": [[131, "q38-does-streaming-inference-support-ddp"]], "Q38: \u540c\u540d\u7684\u6a21\u578b\u662f\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528huggingface\u4e0a\u7684\u5417\uff1f": [[70, "q38-huggingface"]], "Q38: \u8bf7\u95ee\u6d41\u5f0f\u63a8\u7406\u652f\u6301ddp\u5417\uff1f": [[70, "q38-ddp"]], "Q39: Can Qwen2-VL-2B conduct incremental pre-training? Is there guidance available?": [[131, "q39-can-qwen2-vl-2b-conduct-incremental-pre-training-is-there-guidance-available"]], "Q39: Problem encountered during Ovis2-2B inference": [[131, "q39-problem-encountered-during-ovis2-2b-inference"]], "Q39: \u5728Ovis2-2B\u63a8\u7406\u7684\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u95ee\u9898": [[70, "q39-ovis2-2b"]], "Q39: \u8bf7\u95eeQwen2-VL-2B\u80fd\u8fdb\u884c\u589e\u91cf\u9884\u8bad\u7ec3\u5417\uff1f\u6709\u6307\u5bfc\u6587\u4ef6\u5417?\u6709\u56fe\u6587,\u4e5f\u6709\u7eaf\u6587\u672c\u7684\u3002": [[70, "q39-qwen2-vl-2b"]], "Q3: Can I specify a locally saved model during Swift inference?": [[131, "q3-can-i-specify-a-locally-saved-model-during-swift-inference"]], "Q3: Error with mmengine in python3.11 environment during evaluation": [[131, "q3-error-with-mmengine-in-python3-11-environment-during-evaluation"]], "Q3: How can clients pass images during vllm deployment?": [[131, "q3-how-can-clients-pass-images-during-vllm-deployment"]], "Q3: What is the format for dataset_info.json for custom datasets, and how can I use it?": [[131, "q3-what-is-the-format-for-dataset-info-json-for-custom-datasets-and-how-can-i-use-it"]], "Q3: python3.11\u73af\u5883\uff0c\u8bc4\u6d4b\u65f6mmengine\u62a5\u9519": [[70, "q3-python3-11-mmengine"]], "Q3: swift\u63a8\u7406\u7684\u65f6\u5019\u53ef\u4ee5\u6307\u5b9a\u4e0b\u8f7d\u597d\u7684\u6a21\u578b\u5417\uff1f": [[70, "q3-swift"]], "Q3: \u81ea\u5b9a\u4e49\u6570\u636e\u96c6dataset_info.json\u683c\u5f0f\uff0c\u5982\u4f55\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\uff1f": [[70, "q3-dataset-info-json"]], "Q3: \u8bf7\u95ee\u7528vllm\u90e8\u7f72\u7684\u65f6\u5019\uff0c\u5ba2\u6237\u7aef\u600e\u4e48\u4f20\u5165\u56fe\u7247\uff1f": [[70, "q3-vllm"]], "Q40: I have a question: how do I set up greedy search during GRPO training? The documentation states that for inference, greedy search can be enabled by setting temperature=0. However, applying this setting during training leads to many NaNs when calculating logits / self.temperature. If I set temperature=1, top_k=1, and top_p=1, will the model's output correspond to a greedy search result?": [[131, "q40-i-have-a-question-how-do-i-set-up-greedy-search-during-grpo-training-the-documentation-states-that-for-inference-greedy-search-can-be-enabled-by-setting-temperature-0-however-applying-this-setting-during-training-leads-to-many-nans-when-calculating-logits-self-temperature-if-i-set-temperature-1-top-k-1-and-top-p-1-will-the-model-s-output-correspond-to-a-greedy-search-result"]], "Q40: When training with videos, how can I control the frame sampling rate in the parameters? The frame_rate setting doesn't seem to work, and I'm using MiniCPMV.": [[131, "q40-when-training-with-videos-how-can-i-control-the-frame-sampling-rate-in-the-parameters-the-frame-rate-setting-doesn-t-seem-to-work-and-i-m-using-minicpmv"]], "Q40: \u8bf7\u95ee\u4e0b\u7528\u89c6\u9891\u505a\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u5982\u4f55\u5728\u53c2\u6570\u4e2d\u63a7\u5236\u62bd\u5e27\u7387\uff0c\u8bbe\u4e86frame_rate\u8bbe\u4e0d\u8d77, minicpmv": [[70, "q40-frame-rate-minicpmv"]], "Q40: \u95ee\u4e00\u4e2a\u95ee\u9898\uff0c\u8bf7\u95ee\u5728grpo\u8bad\u7ec3\u4e2d\u5982\u679c\u505a\u8d2a\u5fc3\u641c\u7d22\u90a3\u4e48\u5982\u4f55\u8bbe\u7f6e\u5462\uff1f\u6587\u6863\u4e2d\u6709\u8bf4\u63a8\u7406\u65f6\u53ef\u901a\u8fc7temprature=0\u8bbe\u7f6e\u4e3a\u8d2a\u5fc3\u641c\u7d22\u4f46\u662f\u8bad\u7ec3\u5982\u679c\u8fd9\u6837\u8bbe\u7f6e\uff0c\u8ba1\u7b97logits / self.temperature\uff0clogits\u4f1a\u51fa\u73b0\u5f88\u591anan\uff0c\u662f\u4e0d\u662f\u5c06temperature\u8bbe\u7f6e\u4e3a1\uff0ctopk\u8bbe\u7f6e\u4e3a1\uff0ctopp\u4e5f\u8bbe\u7f6e\u4e3a1\uff0c\u6a21\u578b\u63a8\u7406\u5c31\u662f\u8d2a\u5fc3\u641c\u7d22\u7684\u7ed3\u679c\u5462\uff1f": [[70, "q40-grpo-temprature-0-logits-self-temperature-logitsnan-temperature1-topk1-topp1"]], "Q41: Can I save the inference results of the validation set during training in Swift?": [[131, "q41-can-i-save-the-inference-results-of-the-validation-set-during-training-in-swift"]], "Q41: When using Swift for quantization, which components\u2014activations or weights\u2014are quantized by the GPTQ, AWQ, and FP8 methods respectively?": [[131, "q41-when-using-swift-for-quantization-which-componentsactivations-or-weightsare-quantized-by-the-gptq-awq-and-fp8-methods-respectively"]], "Q41: swift\u5728\u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u628a\u9a8c\u8bc1\u96c6\u7684\u63a8\u7406\u7ed3\u679c\u4fdd\u5b58\u4e0b\u6765\u5417\uff1f": [[70, "q41-swift"]], "Q41: \u8bf7\u95ee\u4e0b\uff0cswift\u505a\u91cf\u5316\u65f6\uff0cgptq/awq/fp8\u4e09\u79cd\u65b9\u6cd5\u5206\u522b\u662f\u9488\u5bf9activation\u548cweight\u4e2d\u7684\u54ea\u4e2a\u505a\u7684\u91cf\u5316\u5462\uff1f": [[70, "q41-swift-gptq-awq-fp8activationweight"]], "Q42: When using ms-swift for inference, I'm seeing a large discrepancy in the results between the Transformers engine and the vLLM engine. What could be the reason?": [[131, "q42-when-using-ms-swift-for-inference-i-m-seeing-a-large-discrepancy-in-the-results-between-the-transformers-engine-and-the-vllm-engine-what-could-be-the-reason"]], "Q42: Why is the saved checkpoint larger than the original model file after full parameter DPO?": [[131, "q42-why-is-the-saved-checkpoint-larger-than-the-original-model-file-after-full-parameter-dpo"]], "Q42: \u6211\u5168\u91cffull\u53c2\u6570dpo\uff0c\u4e3a\u4f55\u4fdd\u5b58\u7684checkpoint \u6bd4\u539f\u672c\u6a21\u578b\u6587\u4ef6\u8981\u5927\u5462?\u6574\u6574\u5927\u4e861\u500d": [[70, "q42-fulldpo-checkpoint-1"]], "Q42: \u8bf7\u95ee\u7528ms-swift\u63a8\u7406\u65f6transformers engine\u548cvllm engine\uff0c\u63a8\u7406\u7ed3\u679c\u5dee\u4e86\u5f88\u591a\uff0c\u8fd9\u4e2a\u662f\u4ec0\u4e48\u539f\u56e0\u5462\uff1f": [[70, "q42-ms-swifttransformers-enginevllm-engine"]], "Q43: Training speed slows down when using multi-machine training; using Swift framework for LLM training with deepspeed zero3 causes significant performance drop.": [[131, "q43-training-speed-slows-down-when-using-multi-machine-training-using-swift-framework-for-llm-training-with-deepspeed-zero3-causes-significant-performance-drop"]], "Q43: When using Swift for Qwen2-Audio inference, the output is garbled/chaotic. What could be the potential cause?": [[131, "q43-when-using-swift-for-qwen2-audio-inference-the-output-is-garbled-chaotic-what-could-be-the-potential-cause"]], "Q43: \u591a\u673a\u8bad\u7ec3\u901f\u5ea6\u7f13\u6162\uff0c\u5728\u4f7f\u7528swift\u6846\u67b6\u8fdb\u884cLLM\u8bad\u7ec3\u65f6\uff0c\u53d1\u73b0\u91c7\u7528deepspeed zero3\u8bad\u7ec3\u4f1a\u51fa\u73b0\u4e25\u91cd\u7684\u901f\u5ea6\u4e0b\u964d\u95ee\u9898": [[70, "q43-swiftllm-deepspeed-zero3"]], "Q43: \u8bf7\u95ee\u7528swift\u505aqwen2audio\u7684\u63a8\u7406\uff0c\u63a8\u7406\u7ed3\u679c\u51fa\u73b0\u6df7\u4e71\uff0c\u53ef\u80fd\u662f\u5565\u539f\u56e0\u5462\uff1f": [[70, "q43-swiftqwen2audio"]], "Q44: Does Swift now support multi-stage pre-training for qwen2-vl? It looks like the official best practices only show SFT training with vit+llm together, not sure if separate fine-tuning is supported.": [[131, "q44-does-swift-now-support-multi-stage-pre-training-for-qwen2-vl-it-looks-like-the-official-best-practices-only-show-sft-training-with-vit-llm-together-not-sure-if-separate-fine-tuning-is-supported"]], "Q44: For multi-GPU inference, does --max_batch_size represent the total batch size summed across all GPUs?": [[131, "q44-for-multi-gpu-inference-does-max-batch-size-represent-the-total-batch-size-summed-across-all-gpus"]], "Q44: swift\u73b0\u5728\u662f\u652f\u6301qwen2-vl\u591a\u9636\u6bb5\u9884\u8bad\u7ec3\u7684\u5417\uff1f\u6211\u770b\u5b98\u65b9\u7684\u6700\u4f73\u5b9e\u8df5\u91cc\u7684sft\u597d\u50cf\u90fd\u662fvit+llm\u4e00\u8d77\u8bad\u7684\uff0c\u4e0d\u77e5\u9053\u652f\u4e0d\u652f\u6301\u5355\u72ecfinetune": [[70, "q44-swiftqwen2-vl-sftvit-llm-finetune"]], "Q44: \u591a\u5361\u63a8\u7406\uff0c--max_batch_size\u662f\u6240\u6709\u5361\u52a0\u8d77\u6765\u7684batch_size\u5417\uff1f": [[70, "q44-max-batch-sizebatch-size"]], "Q45: Does qwen2-vl support mixing pure text data?": [[131, "q45-does-qwen2-vl-support-mixing-pure-text-data"]], "Q45: For inference, can I only pass an image file path, or is there a way to pass an Image object directly?": [[131, "q45-for-inference-can-i-only-pass-an-image-file-path-or-is-there-a-way-to-pass-an-image-object-directly"]], "Q45: qwen2-vl\u662f\u4e0d\u662f\u4e0d\u652f\u6301\u6df7\u5408\u7eaf\u6587\u672c\u6570\u636e?": [[70, "q45-qwen2-vl"]], "Q45: \u63a8\u7406\u53ea\u80fd\u4f20\u56fe\u7247\u8def\u5f84\u5417\uff1f\u6709\u6ca1\u6709\u529e\u6cd5\u4f20Image\u5bf9\u8c61\uff1f": [[70, "q45-image"]], "Q46: A model trained with Swift cannot be loaded via ModelScope. How can this be resolved?": [[131, "q46-a-model-trained-with-swift-cannot-be-loaded-via-modelscope-how-can-this-be-resolved"]], "Q46: Can I plot loss curves for different datasets during fine-tuning?": [[131, "q46-can-i-plot-loss-curves-for-different-datasets-during-fine-tuning"]], "Q46: swift\u8bad\u7ec3\u7684\u6a21\u578b\u4e0d\u80fd\u901a\u8fc7modelscope\u52a0\u8f7d\uff0c\u600e\u4e48\u89e3\u51b3\u7684\uff1f": [[70, "q46-swiftmodelscope"]], "Q46: \u5fae\u8c03\u7684\u65f6\u5019\u53ef\u4ee5\u7ed8\u5236\u4e0d\u540c\u6570\u636e\u96c6\u7684loss\u66f2\u7ebf\u5417\uff1f": [[70, "q46-loss"]], "Q47: After model training, the responses have a lot of repeated content.": [[131, "q47-after-model-training-the-responses-have-a-lot-of-repeated-content"]], "Q47: Is there an example script that supports outputting last_hidden_state during large language model inference?": [[131, "q47-is-there-an-example-script-that-supports-outputting-last-hidden-state-during-large-language-model-inference"]], "Q47: \u6709\u6ca1\u6709\u793a\u4f8b\u811a\u672c\u652f\u6301\u5927\u6a21\u578b\u63a8\u7406\u7684\u65f6\u5019\u8f93\u51falast_hidden_state\uff1f": [[70, "q47-last-hidden-state"]], "Q47: \u6a21\u578b\u8bad\u7ec3\u540e\uff0c\u56de\u590d\u91cd\u590d\u4e86\u5f88\u591a\u5185\u5bb9": [[70, "q47"]], "Q48: After fine-tuning an adapter using --init_weights lora-ga, I encounter the following error during inference. How can I resolve it?": [[131, "q48-after-fine-tuning-an-adapter-using-init-weights-lora-ga-i-encounter-the-following-error-during-inference-how-can-i-resolve-it"]], "Q48: Does Swift currently support prompt tuning or prefix tuning?": [[131, "q48-does-swift-currently-support-prompt-tuning-or-prefix-tuning"]], "Q48: \u60f3\u95ee\u4e00\u4e0bswift\u76ee\u524d\u652f\u6301prompt tuning\u6216\u8005prefix tuning\u5417\uff1f": [[70, "q48-swiftprompt-tuningprefix-tuning"]], "Q48: \u8bf7\u95ee\uff0c\u7528--init_weights lora-ga\u5fae\u8c03\u5b8c\u7684adaper\uff0c\u63a8\u7406\u7684\u65f6\u5019\u4f1a\u62a5\u8fd9\u79cd\u9519\u8bef\uff0c\u5982\u4f55\u89e3\u51b3\uff1f": [[70, "q48-init-weights-lora-gaadaper"]], "Q49: Does the swift infer command support distributed inference across multiple nodes?": [[131, "q49-does-the-swift-infer-command-support-distributed-inference-across-multiple-nodes"]], "Q49: I encountered the following error when training with two A10s:": [[131, "q49-i-encountered-the-following-error-when-training-with-two-a10s"]], "Q49: \u4e24\u5f20A10\u8bad\u7ec3\u62a5\u9519\u5982\u4e0b\uff1a": [[70, "q49-a10"]], "Q49: \u4f7f\u7528swift infer\u547d\u4ee4\u8fdb\u884c\u63a8\u7406\uff0c\u652f\u6301\u591a\u673a\u63a8\u7406\u5417\uff1f": [[70, "q49-swift-infer"]], "Q4: After manually downloading the official evaluation dataset, can Swift eval be configured for local path evaluation?": [[131, "q4-after-manually-downloading-the-official-evaluation-dataset-can-swift-eval-be-configured-for-local-path-evaluation"]], "Q4: How can I train with a custom dataset using the interface?": [[131, "q4-how-can-i-train-with-a-custom-dataset-using-the-interface"]], "Q4: How do I infer on a dataset without labels? I see that the dataset format in the documentation is all for the training set.": [[131, "q4-how-do-i-infer-on-a-dataset-without-labels-i-see-that-the-dataset-format-in-the-documentation-is-all-for-the-training-set"]], "Q4: I have a question about deploying qwen2-7b and using it with a client. When calling the OpenAI API, should I use client.completions.create instead of client.chat.completions.create, but when using qwen2-7b-instruct-q5_k_m.gguf, I can use client.chat.completions.create. Why is that?": [[131, "q4-i-have-a-question-about-deploying-qwen2-7b-and-using-it-with-a-client-when-calling-the-openai-api-should-i-use-client-completions-create-instead-of-client-chat-completions-create-but-when-using-qwen2-7b-instruct-q5-k-m-gguf-i-can-use-client-chat-completions-create-why-is-that"]], "Q4: \u5982\u4f55\u5728\u754c\u9762\u8bad\u7ec3\u4f7f\u7528\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\uff1f": [[70, "q4"]], "Q4: \u5b98\u65b9\u652f\u6301\u7684\u8bc4\u6d4b\u6570\u636e\u96c6\u624b\u52a8\u4e0b\u8f7d\u540e\uff0cswift eval\u80fd\u914d\u7f6e\u672c\u5730\u8def\u5f84\u8bc4\u6d4b\u5417\uff1f": [[70, "q4-swift-eval"]], "Q4: \u6211\u60f3\u5728\u4e00\u4e2a\u6ca1\u6709label\u7684\u6570\u636e\u96c6\u4e0a\u63a8\u7406\uff0c\u600e\u4e48\u505a\u5462\uff1f\u6211\u770b\u6587\u6863\u91cc\u9762\u7684\u6570\u636e\u96c6\u683c\u5f0f\u90fd\u662f\u8bad\u7ec3\u96c6": [[70, "q4-label"]], "Q4: \u6709\u4e2a\u95ee\u9898\u60f3\u95ee\u4e00\u4e0b\uff0cqwen2-7b\u90e8\u7f72\u540e\u4f7f\u7528\u5ba2\u6237\u7aef\u65f6\uff0c\u8c03\u7528openai\u7684api\u8981\u4f7f\u7528client.completions.create\uff0c\u4e0d\u80fd\u4f7f\u7528client.chat.completions.create\uff0c\u4f46\u662f\u4f7f\u7528qwen2-7b-instruct-q5_k_m.gguf\u7684\u65f6\u5019\u53ef\u4ee5\u4f7f\u7528client.chat.completions.create\uff0c\u8fd9\u662f\u4e3a\u4ec0\u4e48\u5440\uff1f": [[70, "q4-qwen2-7b-openaiapiclient-completions-create-client-chat-completions-create-qwen2-7b-instruct-q5-k-m-ggufclient-chat-completions-create"]], "Q50: How can I calculate metrics like acc/rouge during inference?": [[131, "q50-how-can-i-calculate-metrics-like-acc-rouge-during-inference"]], "Q50: How to solve the issue of certain parameters not participating in backpropagation when freezing layers during DDP fine-tuning?": [[131, "q50-how-to-solve-the-issue-of-certain-parameters-not-participating-in-backpropagation-when-freezing-layers-during-ddp-fine-tuning"]], "Q50: \u63a8\u7406\u65f6\u5982\u4f55\u8ba1\u7b97acc/rouge\u7b49\u6307\u6807\uff1f": [[70, "q50-acc-rouge"]], "Q50: \u8bf7\u95ee\u5728\u91c7\u7528DDP\u5fae\u8c03\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\uff0c\u51bb\u7ed3\u67d0\u4e9b\u5c42\u65f6\u5bfc\u81f4\u7684\u67d0\u4e9b\u53c2\u6570\u672a\u53c2\u4e0e\u68af\u5ea6\u56de\u4f20\u95ee\u9898\u600e\u4e48\u89e3\u51b3\uff1f": [[70, "q50-ddp"]], "Q51: Does Swift have a dataset quality inspection tool?": [[131, "q51-does-swift-have-a-dataset-quality-inspection-tool"]], "Q51: How do I set the system_prompt to be empty? I removed the --system parameter, but it still adds a default system prompt.": [[131, "q51-how-do-i-set-the-system-prompt-to-be-empty-i-removed-the-system-parameter-but-it-still-adds-a-default-system-prompt"]], "Q51: swift\u6709\u6ca1\u6709\u6570\u636e\u96c6\u8d28\u68c0\u5de5\u5177\uff1f": [[70, "q51-swift"]], "Q51: \u5982\u4f55\u5c06system_prompt\u7f6e\u7a7a\uff1f\u6211\u5220\u9664\u4e86--system\u53c2\u6570\uff0c\u4f46\u662f\u5b83\u4f1a\u7ed9\u6211\u52a0\u4e0a\u9ed8\u8ba4\u7684system\u3002": [[70, "q51-system-prompt-system-system"]], "Q52: My inference data has an \"extra\" field, but this field is not saved in the inference results. How can I configure it to save these extra fields?": [[131, "q52-my-inference-data-has-an-extra-field-but-this-field-is-not-saved-in-the-inference-results-how-can-i-configure-it-to-save-these-extra-fields"]], "Q52: Where to start model parallelism on the web? I only found the option to check for data parallelism.": [[131, "q52-where-to-start-model-parallelism-on-the-web-i-only-found-the-option-to-check-for-data-parallelism"]], "Q52: web\u7aef\u5728\u54ea\u542f\u52a8\u6a21\u578b\u5e76\u884c?\u53ea\u627e\u5230\u4e86\u6570\u636e\u5e76\u884c\u7684\u52fe\u9009\u9879\uff0c\u6ca1\u627e\u5230\u6a21\u578b\u5e76\u884c\u5728\u54ea\u3002": [[70, "q52-web"]], "Q52: \u63a8\u7406\u6570\u636e\u91cc\u9762\u6709\u4e00\u4e2aextra\u5b57\u6bb5\uff0c\u63a8\u7406\u7ed3\u679c\u6ca1\u6cd5\u4fdd\u5b58\u8fd9\u4e2a\u5b57\u6bb5\uff0c\u5e94\u8be5\u5982\u4f55\u8bbe\u7f6e\u624d\u80fd\u4fdd\u5b58\u989d\u5916\u7684\u5b57\u6bb5\u5462\uff1f": [[70, "q52-extra"]], "Q53: How can I set a fixed location for dataset downloads when using --dataset? I can't find this in command line parameters. How can I read from the download location next time?": [[131, "q53-how-can-i-set-a-fixed-location-for-dataset-downloads-when-using-dataset-i-can-t-find-this-in-command-line-parameters-how-can-i-read-from-the-download-location-next-time"]], "Q53: \u8bbe\u7f6e--dataset\u7684\u8bdd\uff0c\u600e\u4e48\u8ba9\u6570\u636e\u96c6\u4e0b\u8f7d\u5230\u56fa\u5b9a\u4f4d\u7f6e\uff0c\u6211\u5728\u547d\u4ee4\u884c\u53c2\u6570\u6ca1\u627e\u5230\uff0c\u4e0b\u6b21\u5982\u679c\u518d\u6b21\u8bfb\u53d6\u7684\u8bdd\u5982\u4f55\u53ef\u4ee5\u4ece\u4e0b\u8f7d\u7684\u5730\u65b9\u8bfb\u53d6": [[70, "q53-dataset"]], "Q54: --streaming true\uff0c\u6211\u8bbe\u7f6enum_train_epochs\u4f1a\u62a5\u9519\u8ba9\u6211\u8bbe\u7f6emax_steps\u3002\u4e0d\u53ef\u4ee5\u53ea\u8bbe\u7f6enum_train_epochs\u5417\uff1f": [[70, "q54-streaming-true-num-train-epochsmax-stepsnum-train-epochs"]], "Q54: When using --streaming true, I get an error asking me to set max_steps when setting num_train_epochs. Can't I just set num_train_epochs?": [[131, "q54-when-using-streaming-true-i-get-an-error-asking-me-to-set-max-steps-when-setting-num-train-epochs-can-t-i-just-set-num-train-epochs"]], "Q55: Why is tools in \"[]\" format rather than directly using []? Could you explain why tools uses this \"[]\" format instead of direct [] notation?": [[131, "q55-why-is-tools-in-format-rather-than-directly-using-could-you-explain-why-tools-uses-this-format-instead-of-direct-notation"]], "Q55: \u597d\u5947tools\u4e3a\u5565\u662f\"[]\"\uff0c\u4e0d\u662f\u76f4\u63a5\u652f\u6301[]\u5462\uff0c\u80fd\u5426\u5e2e\u5fd9\u89e3\u7b54\u4e00\u4e0b\uff0c\u8fd9\u4e2atools\u4e3a\u5565\u662f\"[]\"\u8fd9\u79cd\u683c\u5f0f\u5462\uff0c\u4e0d\u662f\u76f4\u63a5\u4f7f\u7528[]\u5462\uff0c\u6709\u4e9b\u4e0d\u7406\u89e3": [[70, "q55-tools-tools"]], "Q56: Can't this parameter be used? check_dataset_strategy==discard": [[131, "q56-can-t-this-parameter-be-used-check-dataset-strategy-discard"]], "Q56: \u8fd9\u4e2a\u53c2\u6570\u4e0d\u80fd\u7528\u5417\uff1fcheck_dataset_strategy==discard": [[70, "q56-check-dataset-strategy-discard"]], "Q57: Getting this error when running sft command:": [[131, "q57-getting-this-error-when-running-sft-command"]], "Q57: \u8fd0\u884csft\u547d\u4ee4\u51fa\u73b0\u62a5\u9519\u5982\u4e0b\uff1a": [[70, "q57-sft"]], "Q58: Have you encountered this issue? AttributeError:'TrainerState' object has no attribute 'last_model_checkpoint'": [[131, "q58-have-you-encountered-this-issue-attributeerror-trainerstate-object-has-no-attribute-last-model-checkpoint"]], "Q58: \u6709\u9047\u5230\u8fc7\u8fd9\u4e2a\u95ee\u9898\u561b\uff1fAttributeError:\u2019TrainerState\u2019 object has no attribute \u2019last_model_checkpoint\u2019": [[70, "q58-attributeerror-trainerstate-object-has-no-attribute-last-model-checkpoint"]], "Q59: I see preprocess can be defined in CustomPreprocessor. Is this processed all at once before training starts, or loaded during training?": [[131, "q59-i-see-preprocess-can-be-defined-in-custompreprocessor-is-this-processed-all-at-once-before-training-starts-or-loaded-during-training"]], "Q59: \u6211\u770b\u5230custompreprocessor\u91cc\u9762\u53ef\u4ee5\u5b9a\u4e49preprocess\uff0c\u8fd9\u4e2a\u662f\u5728\u8bad\u7ec3\u5f00\u59cb\u524d\u5168\u90e8\u4f1a\u5904\u7406\u597d\uff0c\u8fd8\u662f\u4e00\u8fb9\u8bad\u7ec3\u4e00\u8fb9\u52a0\u8f7d\u7684\u554a": [[70, "q59-custompreprocessorpreprocess"]], "Q5: After launching the server with swift deploy using two cards, when I exit with Ctrl+C, there is always a Python process that continues to occupy the memory of one card. Is this a normal phenomenon?": [[131, "q5-after-launching-the-server-with-swift-deploy-using-two-cards-when-i-exit-with-ctrl-c-there-is-always-a-python-process-that-continues-to-occupy-the-memory-of-one-card-is-this-a-normal-phenomenon"]], "Q5: Can I write a line in the jsonl file like this? {\"index\": \"00000\", \"query\": \"11111\", \"response\": \"22222\", 'source':'qqq'}": [[131, "q5-can-i-write-a-line-in-the-jsonl-file-like-this-index-00000-query-11111-response-22222-source-qqq"]], "Q5: How to resolve the error ValueError: Input length of input_ids is 35, but max_length is set to 20?": [[131, "q5-how-to-resolve-the-error-valueerror-input-length-of-input-ids-is-35-but-max-length-is-set-to-20"]], "Q5: Is there a bug with custom evaluation? I modified the standard example to English, but it doesn't work?": [[131, "q5-is-there-a-bug-with-custom-evaluation-i-modified-the-standard-example-to-english-but-it-doesn-t-work"]], "Q5: \u4f7f\u7528\u4e24\u5f20\u5361\u7528swift deploy\u542f\u52a8\u670d\u52a1\u7aef\u540e\uff0c\u7528Ctrl+C\u9000\u51fa\u540e\uff0c\u4f1a\u4e00\u76f4\u6709\u4e00\u4e2apython\u8fdb\u7a0b\uff0c\u4e00\u76f4\u5360\u7528\u4e00\u5f20\u5361\u7684\u663e\u5b58\uff0c\u8fd9\u662f\u6b63\u5e38\u73b0\u8c61\u5417\uff1f": [[70, "q5-swift-deploy-ctrl-c-python"]], "Q5: \u6570\u636e\u96c6jsonl\u6587\u4ef6\u91cc\u7684\u4e00\u884c\u80fd\u4e0d\u80fd\u5199\u6210\u8fd9\u6837\uff1f{\"index\": \"00000\", \"query\": \"11111\", \"response\": \"22222\", 'source':'qqq'}": [[70, "q5-jsonl-index-00000-query-11111-response-22222-source-qqq"]], "Q5: \u81ea\u5b9a\u4e49\u8bc4\u6d4b\u662f\u4e0d\u662f\u6709bug\uff0c\u628a\u6807\u51c6\u4f8b\u5b50\u6539\u6210\u82f1\u6587\uff0c\u4e00\u76f4\u90fd\u8dd1\u4e0d\u901a\uff1f": [[70, "q5-bug"]], "Q5: \u9047\u5230\u62a5\u9519ValueError: Input length of input_ids is 35, but max_length is set to 20.\u5982\u4f55\u89e3\u51b3\uff1f": [[70, "q5-valueerror-input-length-of-input-ids-is-35-but-max-length-is-set-to-20"]], "Q60: For full-parameter training of internvl2_5, why do vision_model and mlp1 appear in freeze parameters by default? Documentation shows freeze_parameters defaults to [], and command line settings for freeze vit, freeze aligner, freeze llm are all False. It prints trainable parameters: ['mlp1'] - unclear if only mlp1 is trainable or all parameters": [[131, "q60-for-full-parameter-training-of-internvl2-5-why-do-vision-model-and-mlp1-appear-in-freeze-parameters-by-default-documentation-shows-freeze-parameters-defaults-to-and-command-line-settings-for-freeze-vit-freeze-aligner-freeze-llm-are-all-false-it-prints-trainable-parameters-mlp1-unclear-if-only-mlp1-is-trainable-or-all-parameters"]], "Q60: \u5168\u53c2\u6570\u8bad\u7ec3internvl2_5\uff0c\u4e3a\u5565\u91cc\u9762\u7684 freeze parameters\u9ed8\u8ba4\u5c31\u6709vision_model \u548c mlp1\uff1f\u6211\u770b\u547d\u4ee4\u884c\u53c2\u6570\u7684\u6587\u6863\u91cc\u9762freeze parameters\u9ed8\u8ba4\u4e3a[],\u547d\u4ee4\u4e2d\u663e\u793a\u8bbe\u7f6e freeze vit\uff0c freeze aligner\uff0c freeze llm\u90fd\u4e3aFalse\uff0c\u53c8\u4f1a\u6253\u5370\u51fa\u6765trainable parameters\uff1a[\u2018mlp1\u2019] \u4e5f\u4e0d\u77e5\u9053\u662f\u6307\u53ea\u6709mlp1\u53ef\u4ee5train \u8fd8\u662f \u6240\u6709\u7684paras\u90fd\u53ef\u4ee5train \u53ea\u662fmlp1\u6253\u5370\u4e00\u4e0b": [[70, "q60-internvl2-5-freeze-parametersvision-model-mlp1-freeze-parameters-freeze-vit-freeze-aligner-freeze-llmfalse-trainable-parameters-mlp1-mlp1train-parastrain-mlp1"]], "Q61: Does LlamaPro in swift support multimodal adaptation?": [[131, "q61-does-llamapro-in-swift-support-multimodal-adaptation"]], "Q61: \u8bf7\u95eeswift\u4e2d\u7684llamapro\u5bf9\u591a\u6a21\u6001\u505a\u9002\u914d\u4e86\u5417\uff1f": [[70, "q61-swiftllamapro"]], "Q62: I noticed 2.x supports MAX_PIXELS. Is the --max_pixel parameter in 3.x documentation the same thing? What's the processing logic? Using 12000*9000 images with internvl still crashes in 2.x even with resacle_image": [[131, "q62-i-noticed-2-x-supports-max-pixels-is-the-max-pixel-parameter-in-3-x-documentation-the-same-thing-what-s-the-processing-logic-using-12000-9000-images-with-internvl-still-crashes-in-2-x-even-with-resacle-image"]], "Q62: \u6211\u53d1\u73b02.x\u652f\u6301MAX_PIXELS\uff0c3.x\u6587\u6863\u91cc\u6709\u4e2a--max_pixel\u53c2\u6570\u662f\u4e00\u4e2a\u610f\u601d\u5417\uff0c\u4ed6\u7684\u5904\u7406\u903b\u8f91\u662f\u5565\u6837\u7684\uff1f\u6211\u752812000*9000\u7684\u56fe\u7247\uff0c2.x\u8bbe\u7f6eresacle_image\u8bad\u7ec3internvl\u8fd8\u662f\u4f1a\u5d29": [[70, "q62-2-xmax-pixels-3-x-max-pixel-12000-9000-2-xresacle-imageinternvl"]], "Q63: Is there documentation for fine-tuning qwen base model to chat model? Any special configurations needed?": [[131, "q63-is-there-documentation-for-fine-tuning-qwen-base-model-to-chat-model-any-special-configurations-needed"]], "Q63: \u4eceqwen base\u6a21\u578b\u5fae\u8c03\u6210chat\u6a21\u578b\u6709\u6ca1\u6709\u5b9e\u8df5\u6587\u6863\uff0c\u6709\u4ec0\u4e48\u8981\u7279\u522b\u914d\u7f6e\u7684\u5417?": [[70, "q63-qwen-basechat"]], "Q64:  Where can I find sequence parallel examples?": [[131, "q64-where-can-i-find-sequence-parallel-examples"]], "Q64: sequence parallel\u4f8b\u5b50\u5728\u54ea\u5440\uff1f": [[70, "q64-sequence-parallel"]], "Q65: Can swift support training custom model structures?": [[131, "q65-can-swift-support-training-custom-model-structures"]], "Q65: swift\u80fd\u652f\u6301\u8bad\u7ec3\u81ea\u5df1\u5b9a\u4e49\u7684\u6a21\u578b\u7ed3\u6784\u5417\uff1f": [[70, "q65-swift"]], "Q66: Getting an error using longlora with \"name_or_path\": \"/mnt/workspace/model/Qwen2.5-14B-Instruct\". Is longlora only for llama series?": [[131, "q66-getting-an-error-using-longlora-with-name-or-path-mnt-workspace-model-qwen2-5-14b-instruct-is-longlora-only-for-llama-series"]], "Q66: \u6211\u7528\"name_or_path\": \"/mnt/workspace/model/Qwen2.5-14B-Instruct\"\u8dd1longlora \u53d1\u73b0\u51fa\u73b0\u4e86\u62a5\u9519\uff0c\u4e0d\u4f1a\u662f\u53ea\u6709\u4e2allama\u7cfb\u5217\u53ef\u4ee5\u4f7f\u7528longlora\u5427": [[70, "q66-name-or-path-mnt-workspace-model-qwen2-5-14b-instruct-longlora-llamalonglora"]], "Q67: How to add custom special tokens in swift?": [[131, "q67-how-to-add-custom-special-tokens-in-swift"]], "Q67: \u60f3\u95ee\u4e0bswift\u600e\u4e48\u52a0\u5165\u81ea\u5df1\u7684special token\uff1f": [[70, "q67-swiftspecial-token"]], "Q68: --freeze_parameters_ratio\u8fd9\u4e2a\u53c2\u6570\uff0c\u5982\u679c\u8bbe\u5b9a\u4e3a0.7\uff0c\u662f\u4e0d\u662f\u8bf4\u660e\u8bad\u7ec3\u7684\u65f6\u5019\u53ea\u66f4\u65b0llm\u768430%\u7684\u53c2\u6570\uff1f\u662f\u968f\u673a\u66f4\u65b030%\u5417\uff0c\u8fd9\u4e2a\u53c2\u6570\u66f4\u65b0\u7684\u673a\u5236\u662f\u4ec0\u4e48\u5440\uff1f": [[70, "q68-freeze-parameters-ratio-0-7-llm30-30"]], "Q68: For --freeze_parameters_ratio parameter, if set to 0.7, does it mean only 30% of llm parameters are updated during training? Is it random 30%? What's the update mechanism?": [[131, "q68-for-freeze-parameters-ratio-parameter-if-set-to-0-7-does-it-mean-only-30-of-llm-parameters-are-updated-during-training-is-it-random-30-what-s-the-update-mechanism"]], "Q69: Why is the map process so slow? Is this normal?": [[131, "q69-why-is-the-map-process-so-slow-is-this-normal"]], "Q69: map\u8fc7\u7a0b\u4e3a\u5565\u8fd9\u4e48\u6162\uff0c\u8fd9\u662f\u6b63\u5e38\u7684\u5417\uff1f": [[70, "q69-map"]], "Q6: The model after eval fine-tuning keeps stopping at a fixed percentage, but the vllm service seems to be running normally. The larger the model, the sooner it disconnects.": [[131, "q6-the-model-after-eval-fine-tuning-keeps-stopping-at-a-fixed-percentage-but-the-vllm-service-seems-to-be-running-normally-the-larger-the-model-the-sooner-it-disconnects"]], "Q6: Where can I find the command line parameters?": [[131, "q6-where-can-i-find-the-command-line-parameters"]], "Q6: Where to check if a model supports lmdeploy or vllm acceleration?": [[131, "q6-where-to-check-if-a-model-supports-lmdeploy-or-vllm-acceleration"]], "Q6: eval\u5fae\u8c03\u540e\u7684\u6a21\u578b\uff0c\u603b\u662f\u4f1a\u5728\u56fa\u5b9a\u7684\u767e\u5206\u6bd4\u505c\u6389\uff0c\u4f46\u662fvllm\u670d\u52a1\u770b\u7740\u4e00\u76f4\u662f\u6709\u5728\u6b63\u5e38\u8fd0\u884c\u7684\u3002\u6a21\u578b\u8d8a\u5927\uff0c\u65ad\u5f00\u7684\u8d8a\u65e9\u3002": [[70, "q6-eval-vllm"]], "Q6: qwen2-vl inference (training) runs out of memory": [[131, "q6-qwen2-vl-inference-training-runs-out-of-memory"]], "Q6: qwen2-vl\u63a8\u7406\uff08\u8bad\u7ec3\uff09\u7206\u663e\u5b58": [[70, "q6-qwen2-vl"]], "Q6: \u547d\u4ee4\u884c\u53c2\u6570\u5728\u54ea\u4e2a\u6587\u6863\u4e2d\u67e5\u770b\uff1f": [[70, "q6"]], "Q6: \u5728\u54ea\u67e5\u770b\u6a21\u578b\u662f\u5426\u652f\u6301lmdeploy\u6216vllm\u52a0\u901f\uff1f": [[70, "q6-lmdeployvllm"]], "Q70: How can I delete and redownload a dataset? I think there might be an issue with the dataset.": [[131, "q70-how-can-i-delete-and-redownload-a-dataset-i-think-there-might-be-an-issue-with-the-dataset"]], "Q70: \u8bf7\u95ee\u6570\u636e\u96c6\u5982\u4f55\u80fd\u591f\u5220\u9664\u91cd\u65b0\u4e0b\u8f7d\uff0c\u611f\u89c9\u6570\u636e\u96c6\u51fa\u4e86\u70b9\u95ee\u9898": [[70, "q70"]], "Q71: How to solve this error: safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge?": [[131, "q71-how-to-solve-this-error-safetensors-rust-safetensorerror-error-while-deserializing-header-headertoolarge"]], "Q71: \u8bf7\u95ee\u8fd9\u4e2a\u95ee\u9898\u5982\u4f55\u89e3\u51b3\uff1fsafetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge": [[70, "q71-safetensors-rust-safetensorerror-error-while-deserializing-header-headertoolarge"]], "Q72: Does swift3.0 not support get_default_template_type?": [[131, "q72-does-swift3-0-not-support-get-default-template-type"]], "Q72: swift3.0\u4e0d\u652f\u6301get_default_template_type\u662f\u5417\uff1f": [[70, "q72-swift3-0get-default-template-type"]], "Q73: Is the default model training using left padding?": [[131, "q73-is-the-default-model-training-using-left-padding"]], "Q73: \u8bf7\u95ee\u9ed8\u8ba4\u6a21\u578b\u8bad\u7ec3\u90fd\u662fleft padding\u662f\u5427?": [[70, "q73-left-padding"]], "Q74: Does it support grounding tasks now?": [[131, "q74-does-it-support-grounding-tasks-now"]], "Q74: \u8bf7\u95ee\u4e0b\u73b0\u5728\u652f\u6301grounding\u4efb\u52a1\u4e86\u5417": [[70, "q74-grounding"]], "Q75: Does ms-swift support contrastive learning for training llm_emb?": [[131, "q75-does-ms-swift-support-contrastive-learning-for-training-llm-emb"]], "Q75: \u8bf7\u95ee\u73b0\u5728ms-swift\u652f\u6301\u5bf9\u6bd4\u5b66\u4e60\uff0c\u4ece\u800c\u8bad\u7ec3llm_emb\u5417?": [[70, "q75-ms-swift-llm-emb"]], "Q76: Is there a big difference in performance between manually coding fine-tuning and GRPO using peft and trl libraries compared to Swift official training with the same parameters?": [[131, "q76-is-there-a-big-difference-in-performance-between-manually-coding-fine-tuning-and-grpo-using-peft-and-trl-libraries-compared-to-swift-official-training-with-the-same-parameters"]], "Q76: \u8bdd\u8bf4\u76f4\u63a5\u4ecepeft\u548ctrl\u5e93\uff0c\u624b\u6413\u5fae\u8c03\u548cgrpo\u4ee3\u7801\u548cswift\u5b98\u65b9\u5728\u540c\u53c2\u6570\u4e0b\u8fdb\u884c\u8bad\u7ec3\uff0c\u6548\u679c\u5dee\u5f02\u5927\u5417\uff1f": [[70, "q76-pefttrl-grposwift"]], "Q77: Does Swift currently not support audio modal input training for minicpmo? It shows error: assert media_type in {'image', 'video'}": [[131, "q77-does-swift-currently-not-support-audio-modal-input-training-for-minicpmo-it-shows-error-assert-media-type-in-image-video"]], "Q77: swift \u76ee\u524d\u4e0d\u652f\u6301 minicpmo \u4f7f\u7528\u97f3\u9891\u6a21\u6001\u8f93\u5165\u7684\u8bad\u7ec3\u5417\uff1f\u4f1a\u62a5\u9519\uff1a assert media_type in {'image', 'video'}": [[70, "q77-swift-minicpmo-assert-media-type-in-image-video"]], "Q78: Can Swift fine-tune deepseek R1 671B?": [[131, "q78-can-swift-fine-tune-deepseek-r1-671b"]], "Q78: swift\u53ef\u4ee5\u5fae\u8c03deepseek R1 671B\u5417\uff1f": [[70, "q78-swiftdeepseek-r1-671b"]], "Q79: Isn't the latest Swift framework supposed to specify the model location using this command? This is the location of the model I've already downloaded, but I don't know why it still tries to download and fails with a git clone error": [[131, "q79-isn-t-the-latest-swift-framework-supposed-to-specify-the-model-location-using-this-command-this-is-the-location-of-the-model-i-ve-already-downloaded-but-i-don-t-know-why-it-still-tries-to-download-and-fails-with-a-git-clone-error"]], "Q79: \u6700\u65b0\u7684swift\u6846\u67b6\u4e0d\u662f\u901a\u8fc7\u8fd9\u4e2a\u547d\u4ee4\u6765\u6307\u5b9a\u6a21\u578b\u7684\u4f4d\u7f6e\u7684\u4e48\uff1f\u8fd9\u662f\u6211\u5df2\u7ecf\u4e0b\u8f7d\u597d\u7684\u6a21\u578b\u4f4d\u7f6e\uff0c\u4e0d\u77e5\u9053\u4e3a\u4ec0\u4e48\u8fd8\u8981\u4e0b\u8f7d\uff0c\u8fd8\u4e0b\u4e0d\u4e0b\u6765\uff0c\u63d0\u793a\u62a5\u9519git clone": [[70, "q79-swift-git-clone"]], "Q7: Does evalscope support multi-model comparison?": [[131, "q7-does-evalscope-support-multi-model-comparison"]], "Q7: On a V100 GPU, in a Python virtual environment, following the environment setup instructions from https://swift2x.readthedocs.io/zh-cn/latest/Multi-Modal/qwen2-vl%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html, when testing the inference command: CUDA_VISIBLE_DEVICES=0,1,2,3 swift infer --model_type qwen2-vl-7b-instruct, an error occurs: RuntimeError: probability tensor contains either 'inf', 'nan' or element < 0.": [[131, "q7-on-a-v100-gpu-in-a-python-virtual-environment-following-the-environment-setup-instructions-from-https-swift2x-readthedocs-io-zh-cn-latest-multi-modal-qwen2-vl-e6-9c-80-e4-bd-b3-e5-ae-9e-e8-b7-b5-html-when-testing-the-inference-command-cuda-visible-devices-0-1-2-3-swift-infer-model-type-qwen2-vl-7b-instruct-an-error-occurs-runtimeerror-probability-tensor-contains-either-inf-nan-or-element-0"]], "Q7: What parameters need to be configured for training in an offline environment?": [[131, "q7-what-parameters-need-to-be-configured-for-training-in-an-offline-environment"]], "Q7: Why does Tongyi Qianwen 2.5-Math-7B-Instruct sometimes return garbled characters when using vllm deployment? Using vllm to deploy,fp16": [[131, "q7-why-does-tongyi-qianwen-2-5-math-7b-instruct-sometimes-return-garbled-characters-when-using-vllm-deployment-using-vllm-to-deploy-fp16"]], "Q7: evalscope \u652f\u6301\u591a\u6a21\u578b\u5bf9\u6bd4\u5417\uff1f": [[70, "q7-evalscope"]], "Q7: v100\u663e\u5361\uff0c\u5728python\u865a\u62df\u73af\u5883\u4e2d\uff0c\u53c2\u8003https://swift2x.readthedocs.io/zh-cn/latest/Multi-Modal/qwen2-vl%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5.html \u5b8c\u6210\u73af\u5883\u51c6\u5907\uff0c\u5728\u6d4b\u8bd5\u63a8\u7406\u547d\u4ee4\uff1aCUDA_VISIBLE_DEVICES=0,1,2,3 swift infer --model_type qwen2-vl-7b-instruct\u00a0\u65f6\u62a5\u9519\uff1aRuntimeError: probability tensor contains either inf, nan or element < 0": [[70, "q7-v100-python-https-swift2x-readthedocs-io-zh-cn-latest-multi-modal-qwen2-vl-e6-9c-80-e4-bd-b3-e5-ae-9e-e8-b7-b5-html-cuda-visible-devices-0-1-2-3-swift-infer-model-type-qwen2-vl-7b-instruct-runtimeerror-probability-tensor-contains-either-inf-nan-or-element-0"]], "Q7: \u79bb\u7ebf\u73af\u5883\u8bad\u7ec3\u9700\u8981\u914d\u7f6e\u7684\u53c2\u6570\u6709\u54ea\u4e9b\uff1f": [[70, "q7"]], "Q7: \u901a\u4e49\u5343\u95ee2.5-\u6570\u5b66-7B-Instruct\uff0c\u4f1a\u5076\u5c14\u8fd9\u6837\u4e00\u76f4\u8fd4\u56de\u4e71\u7801\uff0c\u662f\u4ec0\u4e48\u95ee\u9898\u5462\uff1f\u7528vllm\u90e8\u7f72\uff0cfp16\u3002": [[70, "q7-2-5-7b-instruct-vllm-fp16"]], "Q80: Does Swift now support multimodal GRPO?": [[131, "q80-does-swift-now-support-multimodal-grpo"]], "Q80: swift\u73b0\u5728\u652f\u6301\u591a\u6a21\u6001\u7684grpo\u5417\uff1f": [[70, "q80-swiftgrpo"]], "Q81: Can the GRPO reward function be customized?": [[131, "q81-can-the-grpo-reward-function-be-customized"]], "Q81: grpo\u7684reward\u51fd\u6570\u652f\u6301\u81ea\u5df1\u5b9a\u4e49\u4e48?": [[70, "q81-grporeward"]], "Q82: Why do I get the error when using --torch_dtype float16 (card cannot use bf16): lib/python3.12/site-packages/torch/amp/grad_scaler.py\", line 260, in unscale_grads raise ValueError(\"Attempting to unscale FP16 gradients.\") ValueError: Attempting to unscale FP16 gradients.": [[131, "q82-why-do-i-get-the-error-when-using-torch-dtype-float16-card-cannot-use-bf16-lib-python3-12-site-packages-torch-amp-grad-scaler-py-line-260-in-unscale-grads-raise-valueerror-attempting-to-unscale-fp16-gradients-valueerror-attempting-to-unscale-fp16-gradients"]], "Q82: \u8bf7\u95ee\u4e3a\u4ec0\u4e48 --torch_dtype float16 \uff08\u5361\u4e0d\u80fd\u4f7f\u7528bf16\uff09\u4f1a\u51fa\u73b0\u62a5\u9519\uff1alib/python3.12/site-packages/torch/amp/grad_scaler.py\", line 260, in unscale_grads raise ValueError(\"Attempting to unscale FP16 gradients.\") ValueError: Attempting to unscale FP16 gradients.": [[70, "q82-torch-dtype-float16-bf16-lib-python3-12-site-packages-torch-amp-grad-scaler-py-line-260-in-unscale-grads-raise-valueerror-attempting-to-unscale-fp16-gradients-valueerror-attempting-to-unscale-fp16-gradients"]], "Q83: I have a question. I trained a reward model using Swift (baseline is qwen2.5-7b), but when loading it in PPO or GRPO, it shows an error. The reward model was trained using LoRA.": [[131, "q83-i-have-a-question-i-trained-a-reward-model-using-swift-baseline-is-qwen2-5-7b-but-when-loading-it-in-ppo-or-grpo-it-shows-an-error-the-reward-model-was-trained-using-lora"]], "Q83: \u8bf7\u6559\u4e00\u4e2a\u95ee\u9898\u3002\u6211\u7528swift\u8bad\u7ec3\u4e86\u4e00\u4e2areward\u6a21\u578b\uff08\u57fa\u7ebf\u662fqwen2.5-7b\uff09\uff0c\u7136\u540e\u7528\u5728ppo\u6216\u8005grpo\u4e2d\u52a0\u8f7d\u4f1a\u62a5\u9519\u3002reward\u6a21\u578b\u662flora\u8bad\u7ec3\u7684\u3002": [[70, "q83-swiftreward-qwen2-5-7b-ppogrporewardlora"]], "Q84: What version of transformers is needed to fine-tune deepseek_vl2? Official docs say <4.42, but it also shows errors with 4.42 and below. Does the peft version need to be lowered too?": [[131, "q84-what-version-of-transformers-is-needed-to-fine-tune-deepseek-vl2-official-docs-say-4-42-but-it-also-shows-errors-with-4-42-and-below-does-the-peft-version-need-to-be-lowered-too"]], "Q84: \u5404\u4f4d\u5927\u4f6c\uff0c\u8bf7\u95ee\u8981\u5fae\u8c03deepseek_vl2\uff0ctransformers\u7528\u4ec0\u4e48\u4ec0\u4e48\u7248\u672c\uff1f\u5b98\u65b9\u6587\u6863\u8bf4<4.42\uff0c\u4f46\u662f4.42\u53ca\u4ee5\u4e0b\u4e5f\u62a5\u9519\u3002peft\u7248\u672c\u4e5f\u8981\u964d\u4f4e\u5417\uff1f": [[70, "q84-deepseek-vl2-transformers-4-42-4-42peft"]], "Q85: Generate train split is too slow (about 30+ datasets with around a million total data points). Previously Swift 2.x wasn't this slow. Lazy tokenize is already enabled.": [[131, "q85-generate-train-split-is-too-slow-about-30-datasets-with-around-a-million-total-data-points-previously-swift-2-x-wasn-t-this-slow-lazy-tokenize-is-already-enabled"]], "Q85: \u8bf7\u95eegenerate train split\u592a\u6162\u4e86\u6709\u6ca1\u6709\u4ec0\u4e48\u597d\u529e\u6cd5\u5440\uff08\u5927\u6982\u670930\u591a\u4e2a\u6570\u636e\u96c6\uff0c\u603b\u6570\u636e\u91cf\u767e\u4e07\u5de6\u53f3\uff09\u3002\u4e4b\u524dswift 2.x\u597d\u50cf\u6ca1\u6709\u8fd9\u4e48\u6162\u3002lazy tokenize \u5df2\u7ecf\u5f00\u4e86": [[70, "q85-generate-train-split-30-swift-2-xlazy-tokenize"]], "Q86: How can I full-parameter fine-tune the visual encoder while using LoRA to fine-tune LLM when fine-tuning qwen2.5vl?": [[131, "q86-how-can-i-full-parameter-fine-tune-the-visual-encoder-while-using-lora-to-fine-tune-llm-when-fine-tuning-qwen2-5vl"]], "Q86: \u8bf7\u95ee\u4e0b\u5fae\u8c03qwen2.5vl\u7684\u65f6\u5019\uff0c\u6211\u60f3\u4f7f\u7528\u5168\u53c2\u6570\u5fae\u8c03visual encoder\u540c\u65f6\u4f7f\u7528LoRA\u5fae\u8c03LLM\uff0c\u600e\u4e48\u5b9e\u73b0\u5462\uff1f": [[70, "q86-qwen2-5vl-visual-encoderlorallm"]], "Q87: How to use custom loss functions in Swift?": [[131, "q87-how-to-use-custom-loss-functions-in-swift"]], "Q87: \u95ee\u4e00\u4e0b\uff0cswift\u600e\u4e48\u4f7f\u7528\u81ea\u5b9a\u4e49\u7684\u635f\u5931\u51fd\u6570\uff1f": [[70, "q87-swift"]], "Q88: What are the parameters for MoE? Can't find keywords in the parameter table. How to set expert numbers and expert routing parameters?": [[131, "q88-what-are-the-parameters-for-moe-can-t-find-keywords-in-the-parameter-table-how-to-set-expert-numbers-and-expert-routing-parameters"]], "Q88: \u8bf7\u95ee\u4e0bMoE\u7684\u53c2\u6570\u6709\u54ea\u4e9b\uff0c\u53c2\u6570\u8868\u91cc\u5173\u952e\u5b57\u641c\u7d22\u4e0d\u5230\uff1f\u4e13\u5bb6\u6570\u91cf\uff0c\u4e13\u5bb6\u8def\u7531\u8fd9\u4e9b\u53c2\u6570\u600e\u4e48\u8bbe\u7f6e\uff1f": [[70, "q88-moe"]], "Q89: Using lmdeploy in grpo training reports missing functions. The load_weights function isn't found in lmdeployengine class.": [[131, "q89-using-lmdeploy-in-grpo-training-reports-missing-functions-the-load-weights-function-isn-t-found-in-lmdeployengine-class"]], "Q89: grpo\u8bad\u7ec3\u4e2d\u4f7f\u7528lmdeploy\u4f1a\u62a5\u76f8\u5173\u51fd\u6570\u4e0d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u60f3\u8bf7\u6559\u4e0b\u5177\u4f53\u95ee\u9898\uff0c\u5728lmdeployengine\u7c7b\u91cc\u9762\u786e\u5b9e\u6ca1\u627e\u5230load_weights\u8fd9\u4e2a\u51fd\u6570": [[70, "q89-grpolmdeploy-lmdeployengineload-weights"]], "Q8: After running the prediction command, where are the results saved? CUDA_VISIBLE_DEVICES=0 swift infer --ckpt_dir output/glm4v-9b-chat/vx-xxx/checkpoint-xxx-merged --load_data_args true": [[131, "q8-after-running-the-prediction-command-where-are-the-results-saved-cuda-visible-devices-0-swift-infer-ckpt-dir-output-glm4v-9b-chat-vx-xxx-checkpoint-xxx-merged-load-data-args-true"]], "Q8: After starting the swift inference service, how can I set configurations like temperature interactively?": [[131, "q8-after-starting-the-swift-inference-service-how-can-i-set-configurations-like-temperature-interactively"]], "Q8: Is there a custom evaluation for multimodal datasets?": [[131, "q8-is-there-a-custom-evaluation-for-multimodal-datasets"]], "Q8: Where can I check model_type?": [[131, "q8-where-can-i-check-model-type"]], "Q8: model_type\u5728\u54ea\u513f\u67e5\u770b\uff1f": [[70, "q8-model-type"]], "Q8: swift\u63a8\u7406\u670d\u52a1\u542f\u52a8\u540e\uff0c\u4ea4\u4e92\u8fdb\u884c\u8bbe\u7f6e\u7684\u6e29\u5ea6\u4e4b\u7c7b\u7684\u914d\u7f6e\uff0c\u5982\u4f55\u8bbe\u7f6e\u5462\uff1f": [[70, "q8-swift"]], "Q8: \u591a\u6a21\u6001\u6570\u636e\u96c6\u6709\u6ca1\u6709\u81ea\u5b9a\u4e49\u8bc4\u4f30\uff1f": [[70, "q8"]], "Q8: \u8fd0\u884c\u4e0b\u9762\u547d\u4ee4\uff0c\u9884\u6d4b\u4e4b\u540e\u7684\u7ed3\u679c\u5728\u54ea\u91cc\uff1fCUDA_VISIBLE_DEVICES=0 swift infer --ckpt_dir output/glm4v-9b-chat/vx-xxx/checkpoint-xxx-merged --load_data_args true": [[70, "q8-cuda-visible-devices-0-swift-infer-ckpt-dir-output-glm4v-9b-chat-vx-xxx-checkpoint-xxx-merged-load-data-args-true"]], "Q90: Getting errors when fine-tuning Moonlight-16B-A3B-Instruct model. Seems ms-swift doesn't support fine-tuning this model?": [[131, "q90-getting-errors-when-fine-tuning-moonlight-16b-a3b-instruct-model-seems-ms-swift-doesn-t-support-fine-tuning-this-model"]], "Q90: Moonlight-16B-A3B-Instruct, \u6211\u5728\u5fae\u8c03\u8fd9\u4e2a\u6a21\u578b\u7684\u65f6\u5019\u62a5\u9519\u600e\u4e48\u529e?ms-swift\u597d\u50cf\u4e0d\u652f\u6301\u8fd9\u4e2a\u6a21\u578b\u8fdb\u884c\u5fae\u8c03": [[70, "q90-moonlight-16b-a3b-instruct-ms-swift"]], "Q91: How to solve this error: RuntimeError: \"triu_tril_cuda_template\" not implemented for 'BFloat16'?": [[131, "q91-how-to-solve-this-error-runtimeerror-triu-tril-cuda-template-not-implemented-for-bfloat16"]], "Q91: \u8bad\u7ec3\u65f6\u51fa\u4e86\u8fd9\u4e2a\u9519\u5e94\u8be5\u548b\u89e3\u51b3\uff1fRuntimeError: \u201ctriu_tril_cuda_template\u201c not implemented for \u2018BFloat16'": [[70, "q91-runtimeerror-triu-tril-cuda-template-not-implemented-for-bfloat16"]], "Q92: Is it normal that both loss and grad_norm are 0 during GRPO training?": [[131, "q92-is-it-normal-that-both-loss-and-grad-norm-are-0-during-grpo-training"]], "Q92: grpo\u8bad\u7ec3\uff0closs\u548cgrad_norm\u5168\u662f0\uff0c\u6b63\u5e38\u7684\u5417\uff1f": [[70, "q92-grpo-lossgrad-norm0"]], "Q93: Where can I pass in accuracy_orm for GRPO's built-in reward function?": [[131, "q93-where-can-i-pass-in-accuracy-orm-for-grpo-s-built-in-reward-function"]], "Q93: \u8bf7\u6559\u4e00\u4e0b\u8fd9\u4e2agrpo\u7684\u5185\u7f6e\u5956\u52b1\u51fd\u6570\uff0c\u4ece\u54ea\u91cc\u53ef\u4ee5\u4f20\u5165accuracy_orm": [[70, "q93-grpo-accuracy-orm"]], "Q94: I notice the reward function has a solution parameter, does it need to be passed from the dataset? Does my dataset must have a solution field?": [[131, "q94-i-notice-the-reward-function-has-a-solution-parameter-does-it-need-to-be-passed-from-the-dataset-does-my-dataset-must-have-a-solution-field"]], "Q94: \u6211\u770b\u8fd9\u5956\u52b1\u51fd\u6570\u6709solution\u53c2\u6570\uff0c\u662f\u8981\u4ece\u6570\u636e\u96c6\u91cc\u9762\u4f20\u8fc7\u6765\u5417\uff1f\u5c31\u662f\u6211\u6570\u636e\u96c6\u5fc5\u987b\u6709solution\u8fd9\u9879\uff1f": [[70, "q94-solution-solution"]], "Q95: Why is there no token_acc during training?": [[131, "q95-why-is-there-no-token-acc-during-training"]], "Q95: \u8bad\u7ec3\u4e3a\u4ec0\u4e48\u6ca1\u6709token_acc\uff1f": [[70, "q95-token-acc"]], "Q96: When fine-tuning Ovis2, LoRA parameters don't seem to work? Memory usage doesn't change with or without --tuner_type lora.": [[131, "q96-when-fine-tuning-ovis2-lora-parameters-don-t-seem-to-work-memory-usage-doesn-t-change-with-or-without-tuner-type-lora"]], "Q96: \u5fae\u8c03Ovis2 \u4f7f\u7528lora\u53c2\u6570\u4e0d\u8d77\u4f5c\u7528\uff1f\u52a0\u4e0d\u52a0--tuner_type lora \\\uff0c\u597d\u50cf\u90fd\u662f\u5168\u53c2\u6570\u5fae\u8c03\uff1f\u663e\u5b58\u6ca1\u53d8\u5316\u3002": [[70, "q96-ovis2-lora-tuner-type-lora"]], "Q97: Getting ValueError when running classification task with Qwen2.5: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask.": [[131, "q97-getting-valueerror-when-running-classification-task-with-qwen2-5-the-model-did-not-return-a-loss-from-the-inputs-only-the-following-keys-logits-for-reference-the-inputs-it-received-are-input-ids-attention-mask"]], "Q97: \u8bf7\u95ee\u4e0b\u7528qwen2.5\u8dd1\u4e00\u4e2a\u5206\u7c7b\u4efb\u52a1\uff0c\u62b1\u4e0b\u9762\u7684\u9519\u8bef\uff0c\u662f\u54ea\u91cc\u914d\u7f6e\u7684\u6709\u95ee\u9898\u5462\uff1fValueError: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask.": [[70, "q97-qwen2-5-valueerror-the-model-did-not-return-a-loss-from-the-inputs-only-the-following-keys-logits-for-reference-the-inputs-it-received-are-input-ids-attention-mask"]], "Q98: How to exit VllmEngine? I want to release GPU memory after inference rather than keeping it occupied.": [[131, "q98-how-to-exit-vllmengine-i-want-to-release-gpu-memory-after-inference-rather-than-keeping-it-occupied"]], "Q98: \u542f\u52a8\u4e86VllmEngine\uff0c\u8981\u5982\u4f55\u9000\u51fa\u5440\uff1f\u5c31\u662f\u8c03\u7528\u4e86engine\uff0c\u6a21\u578b\u5c31\u88ab\u8f7d\u5165\u663e\u5b58\u51c6\u5907\u5de5\u4f5c\u3002\u4f46\u662f\u6211\u63a8\u7406\u5b8c\u60f3\u8981engine\u91ca\u653e\u663e\u5b58\u3002\u4e0b\u6b21\u8c03\u7528\u65f6\uff0c\u518d\u52a0\u8f7d\u3002\u800c\u4e0d\u662f\u4e00\u76f4\u5360\u7528": [[70, "q98-vllmengine-engine-engine"]], "Q99: Does trainer_sampler_random have no effect in streaming mode?": [[131, "q99-does-trainer-sampler-random-have-no-effect-in-streaming-mode"]], "Q99: \u6c42\u95ee\uff0cstreaming\u6a21\u5f0f\u4e0b\uff0ctrainer_sampler_random\u662f\u4e0d\u662f\u5c31\u6ca1\u6709\u4f5c\u7528\u4e86\u5462\uff1f": [[70, "q99-streaming-trainer-sampler-random"]], "Q9: Can I directly convert the model to gguf format after training?": [[131, "q9-can-i-directly-convert-the-model-to-gguf-format-after-training"]], "Q9: Does ms-swift have methods to test QPS, latency, and tokens/s?": [[131, "q9-does-ms-swift-have-methods-to-test-qps-latency-and-tokens-s"]], "Q9: For the latest version of swift, can the infer command output probability values through the logprobs parameter?": [[131, "q9-for-the-latest-version-of-swift-can-the-infer-command-output-probability-values-through-the-logprobs-parameter"]], "Q9: When deploying qwen2vl model locally, how can I input videos during inference? Can I use base64? How to call video with curl?": [[131, "q9-when-deploying-qwen2vl-model-locally-how-can-i-input-videos-during-inference-can-i-use-base64-how-to-call-video-with-curl"]], "Q9: ms-swift\u6709\u65b9\u6cd5\u6d4b\u8bd5qps\uff0c\u5ef6\u8fdf\uff0ctokens/s\u5417\uff1f": [[70, "q9-ms-swiftqps-tokens-s"]], "Q9: \u5728\u672c\u5730\u90e8\u7f72qwen2vl\u6a21\u578b\uff0c\u63a8\u7406\u540e\u7aef\u4f7f\u7528vllm\uff0c\u672c\u5730\u89c6\u9891\u600e\u4e48\u4f20\u5165\u5462\uff1f\u53ef\u4ee5\u4f7f\u7528 base64 \u4f20\u8fdb\u53bb\u5417\uff1fcurl\u8c03\u7528\u5982\u4f55\u52a0\u8f7d\u89c6\u9891\u5462\uff1f": [[70, "q9-qwen2vl-vllm-base64-curl"]], "Q9: \u6a21\u578b\u8bad\u7ec3\u5b8c\u80fd\u76f4\u63a5\u8f6cgguf\u683c\u5f0f\u5417\uff1f": [[70, "q9-gguf"]], "Q9: \u73b0\u5728\u6700\u65b0\u7684swift\u7248\u672c\uff0cinfer\u547d\u4ee4\u80fd\u901a\u8fc7logprobs\u53c2\u6570\u8f93\u51fa\u6982\u7387\u503c\u5417\uff1f": [[70, "q9-swift-inferlogprobs"]], "QAT": [[16, "qat"]], "QLoRA": [[22, "qlora"]], "Quantization": [[130, "quantization"]], "Quantization Arguments": [[128, "quantization-arguments"]], "QuantizationArguments": [[7, "id25"]], "Question-and-Answer Format (QA)": [[129, "question-and-answer-format-qa"]], "Quick Start": [[37, "quick-start"], [39, "quick-start"], [124, null], [166, null]], "Quick Start Example": [[166, "quick-start-example"]], "Qwen2.5-32B": [[179, "id6"]], "Qwen2.5-7B": [[178, "qwen2-5-7b"]], "Qwen3 Best Practices": [[117, null]], "Qwen3 MoE training guide": [[28, null]], "Qwen3 Omni MoE training guide": [[29, null]], "Qwen3 VL training guide": [[30, null]], "Qwen3 training guide": [[27, null]], "Qwen3-30B": [[27, "qwen3-30b"], [27, "id2"], [179, "id5"]], "Qwen3-8B": [[27, "qwen3-8b"], [27, "id1"]], "Qwen3-VL Best Practices": [[118, null]], "Qwen3-VL-30B": [[30, "qwen3-vl-30b"], [30, "id2"]], "Qwen3-VL-8B": [[30, "qwen3-vl-8b"], [30, "id1"]], "Qwen3-VL\u6700\u4f73\u5b9e\u8df5": [[57, null]], "Qwen3Moe Handling in VeOmni": [[40, "qwen3moe-handling-in-veomni"]], "Qwen3\u6700\u4f73\u5b9e\u8df5": [[56, null]], "RAY": [[7, "ray"]], "RAY Arguments": [[128, "ray-arguments"]], "RAY\u53c2\u6570": [[67, "ray"]], "REINFORCE Leave-One-Out (RLOO)": [[77, null], [138, null]], "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models": [[76, null], [137, null]], "RL WeChat Group": [[150, "rl-wechat-group"]], "RLHF": [[7, "rlhf"], [17, "rlhf"], [60, "rlhf"], [121, "rlhf"], [153, null]], "RLHF Arguments": [[128, "rlhf-arguments"]], "RLHF Parameters": [[160, "rlhf-parameters"]], "RLHF\u53c2\u6570": [[67, "rlhf"], [99, "rlhf"]], "RLHF\u8bad\u7ec3\u53c2\u6570\u4ecb\u7ecd": [[7, "id16"]], "RL\u5fae\u4fe1\u7fa4": [[89, "rl"]], "RM": [[92, "rm"], [153, "rm"]], "RM Parameters": [[160, "rm-parameters"]], "RM\u53c2\u6570": [[99, "rm"]], "ROLL": [[220, null]], "Random Sampling": [[37, "random-sampling"]], "Ray": [[9, "ray"]], "Ray Support": [[154, null]], "RayArguments": [[7, "id30"]], "ReFT": [[67, "reft"], [128, "reft"]], "Reference": [[161, "reference"]], "Reference Implementation": [[46, "reference-implementation"]], "Reference Implementation in Vision Model": [[46, "reference-implementation-in-vision-model"]], "Reference SP Processing for Image Deepstack": [[46, "reference-sp-processing-for-image-deepstack"]], "References": [[142, "references"]], "Registration Flow": [[37, "registration-flow"]], "Registry Functions": [[37, "registry-functions"]], "Reinforced Fine-Tuning": [[155, null]], "Reinforcement Learning (RL)": [[117, "reinforcement-learning-rl"]], "Remote \u52a0\u8f7d\u5185\u6838\u793a\u4f8b": [[191, "remote"]], "Required Environment": [[32, "required-environment"], [33, "required-environment"]], "Reranker": [[60, "reranker"], [121, "reranker"]], "Reranker Training": [[120, null]], "Reranker\u8bad\u7ec3": [[59, null]], "Returning response token IDs": [[147, "returning-response-token-ids"]], "Reverse KL": [[132, "reverse-kl"]], "Reverse KL\uff08\u53cd\u5411 KL\uff09": [[71, "reverse-kl-kl"]], "Reward Function": [[113, "reward-function"], [113, "id6"], [148, null]], "Reward Function Definition": [[111, "reward-function-definition"], [113, "reward-function-definition"]], "Reward Functions": [[112, "reward-functions"]], "Reward Model": [[149, null]], "Reward function parameters": [[128, "reward-function-parameters"]], "Reward model": [[17, "reward-model"]], "Reward-function related tips": [[147, "reward-function-related-tips"]], "Reward/Teacher Model Parameters": [[128, "reward-teacher-model-parameters"]], "Reward/Teacher\u6a21\u578b\u53c2\u6570": [[67, "reward-teacher"]], "Role collection control": [[172, "role-collection-control"]], "Rollout Arguments": [[128, "rollout-arguments"]], "Rollout\u53c2\u6570": [[67, "rollout"]], "Running Environment": [[125, "running-environment"]], "SAPO": [[84, "sapo"], [145, "sapo"]], "SAPO Loss Function": [[139, "sapo-loss-function"]], "SAPO Method": [[139, "sapo-method"]], "SAPO \u635f\u5931\u51fd\u6570": [[78, "id3"]], "SAPO \u65b9\u6cd5": [[78, "sapo"]], "SFT \u8bad\u7ec3": [[24, null]], "SGLang": [[229, null]], "SGLang Arguments": [[128, "sglang-arguments"]], "SGLang \u5b89\u88c5": [[230, "sglang"]], "SGLang\u53c2\u6570": [[67, "sglang"]], "SWANLAB": [[67, "swanlab"], [128, "swanlab"]], "SWIFT Implementation": [[155, "swift-implementation"]], "SWIFT Installation": [[125, null]], "SWIFT\u5b89\u88c5": [[64, null]], "SWIFT\u7684\u5b9e\u73b0": [[94, "swift"]], "Sampling": [[156, null]], "Sampling Acceleration": [[132, "sampling-acceleration"]], "Sampling From Large Model": [[156, "sampling-from-large-model"]], "Sampling Parameters": [[128, "sampling-parameters"]], "Seamless Training": [[164, "seamless-training"]], "See Also": [[44, "see-also"]], "Sentence Transformers": [[226, null]], "Seq2SeqTrainer Arguments": [[128, "seq2seqtrainer-arguments"]], "Seq2SeqTrainer\u53c2\u6570": [[67, "seq2seqtrainer"]], "Sequence Classification": [[121, "sequence-classification"]], "Server Side": [[151, "server-side"], [152, "server-side"]], "Setting multi-turn parameters": [[147, "setting-multi-turn-parameters"]], "Sharding Dimension": [[35, "sharding-dimension"]], "Sharding Modules with Correct Dimensions": [[35, "sharding-modules-with-correct-dimensions"]], "Sharding from the bottom up": [[35, "sharding-from-the-bottom-up"]], "ShareGPT": [[19, "sharegpt"]], "SimPO": [[92, "simpo"], [153, "simpo"]], "Single Card Training": [[116, "single-card-training"]], "Soft Adaptive Policy Optimization (SAPO)": [[78, null], [139, null]], "Soft Gate Function": [[139, "soft-gate-function"]], "Soft Overlong Punishment": [[74, "soft-overlong-punishment"], [135, "soft-overlong-punishment"]], "Solution": [[81, "solution"], [142, "solution"]], "Solution 1: Student Model Sampling Acceleration": [[132, "solution-1-student-model-sampling-acceleration"]], "Solution 2: Teacher Model Pre-sampling": [[132, "solution-2-teacher-model-pre-sampling"]], "Solution: Critical Path Sampling": [[172, "solution-critical-path-sampling"]], "Source Code Installation": [[125, "source-code-installation"]], "Special Handling for Qwen3-VL MoE": [[46, "special-handling-for-qwen3-vl-moe"]], "Specific Model Arguments": [[128, "specific-model-arguments"]], "Stability Control: Truncate vs. Mask": [[142, "stability-control-truncate-vs-mask"]], "Stable-Diffusion-WebUI": [[223, null]], "Stage 1: Train Aligner Layer": [[119, "stage-1-train-aligner-layer"]], "Stage 2: Full Model Training": [[119, "stage-2-full-model-training"]], "Standard Dataset Format": [[121, "standard-dataset-format"]], "Start Training": [[114, "start-training"]], "Start training on GPU": [[29, "start-training-on-gpu"], [31, "start-training-on-gpu"]], "Start training on GPU/NPU": [[27, "start-training-on-gpu-npu"], [30, "start-training-on-gpu-npu"]], "Start training on NPU": [[31, "start-training-on-npu"]], "Starting Training": [[109, "starting-training"]], "Summary": [[46, "summary"]], "Supervised Fine-Tuning": [[17, "supervised-fine-tuning"]], "Supervised Fine-Tuning (SFT)": [[117, "supervised-fine-tuning-sft"]], "Supervised Fine-tuning": [[121, "supervised-fine-tuning"]], "Support New Models": [[46, null]], "Supported Hardware": [[125, "supported-hardware"]], "Supported Modalities": [[37, "supported-modalities"]], "Supported Models": [[34, "supported-models"]], "Supported Models and Datasets": [[157, null]], "Survey: Qwen MoE Weight Formats": [[40, "survey-qwen-moe-weight-formats"]], "SwanLab": [[12, "swanlab"]], "SwanLab \u53c2\u6570": [[7, "swanlab"]], "SwanLabArguments": [[7, "id29"]], "Swift Class Static Interfaces": [[158, "swift-class-static-interfaces"]], "SwiftModel Interfaces": [[158, "swiftmodel-interfaces"]], "SwiftModel\u63a5\u53e3": [[97, "swiftmodel"]], "Swift\u7c7b\u9759\u6001\u63a5\u53e3": [[97, "swift"]], "TASK_QUEUE_ENABLE": [[181, "task-queue-enable"]], "TRL \u4e0b\u8f7d\u5b89\u88c5": [[248, "trl"]], "Table 1: SFT Algorithms": [[116, "table-1-sft-algorithms"]], "Table 2: RL Algorithms": [[116, "table-2-rl-algorithms"]], "Table 3: Modules Not Yet Supported / Fully Verified on NPUs": [[116, "table-3-modules-not-yet-supported-fully-verified-on-npus"]], "Table of Contents": [[38, "table-of-contents"]], "Task and Dataset Definition": [[111, "task-and-dataset-definition"], [113, "task-and-dataset-definition"], [113, "id1"], [113, "id5"]], "Technical Details": [[154, "technical-details"]], "Temperature Parameters": [[139, "temperature-parameters"]], "Template Arguments": [[128, "template-arguments"]], "Template Registration": [[114, "template-registration"]], "TensorBoard": [[12, "tensorboard"]], "Test Data": [[143, "test-data"]], "Testing": [[37, "testing"]], "Text-to-Image Format": [[121, "text-to-image-format"]], "The Problem": [[39, "the-problem"]], "The Solution": [[39, "the-solution"]], "This Tool's Approach": [[39, "this-tool-s-approach"]], "Three Training Modes": [[132, "three-training-modes"], [161, "three-training-modes"]], "Tips:": [[152, "tips"]], "Token level Loss": [[74, "token-level-loss"], [135, "token-level-loss"]], "Tools Format": [[127, "tools-format"]], "Torch \u5b89\u88c5\u521b\u5efa": [[221, "torch"]], "TorchTitan": [[238, null]], "TorchTitan \u4e3b\u8981\u914d\u7f6e\u9879\u53c2\u6570\u8bf4\u660e": [[240, "id6"]], "TorchTitan \u5b89\u88c5": [[239, "torchtitan"]], "Torchchat": [[235, null]], "Traditional Method": [[163, "traditional-method"], [166, "traditional-method"]], "Train Loop": [[43, "train-loop"]], "Trainer": [[241, "trainer"]], "Training": [[110, "training"], [117, "training"], [118, "training"], [119, "training"], [127, "training"], [131, "training"], [163, "training"]], "Training Arguments": [[128, "training-arguments"]], "Training Parameters": [[111, "training-parameters"], [113, "training-parameters"], [113, "id3"], [113, "id8"], [160, "training-parameters"]], "Training Script": [[112, "training-script"]], "Training Scripts": [[120, "training-scripts"]], "Training Tips": [[166, "training-tips"]], "Training configuration arguments": [[42, "training-configuration-arguments"]], "Training-Inference-Mismatch": [[81, null], [142, null], [147, "training-inference-mismatch"]], "Transformer Reinforcement Learning": [[247, null]], "Transformers": [[242, null]], "Transformers v5 MoE Weight Loading": [[40, null]], "TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling": [[82, null], [143, null]], "Triton-Ascend \u5b89\u88c5": [[230, "triton-ascend"]], "Troubleshooting": [[37, "troubleshooting"], [44, "troubleshooting"]], "Tuner Arguments": [[128, "tuner-arguments"]], "Tuner\u53c2\u6570": [[67, "tuner"]], "Two CHORD Variants": [[133, "two-chord-variants"]], "UNSLOTH": [[67, "unsloth"], [128, "unsloth"]], "Ubuntu \u64cd\u4f5c\u7cfb\u7edf": [[181, "ubuntu"]], "Unsloth": [[6, "unsloth"]], "Unstable Experiment Records": [[111, "unstable-experiment-records"]], "Usage": [[43, "usage"], [44, "usage"], [45, "usage"], [142, "usage"]], "Usage Example": [[124, "usage-example"]], "Usage in Training Scripts": [[37, "usage-in-training-scripts"]], "Usage of loss_scale": [[127, "usage-of-loss-scale"]], "Usage of rmpad_with_pos_ids and dyn_bsz": [[45, null]], "Using CLI": [[151, "using-cli"], [152, "using-cli"]], "Using Code": [[164, "using-code"]], "Using PRM and ORM for Result Filtering": [[156, "using-prm-and-orm-for-result-filtering"]], "Using Python": [[151, "using-python"], [152, "using-python"]], "Using Tuners": [[158, null]], "Using Web-UI": [[151, "using-web-ui"], [152, "using-web-ui"]], "VLLM_ASCEND_ENABLE_DENSE_OPTIMIZE": [[181, "vllm-ascend-enable-dense-optimize"]], "VLLM_ASCEND_ENABLE_FLASHCOMM": [[181, "vllm-ascend-enable-flashcomm"]], "VLLM_ASCEND_ENABLE_PREFETCH_MLP": [[181, "vllm-ascend-enable-prefetch-mlp"]], "VLM \u63a8\u7406": [[197, "vlm"]], "VLM \u6a21\u578b\u670d\u52a1": [[197, "id13"]], "VeOmni": [[5, null]], "VeOmni Flash Attention Custom Name Adapter (Transformers 5.x)": [[41, null]], "VeOmni Fused MoE Op Interface": [[40, "veomni-fused-moe-op-interface"]], "VeOmni documents": [[26, null]], "Vera": [[67, "vera"], [128, "vera"]], "Visualization": [[172, "visualization"]], "VllmArguments": [[7, "id24"]], "Wan2.1-I2V training guide": [[31, null]], "Wandb": [[12, "wandb"]], "WeNet": [[251, null]], "WeNet \u5b89\u88c5": [[252, "wenet"]], "Web-UI": [[65, null], [126, null]], "Web-UI Arguments": [[128, "web-ui-arguments"]], "Web-UI\u53c2\u6570": [[67, "web-ui"]], "WebUI": [[25, null]], "Weight Name Mapping": [[44, "weight-name-mapping"]], "Weight-Sync Acceleration": [[150, "weight-sync-acceleration"]], "What is all_to_all?": [[38, "what-is-all-to-all"]], "Wheel Packages Installation": [[125, "wheel-packages-installation"]], "Wheel\u5305\u5b89\u88c5": [[64, "wheel"]], "When to Use Reinforced Fine-Tuning": [[155, "when-to-use-reinforced-fine-tuning"]], "Whisper \u6a21\u578b\u4e0b\u8f7d": [[256, "whisper"]], "Whisper.cpp": [[254, null]], "Whisper.cpp \u7f16\u8bd1\u5b89\u88c5": [[255, "whisper-cpp"]], "Why This Approach?": [[46, "why-this-approach"]], "Why This Happens": [[41, "why-this-happens"]], "Why pad_scale=4?": [[46, "why-pad-scale-4"]], "Windows": [[22, "windows"], [22, "id5"]], "Wrong Output Format": [[37, "wrong-output-format"]], "YAML Arguments": [[128, "yaml-arguments"]], "ZeRO-0": [[9, "zero-0"]], "ZeRO-1/2+AutoTP": [[9, "zero-1-2-autotp"]], "ZeRO-2": [[9, "zero-2"]], "ZeRO-2+offload": [[9, "zero-2-offload"]], "ZeRO-3": [[9, "zero-3"]], "ZeRO-3+offload": [[9, "zero-3-offload"]], "accelerate": [[9, "accelerate"], [9, "id11"], [9, "id19"], [9, "id28"], [9, "id31"]], "api": [[21, "api"]], "bitsandbytes": [[16, "bitsandbytes"]], "callback\u56de\u8c03": [[62, "callback"]], "channel loss": [[60, "channel-loss"]], "contrastive/online_contrastive loss\u5bf9\u5e94\u7684\u683c\u5f0f": [[49, "contrastive-online-contrastive-loss"]], "conv_preprocess(source: str, conversations, **kwargs)": [[37, "conv-preprocess-source-str-conversations-kwargs"]], "cosine_similarity loss\u5bf9\u5e94\u7684\u683c\u5f0f": [[49, "cosine-similarity-loss"]], "dataset_info.json": [[60, "dataset-info-json"], [121, "dataset-info-json"]], "deepspeed": [[9, "id15"], [9, "id18"]], "e2b": [[51, "e2b"]], "git lfs": [[245, "git-lfs"]], "grounding": [[60, "grounding"]], "hf-mirror": [[245, "hf-mirror"]], "infonce \u683c\u5f0f": [[49, "infonce"]], "internvl, internvl_phi3": [[67, "internvl-internvl-phi3"], [128, "internvl-internvl-phi3"]], "internvl2, internvl2_phi3, internvl2_5, internvl3, internvl3_5": [[67, "internvl2-internvl2-phi3-internvl2-5-internvl3-internvl3-5"], [128, "internvl2-internvl2-phi3-internvl2-5-internvl3-internvl3-5"]], "jemalloc\u5b89\u88c5": [[181, "jemalloc"]], "judge0": [[51, "judge0"], [112, "judge0"]], "kernels": [[189, null]], "llama.cpp \u4e0b\u8f7d\u5b89\u88c5": [[193, "llama-cpp"]], "llama3_1_omni": [[67, "llama3-1-omni"], [128, "llama3-1-omni"]], "llamafactory-cli": [[9, "llamafactory-cli"], [9, "id9"], [9, "id14"], [9, "id27"]], "lm-evaluation-harness\u5378\u8f7d": [[199, "id4"]], "lm-evaluation-harness\u5b89\u88c5": [[199, "lm-evaluation-harness"]], "lm_deploy \u4e0b\u8f7d\u5b89\u88c5": [[196, "lm-deploy"]], "logged metrics": [[89, "logged-metrics"], [150, "logged-metrics"]], "loss": [[49, "loss"]], "loss_scale\u7684\u4f7f\u7528": [[66, "loss-scale"]], "maintain docs": [[47, null]], "megatron export and Conversion Accuracy Testing": [[164, "megatron-export-and-conversion-accuracy-testing"]], "megatron export \u4e0e \u8f6c\u6362\u7cbe\u5ea6\u6d4b\u8bd5": [[103, "megatron-export"]], "minicpmo": [[67, "minicpmo"], [128, "minicpmo"]], "minicpmv2_6, minicpmv4, minicpmo": [[67, "minicpmv2-6-minicpmv4-minicpmo"], [128, "minicpmv2-6-minicpmv4-minicpmo"]], "modify multisource yaml": [[29, "modify-multisource-yaml"]], "mplug_owl3, mplug_owl3_241101": [[67, "mplug-owl3-mplug-owl3-241101"], [128, "mplug-owl3-mplug-owl3-241101"]], "ms-swift": [[201, null]], "open_clip": [[205, null]], "open_clip \u5b89\u88c5": [[206, "open-clip"]], "opencompass run.py \u53c2\u6570\u8bf4\u660e": [[210, "id6"]], "ovis1_6, ovis2": [[67, "ovis1-6-ovis2"], [128, "ovis1-6-ovis2"]], "ovis2_5": [[67, "ovis2-5"], [128, "ovis2-5"]], "phi3_vision": [[67, "phi3-vision"], [128, "phi3-vision"]], "pip \u5b89\u88c5": [[2, "pip"]], "pipeline": [[246, "pipeline"]], "pipeline \u4f7f\u7528": [[243, "id2"]], "pipeline \u62bd\u8c61\u7c7b": [[243, "pipeline"]], "profilling\u5de5\u5177\u4f7f\u80fd": [[177, "profilling"]], "python\u63a8\u7406\u793a\u4f8b": [[204, "python"]], "qwen2_5_omni, qwen3_omni": [[67, "qwen2-5-omni-qwen3-omni"], [128, "qwen2-5-omni-qwen3-omni"]], "qwen2_audio": [[67, "qwen2-audio"], [128, "qwen2-audio"]], "qwen2_vl, qvq, qwen2_5_vl, mimo_vl, keye_vl, keye_vl_1_5": [[67, "qwen2-vl-qvq-qwen2-5-vl-mimo-vl-keye-vl-keye-vl-1-5"], [128, "qwen2-vl-qvq-qwen2-5-vl-mimo-vl-keye-vl-keye-vl-1-5"]], "qwen3_5_moe": [[40, "qwen3-5-moe"]], "qwen3_moe": [[40, "qwen3-moe"]], "qwen3_vl": [[67, "qwen3-vl"], [128, "qwen3-vl"]], "qwen3_vl_emb, qwen3_vl_reranker": [[67, "qwen3-vl-emb-qwen3-vl-reranker"], [128, "qwen3-vl-emb-qwen3-vl-reranker"]], "qwen3_vl_moe": [[40, "qwen3-vl-moe"]], "ray\u7684\u652f\u6301": [[93, null]], "rmpad_with_pos_ids = True, dyn_bsz = OFF (Recommended for SFT)": [[45, "rmpad-with-pos-ids-true-dyn-bsz-off-recommended-for-sft"]], "rmpad_with_pos_ids = True, dyn_bsz = ON (Recommended for Pretraining)": [[45, "rmpad-with-pos-ids-true-dyn-bsz-on-recommended-for-pretraining"]], "rsLoRA": [[18, "rslora"]], "sentence-transformers \u4e0b\u8f7d\u5b89\u88c5": [[227, "sentence-transformers"]], "sharegpt4v_cap_100k + COCO2017": [[29, "sharegpt4v-cap-100k-coco2017"]], "stage1 \u8bad\u7ec3 Aligner \u5c42": [[58, "stage1-aligner"]], "stage2 \u8bad\u7ec3\u6574\u4e2a\u6a21\u578b": [[58, "stage2"]], "timm": [[232, null]], "timm \u5b89\u88c5": [[233, "timm"]], "tools\u683c\u5f0f": [[66, "tools"]], "torch-npu \u5b89\u88c5": [[206, "torch-npu"], [209, "torch-npu"], [230, "torch-npu"], [233, "torch-npu"], [239, "torch-npu"]], "torchchat \u5b89\u88c5": [[236, "torchchat"]], "torchrun": [[9, "id6"], [9, "id10"]], "transformers + kernels \u7684\u4f7f\u7528": [[191, "transformers-kernels"]], "tulu-3-sft-mixture": [[29, "tulu-3-sft-mixture"]], "vLLM Arguments": [[128, "vllm-arguments"]], "vLLM \u5b89\u88c5": [[230, "vllm"]], "vLLM-Ascend\u5b89\u88c5": [[13, "vllm-ascend"]], "vLLM\u521d\u59cb\u5316\u53c2\u6570": [[171, "vllm"]], "vLLM\u53c2\u6570": [[67, "vllm"]], "verl": [[250, null]], "verl\u6846\u67b6\u53c2\u6570\u8bbe\u7f6e": [[181, "verl"]], "video_cogvlm2": [[67, "video-cogvlm2"], [128, "video-cogvlm2"]], "video_llava": [[67, "video-llava"], [128, "video-llava"]], "vllm & vllm-ascend \u5b89\u88c5": [[221, "vllm-vllm-ascend"]], "vllm \u63a8\u7406": [[7, "vllm"]], "xcomposer2_4khd": [[67, "xcomposer2-4khd"], [128, "xcomposer2-4khd"]], "xcomposer2_5": [[67, "xcomposer2-5"], [128, "xcomposer2-5"]], "yaml\u652f\u6301": [[67, "yaml"]], "\u2699\ufe0f Core API": [[38, "core-api"]], "\u26a1 Async Ulysses CP": [[38, "async-ulysses-cp"]], "\u4e00\u952e\u5b89\u88c5": [[236, "id4"]], "\u4e09\u79cd\u8bad\u7ec3\u6a21\u5f0f": [[71, "id3"], [100, "id6"]], "\u4e0b\u8f7dTokenizer": [[239, "tokenizer"]], "\u4e0b\u8f7d\u6570\u636e": [[253, "id3"]], "\u4e0b\u8f7d\u6a21\u578b": [[237, "id3"]], "\u4e0e\u5fae\u8c03\u540e\u7684\u6a21\u578b\u8fdb\u884c\u5bf9\u8bdd": [[8, "id1"]], "\u4e24\u79cd CHORD \u53d8\u4f53": [[72, "chord"]], "\u4e3b\u8981\u53c2\u6570": [[225, "id3"]], "\u4e86\u89e3\u66f4\u591a": [[63, "id4"]], "\u4eba\u7c7b\u5bf9\u9f50": [[92, null]], "\u4ec0\u4e48\u65f6\u5019\u4f7f\u7528\u5f3a\u5316\u5fae\u8c03": [[94, "id3"]], "\u4ec5\u8bb0\u5f55\u8bca\u65ad\u6307\u6807": [[81, "id4"]], "\u4ece Docker \u955c\u50cf\u8fdb\u884c\u5b89\u88c5": [[175, "docker"]], "\u4ecepip\u5b89\u88c5": [[203, "pip"]], "\u4ece\u6e90\u7801\u5b89\u88c5": [[196, "id2"], [203, "id2"]], "\u4ece\u81ea\u5b9a\u4e49\u73af\u5883\u5b89\u88c5": [[175, "id4"]], "\u4ee3\u7801\u4fee\u6539": [[98, "id2"]], "\u4efb\u52a1\u4e0e\u6570\u636e\u96c6\u5b9a\u4e49": [[50, "id1"], [52, "id1"], [52, "id6"], [52, "id11"]], "\u4f18\u5316\u53c2\u8003": [[180, "id8"]], "\u4f20\u7edf\u65b9\u5f0f": [[102, "id1"], [105, "id4"]], "\u4f7f\u7528 C++": [[213, "c"]], "\u4f7f\u7528 NPU \u7684\u63a8\u7406": [[207, "id4"]], "\u4f7f\u7528 NPU \u7684\u8bad\u7ec3": [[207, "npu"]], "\u4f7f\u7528 Python": [[213, "python"]], "\u4f7f\u7528 SGLang \u542f\u52a8\u670d\u52a1": [[231, "sglang"]], "\u4f7f\u7528 SGLang \u8fdb\u884c\u63a8\u7406\u9a8c\u8bc1": [[231, "id4"]], "\u4f7f\u7528 git \u83b7\u53d6\u6e90\u7801": [[236, "git"]], "\u4f7f\u7528 msleaks \u5de5\u5177\u8fdb\u884c\u6df1\u5c42\u6b21\u5185\u5b58\u5206\u6790": [[177, "msleaks"]], "\u4f7f\u7528 pip \u5b89\u88c5\uff08\u63a8\u8350\uff09": [[196, "pip"]], "\u4f7f\u7528CLI": [[90, "cli"], [91, "cli"]], "\u4f7f\u7528PRM\u548cORM\u8fdb\u884c\u7ed3\u679c\u8fc7\u6ee4": [[95, "prmorm"]], "\u4f7f\u7528Python": [[90, "python"]], "\u4f7f\u7528Tuners": [[97, null]], "\u4f7f\u7528Web-UI": [[90, "web-ui"], [91, "web-ui"]], "\u4f7f\u7528conda\u521b\u5efa\u73af\u5883": [[224, "conda"]], "\u4f7f\u7528python": [[91, "python"]], "\u4f7f\u7528vLLM-ascend\u8fdb\u884c\u90e8\u7f72": [[55, "vllm-ascend"]], "\u4f7f\u7528\u4ee3\u7801": [[103, "id2"]], "\u4f7f\u7528\u5355\u5361\u63a8\u7406": [[194, "id4"]], "\u4f7f\u7528\u539f\u751ftransformers\u8fdb\u884c\u90e8\u7f72": [[55, "transformers"]], "\u4f7f\u7528\u547d\u4ee4\u884c\u4e0eLLM\u6a21\u578b\u5bf9\u8bdd": [[197, "id14"]], "\u4f7f\u7528\u591a\u5361\u63a8\u7406": [[194, "id5"]], "\u4f7f\u7528\u65b9\u5f0f": [[81, "id3"]], "\u4f7f\u7528\u6837\u4f8b": [[63, "id3"]], "\u4f7f\u7528\u6a21\u578b": [[228, "id3"]], "\u4f7f\u7528\u914d\u7f6e\u6587\u4ef6\u6267\u884c agentic pipeline": [[222, "agentic-pipeline"]], "\u4f7f\u80fd": [[98, "id3"]], "\u4f7f\u80fdjemalloc": [[181, "id14"]], "\u4f7f\u80fdvllm v1\u7248\u672c": [[181, "vllm-v1"]], "\u4f7f\u80fd\u65b9\u6cd5": [[177, "id3"]], "\u4fee\u6539\u914d\u7f6e\u6587\u4ef6 config.json": [[58, "config-json"]], "\u4fee\u6539\u955c\u50cf\u6e90": [[245, "id4"]], "\u504f\u597d\u6570\u636e\u96c6": [[19, "id9"], [19, "id24"]], "\u5168\u53c2": [[67, "id9"]], "\u5168\u53c2\u6570\u5fae\u8c03 (Full)": [[15, "full"]], "\u5168\u5c40\u53d8\u91cf\u5bfc\u5165": [[180, "id6"]], "\u5168\u5c40\u91c7\u96c6\u63a7\u5236": [[173, "id2"]], "\u5168\u6d41\u7a0b": [[246, "id3"]], "\u5168\u91cf\u5fae\u8c03\u811a\u672c": [[8, "id2"]], "\u516c\u5f00\u955c\u50cf\u5730\u5740": [[176, "id4"]], "\u5173\u952e\u652f\u6301\u7248\u672c": [[175, "id3"]], "\u5173\u952e\u66f4\u65b0": [[174, "id1"]], "\u5173\u952e\u73af\u5883\u53d8\u91cf": [[15, "id5"]], "\u5176\u4ed6": [[181, "id13"]], "\u5176\u4ed6\u53c2\u6570": [[225, "id4"]], "\u5176\u4ed6\u73af\u5883\u53d8\u91cf": [[67, "id20"]], "\u5176\u4ed6\u7b2c\u4e09\u65b9\u5e93\u8bf4\u660e": [[221, "id3"]], "\u5185\u5b58\u5206\u6790": [[177, "id11"]], "\u5185\u7f6e\u5956\u52b1\u51fd\u6570": [[87, "id4"]], "\u5185\u90e8\u63d2\u4ef6": [[88, "id3"]], "\u5199\u5728\u524d\u9762: kernels \u662f\u4ec0\u4e48": [[191, "kernels"]], "\u51c6\u5907 WeNet \u6570\u636e\u683c\u5f0f": [[253, "wenet"]], "\u51c6\u5907\u8bad\u7ec3\u6570\u636e": [[253, "id4"]], "\u5206\u5e03\u5f0f\u8bad\u7ec3": [[15, "id4"], [207, "id3"]], "\u5206\u5e03\u8bad\u7ec3": [[9, null]], "\u521b\u5efa\u865a\u62df\u73af\u5883": [[244, "id3"]], "\u524d\u7f6e\u51c6\u5907": [[184, "id2"], [228, "id2"], [241, "id2"], [249, "id2"]], "\u529f\u80fd\u652f\u6301": [[100, "id1"]], "\u529f\u80fd\u6837\u4f8b": [[215, null]], "\u52a0\u8f7d\u6570\u636e\u96c6": [[241, "id4"]], "\u52a0\u8f7d\u6a21\u578b": [[241, "id8"]], "\u52a0\u901f": [[6, null]], "\u52a8\u6001bsz": [[181, "bsz"]], "\u52a8\u6001\u5408\u5e76 LoRA \u7684\u63a8\u7406": [[3, "id4"]], "\u533a\u522b1\uff1a\u4f18\u52bf\u51fd\u6570\u57fa\u7ebf\u7684\u6784\u9020\u65b9\u6cd5": [[77, "id2"]], "\u533a\u522b1\uff1a\u6807\u51c6\u5316\u65f6\u4f7f\u7528\u7684\u7edf\u8ba1\u91cf\u4e0d\u540c": [[76, "id2"]], "\u533a\u522b2: KL \u6563\u5ea6\u6b63\u5219\u5316": [[76, "kl"]], "\u533a\u522b2\uff1aKL \u6563\u5ea6\u6b63\u5219\u5316\u9879\u7684\u5904\u7406\u65b9\u5f0f": [[77, "kl"]], "\u5355\u5361/\u5206\u5e03\u5f0f\u8bad\u7ec3": [[234, "id2"]], "\u5355\u5361\u8bad\u7ec3": [[55, "id6"], [207, "id2"]], "\u5355\u673a\u591a\u5361": [[9, "id4"], [9, "id12"], [9, "id25"], [9, "id33"]], "\u5355\u673a\u8bad\u7ec3": [[15, "id6"]], "\u5378\u8f7d torch_npu": [[236, "id5"]], "\u5378\u8f7dtransformers": [[244, "id5"]], "\u539f\u59cb\u6a21\u578b\u63a8\u7406\u914d\u7f6e": [[21, "id2"]], "\u539f\u5b50\u53c2\u6570": [[67, "id8"]], "\u539f\u7406": [[81, "id6"]], "\u539f\u7406\u4ecb\u7ecd": [[79, "id1"], [82, "id1"]], "\u53c2\u6570\u4ecb\u7ecd": [[7, null]], "\u53c2\u6570\u5bf9\u6bd4": [[101, "id1"]], "\u53c2\u6570\u8bbe\u7f6e": [[71, "id5"], [73, "id3"], [74, "id1"], [76, "id3"], [77, "id3"], [78, "id5"], [93, "id2"]], "\u53c2\u6570\u8bf4\u660e": [[100, "id3"], [225, "id2"]], "\u53c2\u6570\u914d\u7f6e\uff08\u6570\u636e\u4e0e\u6279\u91cf\u5927\u5c0f\uff09": [[72, "id2"]], "\u53c2\u8003": [[100, "id7"]], "\u53ef\u89c6\u5316": [[173, "id7"]], "\u53ef\u89c6\u5316\u754c\u9762": [[13, "id2"]], "\u53ef\u89c6\u5316\u8bc4\u4f30\u7ed3\u679c": [[210, "id5"]], "\u5408\u5e76": [[23, "id1"]], "\u5408\u5e76\u53c2\u6570": [[67, "id10"]], "\u542f\u52a8\u8bad\u7ec3": [[48, "id4"]], "\u542f\u52a8\u8bc4\u4f30": [[210, "id4"]], "\u542f\u52a8\u955c\u50cf": [[183, "id2"]], "\u542f\u7528\u91cd\u8981\u6027\u91c7\u6837\u6821\u6b63": [[81, "id5"]], "\u547d\u4ee4\u884c": [[24, "id2"]], "\u547d\u4ee4\u884c\u53c2\u6570": [[67, null], [99, null]], "\u56db\u79cd\u6821\u6b63\u6a21\u5f0f": [[81, "id2"]], "\u56fe\u50cf\u5206\u7c7b": [[243, "id7"]], "\u56fe\u50cf\u5904\u7406": [[213, "id2"]], "\u56fe\u50cf\u5904\u7406\u7ed3\u679c": [[213, "id3"]], "\u56fe\u50cf\u6570\u636e\u96c6": [[19, "id15"]], "\u56fe\u50cf\u8f6c\u56fe\u50cf": [[243, "id8"]], "\u56fe\u50cf\u8f6c\u6587\u672c": [[243, "id14"]], "\u56fe\u751f\u56fe": [[225, "id6"]], "\u5728 Scheduler \u4e2d\u83b7\u53d6\u989d\u5916\u7684\u6570\u636e\u96c6\u4fe1\u606f": [[86, "scheduler"]], "\u5728\u6607\u817e\u8bbe\u5907\u4e0a\u57fa\u4e8e FSDP \u6216 MindSpeed (Megatron) \u540e\u7aef\u8fdb\u884c\u6027\u80fd\u6570\u636e\u91c7\u96c6": [[173, "fsdp-mindspeed-megatron"]], "\u5728\u7ebf\u670d\u52a1": [[197, "id11"]], "\u57fa\u4e8e LoRA \u7684\u5fae\u8c03": [[3, "lora"]], "\u57fa\u672c\u53c2\u6570": [[7, "id3"], [7, "id6"], [67, "id2"]], "\u57fa\u7840\u73af\u5883": [[181, "id2"]], "\u58f0\u660e": [[174, "id30"], [176, "id5"], [222, "id5"]], "\u5916\u90e8\u90e8\u7f72": [[88, "id4"]], "\u591a\u4efb\u52a1\u8bad\u7ec3": [[85, null]], "\u591a\u673a\u4efb\u52a1\u62c9\u8d77": [[181, "id6"]], "\u591a\u673a\u591a\u5361": [[9, "id7"], [9, "id16"], [9, "id29"], [9, "id35"]], "\u591a\u673a\u8bad\u7ec3": [[15, "id7"]], "\u591a\u6a21\u6001": [[60, "id6"], [243, "id12"]], "\u591a\u6a21\u6001GRPO\u5b8c\u6574\u5b9e\u9a8c\u6d41\u7a0b": [[52, null]], "\u591a\u6a21\u6001\u5927\u6a21\u578b": [[96, "id4"]], "\u591a\u6a21\u6001\u6570\u636e\u4fee\u6539": [[86, "id5"]], "\u591a\u6a21\u6001\u6570\u636e\u6784\u5efa": [[11, "id2"]], "\u591a\u6a21\u6001\u6570\u636e\u96c6": [[19, "id13"]], "\u591a\u6a21\u6001\u6a21\u578b": [[7, "id7"], [21, "id4"], [104, null]], "\u591a\u6d41\u590d\u7528": [[181, "id15"]], "\u591a\u8f6e\u89c4\u5212\u5668 MultiTurnScheduler": [[86, "multiturnscheduler"]], "\u591a\u8f6e\u8bad\u7ec3": [[86, null]], "\u5927\u6a21\u578b\u84b8\u998f\u91c7\u6837": [[95, "id7"]], "\u5927\u8bed\u8a00\u6a21\u578b": [[96, "id3"]], "\u5956\u52b1\u51fd\u6570": [[51, "id1"], [52, "id7"], [52, "id12"], [87, null]], "\u5956\u52b1\u51fd\u6570\u53c2\u6570": [[67, "id13"]], "\u5956\u52b1\u51fd\u6570\u5b9a\u4e49\uff1a": [[50, "id2"], [52, "id2"]], "\u5956\u52b1\u51fd\u6570\u76f8\u5173": [[86, "id7"]], "\u5956\u52b1\u6a21\u578b": [[88, null]], "\u5956\u52b1\u6a21\u578b (RM)": [[15, "rm"]], "\u5982\u4f55\u542f\u52a8": [[48, "id2"]], "\u5b89\u88c5": [[22, null], [55, "id1"], [63, "id2"], [175, "id2"], [197, "id3"]], "\u5b89\u88c5 Accelerate \u53ca\u4f9d\u8d56\u5305": [[183, "id3"]], "\u5b89\u88c5 Deep-ep \u4e0e sgl-kernel-npu:": [[230, "deep-ep-sgl-kernel-npu"]], "\u5b89\u88c5 MindSpeed": [[174, "mindspeed"]], "\u5b89\u88c5 kernels \u5305": [[190, "kernels"]], "\u5b89\u88c5 python \u4f9d\u8d56": [[230, "id4"]], "\u5b89\u88c5 roll": [[221, "roll"]], "\u5b89\u88c5 torch \u548c torch_npu": [[190, "torch-torch-npu"]], "\u5b89\u88c5 torch_npu": [[236, "torch-npu"]], "\u5b89\u88c5 vllm & vllm-ascend": [[174, "vllm-vllm-ascend"]], "\u5b89\u88c5miniconda": [[224, "miniconda"]], "\u5b89\u88c5msprobe": [[98, "msprobe"]], "\u5b89\u88c5stable-diffusion-webui": [[224, "stable-diffusion-webui"]], "\u5b89\u88c5transformers": [[244, "transformers"]], "\u5b89\u88c5verl": [[174, "verl"]], "\u5b89\u88c5\u4f9d\u8d56": [[48, "id1"]], "\u5b89\u88c5\u5176\u4ed6\u8f6f\u4ef6\u5305": [[174, "id7"]], "\u5b89\u88c5\u57fa\u7840\u73af\u5883": [[174, "id5"], [180, "id2"], [181, "id3"]], "\u5b89\u88c5\u5fc5\u8981\u5e93": [[241, "id3"]], "\u5b89\u88c5\u6307\u5357": [[2, null], [183, null], [187, null], [190, null], [193, null], [196, null], [199, null], [203, null], [206, null], [209, null], [212, null], [218, null], [221, null], [224, null], [227, null], [230, null], [233, null], [236, null], [239, null], [244, null], [248, null], [252, null], [255, null]], "\u5b89\u88c5\u6821\u9a8c": [[2, "id3"], [193, "id2"], [196, "id3"], [199, "id3"], [206, "id3"], [209, "id3"], [212, "id4"], [233, "id3"], [252, "id3"], [255, "id3"]], "\u5b89\u88c5\u6d41\u7a0b": [[174, "id3"]], "\u5b9a\u5236\u5316agent template": [[62, "agent-template"]], "\u5b9a\u5236\u5316loss": [[62, "loss"]], "\u5b9a\u5236\u5316loss_scale": [[62, "loss-scale"]], "\u5b9a\u5236\u5316metric": [[62, "metric"]], "\u5b9a\u5236\u5316optimizer": [[62, "optimizer"]], "\u5b9a\u5236\u5316tuner": [[62, "tuner"]], "\u5b9e\u73b0\u65b9\u5f0f": [[59, "id1"]], "\u5b9e\u73b0\u7ec6\u8282": [[73, "id2"], [79, "id3"], [82, "id2"]], "\u5b9e\u9645\u4f8b\u5b50": [[95, "id6"]], "\u5b9e\u9a8c\u73b0\u8c61": [[50, "id5"], [52, "id5"], [52, "id10"], [52, "id15"]], "\u5b9e\u9a8c\u76d1\u63a7": [[12, null]], "\u5b9e\u9a8c\u7ed3\u679c": [[94, "id4"]], "\u5ba2\u6237\u7aef": [[90, "id5"], [91, "id8"]], "\u5bfc\u5165 torch-npu": [[234, "torch-npu"]], "\u5bfc\u51fa": [[25, "id3"]], "\u5bfc\u51fa\u4e0e\u63a8\u9001": [[69, null]], "\u5bfc\u51fa\u53c2\u6570": [[67, "id17"], [99, "id3"]], "\u5bfc\u51fa\u8bad\u7ec3\u597d\u7684\u6a21\u578b": [[253, "id9"]], "\u5e38\u89c1\u95ee\u9898\u6574\u7406": [[70, null]], "\u5e7f\u4e49 Jensen-Shannon \u6563\u5ea6\uff08Generalized JSD\uff09": [[71, "jensen-shannon-generalized-jsd"]], "\u5e8f\u5217\u5206\u7c7b": [[60, "id5"]], "\u5f00\u59cb\u8bad\u7ec3": [[53, "id6"]], "\u5f02\u6b65\u5956\u52b1\u51fd\u6570": [[87, "id3"]], "\u5f15\u5165 vLLM \u540e\u7684\u5047\u8bbe\u504f\u79bb": [[81, "vllm"]], "\u5f15\u8a00": [[178, "id1"], [179, "id1"]], "\u5f3a\u5316\u5b66\u4e60 (RL)": [[56, "rl"]], "\u5f3a\u5316\u5b66\u4e60\u8ba1\u7b97\u6d41\u7a0b\u6982\u8ff0": [[177, "id2"]], "\u5f3a\u5316\u5fae\u8c03": [[94, null]], "\u5f3a\u5316\u5fae\u8c03\u7684\u6982\u5ff5": [[94, "id2"]], "\u5f53\u524d\u9650\u5236": [[100, "id2"]], "\u5fae\u4fe1\u7fa4": [[216, "id1"]], "\u5fae\u8c03": [[55, "id5"], [91, "id4"]], "\u5fae\u8c03\u53c2\u6570": [[7, "id2"]], "\u5fae\u8c03\u6a21\u578b\u63a8\u7406\u914d\u7f6e": [[21, "id3"]], "\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b": [[241, null]], "\u5feb\u901f\u4f7f\u7528": [[191, null]], "\u5feb\u901f\u5165\u95e8\u6848\u4f8b": [[105, "id3"]], "\u5feb\u901f\u5b89\u88c5\u6607\u817e\u73af\u5883": [[185, null]], "\u5feb\u901f\u5f00\u59cb": [[3, null], [15, "id3"], [63, null], [105, null], [174, "id9"], [175, "id6"], [184, null], [188, null], [194, null], [197, null], [200, null], [204, null], [207, null], [210, null], [213, null], [219, null], [225, null], [228, null], [231, null], [234, null], [237, null], [240, null], [246, null], [249, null], [253, null], [256, null]], "\u5feb\u901f\u5f00\u59cb\uff0c\u5355\u8282\u70b9\u90e8\u7f72\u6307\u5f15": [[222, null]], "\u5feb\u901f\u8bad\u7ec3VL\u6a21\u578b": [[58, null]], "\u6027\u80fd\u4f18\u5316": [[15, "id9"]], "\u6027\u80fd\u5206\u6790": [[177, "id10"]], "\u6027\u80fd\u5206\u6790\u65b9\u6cd5\u8bba": [[177, "id4"]], "\u6027\u80fd\u5206\u6790\u6848\u4f8b": [[177, "id12"]], "\u6027\u80fd\u5bf9\u6bd4": [[13, "id3"]], "\u6027\u80fd\u8c03\u4f18": [[181, "id7"]], "\u6027\u80fd\u91c7\u96c6": [[179, "id9"]], "\u6279\u91cf\u63a8\u7406": [[21, "id5"]], "\u6279\u91cf\u76f8\u5173\u53c2\u6570": [[100, "id5"]], "\u6280\u672f\u7ec6\u8282": [[93, "id1"]], "\u6307\u4ee4\u76d1\u7763\u5fae\u8c03\u6570\u636e\u96c6": [[19, "id4"], [19, "id22"]], "\u635f\u5931\u51fd\u6570": [[71, "id1"], [84, "id1"]], "\u635f\u5931\u51fd\u6570\u7c7b\u578b": [[59, "id4"]], "\u635f\u5931\u63a9\u7801": [[86, "id6"]], "\u63a5\u53e3\u5217\u8868": [[97, "id1"]], "\u63a8\u7406": [[21, null], [49, "id3"], [55, "id8"], [56, "id1"], [57, "id2"], [58, "id5"], [66, "id3"], [70, "id3"], [90, "id2"], [102, "id3"], [102, "id5"], [181, "id9"], [194, "id3"], [243, null]], "\u63a8\u7406/\u90e8\u7f72/\u8bc4\u6d4b": [[58, "id4"]], "\u63a8\u7406\u53c2\u6570": [[67, "id14"]], "\u63a8\u7406\u540e\u7aef\u5207\u6362": [[181, "id10"]], "\u63a8\u7406\u548c\u90e8\u7f72": [[90, null]], "\u63a8\u7406\u5bf9\u9f50": [[53, "id5"]], "\u63a8\u7406\u6d4b\u8bd5": [[13, "id1"]], "\u63a8\u7406\uff08\u5fae\u8c03\u540e\u6a21\u578b\uff09": [[91, "id5"]], "\u63a8\u9001\u6a21\u578b": [[69, "id3"]], "\u63d0\u4f9b\u4e00\u4e2a\u7b80\u5355\u7684\u6837\u4f8b\uff0c\u9a8c\u8bc1 kernels \u7684\u5b89\u88c5\u662f\u5426\u6210\u529f": [[191, "id2"]], "\u63d0\u4f9b\u6a21\u578b\u8def\u5f84": [[11, "id5"]], "\u63d0\u53d6\u6700\u4f73 cmvn \u7279\u5f81\uff08\u53ef\u9009\uff09": [[253, "cmvn"]], "\u63d2\u4ef6\u5316": [[62, null]], "\u652f\u6301\u529f\u80fd": [[15, "id2"]], "\u652f\u6301\u73b0\u72b6": [[55, "id10"], [222, "id4"]], "\u652f\u6301\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6": [[96, null]], "\u652f\u6301\u7684\u786c\u4ef6": [[64, "id3"]], "\u652f\u6301\u8bbe\u5907": [[15, "id1"]], "\u6563\u5ea6\u5ea6\u91cf\u51fd\u6570": [[71, "id2"]], "\u6570\u636e\u51c6\u5907": [[56, "id3"], [56, "id6"]], "\u6570\u636e\u53c2\u6570": [[7, "id4"], [67, "id4"]], "\u6570\u636e\u5904\u7406": [[19, null]], "\u6570\u636e\u5e76\u884c\u8bad\u7ec3": [[55, "id7"]], "\u6570\u636e\u96c6": [[21, "vllm"], [92, "id2"], [96, "id5"]], "\u6570\u636e\u96c6\u51c6\u5907": [[180, "id4"], [181, "id5"]], "\u6570\u636e\u96c6\u683c\u5f0f": [[49, "id1"], [59, "id5"], [66, "id1"]], "\u6570\u636e\u96c6\u6ce8\u518c": [[60, "id8"]], "\u6574\u4f53\u6027\u80fd\u6982\u89c8\u5206\u6790": [[177, "id5"]], "\u6587\u672c\u5206\u7c7b": [[243, "id10"]], "\u6587\u672c\u751f\u6210": [[243, "id11"]], "\u6587\u672c\u8f6c\u97f3\u9891": [[243, "id5"]], "\u6587\u751f\u56fe": [[3, "id2"], [225, "id5"]], "\u6587\u751f\u56fe\u683c\u5f0f": [[60, "id7"]], "\u65b9\u5f0f\u4e00\uff1a\u624b\u52a8\u5b89\u88c5\u73af\u5883": [[14, "install-form-pip"]], "\u65b9\u5f0f\u4e09\uff1aDocker \u672c\u5730\u6784\u5efa": [[14, "install-form-docker"]], "\u65b9\u5f0f\u4e8c\uff1aDocker \u9884\u5b89\u88c5\u955c\u50cf": [[14, "docker"]], "\u65b9\u6848 1\uff1a\u5b66\u751f\u6a21\u578b\u91c7\u6837\u52a0\u901f": [[71, "id7"]], "\u65b9\u6848 2\uff1a\u6559\u5e08\u6a21\u578b\u9884\u91c7\u6837": [[71, "id8"]], "\u65b9\u6cd51\uff1a\u4f7f\u7528\u6e90\u7801\u5b89\u88c5 SGLang": [[230, "id3"]], "\u65b9\u6cd52\uff1a\u4f7f\u7528 docker \u955c\u50cf\u5b89\u88c5 SGLang": [[230, "docker-sglang"]], "\u65e0\u7f1d\u8bad\u7ec3": [[103, "id1"]], "\u6607\u817e\u5f00\u6e90\u6587\u6863\u4e2d\u5fc3": [[0, null]], "\u6607\u817e\u6682\u4e0d\u652f\u6301\u751f\u6001\u5e93\u8bf4\u660e": [[174, "id8"]], "\u6607\u817e\u73af\u5883\u5b89\u88c5": [[2, "id2"], [190, "id2"], [206, "id2"], [209, "id2"], [212, "id2"], [221, "id2"], [227, "id2"], [230, "id2"], [233, "id2"], [236, "id2"], [239, "id2"], [248, "id2"], [252, "id2"], [255, "id2"]], "\u663e\u5b58\u63a7\u5236": [[95, "id5"]], "\u66f4\u591a\u6700\u4f73\u5b9e\u8df5": [[54, null]], "\u6700\u4f73\u5b9e\u8df5": [[79, "id2"], [83, "id2"]], "\u670d\u52a1\u7aef": [[90, "id4"], [91, "id7"]], "\u6743\u91cd\u4e0b\u8f7d": [[180, "id5"]], "\u6743\u91cd\u540c\u6b65\u52a0\u901f": [[89, "id3"]], "\u6743\u91cd\u83b7\u53d6": [[181, "id4"]], "\u6784\u5efa\u955c\u50cf": [[197, "id8"]], "\u67e5\u770b\u5e2e\u52a9": [[237, "id2"]], "\u6807\u51c6\u6570\u636e\u96c6\u683c\u5f0f": [[60, "id2"]], "\u6838\u5fc3\u4f9d\u8d56\u8bf4\u660e": [[14, "id1"]], "\u6982\u89c8": [[210, "id2"], [231, "id3"], [240, "id3"]], "\u6a21\u578b": [[96, "id2"]], "\u6a21\u578b\u4fee\u6539": [[58, "id1"]], "\u6a21\u578b\u51c6\u5907": [[204, "id3"]], "\u6a21\u578b\u53c2\u6570": [[7, "id5"], [67, "id3"]], "\u6a21\u578b\u53ca\u6570\u636e\u96c6\u4e0b\u8f7d": [[3, "download"]], "\u6a21\u578b\u5bfc\u51fa": [[7, "id9"]], "\u6a21\u578b\u63a8\u7406": [[204, "id7"], [234, "id4"], [237, "id5"]], "\u6a21\u578b\u652f\u6301": [[11, null]], "\u6a21\u578b\u6587\u4ef6\u51c6\u5907\u53ca\u91cf\u5316": [[194, "id2"]], "\u6a21\u578b\u6743\u91cd\u521d\u59cb\u5316\u4e0e\u66ff\u6362": [[58, "id2"]], "\u6a21\u578b\u6ce8\u518c": [[61, "id2"]], "\u6a21\u578b\u83b7\u53d6": [[245, null]], "\u6a21\u578b\u8bad\u7ec3": [[180, "id3"], [184, "id3"], [249, "id3"], [253, "id5"]], "\u6a21\u578b\u8bad\u7ec3\u4e0e\u8bc4\u4f30": [[178, "id3"], [179, "id3"]], "\u6a21\u578b\u8bc4\u4f30": [[207, "id5"], [241, "id10"]], "\u6a21\u578b\u91cf\u5316": [[7, "id8"]], "\u6a21\u578b\u9a8c\u8bc1": [[234, "id3"]], "\u6a21\u5f0f\u9009\u62e9\u903b\u8f91": [[71, "id4"]], "\u6a21\u677f\u53c2\u6570": [[67, "id5"]], "\u6ce8\u518c template": [[11, "template"]], "\u6ce8\u518c\u591a\u6a21\u6001\u6a21\u578b\u6700\u4f73\u5b9e\u8df5": [[53, null]], "\u6ce8\u518c\u6a21\u578b": [[53, "id3"]], "\u6ce8\u518c\u6a21\u677f": [[53, "id4"]], "\u6ce8\u610f\u4e8b\u9879": [[83, "id3"], [87, "id5"]], "\u6d4b\u8bd5\u63a8\u7406": [[253, "id7"]], "\u6d4b\u8bd5\u6570\u636e": [[82, "id3"]], "\u6dfb\u52a0\u65b0\u7528\u4f8b\u6307\u5357": [[170, "id1"]], "\u6e29\u5ea6\u53c2\u6570": [[78, "id4"]], "\u6e90\u4ee3\u7801\u5b89\u88c5": [[64, "id1"]], "\u6e90\u7801\u5b89\u88c5 SGLang\uff1a": [[230, "id6"]], "\u6e90\u7801\u7f16\u8bd1": [[212, "id3"]], "\u7279\u5b9a\u6a21\u578b\u53c2\u6570": [[67, "id19"]], "\u73af\u5883\u51c6\u5907": [[53, "id2"], [55, "id2"], [57, "id1"], [68, "id3"], [91, "id2"], [95, "id3"], [105, "id2"], [197, "id4"], [204, "id2"]], "\u73af\u5883\u521b\u5efa": [[236, "id3"]], "\u73af\u5883\u53d8\u91cf": [[7, "id13"]], "\u73af\u5883\u53d8\u91cf\u914d\u7f6e": [[171, "id1"]], "\u73af\u5883\u5b89\u88c5": [[55, "id3"]], "\u73af\u5883\u6784\u5efa": [[178, "id2"], [179, "id2"]], "\u73af\u5883\u67e5\u770b": [[55, "id4"]], "\u73af\u5883\u8bbe\u7f6e": [[56, "id5"]], "\u751f\u6210 token \u5b57\u5178": [[253, "token"]], "\u751f\u6210\u53c2\u6570": [[7, "id11"], [67, "id6"]], "\u76d1\u7763\u5fae\u8c03": [[60, "id4"]], "\u76d1\u7763\u5fae\u8c03 (SFT)": [[15, "sft"], [56, "sft"]], "\u76f4\u63a5\u4e0b\u8f7d": [[245, "id3"]], "\u786c\u4ef6\u652f\u6301": [[174, "id2"], [175, "id1"]], "\u786c\u4ef6\u8981\u6c42": [[180, "id1"]], "\u793a\u4f8b": [[98, "id4"], [173, "id3"]], "\u7981\u7528\u91c7\u96c6": [[173, "id4"]], "\u79bb\u6563\u6a21\u5f0f\u91c7\u96c6": [[173, "id6"]], "\u79bb\u7ebf\u6279\u5904\u7406": [[197, "id10"]], "\u7a33\u5b9a\u6027\u63a7\u5236\uff1aTruncate vs. Mask": [[81, "truncate-vs-mask"]], "\u7aef\u5230\u7aef\u91c7\u96c6": [[173, "id5"]], "\u7b97\u5b50\u4e0b\u53d1\u4f18\u5316": [[15, "id11"]], "\u7b97\u6cd5\u539f\u7406": [[73, "id1"], [76, "id1"], [77, "id1"], [89, "id1"]], "\u7b97\u6cd5\u652f\u6301\u73b0\u72b6": [[174, "id10"]], "\u7b97\u6cd5\u6982\u8ff0": [[72, "id1"]], "\u7b97\u6cd5\u9002\u914d": [[181, "id1"]], "\u7c7b\u522b\u6807\u7b7e": [[204, "id5"]], "\u7ec6\u7c92\u5ea6\u5206\u6790": [[177, "id9"]], "\u7ed1\u6838\u4f18\u5316": [[181, "id12"]], "\u80cc\u666f\u4e0e\u52a8\u673a": [[78, "id1"]], "\u80cc\u666f\u4e0e\u6311\u6218": [[173, "id9"]], "\u80cc\u666f\u4ecb\u7ecd": [[177, null]], "\u80fd\u529b\u4ecb\u7ecd": [[68, "id2"], [95, "id2"]], "\u811a\u624b\u67b6": [[59, "id6"]], "\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b": [[256, "id6"]], "\u81ea\u5b9a\u4e49PRM\u6216ORM": [[95, "id4"]], "\u81ea\u5b9a\u4e49\u591a\u8f6e\u4ea4\u4e92\u903b\u8f91": [[86, "id4"]], "\u81ea\u5b9a\u4e49\u5956\u52b1\u51fd\u6570": [[87, "id2"]], "\u81ea\u5b9a\u4e49\u5956\u52b1\u6a21\u578b": [[88, "id2"]], "\u81ea\u5b9a\u4e49\u6570\u636e\u96c6": [[60, null]], "\u81ea\u5b9a\u4e49\u6a21\u578b": [[61, null]], "\u81ea\u5b9a\u4e49\u8bc4\u6d4b\u96c6": [[68, "id6"]], "\u81ea\u7136\u8bed\u8a00\u5904\u7406": [[243, "id9"]], "\u878d\u5408\u7b97\u5b50": [[15, "id10"]], "\u8868 1\uff1aSFT \u7c7b\u7b97\u6cd5": [[55, "sft"]], "\u8868 2\uff1aRL \u7c7b\u7b97\u6cd5": [[55, "rl"]], "\u8868 3\uff1a\u5f53\u524d NPU \u6682\u4e0d\u652f\u6301 / \u672a\u5b8c\u5168\u9a8c\u8bc1\u7684\u6a21\u5757": [[55, "id11"]], "\u89c6\u89c9\u95ee\u7b54": [[243, "id13"]], "\u89c6\u9891\u6570\u636e\u96c6": [[19, "id17"]], "\u89d2\u8272profiler\u63a7\u5236": [[173, "profiler"]], "\u89e3\u51b3\u65b9\u6848\uff1a\u5173\u952e\u8def\u5f84\u91c7\u6837": [[173, "id10"]], "\u8ba1\u7b97\u673a\u89c6\u89c9": [[243, "id6"]], "\u8bad\u63a8\u4e00\u81f4\u6027\u517c\u5bb9": [[86, "id8"]], "\u8bad\u7ec3": [[25, "id1"], [49, "id2"], [56, "id2"], [57, "id3"], [58, "id3"], [66, "id2"], [70, "id2"], [102, "id4"], [180, "id7"], [181, "id8"], [241, "id7"]], "\u8bad\u7ec3\u4e2d\u8bc4\u6d4b": [[68, "id5"]], "\u8bad\u7ec3\u53c2\u6570": [[7, "id12"], [67, "id12"], [99, "id2"]], "\u8bad\u7ec3\u53c2\u6570\uff1a": [[50, "id4"], [52, "id4"], [52, "id9"], [52, "id14"]], "\u8bad\u7ec3\u6280\u5de7": [[105, "id5"]], "\u8bad\u7ec3\u65b9\u5f0f": [[15, "id8"]], "\u8bad\u7ec3\u65b9\u6cd5": [[17, null]], "\u8bad\u7ec3\u793a\u4f8b": [[240, "id5"]], "\u8bad\u7ec3\u811a\u672c": [[51, "id2"]], "\u8bbe\u7f6e\u591a\u8f6e\u8bad\u7ec3\u53c2\u6570": [[86, "id2"]], "\u8bc4\u4f30": [[20, null]], "\u8bc4\u4f30\u53c2\u6570": [[7, "id10"]], "\u8bc4\u4f30\u76f8\u5173\u53c2\u6570": [[20, "id3"]], "\u8bc4\u4f30\u9884\u6d4b\u4e0e\u5bf9\u8bdd": [[25, "id2"]], "\u8bc4\u6d4b": [[58, "id7"], [68, null], [68, "id4"], [70, "id7"]], "\u8bc4\u6d4b\u53c2\u6570": [[67, "id16"]], "\u8bed\u97f3\u6587\u4ef6\u9884\u5904\u7406": [[256, "id5"]], "\u8c03\u4f18\u7b97\u6cd5": [[18, null]], "\u8c03\u5ea6": [[181, "id11"]], "\u8d85\u53c2\u6570\u8c03\u4f18": [[241, "id9"]], "\u8f6c\u6362\u524d\u540e\u793a\u4f8b": [[49, "id5"]], "\u8f6f\u95e8\u63a7\u51fd\u6570": [[78, "id2"]], "\u8fd0\u884c\u73af\u5883": [[64, "id4"]], "\u8fd4\u56de response token ids": [[86, "response-token-ids"]], "\u8fdb\u9636\u6307\u5357\uff1a\u7cbe\u7ec6\u5316\u91c7\u96c6": [[173, "id8"]], "\u9009\u62e9\u9898\u683c\u5f0f\uff08MCQ\uff09": [[68, "mcq"]], "\u901a\u7528\u80fd\u529b\u8bc4\u4f30": [[20, "id2"]], "\u901a\u8fc7 Profiling \u7ed3\u5408\u8c03\u7528\u6808\u5206\u6790\u7cfb\u7edf\u5185\u5b58\u53d8\u5316": [[177, "profiling"]], "\u90e8\u7f72": [[55, "id9"], [58, "id6"], [66, "id4"], [70, "id6"], [90, "id3"]], "\u90e8\u7f72\u53c2\u6570": [[67, "id15"]], "\u90e8\u7f72\uff08\u5fae\u8c03\u540e\u6a21\u578b\uff09": [[91, "id6"]], "\u914d\u7f6e": [[173, "id1"]], "\u914d\u7f6e\u6587\u4ef6\u793a\u4f8b": [[48, "id3"]], "\u914d\u7f6e\u8bad\u7ec3\u53c2\u6570": [[240, "id4"]], "\u914d\u7f6e\u8bc4\u4f30\u4efb\u52a1": [[210, "id3"]], "\u91c7\u6837": [[95, null]], "\u91c7\u6837\u52a0\u901f": [[71, "id6"]], "\u91c7\u6837\u53c2\u6570": [[67, "id18"]], "\u91cd\u8981\u53c2\u6570\u8bf4\u660e": [[76, "id4"], [77, "id4"]], "\u91cd\u8981\u6027\u91c7\u6837\u6821\u6b63": [[81, "id1"]], "\u91cd\u8981\u8bad\u7ec3\u53c2\u6570": [[24, "id4"]], "\u91cf\u5316": [[16, null], [23, "id2"], [69, "id2"], [197, "id15"]], "\u91cf\u5316\u53c2\u6570": [[67, "id7"]], "\u955c\u50cf": [[64, "id2"]], "\u955c\u50cf\u5185\u5404\u7ec4\u4ef6\u7248\u672c\u4fe1\u606f\u6e05\u5355": [[176, "id2"]], "\u955c\u50cf\u6784\u5efa\u547d\u4ee4\u793a\u4f8b": [[176, "id3"]], "\u955c\u50cf\u786c\u4ef6\u652f\u6301": [[176, "id1"]], "\u95ee\u7b54\u9898\u683c\u5f0f\uff08QA\uff09": [[68, "qa"]], "\u96c6\u6210\u53c2\u6570": [[67, "id11"]], "\u96c6\u7fa4\u652f\u6301": [[89, "id2"]], "\u97f3\u9891": [[243, "id3"]], "\u97f3\u9891\u6570\u636e\u96c6": [[19, "id19"]], "\u97f3\u9891\u8bc6\u522b": [[243, "id4"]], "\u9884\u5904\u7406\u6570\u636e\u96c6": [[241, "id5"]], "\u9884\u8bad\u7ec3": [[60, "id3"], [91, "id3"]], "\u9884\u8bad\u7ec3 (PT)": [[15, "pt"]], "\u9884\u8bad\u7ec3\u4e0e\u5fae\u8c03": [[91, null]], "\u9884\u8bad\u7ec3\u5168\u6d41\u7a0b": [[241, "id11"]], "\u9884\u8bad\u7ec3\u6570\u636e\u96c6": [[19, "id6"]], "\u989d\u5916\u9009\u9879": [[10, null]], "\u9a8c\u8bc1\u5b89\u88c5": [[244, "id4"]], "\u9ad8\u7ea7\u529f\u80fd": [[49, "id4"], [59, "id7"]], "\u9ad8\u7ea7\u8bbe\u7f6e": [[86, "id3"]], "\ud83d\udcda Overview": [[36, "overview"], [38, "overview"]], "\ud83d\udd0d Dive into Ulysses Sequence Parallelism": [[38, "dive-into-ulysses-sequence-parallelism"]], "\ud83d\udd0d Model Registry System": [[36, "model-registry-system"]], "\ud83d\udd16 Table of Contents": [[36, "table-of-contents"]], "\ud83d\ude80 Quick Start": [[38, "quick-start"]], "\ud83d\udee0\ufe0f Add Your Own Model": [[36, "add-your-own-model"]], "\ud83d\udee0\ufe0f Support Ulysses for a New Model": [[38, "support-ulysses-for-a-new-model"]]}, "docnames": ["index", "sources/Diffusers/index", "sources/Diffusers/install", "sources/Diffusers/quick_start", "sources/LLaMA-Factory/index", "sources/VeOmni/index", "sources/_generated/sources/LLaMA-Factory/source/advanced/acceleration", "sources/_generated/sources/LLaMA-Factory/source/advanced/arguments", "sources/_generated/sources/LLaMA-Factory/source/advanced/best_practice/gpt-oss", "sources/_generated/sources/LLaMA-Factory/source/advanced/distributed", "sources/_generated/sources/LLaMA-Factory/source/advanced/extras", "sources/_generated/sources/LLaMA-Factory/source/advanced/model_support", "sources/_generated/sources/LLaMA-Factory/source/advanced/monitor", "sources/_generated/sources/LLaMA-Factory/source/advanced/npu_inference", "sources/_generated/sources/LLaMA-Factory/source/advanced/npu_installation", "sources/_generated/sources/LLaMA-Factory/source/advanced/npu_training", "sources/_generated/sources/LLaMA-Factory/source/advanced/quantization", "sources/_generated/sources/LLaMA-Factory/source/advanced/trainers", "sources/_generated/sources/LLaMA-Factory/source/advanced/tuning_algorithms", "sources/_generated/sources/LLaMA-Factory/source/getting_started/data_preparation", "sources/_generated/sources/LLaMA-Factory/source/getting_started/eval", "sources/_generated/sources/LLaMA-Factory/source/getting_started/inference", "sources/_generated/sources/LLaMA-Factory/source/getting_started/installation", "sources/_generated/sources/LLaMA-Factory/source/getting_started/merge_lora", "sources/_generated/sources/LLaMA-Factory/source/getting_started/sft", "sources/_generated/sources/LLaMA-Factory/source/getting_started/webui", "sources/_generated/sources/VeOmni/README", "sources/_generated/sources/VeOmni/examples/qwen3", "sources/_generated/sources/VeOmni/examples/qwen3_moe", "sources/_generated/sources/VeOmni/examples/qwen3_omni_moe", "sources/_generated/sources/VeOmni/examples/qwen3_vl", "sources/_generated/sources/VeOmni/examples/wan2.1", "sources/_generated/sources/VeOmni/get_started/installation/install", "sources/_generated/sources/VeOmni/get_started/installation/install_ascend", "sources/_generated/sources/VeOmni/hardware_support/get_started_npu", "sources/_generated/sources/VeOmni/key_features/ep_fsdp2", "sources/_generated/sources/VeOmni/key_features/model_loader", "sources/_generated/sources/VeOmni/key_features/preprocessor_registry", "sources/_generated/sources/VeOmni/key_features/ulysses", "sources/_generated/sources/VeOmni/transformers_v5/patchgen", "sources/_generated/sources/VeOmni/transformers_v5/transformers_v5_moe_weight_loading", "sources/_generated/sources/VeOmni/transformers_v5/veomni_flash_attention_kernel_adapter", "sources/_generated/sources/VeOmni/usage/arguments", "sources/_generated/sources/VeOmni/usage/basic_modules", "sources/_generated/sources/VeOmni/usage/checkpoint_conversion", "sources/_generated/sources/VeOmni/usage/rmpad_with_pos_ids_and_dyn_bsz", "sources/_generated/sources/VeOmni/usage/support_new_models", "sources/_generated/sources/ms-swift/README", "sources/_generated/sources/ms-swift/source/BestPractices/Elastic", "sources/_generated/sources/ms-swift/source/BestPractices/Embedding", "sources/_generated/sources/ms-swift/source/BestPractices/GRPO", "sources/_generated/sources/ms-swift/source/BestPractices/GRPO-Code-Training", "sources/_generated/sources/ms-swift/source/BestPractices/GRPO-Multi-Modal-Training", "sources/_generated/sources/ms-swift/source/BestPractices/MLLM-Registration", "sources/_generated/sources/ms-swift/source/BestPractices/More-Best-Practices", "sources/_generated/sources/ms-swift/source/BestPractices/NPU-support", "sources/_generated/sources/ms-swift/source/BestPractices/Qwen3-Best-Practice", "sources/_generated/sources/ms-swift/source/BestPractices/Qwen3-VL-Best-Practice", "sources/_generated/sources/ms-swift/source/BestPractices/Rapidly-Training-VL-model", "sources/_generated/sources/ms-swift/source/BestPractices/Reranker", "sources/_generated/sources/ms-swift/source/Customization/Custom-dataset", "sources/_generated/sources/ms-swift/source/Customization/Custom-model", "sources/_generated/sources/ms-swift/source/Customization/Pluginization", "sources/_generated/sources/ms-swift/source/GetStarted/Quick-start", "sources/_generated/sources/ms-swift/source/GetStarted/SWIFT-installation", "sources/_generated/sources/ms-swift/source/GetStarted/Web-UI", "sources/_generated/sources/ms-swift/source/Instruction/Agent-support", "sources/_generated/sources/ms-swift/source/Instruction/Command-line-parameters", "sources/_generated/sources/ms-swift/source/Instruction/Evaluation", "sources/_generated/sources/ms-swift/source/Instruction/Export-and-push", "sources/_generated/sources/ms-swift/source/Instruction/Frequently-asked-questions", "sources/_generated/sources/ms-swift/source/Instruction/GKD", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/CHORD", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/CISPO", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/DAPO", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/GSPO", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/REINFORCEPP", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/RLOO", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/SAPO", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/deepeyes", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/entropy_mask", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/training_inference_mismatch", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/treepo", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/gym_env", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/loss_types", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/multi_task", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/multi_turn", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/reward_function", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/reward_model", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/GetStarted/GRPO", "sources/_generated/sources/ms-swift/source/Instruction/Inference-and-deployment", "sources/_generated/sources/ms-swift/source/Instruction/Pre-training-and-Fine-tuning", "sources/_generated/sources/ms-swift/source/Instruction/RLHF", "sources/_generated/sources/ms-swift/source/Instruction/Ray", "sources/_generated/sources/ms-swift/source/Instruction/Reinforced-Fine-tuning", "sources/_generated/sources/ms-swift/source/Instruction/Sample", "sources/_generated/sources/ms-swift/source/Instruction/Supported-models-and-datasets", "sources/_generated/sources/ms-swift/source/Instruction/Use-tuners", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Ascend", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Command-line-parameters", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/GKD", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/GRPO", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/LoRA-Training", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Mcore-Bridge", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Multimodal-Model", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Quick-start", "sources/_generated/sources/ms-swift/source/_templates/autosummary/class", "sources/_generated/sources/ms-swift/source/_templates/classtemplate", "sources/_generated/sources/ms-swift/source/_templates/sobolengine", "sources/_generated/sources/ms-swift/source_en/BestPractices/Elastic", "sources/_generated/sources/ms-swift/source_en/BestPractices/Embedding", "sources/_generated/sources/ms-swift/source_en/BestPractices/GRPO", "sources/_generated/sources/ms-swift/source_en/BestPractices/GRPO-Code-Training", "sources/_generated/sources/ms-swift/source_en/BestPractices/GRPO-Multi-Modal-Training", "sources/_generated/sources/ms-swift/source_en/BestPractices/MLLM-Registration", "sources/_generated/sources/ms-swift/source_en/BestPractices/More-Best-Practices", "sources/_generated/sources/ms-swift/source_en/BestPractices/NPU-support", "sources/_generated/sources/ms-swift/source_en/BestPractices/Qwen3-Best-Practice", "sources/_generated/sources/ms-swift/source_en/BestPractices/Qwen3-VL-Best-Practice", "sources/_generated/sources/ms-swift/source_en/BestPractices/Rapidly-Training-VL-model", "sources/_generated/sources/ms-swift/source_en/BestPractices/Reranker", "sources/_generated/sources/ms-swift/source_en/Customization/Custom-dataset", "sources/_generated/sources/ms-swift/source_en/Customization/Custom-model", "sources/_generated/sources/ms-swift/source_en/Customization/Pluginization", "sources/_generated/sources/ms-swift/source_en/GetStarted/Quick-start", "sources/_generated/sources/ms-swift/source_en/GetStarted/SWIFT-installation", "sources/_generated/sources/ms-swift/source_en/GetStarted/Web-UI", "sources/_generated/sources/ms-swift/source_en/Instruction/Agent-support", "sources/_generated/sources/ms-swift/source_en/Instruction/Command-line-parameters", "sources/_generated/sources/ms-swift/source_en/Instruction/Evaluation", "sources/_generated/sources/ms-swift/source_en/Instruction/Export-and-push", "sources/_generated/sources/ms-swift/source_en/Instruction/Frequently-asked-questions", "sources/_generated/sources/ms-swift/source_en/Instruction/GKD", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/CHORD", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/CISPO", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/DAPO", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/GSPO", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/REINFORCEPP", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/RLOO", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/SAPO", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/deepeyes", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/entropy_mask", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/training_inference_mismatch", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/treepo", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/gym_env", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/loss_types", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/multi_task", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/multi_turn", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/reward_function", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/reward_model", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/GetStarted/GRPO", "sources/_generated/sources/ms-swift/source_en/Instruction/Inference-and-deployment", "sources/_generated/sources/ms-swift/source_en/Instruction/Pre-training-and-Fine-tuning", "sources/_generated/sources/ms-swift/source_en/Instruction/RLHF", "sources/_generated/sources/ms-swift/source_en/Instruction/Ray", "sources/_generated/sources/ms-swift/source_en/Instruction/Reinforced-Fine-tuning", "sources/_generated/sources/ms-swift/source_en/Instruction/Sample", "sources/_generated/sources/ms-swift/source_en/Instruction/Supported-models-and-datasets", "sources/_generated/sources/ms-swift/source_en/Instruction/Use-tuners", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Ascend", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Command-line-parameters", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/GKD", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/GRPO", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/LoRA-Training", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Mcore-Bridge", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Multimodal-Model", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Quick-start", "sources/_generated/sources/ms-swift/source_en/_templates/autosummary/class", "sources/_generated/sources/ms-swift/source_en/_templates/classtemplate", "sources/_generated/sources/ms-swift/source_en/_templates/sobolengine", "sources/_generated/sources/verl/ascend_ci_guide_zh", "sources/_generated/sources/verl/ascend_consistency", "sources/_generated/sources/verl/ascend_profiling_en", "sources/_generated/sources/verl/ascend_profiling_zh", "sources/_generated/sources/verl/ascend_quick_start", "sources/_generated/sources/verl/ascend_sglang_quick_start", "sources/_generated/sources/verl/dockerfile_build_guidance", "sources/_generated/sources/verl/examples/ascend_performance_analysis_guide", "sources/_generated/sources/verl/examples/ascend_retool_best_pratice", "sources/_generated/sources/verl/examples/ascend_sglang_best_practices", "sources/_generated/sources/verl/examples/dapo_multi_model_optimization_practice", "sources/_generated/sources/verl/examples/gspo_optimization_practice", "sources/accelerate/index", "sources/accelerate/install", "sources/accelerate/quick_start", "sources/ascend/quick_install", "sources/deepspeed/index", "sources/deepspeed/install", "sources/deepspeed/quick_start", "sources/kernels/index", "sources/kernels/install", "sources/kernels/quick_start", "sources/llama_cpp/index", "sources/llama_cpp/install", "sources/llama_cpp/quick_start", "sources/lm_deploy/index", "sources/lm_deploy/install", "sources/lm_deploy/quick_start", "sources/lm_evaluation/index", "sources/lm_evaluation/install", "sources/lm_evaluation/quick_start", "sources/ms-swift/index", "sources/onnxruntime/index", "sources/onnxruntime/install", "sources/onnxruntime/quick_start", "sources/open_clip/index", "sources/open_clip/install", "sources/open_clip/quick_start", "sources/opencompass/index", "sources/opencompass/install", "sources/opencompass/quick_start", "sources/opencv/index", "sources/opencv/install", "sources/opencv/quick_start", "sources/pytorch/api_doc", "sources/pytorch/examples", "sources/pytorch/faq", "sources/pytorch/index", "sources/pytorch/install", "sources/pytorch/quick_start", "sources/roll/index", "sources/roll/install", "sources/roll/quick_start", "sources/sd_webui/index", "sources/sd_webui/install", "sources/sd_webui/quick_start", "sources/sentence_transformers/index", "sources/sentence_transformers/install", "sources/sentence_transformers/quick_start", "sources/sglang/index", "sources/sglang/install", "sources/sglang/quick_start", "sources/timm/index", "sources/timm/install", "sources/timm/quick_start", "sources/torchchat/index", "sources/torchchat/install", "sources/torchchat/quick_start", "sources/torchtitan/index", "sources/torchtitan/install", "sources/torchtitan/quick_start", "sources/transformers/fine-tune", "sources/transformers/index", "sources/transformers/inference", "sources/transformers/install", "sources/transformers/modeldownload", "sources/transformers/quick_start", "sources/trl/index", "sources/trl/install", "sources/trl/quick_start", "sources/verl/index", "sources/wenet/index", "sources/wenet/install", "sources/wenet/quick_start", "sources/whisper_cpp/index", "sources/whisper_cpp/install", "sources/whisper_cpp/quick_start"], "envversion": {"sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["index.rst", "sources/Diffusers/index.rst", "sources/Diffusers/install.rst", "sources/Diffusers/quick_start.rst", "sources/LLaMA-Factory/index.rst", "sources/VeOmni/index.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/acceleration.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/arguments.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/best_practice/gpt-oss.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/distributed.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/extras.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/model_support.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/monitor.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/npu_inference.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/npu_installation.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/npu_training.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/quantization.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/trainers.rst", "sources/_generated/sources/LLaMA-Factory/source/advanced/tuning_algorithms.rst", "sources/_generated/sources/LLaMA-Factory/source/getting_started/data_preparation.rst", "sources/_generated/sources/LLaMA-Factory/source/getting_started/eval.rst", "sources/_generated/sources/LLaMA-Factory/source/getting_started/inference.rst", "sources/_generated/sources/LLaMA-Factory/source/getting_started/installation.rst", "sources/_generated/sources/LLaMA-Factory/source/getting_started/merge_lora.rst", "sources/_generated/sources/LLaMA-Factory/source/getting_started/sft.rst", "sources/_generated/sources/LLaMA-Factory/source/getting_started/webui.rst", "sources/_generated/sources/VeOmni/README.md", "sources/_generated/sources/VeOmni/examples/qwen3.md", "sources/_generated/sources/VeOmni/examples/qwen3_moe.md", "sources/_generated/sources/VeOmni/examples/qwen3_omni_moe.md", "sources/_generated/sources/VeOmni/examples/qwen3_vl.md", "sources/_generated/sources/VeOmni/examples/wan2.1.md", "sources/_generated/sources/VeOmni/get_started/installation/install.md", "sources/_generated/sources/VeOmni/get_started/installation/install_ascend.md", "sources/_generated/sources/VeOmni/hardware_support/get_started_npu.md", "sources/_generated/sources/VeOmni/key_features/ep_fsdp2.md", "sources/_generated/sources/VeOmni/key_features/model_loader.md", "sources/_generated/sources/VeOmni/key_features/preprocessor_registry.md", "sources/_generated/sources/VeOmni/key_features/ulysses.md", "sources/_generated/sources/VeOmni/transformers_v5/patchgen.md", "sources/_generated/sources/VeOmni/transformers_v5/transformers_v5_moe_weight_loading.md", "sources/_generated/sources/VeOmni/transformers_v5/veomni_flash_attention_kernel_adapter.md", "sources/_generated/sources/VeOmni/usage/arguments.md", "sources/_generated/sources/VeOmni/usage/basic_modules.md", "sources/_generated/sources/VeOmni/usage/checkpoint_conversion.md", "sources/_generated/sources/VeOmni/usage/rmpad_with_pos_ids_and_dyn_bsz.md", "sources/_generated/sources/VeOmni/usage/support_new_models.md", "sources/_generated/sources/ms-swift/README.md", "sources/_generated/sources/ms-swift/source/BestPractices/Elastic.md", "sources/_generated/sources/ms-swift/source/BestPractices/Embedding.md", "sources/_generated/sources/ms-swift/source/BestPractices/GRPO.md", "sources/_generated/sources/ms-swift/source/BestPractices/GRPO-Code-Training.md", "sources/_generated/sources/ms-swift/source/BestPractices/GRPO-Multi-Modal-Training.md", "sources/_generated/sources/ms-swift/source/BestPractices/MLLM-Registration.md", "sources/_generated/sources/ms-swift/source/BestPractices/More-Best-Practices.md", "sources/_generated/sources/ms-swift/source/BestPractices/NPU-support.md", "sources/_generated/sources/ms-swift/source/BestPractices/Qwen3-Best-Practice.md", "sources/_generated/sources/ms-swift/source/BestPractices/Qwen3-VL-Best-Practice.md", "sources/_generated/sources/ms-swift/source/BestPractices/Rapidly-Training-VL-model.md", "sources/_generated/sources/ms-swift/source/BestPractices/Reranker.md", "sources/_generated/sources/ms-swift/source/Customization/Custom-dataset.md", "sources/_generated/sources/ms-swift/source/Customization/Custom-model.md", "sources/_generated/sources/ms-swift/source/Customization/Pluginization.md", "sources/_generated/sources/ms-swift/source/GetStarted/Quick-start.md", "sources/_generated/sources/ms-swift/source/GetStarted/SWIFT-installation.md", "sources/_generated/sources/ms-swift/source/GetStarted/Web-UI.md", "sources/_generated/sources/ms-swift/source/Instruction/Agent-support.md", "sources/_generated/sources/ms-swift/source/Instruction/Command-line-parameters.md", "sources/_generated/sources/ms-swift/source/Instruction/Evaluation.md", "sources/_generated/sources/ms-swift/source/Instruction/Export-and-push.md", "sources/_generated/sources/ms-swift/source/Instruction/Frequently-asked-questions.md", "sources/_generated/sources/ms-swift/source/Instruction/GKD.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/CHORD.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/CISPO.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/DAPO.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/GSPO.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/REINFORCEPP.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/RLOO.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/SAPO.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/deepeyes.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/entropy_mask.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/training_inference_mismatch.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/AdvancedResearch/treepo.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/gym_env.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/loss_types.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/multi_task.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/multi_turn.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/reward_function.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/DeveloperGuide/reward_model.md", "sources/_generated/sources/ms-swift/source/Instruction/GRPO/GetStarted/GRPO.md", "sources/_generated/sources/ms-swift/source/Instruction/Inference-and-deployment.md", "sources/_generated/sources/ms-swift/source/Instruction/Pre-training-and-Fine-tuning.md", "sources/_generated/sources/ms-swift/source/Instruction/RLHF.md", "sources/_generated/sources/ms-swift/source/Instruction/Ray.md", "sources/_generated/sources/ms-swift/source/Instruction/Reinforced-Fine-tuning.md", "sources/_generated/sources/ms-swift/source/Instruction/Sample.md", "sources/_generated/sources/ms-swift/source/Instruction/Supported-models-and-datasets.md", "sources/_generated/sources/ms-swift/source/Instruction/Use-tuners.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Ascend.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Command-line-parameters.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/GKD.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/GRPO.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/LoRA-Training.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Mcore-Bridge.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Multimodal-Model.md", "sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Quick-start.md", "sources/_generated/sources/ms-swift/source/_templates/autosummary/class.rst", "sources/_generated/sources/ms-swift/source/_templates/classtemplate.rst", "sources/_generated/sources/ms-swift/source/_templates/sobolengine.rst", "sources/_generated/sources/ms-swift/source_en/BestPractices/Elastic.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/Embedding.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/GRPO.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/GRPO-Code-Training.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/GRPO-Multi-Modal-Training.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/MLLM-Registration.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/More-Best-Practices.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/NPU-support.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/Qwen3-Best-Practice.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/Qwen3-VL-Best-Practice.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/Rapidly-Training-VL-model.md", "sources/_generated/sources/ms-swift/source_en/BestPractices/Reranker.md", "sources/_generated/sources/ms-swift/source_en/Customization/Custom-dataset.md", "sources/_generated/sources/ms-swift/source_en/Customization/Custom-model.md", "sources/_generated/sources/ms-swift/source_en/Customization/Pluginization.md", "sources/_generated/sources/ms-swift/source_en/GetStarted/Quick-start.md", "sources/_generated/sources/ms-swift/source_en/GetStarted/SWIFT-installation.md", "sources/_generated/sources/ms-swift/source_en/GetStarted/Web-UI.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Agent-support.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Command-line-parameters.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Evaluation.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Export-and-push.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Frequently-asked-questions.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GKD.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/CHORD.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/CISPO.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/DAPO.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/GSPO.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/REINFORCEPP.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/RLOO.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/SAPO.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/deepeyes.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/entropy_mask.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/training_inference_mismatch.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/treepo.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/gym_env.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/loss_types.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/multi_task.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/multi_turn.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/reward_function.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/reward_model.md", "sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/GetStarted/GRPO.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Inference-and-deployment.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Pre-training-and-Fine-tuning.md", "sources/_generated/sources/ms-swift/source_en/Instruction/RLHF.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Ray.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Reinforced-Fine-tuning.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Sample.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Supported-models-and-datasets.md", "sources/_generated/sources/ms-swift/source_en/Instruction/Use-tuners.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Ascend.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Command-line-parameters.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/GKD.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/GRPO.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/LoRA-Training.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Mcore-Bridge.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Multimodal-Model.md", "sources/_generated/sources/ms-swift/source_en/Megatron-SWIFT/Quick-start.md", "sources/_generated/sources/ms-swift/source_en/_templates/autosummary/class.rst", "sources/_generated/sources/ms-swift/source_en/_templates/classtemplate.rst", "sources/_generated/sources/ms-swift/source_en/_templates/sobolengine.rst", "sources/_generated/sources/verl/ascend_ci_guide_zh.rst", "sources/_generated/sources/verl/ascend_consistency.rst", "sources/_generated/sources/verl/ascend_profiling_en.rst", "sources/_generated/sources/verl/ascend_profiling_zh.rst", "sources/_generated/sources/verl/ascend_quick_start.rst", "sources/_generated/sources/verl/ascend_sglang_quick_start.rst", "sources/_generated/sources/verl/dockerfile_build_guidance.rst", "sources/_generated/sources/verl/examples/ascend_performance_analysis_guide.md", "sources/_generated/sources/verl/examples/ascend_retool_best_pratice.rst", "sources/_generated/sources/verl/examples/ascend_sglang_best_practices.rst", "sources/_generated/sources/verl/examples/dapo_multi_model_optimization_practice.md", "sources/_generated/sources/verl/examples/gspo_optimization_practice.md", "sources/accelerate/index.rst", "sources/accelerate/install.rst", "sources/accelerate/quick_start.rst", "sources/ascend/quick_install.rst", "sources/deepspeed/index.rst", "sources/deepspeed/install.rst", "sources/deepspeed/quick_start.rst", "sources/kernels/index.rst", "sources/kernels/install.rst", "sources/kernels/quick_start.rst", "sources/llama_cpp/index.rst", "sources/llama_cpp/install.rst", "sources/llama_cpp/quick_start.rst", "sources/lm_deploy/index.rst", "sources/lm_deploy/install.rst", "sources/lm_deploy/quick_start.rst", "sources/lm_evaluation/index.rst", "sources/lm_evaluation/install.rst", "sources/lm_evaluation/quick_start.rst", "sources/ms-swift/index.rst", "sources/onnxruntime/index.rst", "sources/onnxruntime/install.rst", "sources/onnxruntime/quick_start.rst", "sources/open_clip/index.rst", "sources/open_clip/install.rst", "sources/open_clip/quick_start.rst", "sources/opencompass/index.rst", "sources/opencompass/install.rst", "sources/opencompass/quick_start.rst", "sources/opencv/index.rst", "sources/opencv/install.rst", "sources/opencv/quick_start.rst", "sources/pytorch/api_doc.rst", "sources/pytorch/examples.rst", "sources/pytorch/faq.rst", "sources/pytorch/index.rst", "sources/pytorch/install.rst", "sources/pytorch/quick_start.rst", "sources/roll/index.rst", "sources/roll/install.rst", "sources/roll/quick_start.rst", "sources/sd_webui/index.rst", "sources/sd_webui/install.rst", "sources/sd_webui/quick_start.rst", "sources/sentence_transformers/index.rst", "sources/sentence_transformers/install.rst", "sources/sentence_transformers/quick_start.rst", "sources/sglang/index.rst", "sources/sglang/install.rst", "sources/sglang/quick_start.rst", "sources/timm/index.rst", "sources/timm/install.rst", "sources/timm/quick_start.rst", "sources/torchchat/index.rst", "sources/torchchat/install.rst", "sources/torchchat/quick_start.rst", "sources/torchtitan/index.rst", "sources/torchtitan/install.rst", "sources/torchtitan/quick_start.rst", "sources/transformers/fine-tune.rst", "sources/transformers/index.rst", "sources/transformers/inference.rst", "sources/transformers/install.rst", "sources/transformers/modeldownload.rst", "sources/transformers/quick_start.rst", "sources/trl/index.rst", "sources/trl/install.rst", "sources/trl/quick_start.rst", "sources/verl/index.rst", "sources/wenet/index.rst", "sources/wenet/install.rst", "sources/wenet/quick_start.rst", "sources/whisper_cpp/index.rst", "sources/whisper_cpp/install.rst", "sources/whisper_cpp/quick_start.rst"], "indexentries": {"built-in function": [[214, "torch_npu._npu_dropout", false], [214, "torch_npu.copy_memory_", false], [214, "torch_npu.empty_with_format", false], [214, "torch_npu.fast_gelu", false], [214, "torch_npu.npu_alloc_float_status", false], [214, "torch_npu.npu_anchor_response_flags", false], [214, "torch_npu.npu_anti_quant", false], [214, "torch_npu.npu_apply_adam", false], [214, "torch_npu.npu_batch_nms", false], [214, "torch_npu.npu_bert_apply_adam", false], [214, "torch_npu.npu_bmmV2", false], [214, "torch_npu.npu_bounding_box_decode", false], [214, "torch_npu.npu_bounding_box_encode", false], [214, "torch_npu.npu_broadcast", false], [214, "torch_npu.npu_ciou", false], [214, "torch_npu.npu_clear_float_status", false], [214, "torch_npu.npu_confusion_transpose", false], [214, "torch_npu.npu_conv2d", false], [214, "torch_npu.npu_conv3d", false], [214, "torch_npu.npu_conv_transpose2d", false], [214, "torch_npu.npu_convert_weight_to_int4pack", false], [214, "torch_npu.npu_convolution", false], [214, "torch_npu.npu_convolution_transpose", false], [214, "torch_npu.npu_deformable_conv2d", false], [214, "torch_npu.npu_diou", false], [214, "torch_npu.npu_dropout_with_add_softmax", false], [214, "torch_npu.npu_dtype_cast", false], [214, "torch_npu.npu_ffn", false], [214, "torch_npu.npu_format_cast", false], [214, "torch_npu.npu_format_cast_", false], [214, "torch_npu.npu_fused_attention_score", false], [214, "torch_npu.npu_fused_infer_attention_score", false], [214, "torch_npu.npu_fusion_attention", false], [214, "torch_npu.npu_geglu", false], [214, "torch_npu.npu_get_float_status", false], [214, "torch_npu.npu_giou", false], [214, "torch_npu.npu_grid_assign_positive", false], [214, "torch_npu.npu_grouped_matmul", false], [214, "torch_npu.npu_gru", false], [214, "torch_npu.npu_ifmr", false], [214, "torch_npu.npu_incre_flash_attention", false], [214, "torch_npu.npu_indexing", false], [214, "torch_npu.npu_iou", false], [214, "torch_npu.npu_layer_norm_eval", false], [214, "torch_npu.npu_linear", false], [214, "torch_npu.npu_lstm", false], [214, "torch_npu.npu_masked_fill_range", false], [214, "torch_npu.npu_max", false], [214, "torch_npu.npu_min", false], [214, "torch_npu.npu_mish", false], [214, "torch_npu.npu_mm_all_reduce_base", false], [214, "torch_npu.npu_multi_head_attention", false], [214, "torch_npu.npu_nms_rotated", false], [214, "torch_npu.npu_nms_v4", false], [214, "torch_npu.npu_nms_with_mask", false], [214, "torch_npu.npu_normalize_batch", false], [214, "torch_npu.npu_one_hot", false], [214, "torch_npu.npu_pad", false], [214, "torch_npu.npu_prompt_flash_attention", false], [214, "torch_npu.npu_ps_roi_pooling", false], [214, "torch_npu.npu_ptiou", false], [214, "torch_npu.npu_quant_matmul", false], [214, "torch_npu.npu_quant_scatter", false], [214, "torch_npu.npu_quant_scatter_", false], [214, "torch_npu.npu_random_choice_with_mask", false], [214, "torch_npu.npu_reshape", false], [214, "torch_npu.npu_rms_norm", false], [214, "torch_npu.npu_roi_align", false], [214, "torch_npu.npu_rotary_mul", false], [214, "torch_npu.npu_rotated_box_decode", false], [214, "torch_npu.npu_rotated_box_encode", false], [214, "torch_npu.npu_rotated_iou", false], [214, "torch_npu.npu_rotated_overlaps", false], [214, "torch_npu.npu_scaled_masked_softmax", false], [214, "torch_npu.npu_scatter", false], [214, "torch_npu.npu_scatter_nd_update", false], [214, "torch_npu.npu_scatter_nd_update_", false], [214, "torch_npu.npu_sign_bits_pack", false], [214, "torch_npu.npu_sign_bits_unpack", false], [214, "torch_npu.npu_silu", false], [214, "torch_npu.npu_slice", false], [214, "torch_npu.npu_softmax_cross_entropy_with_logits", false], [214, "torch_npu.npu_sort_v2", false], [214, "torch_npu.npu_stride_add", false], [214, "torch_npu.npu_swiglu", false], [214, "torch_npu.npu_trans_quant_param", false], [214, "torch_npu.npu_transpose", false], [214, "torch_npu.npu_weight_quant_batchmatmul", false], [214, "torch_npu.npu_yolo_boxes_encode", false], [214, "torch_npu.one_", false]], "torch_npu._npu_dropout()": [[214, "torch_npu._npu_dropout", false]], "torch_npu.copy_memory_()": [[214, "torch_npu.copy_memory_", false]], "torch_npu.empty_with_format()": [[214, "torch_npu.empty_with_format", false]], "torch_npu.fast_gelu()": [[214, "torch_npu.fast_gelu", false]], "torch_npu.npu_alloc_float_status()": [[214, "torch_npu.npu_alloc_float_status", false]], "torch_npu.npu_anchor_response_flags()": [[214, "torch_npu.npu_anchor_response_flags", false]], "torch_npu.npu_anti_quant()": [[214, "torch_npu.npu_anti_quant", false]], "torch_npu.npu_apply_adam()": [[214, "torch_npu.npu_apply_adam", false]], "torch_npu.npu_batch_nms()": [[214, "torch_npu.npu_batch_nms", false]], "torch_npu.npu_bert_apply_adam()": [[214, "torch_npu.npu_bert_apply_adam", false]], "torch_npu.npu_bmmv2()": [[214, "torch_npu.npu_bmmV2", false]], "torch_npu.npu_bounding_box_decode()": [[214, "torch_npu.npu_bounding_box_decode", false]], "torch_npu.npu_bounding_box_encode()": [[214, "torch_npu.npu_bounding_box_encode", false]], "torch_npu.npu_broadcast()": [[214, "torch_npu.npu_broadcast", false]], "torch_npu.npu_ciou()": [[214, "torch_npu.npu_ciou", false]], "torch_npu.npu_clear_float_status()": [[214, "torch_npu.npu_clear_float_status", false]], "torch_npu.npu_confusion_transpose()": [[214, "torch_npu.npu_confusion_transpose", false]], "torch_npu.npu_conv2d()": [[214, "torch_npu.npu_conv2d", false]], "torch_npu.npu_conv3d()": [[214, "torch_npu.npu_conv3d", false]], "torch_npu.npu_conv_transpose2d()": [[214, "torch_npu.npu_conv_transpose2d", false]], "torch_npu.npu_convert_weight_to_int4pack()": [[214, "torch_npu.npu_convert_weight_to_int4pack", false]], "torch_npu.npu_convolution()": [[214, "torch_npu.npu_convolution", false]], "torch_npu.npu_convolution_transpose()": [[214, "torch_npu.npu_convolution_transpose", false]], "torch_npu.npu_deformable_conv2d()": [[214, "torch_npu.npu_deformable_conv2d", false]], "torch_npu.npu_diou()": [[214, "torch_npu.npu_diou", false]], "torch_npu.npu_dropout_with_add_softmax()": [[214, "torch_npu.npu_dropout_with_add_softmax", false]], "torch_npu.npu_dtype_cast()": [[214, "torch_npu.npu_dtype_cast", false]], "torch_npu.npu_ffn()": [[214, "torch_npu.npu_ffn", false]], "torch_npu.npu_format_cast()": [[214, "torch_npu.npu_format_cast", false]], "torch_npu.npu_format_cast_()": [[214, "torch_npu.npu_format_cast_", false]], "torch_npu.npu_fused_attention_score()": [[214, "torch_npu.npu_fused_attention_score", false]], "torch_npu.npu_fused_infer_attention_score()": [[214, "torch_npu.npu_fused_infer_attention_score", false]], "torch_npu.npu_fusion_attention()": [[214, "torch_npu.npu_fusion_attention", false]], "torch_npu.npu_geglu()": [[214, "torch_npu.npu_geglu", false]], "torch_npu.npu_get_float_status()": [[214, "torch_npu.npu_get_float_status", false]], "torch_npu.npu_giou()": [[214, "torch_npu.npu_giou", false]], "torch_npu.npu_grid_assign_positive()": [[214, "torch_npu.npu_grid_assign_positive", false]], "torch_npu.npu_grouped_matmul()": [[214, "torch_npu.npu_grouped_matmul", false]], "torch_npu.npu_gru()": [[214, "torch_npu.npu_gru", false]], "torch_npu.npu_ifmr()": [[214, "torch_npu.npu_ifmr", false]], "torch_npu.npu_incre_flash_attention()": [[214, "torch_npu.npu_incre_flash_attention", false]], "torch_npu.npu_indexing()": [[214, "torch_npu.npu_indexing", false]], "torch_npu.npu_iou()": [[214, "torch_npu.npu_iou", false]], "torch_npu.npu_layer_norm_eval()": [[214, "torch_npu.npu_layer_norm_eval", false]], "torch_npu.npu_linear()": [[214, "torch_npu.npu_linear", false]], "torch_npu.npu_lstm()": [[214, "torch_npu.npu_lstm", false]], "torch_npu.npu_masked_fill_range()": [[214, "torch_npu.npu_masked_fill_range", false]], "torch_npu.npu_max()": [[214, "torch_npu.npu_max", false]], "torch_npu.npu_min()": [[214, "torch_npu.npu_min", false]], "torch_npu.npu_mish()": [[214, "torch_npu.npu_mish", false]], "torch_npu.npu_mm_all_reduce_base()": [[214, "torch_npu.npu_mm_all_reduce_base", false]], "torch_npu.npu_multi_head_attention()": [[214, "torch_npu.npu_multi_head_attention", false]], "torch_npu.npu_nms_rotated()": [[214, "torch_npu.npu_nms_rotated", false]], "torch_npu.npu_nms_v4()": [[214, "torch_npu.npu_nms_v4", false]], "torch_npu.npu_nms_with_mask()": [[214, "torch_npu.npu_nms_with_mask", false]], "torch_npu.npu_normalize_batch()": [[214, "torch_npu.npu_normalize_batch", false]], "torch_npu.npu_one_hot()": [[214, "torch_npu.npu_one_hot", false]], "torch_npu.npu_pad()": [[214, "torch_npu.npu_pad", false]], "torch_npu.npu_prompt_flash_attention()": [[214, "torch_npu.npu_prompt_flash_attention", false]], "torch_npu.npu_ps_roi_pooling()": [[214, "torch_npu.npu_ps_roi_pooling", false]], "torch_npu.npu_ptiou()": [[214, "torch_npu.npu_ptiou", false]], "torch_npu.npu_quant_matmul()": [[214, "torch_npu.npu_quant_matmul", false]], "torch_npu.npu_quant_scatter()": [[214, "torch_npu.npu_quant_scatter", false]], "torch_npu.npu_quant_scatter_()": [[214, "torch_npu.npu_quant_scatter_", false]], "torch_npu.npu_random_choice_with_mask()": [[214, "torch_npu.npu_random_choice_with_mask", false]], "torch_npu.npu_reshape()": [[214, "torch_npu.npu_reshape", false]], "torch_npu.npu_rms_norm()": [[214, "torch_npu.npu_rms_norm", false]], "torch_npu.npu_roi_align()": [[214, "torch_npu.npu_roi_align", false]], "torch_npu.npu_rotary_mul()": [[214, "torch_npu.npu_rotary_mul", false]], "torch_npu.npu_rotated_box_decode()": [[214, "torch_npu.npu_rotated_box_decode", false]], "torch_npu.npu_rotated_box_encode()": [[214, "torch_npu.npu_rotated_box_encode", false]], "torch_npu.npu_rotated_iou()": [[214, "torch_npu.npu_rotated_iou", false]], "torch_npu.npu_rotated_overlaps()": [[214, "torch_npu.npu_rotated_overlaps", false]], "torch_npu.npu_scaled_masked_softmax()": [[214, "torch_npu.npu_scaled_masked_softmax", false]], "torch_npu.npu_scatter()": [[214, "torch_npu.npu_scatter", false]], "torch_npu.npu_scatter_nd_update()": [[214, "torch_npu.npu_scatter_nd_update", false]], "torch_npu.npu_scatter_nd_update_()": [[214, "torch_npu.npu_scatter_nd_update_", false]], "torch_npu.npu_sign_bits_pack()": [[214, "torch_npu.npu_sign_bits_pack", false]], "torch_npu.npu_sign_bits_unpack()": [[214, "torch_npu.npu_sign_bits_unpack", false]], "torch_npu.npu_silu()": [[214, "torch_npu.npu_silu", false]], "torch_npu.npu_slice()": [[214, "torch_npu.npu_slice", false]], "torch_npu.npu_softmax_cross_entropy_with_logits()": [[214, "torch_npu.npu_softmax_cross_entropy_with_logits", false]], "torch_npu.npu_sort_v2()": [[214, "torch_npu.npu_sort_v2", false]], "torch_npu.npu_stride_add()": [[214, "torch_npu.npu_stride_add", false]], "torch_npu.npu_swiglu()": [[214, "torch_npu.npu_swiglu", false]], "torch_npu.npu_trans_quant_param()": [[214, "torch_npu.npu_trans_quant_param", false]], "torch_npu.npu_transpose()": [[214, "torch_npu.npu_transpose", false]], "torch_npu.npu_weight_quant_batchmatmul()": [[214, "torch_npu.npu_weight_quant_batchmatmul", false]], "torch_npu.npu_yolo_boxes_encode()": [[214, "torch_npu.npu_yolo_boxes_encode", false]], "torch_npu.one_()": [[214, "torch_npu.one_", false]]}, "objects": {"torch_npu": [[214, 0, 1, "", "_npu_dropout"], [214, 0, 1, "", "copy_memory_"], [214, 0, 1, "", "empty_with_format"], [214, 0, 1, "", "fast_gelu"], [214, 0, 1, "", "npu_alloc_float_status"], [214, 0, 1, "", "npu_anchor_response_flags"], [214, 0, 1, "", "npu_anti_quant"], [214, 0, 1, "", "npu_apply_adam"], [214, 0, 1, "", "npu_batch_nms"], [214, 0, 1, "", "npu_bert_apply_adam"], [214, 0, 1, "", "npu_bmmV2"], [214, 0, 1, "", "npu_bounding_box_decode"], [214, 0, 1, "", "npu_bounding_box_encode"], [214, 0, 1, "", "npu_broadcast"], [214, 0, 1, "", "npu_ciou"], [214, 0, 1, "", "npu_clear_float_status"], [214, 0, 1, "", "npu_confusion_transpose"], [214, 0, 1, "", "npu_conv2d"], [214, 0, 1, "", "npu_conv3d"], [214, 0, 1, "", "npu_conv_transpose2d"], [214, 0, 1, "", "npu_convert_weight_to_int4pack"], [214, 0, 1, "", "npu_convolution"], [214, 0, 1, "", "npu_convolution_transpose"], [214, 0, 1, "", "npu_deformable_conv2d"], [214, 0, 1, "", "npu_diou"], [214, 0, 1, "", "npu_dropout_with_add_softmax"], [214, 0, 1, "", "npu_dtype_cast"], [214, 0, 1, "", "npu_ffn"], [214, 0, 1, "", "npu_format_cast"], [214, 0, 1, "", "npu_format_cast_"], [214, 0, 1, "", "npu_fused_attention_score"], [214, 0, 1, "", "npu_fused_infer_attention_score"], [214, 0, 1, "", "npu_fusion_attention"], [214, 0, 1, "", "npu_geglu"], [214, 0, 1, "", "npu_get_float_status"], [214, 0, 1, "", "npu_giou"], [214, 0, 1, "", "npu_grid_assign_positive"], [214, 0, 1, "", "npu_grouped_matmul"], [214, 0, 1, "", "npu_gru"], [214, 0, 1, "", "npu_ifmr"], [214, 0, 1, "", "npu_incre_flash_attention"], [214, 0, 1, "", "npu_indexing"], [214, 0, 1, "", "npu_iou"], [214, 0, 1, "", "npu_layer_norm_eval"], [214, 0, 1, "", "npu_linear"], [214, 0, 1, "", "npu_lstm"], [214, 0, 1, "", "npu_masked_fill_range"], [214, 0, 1, "", "npu_max"], [214, 0, 1, "", "npu_min"], [214, 0, 1, "", "npu_mish"], [214, 0, 1, "", "npu_mm_all_reduce_base"], [214, 0, 1, "", "npu_multi_head_attention"], [214, 0, 1, "", "npu_nms_rotated"], [214, 0, 1, "", "npu_nms_v4"], [214, 0, 1, "", "npu_nms_with_mask"], [214, 0, 1, "", "npu_normalize_batch"], [214, 0, 1, "", "npu_one_hot"], [214, 0, 1, "", "npu_pad"], [214, 0, 1, "", "npu_prompt_flash_attention"], [214, 0, 1, "", "npu_ps_roi_pooling"], [214, 0, 1, "", "npu_ptiou"], [214, 0, 1, "", "npu_quant_matmul"], [214, 0, 1, "", "npu_quant_scatter"], [214, 0, 1, "", "npu_quant_scatter_"], [214, 0, 1, "", "npu_random_choice_with_mask"], [214, 0, 1, "", "npu_reshape"], [214, 0, 1, "", "npu_rms_norm"], [214, 0, 1, "", "npu_roi_align"], [214, 0, 1, "", "npu_rotary_mul"], [214, 0, 1, "", "npu_rotated_box_decode"], [214, 0, 1, "", "npu_rotated_box_encode"], [214, 0, 1, "", "npu_rotated_iou"], [214, 0, 1, "", "npu_rotated_overlaps"], [214, 0, 1, "", "npu_scaled_masked_softmax"], [214, 0, 1, "", "npu_scatter"], [214, 0, 1, "", "npu_scatter_nd_update"], [214, 0, 1, "", "npu_scatter_nd_update_"], [214, 0, 1, "", "npu_sign_bits_pack"], [214, 0, 1, "", "npu_sign_bits_unpack"], [214, 0, 1, "", "npu_silu"], [214, 0, 1, "", "npu_slice"], [214, 0, 1, "", "npu_softmax_cross_entropy_with_logits"], [214, 0, 1, "", "npu_sort_v2"], [214, 0, 1, "", "npu_stride_add"], [214, 0, 1, "", "npu_swiglu"], [214, 0, 1, "", "npu_trans_quant_param"], [214, 0, 1, "", "npu_transpose"], [214, 0, 1, "", "npu_weight_quant_batchmatmul"], [214, 0, 1, "", "npu_yolo_boxes_encode"], [214, 0, 1, "", "one_"]]}, "objnames": {"0": ["py", "function", "Python \u51fd\u6570"]}, "objtypes": {"0": "py:function"}, "terms": {"00": [39, 51, 55, 82, 97, 112, 116, 143, 158, 184, 185, 187, 194, 214, 228, 231, 241, 249, 256], "000": [42, 82, 143, 194, 219, 234, 256], "0000": [55, 116, 185, 214], "00000": [27, 29, 51, 112], "000000": 194, "000000000009": 29, "000000000026": 29, "000000039769": 243, "00000763": [70, 131], "00001": [29, 44, 51, 112], "000010": 194, "00002": [29, 44], "00003": [29, 44], "00004": [29, 44], "00005": [29, 44], "00006": [27, 29], "0000e": 214, "0001": [51, 112], "0003": 181, "0004": 181, "0004e": 214, "000946458": 234, "001": [50, 51, 52, 111, 112, 113, 174, 188, 215, 219, 243], "0010": [207, 214], "0010740706": 234, "0010e": 214, "0011": [51, 112, 214], "0011100": [51, 112], "0012754521": 234, "0019760131836": 249, "002": 243, "00210": 219, "0022e": 214, "0029": 214, "003": 243, "0030552391": 234, "0031e": 214, "0033": 214, "0039": 214, "0040": 181, "0041": 200, "0045": 214, "0049": [207, 214], "0054": 214, "0055": 214, "0056": 214, "0059": 181, "0060": 214, "0062": 214, "0067": 214, "0068e": 214, "0070": 200, "0073": 214, "0075e": 214, "0080": 214, "0081": 214, "0085": 200, "0088": [200, 214], "0089": 200, "008s": 234, "0091": 214, "0092": 214, "009252": [70, 131], "0095": 214, "01": [39, 48, 50, 51, 52, 53, 55, 56, 57, 58, 67, 70, 89, 96, 99, 103, 104, 109, 111, 112, 113, 114, 116, 117, 118, 119, 128, 131, 150, 157, 160, 164, 165, 175, 179, 180, 184, 194, 214, 249], "010": [51, 112], "0101": [51, 112, 214], "01011": [51, 112], "0109e": 214, "011": 234, "0110": 214, "0111": [51, 112], "0114": 214, "0117": 214, "0118": 214, "0122": 200, "012223720550537": 249, "0125": [70, 96, 131, 157], "0127": 214, "013": 243, "0131": 214, "0136": 214, "01375547": 228, "0137e": 214, "0138e": 214, "014": [99, 160], "0140": 214, "0142": 214, "0143": 200, "0146": 214, "014782": [70, 131], "0148e": 214, "0149": 214, "0150": 214, "015390396118164": 249, "0154": 214, "01562478": 228, "0156e": 214, "0157": 214, "0158e": 214, "0162": 214, "0162e": 214, "0164": 214, "0165100097656": 249, "0166e": 214, "0169e": 214, "0171e": 214, "0173": 214, "0176": 214, "0177": 214, "0179": [200, 214], "0180": 214, "01825": [94, 155], "0183e": 214, "0184e": 214, "0186": 214, "018695": [70, 131], "0193": 214, "0194": 214, "01ai": [96, 157], "02": [55, 70, 116, 131, 170, 177, 178, 181, 184, 194, 214, 237, 249], "0200": 200, "0201": 214, "0204": 214, "0205": 214, "0212": 200, "0218": 214, "0219": 214, "0225": [96, 157], "0226": 214, "0229e": 214, "0232e": 214, "0237": 214, "0242": [214, 237], "0243e": 214, "0244": 214, "0246": [200, 214], "0249e": 214, "0250": 200, "0252": 214, "0254": 214, "0254e": 214, "0256": 214, "0258e": 214, "0260e": 214, "026123": 241, "0267": 214, "0268": 200, "0270": 214, "0271e": 214, "0272": 214, "0274658203125": 249, "0276": 200, "0278": 200, "0284": 200, "0284e": 214, "0285": 214, "0286": 200, "0288": 214, "0291": [200, 214], "0293": 200, "0294": 214, "0296": 214, "03": [184, 185, 194, 197, 207, 214, 241, 249], "0302": 214, "0303e": 214, "0304": 214, "0307": 200, "0310": 200, "0312": [200, 214], "03137118": 228, "0320": 200, "0321": 200, "0324": [96, 157], "0325": 200, "0326e": 214, "0327": 214, "0328e": 214, "0330": 214, "03300": [94, 155], "03337045": 228, "0334": 200, "0337": 200, "0342": 214, "0343": 200, "0345": 200, "0351": 200, "0355e": 214, "0356": 200, "0361": 200, "0366": 214, "0368": 214, "0370e": 214, "0371e": 214, "0377": [200, 214], "0379": 214, "0381e": 214, "0383": 200, "0384": 200, "0384e": 214, "0387": 200, "0390": 214, "0391": 214, "0391e": 214, "0392": 200, "0397": 214, "0398": 200, "03_linux": 22, "04": [3, 14, 22, 50, 64, 67, 70, 99, 105, 111, 125, 128, 131, 160, 166, 170, 176, 181, 183, 185, 194, 214, 234, 249], "040": 234, "0402": 214, "0404": 200, "0406": 200, "0407": 214, "0414": [66, 96, 127, 157], "0417": 200, "0420": 214, "0420e": 214, "0423": 214, "04230832": 228, "0424e": 214, "0429": 200, "0429e": 214, "04301599": 228, "0431": 200, "0433": 214, "0436": 200, "0437": [200, 214], "0437e": 214, "0438": 200, "04393559": 228, "0442": 214, "0446": 200, "0450": 214, "0451": 200, "0453": 200, "0457e": 214, "046": 243, "0469": 200, "0473": [200, 214], "0474": 214, "0479": 200, "0480": 200, "0480e": 214, "0482": 200, "04824848": 228, "0483": [200, 214], "0485": 214, "0486": 214, "0488": 214, "0488e": 214, "049": 249, "0493": 249, "0498": 200, "0498e": 214, "0499": 214, "04s": [105, 166], "05": [7, 18, 19, 51, 52, 53, 56, 57, 58, 63, 67, 70, 78, 92, 99, 102, 103, 104, 105, 112, 113, 114, 117, 118, 119, 124, 128, 131, 139, 153, 160, 163, 164, 165, 166, 184, 194, 214, 219, 249, 256], "050": 194, "0501": 200, "0501e": 214, "0502": 200, "0503": 200, "0504": 214, "0507": 214, "0510e": 214, "0514": 214, "0518e": 214, "05215353": 228, "0525": 214, "0526e": 214, "0528": [96, 157], "0529e": 214, "0530": [96, 157, 214], "0532e": 214, "0533": 214, "0537": 214, "0538": 214, "0538e": 214, "0547": 214, "0547e": 214, "05488579": 228, "0548e": 214, "0550e": 214, "0551": 249, "0556": [68, 129], "0557311197916666": 241, "0558": 214, "05615513": 228, "05640831": 228, "0569e": 214, "0576": 214, "0576e": 214, "05903088": 228, "0591": 214, "06": [210, 214, 241, 249], "0604e": 214, "0609": 214, "0611": 214, "0620": 214, "0625": [68, 129, 214], "0630e": 214, "0632": 214, "0633": 214, "0635e": 214, "0638": 237, "0638e": 214, "0639": 214, "0640e": 214, "0645e": 214, "0647": 214, "0651": 214, "0656": 214, "0657": 214, "0661": 214, "0662": 214, "0664e": 214, "06652435": 228, "0666": 237, "0669e": 214, "0687e": 214, "0691e": 214, "0693": 214, "0694": 214, "0698": 214, "07": [70, 131, 184, 210, 249], "0706e": 214, "0720e": 214, "0723e": 214, "073": 243, "0730": 214, "07301": [94, 155], "0732": 214, "0733e": 214, "0734": 214, "0742e": 214, "0748": 214, "0749e": 214, "075": 243, "0750e": 214, "0754e": 214, "076": 210, "0760e": 214, "0766": 214, "0769": 214, "0771": 214, "0776e": 214, "0780e": 214, "0783": 214, "0783e": 214, "0793e": 214, "0794": 214, "08": [70, 131, 214, 219, 228], "0801e": 214, "0803": 214, "0804": 214, "0804e": 214, "0808e": 214, "0809e": 214, "0811e": 214, "0815": 214, "0820e": 214, "0830e": 214, "0831e": 214, "08333969": [70, 131], "0833e": 214, "0837e": 214, "083s": 234, "0846e": 214, "0847": 214, "0848e": 214, "0849": 214, "08493122": 228, "0862e": 214, "0865316167473793": 249, "0871": 214, "0872e": 214, "088": 243, "08838": 214, "0892e": 214, "0899": 214, "08998": [94, 155], "0899e": 214, "0904e": 214, "0905": [96, 157, 214], "0909e": 214, "0910e": 214, "0911e": 214, "0917e": 214, "0919e": 214, "0923": 214, "0924": [96, 157], "0928": 214, "0930": 214, "0930e": 214, "0933e": 214, "0935": 214, "09556": 219, "0955e": 214, "0957e": 214, "0960e": 214, "0967": 214, "0970": 214, "0974e": 214, "0979": 214, "0980": 214, "0981e": 214, "0986": 214, "0998": 214, "0_30_s_academic_mc_v0_1_qa_process": 29, "0_30_s_academic_v0_10_30_s_youtube_v0_11_2_m_academic_v0_11_2_m_youtube_v0_12_3_m_academic_v0_12_3_m_youtube_v0_130_60_s_academic_v0_130_60_s_youtube_v0_1": [96, 157], "0_535": 22, "0_core_r0": [55, 116], "0b1": [64, 105, 125, 166], "0d": 214, "0e": [8, 17, 24, 194, 222], "0f": [188, 219], "0npu_out": 214, "0rc": 230, "0rc1": [172, 173, 174, 176], "0rc3": [55, 116], "0rc4": [174, 176], "0th": 121, "0x40000": 214, "0xffff839ef4a0": 222, "10": [0, 2, 8, 9, 13, 17, 22, 24, 35, 42, 45, 48, 50, 51, 52, 55, 58, 60, 63, 64, 66, 67, 68, 71, 76, 77, 89, 90, 91, 92, 95, 97, 99, 104, 105, 109, 111, 112, 113, 116, 119, 121, 124, 125, 127, 128, 129, 132, 137, 138, 150, 151, 152, 153, 156, 158, 160, 165, 166, 174, 175, 178, 180, 181, 185, 187, 188, 191, 193, 194, 199, 206, 209, 212, 214, 215, 218, 219, 221, 222, 224, 228, 233, 234, 236, 239, 244, 249, 252], "100": [0, 3, 9, 19, 50, 55, 56, 57, 63, 66, 67, 68, 70, 96, 102, 105, 111, 116, 117, 118, 124, 127, 128, 129, 157, 163, 166, 178, 184, 188, 191, 193, 194, 207, 210, 212, 214, 219, 222, 228, 231, 234, 241, 249, 255], "1000": [7, 8, 9, 17, 24, 48, 50, 51, 52, 56, 57, 58, 67, 71, 103, 109, 111, 112, 113, 117, 118, 119, 128, 132, 164, 188, 207, 219, 234, 241, 249], "10000": [57, 96, 118, 157, 188, 207, 219, 222, 240], "100000": [96, 157], "1000m": [97, 158], "10029524": 228, "1003": [96, 157], "1003520": [53, 58, 60, 70, 90, 104, 114, 119, 121, 131, 151, 165], "1006": 214, "1009": [96, 157, 214], "100k": [29, 96, 157], "100m": [97, 158], "100poisonmpt": [96, 157], "101": [51, 55, 60, 96, 112, 116, 121, 157], "1018e": 214, "102": [50, 55, 96, 111, 116, 157], "10205095": 228, "1023": 214, "1023e": 214, "1024": [3, 7, 17, 24, 35, 42, 50, 52, 57, 67, 70, 87, 99, 103, 111, 113, 118, 128, 148, 160, 164, 178, 194, 204, 207, 214, 219, 222], "10240": 214, "1025e": 214, "1028": [96, 157, 214], "1029": [96, 157], "1029e": 214, "102b": [96, 157], "103": [37, 55, 116], "1030": [194, 214], "103329": [96, 157], "1035e": 214, "103695": [96, 157], "1037": [96, 157], "1039": [96, 157], "104": [13, 96, 157], "1040": 214, "1042e": 214, "1045": 214, "105": [60, 66, 82, 121, 127, 143], "1050e": 214, "1052": [70, 131], "1056": 214, "1058": 214, "106": [96, 157], "1061": 214, "1064": 214, "1067": 214, "107": [96, 157], "1070": [96, 157], "1074": 214, "108": [13, 96, 157], "1080": [96, 157], "1081": 214, "1084e": 214, "1086e": 214, "1087": [96, 157], "10884": [96, 157], "109184": [96, 157], "1094e": 214, "1096e": 214, "1099": [60, 121], "10b": [96, 157], "10g": 14, "10gb": [67, 128], "10gib": [97, 158], "10h": [70, 131], "10k": [51, 96, 112, 157], "10k_decontamin": [96, 157], "10pt": [74, 135], "10x": [124, 166], "11": [14, 22, 35, 37, 51, 55, 57, 60, 64, 66, 67, 73, 75, 78, 81, 82, 86, 89, 101, 105, 112, 116, 118, 121, 125, 127, 128, 134, 136, 139, 142, 143, 147, 150, 162, 166, 170, 171, 172, 173, 174, 175, 176, 178, 180, 181, 185, 190, 194, 214, 228, 230, 236, 241, 249, 256], "110": [96, 157, 214], "110000": [96, 157], "11010": [51, 112], "11021": [96, 157], "1102681159973145": 249, "11087": [96, 157], "1108e": 214, "110b": [96, 157], "110k": [56, 96, 103, 117, 157, 164], "111": 194, "1110": [51, 112], "1111": [67, 128], "1113": 214, "1115": 214, "1115e": 214, "1116e": 214, "1118": 214, "112": [96, 157, 194, 214], "1122e": 214, "1123": 214, "1124": 214, "11264": 214, "112958": [96, 157], "113": [60, 96, 121, 157], "1130": 214, "11301": [96, 157], "1130e": 214, "1131": 214, "1133e": 214, "1134e": 214, "113957": [96, 157], "11399": [96, 157], "11419677734375": 249, "1142": 214, "1144": [96, 157], "114k": [96, 157], "11500": [96, 157], "115132": [96, 157], "11536": 178, "1155": 214, "1156e": 214, "1157": [96, 157, 214], "115b": [96, 157], "116": [96, 157], "1160": 214, "1162": [96, 157], "11637": [96, 157], "1163e": 214, "1166": [96, 157], "1167": [96, 157], "117": [96, 157], "1176e": 214, "1179e": 214, "118": [70, 96, 131, 157, 194, 214], "1186e": 214, "1188": [96, 157], "119": [55, 96, 116, 157], "1190": [96, 157], "1192": 214, "1192e": 214, "1193e": 214, "11998": [96, 157], "11b": [96, 157], "12": [22, 32, 34, 35, 53, 55, 57, 58, 64, 67, 68, 83, 86, 87, 90, 94, 96, 100, 105, 114, 116, 118, 119, 125, 128, 129, 144, 147, 148, 151, 155, 157, 160, 161, 166, 172, 173, 174, 175, 176, 178, 180, 181, 184, 188, 194, 196, 210, 214, 219], "120": [188, 214, 219], "12000": [96, 157], "120000": [96, 157], "1200g": [14, 15], "1202": 214, "1208": 214, "120b": [96, 157], "121": [96, 157], "1210": [96, 157], "1218": 214, "122": [96, 157, 214], "1223e": 214, "1224e": 214, "1225": 214, "1226": 214, "12288": [58, 119], "1228e": 214, "122b": [96, 157], "123": [70, 96, 131, 157, 207], "1232": 214, "1234": [171, 179], "1234e": 214, "12379668": 228, "124": 194, "1242": 214, "124345": [96, 157], "1244e": 214, "1248": 214, "12489": [96, 157], "125": [50, 96, 111, 157, 214, 234, 256], "1250": 214, "1254e": 214, "1258": 214, "125894": [96, 157], "126": [96, 157, 214], "1260": [194, 214], "1266": [96, 157], "1268": [52, 113], "127": [50, 51, 52, 70, 88, 90, 91, 111, 112, 113, 131, 149, 151, 152, 214, 231], "1270": 214, "1273": 214, "1273e": 214, "128": [7, 18, 35, 50, 53, 57, 58, 67, 96, 103, 111, 114, 118, 119, 128, 157, 164, 174, 177, 181, 194, 207, 214, 222, 231], "1280": [67, 128, 214], "128000": [194, 241], "128009": 194, "1281e": 214, "128256": 194, "12859": [96, 157], "1289e": 214, "128e": [11, 96, 157], "128k": [96, 157], "129": [96, 157], "1293": 214, "1297e": 214, "12b": [96, 157], "12k": [96, 157], "13": [0, 35, 64, 105, 125, 166, 174, 175, 194, 207, 214, 230, 234, 237, 241, 252, 256], "130": [96, 157], "1300": [52, 113], "130m": [96, 157], "131": [96, 157, 256], "131201": [96, 157], "1313e": 214, "13152": 194, "1316e": 214, "1318": 214, "131867": [96, 157], "131k": [96, 157], "132": [60, 66, 121, 127], "1325e": 214, "132673": [96, 157], "1328": 214, "1328e": 214, "1329": 214, "133": [70, 96, 131, 157], "13313": 194, "1332e": 214, "1334": 214, "1335": 214, "1335486": [96, 157], "1337": 214, "1342e": 214, "1344": [67, 128, 214], "1344e": 214, "1346e": 214, "135": [50, 57, 60, 111, 118, 121], "1353e": 214, "1355": 249, "136": [50, 96, 111, 157], "1361": 214, "13623": 194, "1364": 214, "13640": [96, 157], "1365e": 214, "137": 214, "1371": 214, "1375": 214, "1383": [96, 157], "13868": [96, 157], "1387": 214, "139": 249, "1396e": 214, "13b": [96, 157], "14": [35, 50, 51, 57, 64, 66, 67, 96, 99, 111, 112, 118, 125, 127, 128, 157, 160, 175, 187, 194, 207, 210, 214, 219, 249], "140": [96, 157], "1400e": 214, "1401": 214, "1405e": 214, "1406": 214, "141": [96, 157], "1416": [96, 157], "141600": [96, 157], "142": [96, 157], "1421": 214, "1422e": 214, "1427": [60, 121], "143": [96, 157, 249], "1431e": 214, "14336": 194, "1433e": 214, "144": [55, 83, 86, 116, 144, 147, 243, 249], "1445": 214, "145": [96, 157], "1450e": 214, "1451": [68, 129], "1452e": 214, "1453": [68, 129], "1455": [96, 157, 214], "1457": 214, "1458e": 214, "1461": 214, "1465e": 214, "1467": 214, "1469e": 214, "147": 256, "1474": 214, "1474e": 214, "1477": 214, "1481e": 214, "1484": 214, "1490": 214, "1492": 214, "1496": 214, "14b": [31, 34, 55, 96, 105, 116, 157, 166, 174], "14gib": [102, 163], "15": [19, 35, 50, 64, 67, 70, 96, 99, 105, 111, 125, 128, 131, 157, 160, 166, 175, 181, 184, 188, 194, 214, 219, 222, 228, 237, 241, 249, 256], "150": [60, 63, 70, 96, 121, 124, 131, 157, 179, 234], "1500": 256, "15000": 219, "15011": [96, 157], "1502": 214, "1502880093958574": 245, "1507": 214, "1508": [96, 157], "150b": [96, 157], "150k": [96, 157], "151": [214, 221], "1511e": 214, "1514": 214, "151645": 231, "151655": [66, 127], "15169": 185, "1516e": 214, "1517": [96, 157], "1518": 214, "151936": [58, 119], "152064": [58, 119], "1523": 214, "1523e": 214, "153": [96, 157, 214, 256], "15317": 194, "1532": 214, "1532e": 214, "1533e": 214, "1536": 177, "15380859375": 249, "1539": [96, 157], "154": [96, 157], "1540": 214, "1543": 214, "15474730730056763": 249, "1548289060592651": 249, "1553": 214, "15536": [70, 131], "1554": 214, "1556": 214, "155628": 241, "1558": 214, "156": [96, 157], "1560": 214, "1562": 214, "1562e": 214, "157": [96, 157, 214, 234], "1571": [96, 157, 214], "1572e": 214, "1574": [96, 157], "15777587890625": 249, "1578": 214, "158": [96, 157, 221], "1582": 214, "159": 214, "1591": [96, 157], "1594": [60, 121], "15k": [96, 157], "16": [6, 7, 8, 9, 15, 17, 18, 20, 24, 27, 35, 46, 48, 50, 51, 53, 55, 56, 57, 63, 67, 68, 70, 82, 83, 86, 89, 96, 99, 102, 103, 105, 109, 111, 112, 114, 116, 117, 118, 124, 128, 129, 131, 143, 144, 147, 150, 157, 160, 163, 164, 166, 178, 180, 181, 188, 194, 214, 219, 221, 222, 243, 256], "160": [57, 60, 118, 121], "16000": [67, 128, 256], "1601e": 214, "1607": 256, "1610": 214, "1611": 214, "1615e": 214, "162": [96, 157, 207], "1621": 214, "162149": [96, 157], "1631": 214, "1632": 214, "16384": [7, 67, 70, 128, 131], "1638e": 214, "164": [96, 157, 214], "1641": 214, "1642e": 214, "1648e": 214, "1649": 214, "1649399": [96, 157], "165": 214, "1650e": 214, "166": 214, "166211": [96, 157], "166758": [96, 157], "1669": 214, "167": [55, 96, 116, 157], "16710": [96, 157], "168": [9, 15, 50, 111], "1682e": 214, "1683": [96, 157], "1685": 214, "1687e": 214, "1689": 214, "1691": 214, "1694": 214, "16967": [96, 157], "1698e": 214, "1699": [96, 157, 214], "16b": [96, 157], "16e": [11, 96, 157], "16g": [170, 183, 230], "16gi": [48, 109], "16k": [96, 157, 214], "16kb": 177, "17": [50, 67, 111, 128, 171, 194, 214, 218, 219, 237, 256], "170": [96, 157], "17050": [96, 157], "1707e": 214, "171": [50, 111], "1710": [96, 157], "1716": [96, 157], "1716e": 214, "1718": 214, "1718e": 214, "1719": 214, "1720e": 214, "1721e": 214, "1722e": 214, "1723": 214, "1723e": 214, "1725": 184, "17256": [94, 155], "1726": [96, 157], "1728907816": 194, "1731e": 214, "1736": 214, "17398": [96, 157], "1742e": 214, "1746": 214, "175": [96, 157, 207, 214], "1753845214844": 249, "1757e": 214, "1759136880": 231, "176": 214, "176000": 256, "1761e": 214, "1764": 214, "177": [96, 157], "1776e": 214, "178": [96, 157, 214], "1787e": 214, "1788e": 214, "17899": [96, 157], "178k": [96, 157], "179": [96, 157], "1790": 214, "1790e": 214, "1792": [67, 128], "1795e": 214, "1797e": 214, "1799": [96, 157], "17b": [11, 96, 157], "17k": [96, 157, 178, 179, 181], "18": [64, 75, 82, 96, 125, 136, 143, 157, 194, 197, 210, 214, 256], "180": [50, 111, 213], "1800": [67, 96, 128, 157, 214], "18000000": [67, 99, 128, 160], "180000000": [8, 17, 20, 24], "1801": [96, 157], "1801e": 214, "1807e": 214, "1811e": 214, "1812": 241, "1813e": 214, "1816e": 214, "1818": 214, "182": 214, "18201": [96, 157], "1821": 214, "1823e": 214, "1826": [96, 157], "1828e": 214, "1829e": 214, "1831": [96, 157], "1834": 214, "1834e": 214, "184": 214, "1850": 214, "1850809": [96, 157], "1855": 214, "1859": 214, "186": [96, 157, 214], "1863": 214, "18659590184688568": 249, "1866": [96, 157], "186753": [96, 157], "1872": [96, 157], "1875": 214, "1876": 214, "1876e": 214, "1877e": 214, "1879e": 214, "188": [96, 157, 214], "1880": 214, "1887e": 214, "1889": 214, "189": [50, 96, 111, 157], "1890e": 214, "1891": [214, 234], "18944": [58, 119], "1894e": 214, "1895003467798233": 249, "19": [64, 68, 70, 105, 125, 129, 131, 166, 184, 194, 214, 249, 256], "1902": 214, "1904": 214, "1904e": 214, "191": [96, 157], "1919e": 214, "192": [9, 15, 194, 256], "1924": 214, "1925e": 214, "1926": [96, 157], "1926e": 214, "19288": [96, 157], "1928e": 214, "193": [96, 157], "1932": [96, 157], "1934": 214, "1936e": 214, "1938": 214, "194063": [96, 157], "1946": 214, "195": [66, 127, 214], "1951e": 214, "1954": 214, "19548": [96, 157], "196": [96, 157], "1961": 214, "19654": [96, 157], "1970": [70, 131], "1970e": 214, "1971": [96, 157], "1972e": 214, "1976": 214, "1978": [96, 157], "19788": 241, "198": [96, 157], "1980e": 214, "1982": 214, "1982e": 214, "1983e": 214, "1989e": 214, "199": [96, 157, 237], "1990": 19, "1993": 214, "1999": 219, "19b": [96, 157], "19m": [70, 131], "1_5b": [70, 131], "1_8b": [94, 155, 210], "1_8b_instruct": [94, 155], "1_8b_sft": [94, 155], "1b": [16, 96, 157, 170], "1bit": 214, "1d": 214, "1d7fe4": 210, "1dev0": [96, 157], "1e": [3, 7, 9, 18, 24, 38, 39, 42, 50, 51, 52, 53, 55, 56, 57, 63, 67, 68, 70, 89, 99, 102, 103, 104, 105, 111, 112, 113, 114, 116, 117, 118, 124, 128, 129, 131, 150, 160, 163, 164, 165, 166, 178, 188, 207, 214, 219], "1e9": 9, "1f": 219, "1f1b": [99, 160], "1k": [96, 157, 175], "1lm": [70, 131], "1m": [70, 96, 131, 157], "1ms": 177, "1nhs": 214, "1nss": 214, "1s": [104, 147, 165], "1t": [96, 157], "1ubuntu1": [22, 194], "1v": [96, 157], "1x16": [96, 157], "20": [13, 19, 48, 50, 57, 67, 68, 96, 109, 111, 118, 125, 128, 129, 157, 172, 173, 174, 177, 178, 181, 185, 187, 194, 213, 214, 215, 219, 221, 234], "200": [7, 18, 50, 51, 56, 67, 82, 103, 104, 111, 112, 113, 117, 128, 143, 164, 165, 214, 231], "2000": [27, 48, 50, 53, 56, 57, 67, 103, 109, 111, 114, 117, 118, 128, 164, 188, 219], "20000": [70, 103, 131, 164], "200000": [96, 157], "2000000000": 44, "20022": [96, 157], "2002e": 214, "200gi": [48, 109], "200k": [96, 157], "200t": [174, 175, 176], "200token": 52, "200us": 177, "201": [60, 96, 121, 157], "2010": [96, 157], "2012": 214, "2012e": 214, "2019": 214, "202": [96, 157, 214], "2020": [214, 219], "20200220_120000": 210, "2021e": 214, "2022": [22, 94, 96, 155, 157], "2023": 210, "20230220_183030": 210, "20230720": [96, 157], "202364": [96, 157], "2023e": 214, "2024": [179, 228], "20241220": [96, 157], "2024e": 214, "2025": [34, 171, 172, 173, 174, 176, 219, 230], "2026": [39, 170, 174, 175, 177, 178, 179, 180, 181, 214], "2036e": 214, "203823": [70, 131], "204": [96, 157], "2041": 214, "2041e": 214, "2048": [7, 8, 20, 35, 42, 50, 51, 53, 55, 56, 57, 58, 63, 68, 70, 71, 90, 91, 102, 103, 104, 105, 111, 112, 114, 116, 117, 118, 119, 124, 129, 131, 132, 151, 152, 163, 164, 165, 166, 178, 179, 181, 194, 210, 214, 240], "20480": 178, "204kb": 184, "2052e": 214, "2054e": 214, "2055": [96, 157], "2056": 214, "2057": 214, "2057e": 214, "2059": 214, "206": [96, 157], "2062": [68, 129], "2063e": 214, "2065": 214, "2068589": [96, 157], "207": [96, 157, 214], "2070": [96, 157], "2077": [67, 128], "2077e": 214, "2078": 214, "207843": [96, 157], "208": [96, 157], "2080": 214, "2087": 214, "209": [96, 157], "2092e": 214, "20b": [8, 96, 157], "20gb": [67, 128], "20k": [96, 157], "20s": 67, "21": [50, 96, 111, 157, 194, 214, 230, 234, 241], "2109": 214, "2109e": 214, "2112": 177, "2115e": 214, "2117": [96, 157], "2119e": 214, "212": [57, 60, 118, 121], "2120": [96, 157], "2123": 214, "2124": 214, "2126": 214, "21268120": 234, "2128": 214, "2128e": 214, "2131": 214, "2134": 214, "2136e": 214, "2137e": 214, "2139": 214, "213kb": 184, "214": [96, 157], "214661": [96, 157], "2147473647": 214, "2147483647": 214, "21476": [96, 157], "2149": 214, "2153e": 214, "2168": 214, "2168960571289": 249, "217": 214, "2177e": 214, "2178e": 214, "218": [96, 157], "2185": 200, "2186e": 214, "219": [96, 157], "21910": [96, 157], "219116": [96, 157], "2193": [96, 157], "2194": 214, "2194e": 214, "2195": 214, "21993154287338257": 249, "21b": [96, 157], "21gib": [57, 118], "21h2": 22, "22": [13, 22, 55, 68, 96, 116, 129, 157, 174, 176, 184, 185, 194, 214, 236], "2200e": 214, "2206": 214, "221": [60, 96, 121, 157], "2212e": 214, "2213e": 214, "2218e": 214, "2219": 214, "2219e": 214, "2221": [96, 157, 214], "223": [96, 157, 214, 256], "2230": 214, "2232": [96, 157], "224": [96, 157, 204, 207, 234, 243], "2243e": 214, "225": [204, 234], "2251": [96, 157], "2253e": 214, "2257": 214, "226": [60, 121, 194], "2264": 214, "2265": 214, "2266": 214, "2267": [96, 157], "2267e": 214, "2268": [96, 157], "227": 214, "22747": 241, "2279": 214, "228": 14, "2285": 214, "229": [204, 234], "2291": 214, "2292": 214, "22941": [96, 157], "2297e": 214, "22b": [96, 157], "22gb": [56, 63, 117, 124], "22h2": 22, "23": [34, 55, 64, 105, 116, 125, 166, 184, 185, 197, 210, 214, 224, 237], "2303": 219, "230720": [96, 157], "2307e": 214, "2308": [94, 155], "23089599609375": 249, "2311e": 214, "2312": 219, "2315": [96, 157], "2316": 214, "232": [96, 157], "2323": 214, "2324": [68, 129, 214], "2324e": 214, "233": [66, 96, 127, 157, 214], "2335": 214, "234": [96, 157], "2341": 214, "2344": [96, 157], "2344e": 214, "2359": [96, 157], "2359223c1837a7587402bda0f2643382a6eefeab": 243, "235b": [56, 96, 102, 103, 117, 157, 163, 164], "236": [96, 157], "2361": 214, "2362": 214, "2367": 214, "2369": 214, "2372e": 214, "2375e": 214, "2378": 214, "237kb": 184, "238": 194, "2381e": 214, "239": [50, 111], "2393": [68, 129], "2397e": 214, "23gib": [104, 165], "23h2": 22, "23mb": 184, "24": [52, 55, 67, 96, 113, 116, 128, 157, 177, 185, 194, 206, 214, 230], "240": 128, "2402": [94, 155], "2402e": 214, "2404": 214, "2405": 214, "2405e": 214, "2406e": 214, "2407": [96, 157], "240728": [96, 157], "2409": [96, 157], "240s": [67, 99, 160], "241": [96, 157, 237], "2410": [96, 157, 214], "241014": [96, 157], "241101": [67, 96, 128, 157], "2412": [94, 155], "24127893149852753": 249, "2416e": 214, "2419e": 214, "241b": [96, 157], "242": [96, 157], "2422e": 214, "2425": 200, "242685556411743": 249, "2426e": 214, "243": [96, 157, 214], "2432": 214, "2432083934545517": 249, "2433e": 214, "244": [70, 131], "2449": [96, 157], "2452": 214, "2453e": 214, "24576": [67, 128], "246": [60, 96, 121, 157], "2462": 214, "2463": 214, "246370": 184, "2468e": 214, "247": 214, "2472e": 214, "2473": 214, "2476": 214, "2478": 214, "2479": 214, "248": [96, 157], "24832": [82, 143], "248481": [96, 157], "2485": 214, "2488": 214, "2490": 214, "24926": [96, 157], "2494e": 214, "2496635913848877": 249, "24b": [96, 157], "25": [7, 14, 18, 50, 64, 70, 82, 89, 94, 95, 96, 103, 111, 125, 131, 143, 150, 155, 156, 157, 164, 175, 210, 213, 214, 234], "250": [52, 63, 96, 113, 124, 157, 234], "2500": 214, "25000": [96, 157], "25000763": [70, 131], "2501": [94, 96, 155, 157], "2503": [96, 157], "2504": 178, "2505": [96, 157], "2506": [96, 157], "2507": [27, 40, 96, 103, 157, 164, 170], "250718": [56, 102, 117, 163], "2507e": 214, "251": [96, 157], "2512": [96, 157], "2513": [82, 143], "252": [96, 157], "2521e": 214, "2524e": 214, "2526e": 214, "2528": 214, "252d76908b903ad8fb6969eb3a5e5f873c95ea2b": [180, 181], "253": [96, 157, 214], "2534e": 214, "2535e": 214, "2536e": 214, "254": [96, 157, 214], "2542e": 214, "2547": [96, 157], "2549": [96, 157], "255": [96, 157, 204, 214], "2556": 214, "2556e": 214, "2558e": 214, "2559": 214, "256": [7, 67, 89, 90, 96, 128, 150, 151, 157, 177, 194, 214, 234, 246], "2560": 214, "2560e": 214, "2563016414642334": 249, "2565e": 214, "256k": [96, 157], "256x256": 207, "257": [96, 157], "2570": 214, "2571e": 214, "2573": 214, "2573e": 214, "2574e": 214, "2576e": 214, "2580": 214, "25826": [96, 157], "259": [96, 157], "2590e": 214, "2592": 214, "25921": [96, 157], "2598e": 214, "25m": [96, 157], "25t10": 39, "26": [14, 64, 70, 82, 96, 125, 131, 143, 157, 181, 184, 206, 209, 214, 230, 233], "2604": 214, "2608": 214, "261324": [82, 143], "2617": 214, "2619e": 214, "26203155517578": 249, "262040": [96, 157], "262144": [52, 113], "2622e": 214, "2624e": 214, "2626e": 214, "2627e": 214, "2633": 214, "2636": [96, 157], "2638e": 214, "264": [96, 157, 214], "2644e": 214, "2646": 214, "2647e": 214, "26485": [96, 157], "265": [96, 157], "2651": 214, "2654": 214, "2656": 214, "2659e": 214, "266": [60, 96, 121, 157], "2661": [96, 157], "2674": 214, "2677e": 214, "268": [96, 157], "2687": 214, "2691e": 214, "26b": [96, 157], "27": [37, 64, 96, 125, 157, 175, 179, 180, 194, 214, 234, 241], "270": 213, "2700": 200, "2701e": 214, "2702": 214, "270m": [96, 157], "271": [96, 157], "271211a558b7808d8b12d403fd15edda": [81, 142], "271261": [96, 157], "2714": 214, "2717": 214, "272": [96, 157], "2720e": 214, "27224": [96, 157], "272339": [82, 143], "2728e": 214, "2729e": 214, "273": [96, 157], "2733": 214, "2734e": 214, "274": [96, 157], "2745": 214, "2747": 214, "2753": 214, "2754": 214, "27545": 241, "2755e": 214, "276": [96, 157], "277": [96, 157], "27701": 184, "2770e": 214, "2775": [75, 136], "27755": [82, 143], "2779": [96, 157], "2783": 214, "27839": [96, 157], "2789": 214, "279": 241, "2792e": 214, "27b": [96, 157], "27k": [96, 157], "28": [50, 55, 58, 60, 64, 67, 74, 82, 96, 111, 116, 119, 121, 125, 128, 135, 143, 157, 178, 180, 194, 214, 256], "2800": 200, "280147": 194, "2804": 214, "2817e": 214, "2818": [96, 157], "282": [96, 157], "2822": 214, "2825e": 214, "2826": [96, 157], "28299": [96, 157], "283": 249, "2831": 214, "2850e": 214, "2854": 256, "2857": 200, "2860e": 214, "2864": 214, "2871": 214, "2871e": 214, "2874": 214, "2877e": 214, "288": [96, 157], "2881": 214, "288kb": 184, "289": 234, "2891": 214, "2891e": 214, "2892e": 214, "2893e": 214, "2894e": 214, "28b": [96, 157], "28gb": [55, 116], "29": [52, 64, 70, 96, 105, 113, 125, 131, 157, 166, 172, 173, 194, 214], "291": [194, 249], "2924": [96, 157], "292436": [82, 143], "29246845841407776": 249, "2932": [96, 157], "2937": 214, "2938": 214, "293855": [96, 157], "2938e": 214, "2941": 200, "29500": [9, 15, 67, 128, 215], "2955": 214, "2959": 214, "2959e": 214, "296": [96, 157], "29600": [52, 113], "2963": 200, "2969": 214, "2978": 214, "298": 249, "2980e": 214, "2981": 214, "2986e": 214, "299": 214, "2990": [82, 143], "2992": 214, "29s": [70, 131], "2_visual_toolbox_v2": [79, 140], "2b": [49, 55, 59, 71, 96, 110, 116, 120, 132, 157, 197], "2bit": [96, 157], "2d": [214, 240], "2e8": [48, 109], "2f": 219, "2gb": 44, "2nd": 214, "2s": [56, 105, 117, 166], "2vfqelfyfyji": 245, "30": [3, 39, 50, 64, 82, 96, 111, 125, 143, 157, 172, 173, 178, 188, 214, 219, 237, 241, 256], "300": [0, 63, 67, 96, 124, 128, 157, 214], "3000": 19, "30000": [96, 157, 230], "300000": [96, 157], "3002": [96, 157, 180], "300b": [96, 157], "300i": [185, 214], "300k": [96, 157], "300m": [96, 157], "300t": [185, 193], "301": [96, 157], "3016e": 214, "3017e": 214, "3022": 214, "3027": 214, "3027e": 214, "303": [96, 157, 207], "3031154274940491": 249, "3031e": 214, "3032": 214, "30354": [96, 157], "3036": 200, "304": 241, "3041e": 214, "305": 249, "3050e": 214, "3054e": 214, "3058021068573": 249, "3063": 214, "3063e": 214, "307": [96, 157, 214, 249], "3070": 214, "3081e": 214, "3086": 214, "308791": [82, 143], "3089": 214, "308k": 184, "3090": [63, 70, 91, 124, 131, 152], "3091": 214, "3091e": 214, "3092": 214, "3093": 214, "3096": 214, "30b": [28, 29, 34, 35, 40, 42, 55, 56, 57, 96, 103, 104, 105, 116, 117, 118, 157, 164, 165, 166, 170, 174, 175, 180], "30b_sglang_megatron_npu": 179, "30us": 214, "31": [19, 55, 64, 96, 116, 125, 157, 194, 214], "310": [96, 157], "3103": 214, "3105": 214, "310p": 214, "311": 241, "3114e": 214, "3115e": 214, "3118": 237, "312": [96, 157], "3120": 19, "3123e": 214, "3125": 214, "3125e": 214, "313": 249, "3131": 214, "3131723403930664": 249, "3131807306": [75, 136], "3136": [96, 157], "3139": 241, "314": 249, "3147": 214, "315": [214, 241, 249], "3150e": 214, "3151": [96, 157], "3152e": 214, "3153": [96, 157], "3156": 241, "31563": [96, 157], "3158": 200, "3159e": 214, "316820": [96, 157], "3174e": 214, "3175": 214, "31819": [82, 143], "3182e": 214, "3184": 214, "319": 249, "3193": 214, "3197e": 214, "3198e": 214, "32": [7, 48, 51, 52, 53, 56, 57, 58, 63, 64, 67, 68, 70, 94, 96, 99, 102, 103, 104, 105, 109, 112, 113, 114, 117, 118, 119, 124, 125, 128, 129, 131, 155, 157, 160, 163, 164, 165, 166, 178, 181, 184, 193, 194, 207, 210, 214, 219, 222, 256], "320": [96, 157, 214], "3206": [96, 157], "321538": 214, "3217742443084717": 249, "3218e": 214, "322": 249, "3228": 214, "323": [241, 249], "3232e": 214, "3234": [96, 157], "324": 214, "32400": 214, "3241": 214, "3242": 214, "3242e": 214, "3243e": 214, "3244e": 214, "32469": [96, 157], "32563": [96, 157], "326154": [96, 157], "3262": 214, "3267": 214, "327": 249, "3272": [96, 157], "3273": 214, "3274": 214, "32768": [86, 147, 179, 180, 181, 185, 191], "3279e": 214, "328": [96, 157], "3281": 214, "3284e": 214, "3292e": 214, "3295e": 214, "3296": 214, "3298": 214, "32b": [55, 56, 96, 116, 117, 157, 174, 175, 214], "32b_npu": 174, "32byte": 214, "32k": [96, 105, 157, 166, 175, 214], "32s": [105, 166], "33": [50, 64, 96, 105, 111, 125, 157, 166, 194, 207, 214, 253], "3300": 200, "331": [60, 96, 121, 157, 249], "331149": [96, 157], "33126339316368103": 249, "3314": [55, 116], "3315": [55, 116], "3318": [55, 116], "3318e": 214, "3319e": 214, "332": 249, "3325e": 214, "3329e": 214, "333": [68, 96, 129, 157], "3330e": 214, "3333": 200, "3335": 214, "3335e": 214, "3337": 214, "334": [96, 157], "3341": [96, 157], "3344e": 214, "3347e": 214, "3348": [82, 143], "3349": 214, "3350830078125": 249, "3350e": 214, "3353": 214, "3354": 214, "3364e": 214, "336639": [82, 143], "3369": 214, "337": [96, 157], "3370e": 214, "3378": 184, "338": [96, 157], "3381": 214, "3382": 214, "3389": 214, "339": [96, 157], "3398": 214, "33b": [96, 157], "34": [14, 70, 82, 96, 131, 143, 157, 188, 214], "3407": [96, 157], "3410": 214, "3411e": 214, "3413e": 214, "3417": [96, 157], "3418": 214, "3422": 214, "3424e": 214, "3428": 214, "3428e": 214, "343": 249, "3438": 214, "344": 249, "3441": [68, 129], "3443e": 214, "3445": 214, "3445e": 214, "3447": 214, "346": 249, "3460": [96, 157], "3474e": 214, "3475": 214, "3475e": 214, "3476": [96, 157], "3477": 214, "3479": [96, 157], "3485": 214, "3486": 214, "3486e": 214, "349": [96, 157], "3490": 214, "3490e": 214, "3496e": 214, "3497e": 214, "34b": [96, 157], "34s": [70, 131], "35": [50, 82, 96, 111, 143, 157, 184, 194, 214], "350": [50, 111], "3500e": 214, "3503": 194, "3510": 214, "3519": 200, "3520": 194, "3522": 214, "3525": 214, "353": [96, 157, 249], "3532": 200, "3535": 214, "3542": 214, "3542e": 214, "3548e": 214, "3553": 184, "3554e": 214, "3556": [96, 157], "3559": 214, "3561025857925415": 249, "3564": 214, "3571e": 214, "3572": 200, "35735": [96, 157], "3573e": 214, "3574e": 214, "3576e": 214, "3577519": [96, 157], "3578": 214, "3584": [58, 119], "3589": 214, "3591": 214, "3595": 214, "35b": [96, 157], "35gib": [53, 114], "36": [58, 83, 86, 96, 119, 144, 147, 157, 214, 228, 231], "360": [57, 60, 118, 121], "3600": [179, 181, 200], "3601e": 214, "3602": 214, "3610": 214, "3612": 214, "3613": 214, "3618e": 214, "362": [96, 157], "3620e": 214, "3623": 214, "3625e": 214, "3628": 214, "362909": [96, 157], "3639e": 214, "364": [96, 157, 249], "3647": 214, "3648269176483154": 249, "3649e": 214, "365": [96, 157], "3651": 214, "3657": 214, "366": [96, 157], "3661e": 214, "3663": 214, "3667": [50, 111], "3668": 184, "3672": 214, "3676": 200, "3678": [82, 143], "368": [70, 131], "3686": 214, "3689": 200, "369": [96, 157, 241], "369903326034546": 249, "36b": [96, 157], "36s": [70, 131], "37": [50, 96, 111, 157, 214, 219, 256], "3700": 214, "3703": 214, "3703e": 214, "3705289363861084": 249, "3708e": 214, "370m": [96, 157], "3713": 214, "3717": 214, "3717e": 214, "3719": 214, "3722e": 214, "3723": [50, 111], "3735": [96, 157], "3739": 214, "3743": 214, "3748": 214, "375": 241, "3750": 214, "3750e": 214, "3753e": 214, "3755": 214, "3755e": 214, "3758e": 214, "3761": 214, "3761059045791626": 249, "3769": 214, "3772e": 214, "3777": 214, "3779": 214, "3780e": 214, "3788e": 214, "378931999206543": 249, "3793": [105, 166], "38": [82, 96, 143, 157, 214], "3800": [96, 157], "381": [60, 121], "3813e": 214, "3818e": 214, "3819": 200, "3826913833618164": 249, "3828": 214, "3838": 214, "384": [214, 241], "384589433670044": 249, "3858e": 214, "3865e": 214, "3868e": 214, "3872": 214, "3873e": 214, "3877e": 214, "3883": 249, "3887": 214, "3888": [82, 143, 214], "389": [96, 157], "3892": 200, "38b": [96, 157], "39": [55, 94, 96, 116, 155, 157, 214], "3901": 200, "390m": [96, 157], "3913e": 214, "3914": 214, "3916": 214, "391783": [96, 157], "39193": [96, 157], "3922": 214, "3927": 214, "3928e": 214, "3931e": 214, "393424": 210, "3935241699219": 249, "394": 234, "3945": 214, "3947": 200, "396004": [96, 157], "3960e": 214, "3966": 214, "3967": [96, 157, 214], "3967204988002777": 249, "3975": 214, "3975e": 214, "3976": 214, "39781": [96, 157], "397b": [40, 96, 157], "398": [96, 157], "3987": 214, "3993e": 214, "3994": 214, "3994e": 214, "3997": 214, "3999": 214, "3999e": 214, "399s": 234, "39m": [70, 131], "3_linux": 14, "3b": [46, 50, 52, 53, 55, 90, 95, 96, 111, 113, 114, 116, 151, 156, 157, 170, 174, 222], "3d": [46, 181, 214, 240], "3e": [75, 136, 188, 219], "3f": [188, 219], "3f2f1aa779b544c19f01c08b803bf4ef": 231, "3kb": 184, "3m7m0625gen7m_domain": [96, 157], "3n": [96, 157], "3rc0": 230, "3rd": 128, "3s": [70, 103, 104, 131, 164, 165], "3sh": 38, "3to4": [50, 96, 111, 157], "40": [55, 64, 96, 116, 125, 157, 174, 177, 185, 194, 214], "400": [52, 113, 194], "4000": 214, "400s": 234, "401": [60, 96, 121, 157], "40106": 231, "40108": 231, "4011e": 214, "4014": 214, "401408": [52, 113], "4018e": 214, "40194": [53, 114], "402": 45, "4026": 214, "4030": [56, 117], "4033e": 214, "4036": 214, "4037e": 214, "4038e": 214, "4043e": 214, "4044e": 214, "405": [96, 157], "4053": 214, "4059e": 214, "405b": [96, 157], "406": [204, 234], "4062": 241, "4064": [200, 214], "4068": [96, 157], "408": 184, "4080": 214, "4082e": 214, "4084": 214, "4090e": 214, "40937": 212, "4094": 214, "4096": [7, 51, 53, 56, 57, 58, 74, 112, 114, 117, 118, 119, 135, 194, 214], "4098": [96, 157], "4098e": 214, "40b": [96, 157], "40k": [96, 157], "40min": 170, "41": [22, 37, 55, 96, 116, 157, 214], "410": [96, 157], "4106750488281": 249, "4108": [96, 157], "4108e": 214, "4109e": 214, "4111e": 214, "4128e": 214, "413": [96, 157], "4130": 214, "4133e": 214, "414": [96, 157], "4141845703125": 249, "4145514667034149": 249, "4145e": 214, "4150e": 214, "4157": 200, "4158": 214, "4159e": 214, "4160": 214, "4172": 214, "4174e": 214, "4179": 214, "418": [214, 234], "4189e": 214, "4192": 214, "42": [3, 7, 20, 42, 50, 55, 67, 96, 99, 111, 116, 128, 157, 160, 184, 214, 222, 237, 241], "4209e": 214, "4210e": 214, "4212e": 214, "4215": 214, "423": [60, 121], "4231": 200, "4238": 214, "4238e": 214, "424": [96, 157], "4242": 214, "4243": 214, "4247e": 214, "4248e": 214, "424b": [96, 157], "425": 243, "4250e": 214, "4253": 214, "4255": 214, "42580509185791": 249, "426": [96, 157], "4260e": 214, "4264": 214, "4269": 214, "427": [207, 234], "4270e": 214, "4274e": 214, "4276e": 214, "4277": [200, 214], "4280e": 214, "4282e": 214, "4287": 214, "4294967296": 204, "4294e": 214, "4297": 214, "43": [7, 55, 96, 116, 157, 214, 256], "4300": 200, "4302": 214, "4303": 214, "430453300476074": 249, "4306": 214, "4312": [82, 143], "4314": 200, "4314e": 214, "4319e": 214, "432": [67, 128], "4320e": 214, "4322e": 214, "4325330853462219": 249, "4331e": 214, "4336": [200, 214], "4344e": 214, "435": [96, 157, 234], "4353e": 214, "4360e": 214, "436467409133911": 249, "4365": 214, "43666": [96, 157], "4368": 214, "436kb": 184, "436m": 184, "4373e": 214, "4375": 214, "438": [96, 157, 234], "4387": 214, "4388": 214, "439": [96, 157], "4390e": 214, "4393": 214, "4396e": 214, "4397": 214, "43gib": [104, 165], "43m": [70, 131], "44": [50, 55, 67, 70, 96, 111, 116, 128, 131, 157, 194, 214, 231], "440": [96, 157], "4403": 214, "4404e": 214, "4407e": 214, "441": [96, 157], "442": [96, 157, 243], "443": 184, "4434e": 214, "4438e": 214, "4440": 214, "4441e": 214, "4444": 200, "4457e": 214, "4458e": 214, "4462e": 214, "4463": 214, "44694": [96, 157], "4473": 214, "448": [67, 96, 128, 157, 256], "4481": 214, "4482e": 214, "4484e": 214, "4489e": 214, "4490e": 214, "4493e": 214, "45": [55, 66, 96, 116, 127, 157, 214, 230, 256], "45012": [96, 157], "4502e": 214, "4508": 214, "451": [60, 121], "4513": 214, "4517e": 214, "4520": 214, "4521": 214, "4524e": 214, "4528e": 214, "453": [96, 157], "4536": 214, "454": [96, 157], "454617": [96, 157], "4547": 214, "4548392295837402": 249, "4551e": 214, "4555e": 214, "4557e": 214, "455843925476074": 249, "456": [204, 234], "4570e": 214, "4572": [64, 125], "4574": [200, 214], "4575e": 214, "4580e": 214, "4581611156463623": 249, "4592": 214, "45c443b316737a4ab6e40413d7794a7f5657c19f": 224, "45kb": 184, "45s": [102, 163], "46": [96, 157, 214], "460": [96, 157], "4600": 214, "4600e": 214, "4603": 214, "4604e": 214, "4609e": 214, "4614": 214, "4619": 214, "4626": 214, "4631": 214, "4632484912872314": 249, "4634": [96, 157], "4639": 214, "4641": 214, "4642e": 214, "464885": [96, 157], "465": [96, 157], "4651": 214, "4656": 214, "4667": 200, "4673e": 214, "4678": 214, "4679": [200, 214], "468": [96, 157], "4682": 234, "4683": 214, "4685e": 214, "4689": 214, "4695": [96, 157], "4697": 214, "46b73de": 176, "47": [96, 157, 214, 241], "4700": 200, "4700e": 214, "4702": 214, "4704": 214, "4704e": 214, "4705e": 214, "4709e": 214, "471": [96, 157], "4710e": 214, "4723": 214, "4724": [200, 214], "4724509716033936": 249, "4727": 214, "4728": 214, "4731": 214, "4734": 214, "4735e": 214, "4739": 214, "474": [96, 157], "4740": 214, "4751": 214, "4759": 200, "4760e": 214, "4765": [214, 234], "4766": 214, "4771": 214, "4778e": 214, "4780": 214, "4781": 214, "4787": 214, "479": 243, "4790": 214, "4792e": 214, "4793e": 214, "4796": 200, "4798": 214, "47k": [79, 140], "48": [55, 70, 96, 116, 131, 157, 177, 179, 214], "480": [57, 60, 96, 118, 121, 157], "4803e": 214, "4805e": 214, "4806": 200, "4807": 214, "4807929992675781": 249, "4807e": 214, "480b": [96, 157], "480p": 31, "4812": 214, "4814": 214, "4814e": 214, "4821": 214, "48211a1594f1321b00f14c9f7a5b4813144b2fb9": 224, "4829e": 214, "483": [96, 157], "4834e": 214, "4839e": 214, "484": [70, 131], "4844": 214, "4844e": 214, "485": [204, 234], "4856e": 214, "4857": 200, "4858": 214, "4865": 214, "4872": 214, "4873": 214, "4875": 214, "48818": [96, 157], "4890e": 214, "4895e": 214, "4897": 200, "4899": 214, "4899e": 214, "48batch": 177, "49": [50, 55, 96, 111, 116, 157, 184, 188, 194], "4900": 214, "4902e": 214, "490364": [96, 157], "490480": [96, 157], "4905": 214, "4912": 200, "4914": 214, "4917": 214, "4919": 214, "4922": [200, 214], "4924": 214, "4927": 214, "4929": 234, "4931e": 214, "4941e": 214, "4942e": 214, "4948": 214, "495": [57, 60, 118, 121], "4951": 214, "4952e": 214, "4953": [200, 214], "4954e": 214, "4958": 214, "4959": [96, 157], "4961e": 214, "4962e": 214, "4968": 214, "4969e": 214, "4972": 214, "4974e": 214, "4979": 214, "498082": [96, 157], "4984": 214, "4985": 214, "4985e": 214, "4987e": 214, "499000": 241, "4991": 214, "4992e": 214, "4997": 214, "49s": [70, 131], "4b": [49, 57, 59, 96, 103, 110, 118, 120, 157, 164, 174], "4b_npu": 174, "4bit": [67, 96, 128, 157], "4d": 214, "4e": [75, 136], "4f": 204, "4gb": [58, 119], "4k": [96, 157], "4kb": 184, "4khd": [67, 96, 128, 157], "4m": [38, 96, 157], "4o": [96, 157], "4rc2": 221, "4sh": 38, "4v": [96, 157], "50": [7, 16, 18, 20, 50, 53, 56, 63, 67, 68, 70, 96, 99, 111, 114, 117, 124, 128, 129, 157, 160, 177, 194, 210, 234], "500": [3, 8, 9, 17, 24, 42, 48, 50, 52, 57, 63, 67, 91, 98, 99, 102, 103, 105, 109, 111, 113, 118, 124, 128, 152, 159, 160, 163, 164, 166, 179, 188, 214, 219], "5000": [53, 56, 57, 71, 96, 103, 104, 114, 117, 118, 132, 157, 164, 165, 200, 214], "50000": [50, 96, 111, 157, 241], "500000": 194, "50000000": [188, 219], "5000000000": 44, "50001": 214, "5000e": 214, "5004": 214, "5009": [96, 157], "5009e": 214, "500k": [96, 157], "5010": 214, "5010e": 214, "50143": [96, 157], "50176": [53, 58, 90, 114, 119, 151], "5021": 214, "5022e": 214, "5023e": 214, "5024": 214, "5029": 214, "5029e": 214, "5031": 214, "5033": [56, 102, 117, 163], "5034": 214, "5039e": 214, "504": 243, "5044e": 214, "5045e": 214, "5049": 200, "5051e": 214, "5052e": 214, "5053e": 214, "5054": 214, "5059e": 214, "5063": 214, "5063e": 214, "5064": [96, 157], "5068": 214, "5076e": 214, "5078": 214, "5083": 214, "5085": 214, "5090e": 214, "50gib": [103, 164], "51": [50, 55, 90, 96, 111, 116, 151, 157], "5100e": 214, "5101": 200, "5104": 214, "5109": 184, "5115": 200, "5118070840835571": 249, "512": [53, 58, 67, 68, 71, 89, 90, 91, 99, 100, 104, 114, 119, 128, 129, 132, 150, 151, 152, 160, 161, 165, 174, 194, 214, 219, 234, 256], "5120": 214, "51216": [67, 128], "5126e": 214, "512b": 177, "5131": 214, "5137": 214, "513734817504883": 249, "5139e": 214, "5141": 214, "5146e": 214, "5149e": 214, "5150e": 214, "5155e": 214, "5157": 214, "5160": 200, "5161e": 214, "5163e": 214, "5166": 214, "516620": [96, 157], "5171": 214, "5173e": 214, "5176": 214, "51760": [96, 157], "5176e": 214, "5179": 214, "517982": [96, 157], "5184e": 214, "5185": 200, "51864": 256, "5186e": 214, "5187": 214, "5190": 214, "519255": [96, 157], "51b": [96, 157], "52": [70, 82, 94, 96, 131, 143, 155, 157, 188, 214, 221], "52002": [96, 157], "5200e": 214, "5202": [82, 143], "5215": 214, "521921": [96, 157], "523": [96, 157], "5234e": 214, "5235e": 214, "5236e": 214, "5238e": 214, "524": [96, 157], "5242": 214, "5244e": 214, "5247": 214, "5249": 214, "5250": 214, "52541": [96, 157], "5254e": 214, "5257": 214, "5262": 214, "527": 241, "5276e": 214, "5278e": 214, "5283e": 214, "5285": 214, "5285e": 214, "5292e": 214, "52b": [96, 157], "53": [50, 96, 111, 157, 194, 214], "530369997024536": 249, "5309e": 214, "5312e": 214, "5313": 214, "532": [57, 60, 118, 121], "5321": 214, "5327": 200, "5331e": 214, "5332e": 214, "5342": 214, "5342e": 214, "5347": 214, "5352": 214, "5361": 214, "5364": 214, "5369e": 214, "5375": 214, "5376": 200, "5378": 214, "5385e": 214, "5387": 214, "539": 241, "5390e": 214, "5396": 214, "54": [22, 96, 157, 191, 194, 214], "5400": [180, 200, 214], "5405e": 214, "5406e": 214, "5410": 214, "5410e": 214, "5425": 214, "543": [96, 157], "5430492162704468": 249, "5439": 214, "5439e": 214, "544": [96, 157], "5440": [70, 131], "5445": 214, "5447e": 214, "5449e": 214, "545": [96, 157], "5456": 214, "5456e": 214, "5464": 214, "5467e": 214, "5470e": 214, "5488e": 214, "5489": 214, "5493": 214, "5493e": 214, "5498": 214, "54s": [70, 131], "55": [8, 50, 67, 70, 96, 111, 128, 131, 157, 210, 214, 241], "550": [60, 121], "5502": 214, "5510": 214, "5515": 214, "5519": 241, "55230712890625": 249, "5525": 214, "5526e": 214, "5528e": 214, "5532e": 214, "5533": 214, "5537": 214, "5540e": 214, "5544": 214, "5544e": 214, "5549": 214, "5552e": 214, "556": [96, 157], "5580e": 214, "55895": [96, 157], "559": [96, 157], "5590": 214, "5593773722648621": 249, "5596": 214, "5597": 214, "56": [50, 96, 111, 157, 188, 210, 214, 256], "560": 11, "5609": 214, "5609e": 214, "560m": [96, 157], "561": [96, 157], "5615": 214, "5621": 214, "5625e": 214, "5628": 214, "563": [96, 157], "5630e": 214, "5635e": 214, "5637": 214, "5637512207031": 249, "5637e": 214, "5640": 214, "5646e": 214, "5653e": 214, "5654": 214, "5654e": 214, "5663e": 214, "56649": [96, 157], "5665e": 214, "5684": 214, "5684e": 214, "5686e": 214, "569": [60, 121], "5697": 200, "56s": [105, 166], "57": [39, 53, 57, 64, 96, 105, 114, 118, 125, 157, 166, 174, 178, 180, 181, 188, 214, 219], "5703": 214, "5704": 214, "570b": 184, "571": [96, 157], "5712e": 214, "5713e": 214, "5720e": 214, "5722e": 214, "5723": 214, "5725": 200, "5728": 214, "57289": [96, 157], "5732": 214, "5735e": 214, "5738e": 214, "5740": 214, "574000": 241, "5743e": 214, "5747": 214, "5748": [96, 157], "575": [96, 157], "5752": 214, "5755e": 214, "576": 177, "5762e": 214, "5769": 249, "5771e": 214, "5775e": 214, "5780": 214, "5781": 214, "5781e": 214, "579": [96, 157], "5792e": 214, "5796e": 214, "5799999833106995": 249, "57b": [96, 157], "58": [50, 52, 94, 96, 111, 113, 155, 157], "5800": 214, "5806e": 214, "581": [96, 157], "5811": 214, "5823": 200, "5833": [68, 129, 214], "5837e": 214, "5839": 214, "5845e": 214, "5857e": 214, "587": [96, 157], "5877e": 214, "58gb": [105, 166], "59": [96, 157, 188, 214], "590000": 241, "5907e": 214, "5913": 214, "5918e": 214, "5931": 214, "5938e": 214, "594": [96, 157], "5943e": 214, "5948e": 214, "5949": 214, "5953": 214, "5959": [96, 157], "5959e": 214, "5965": [82, 143, 214], "5967": 249, "5967e": 214, "5977e": 214, "5986": 214, "5987": [96, 157], "599": [96, 157], "5991": 214, "5996": 214, "5996e": 214, "5998": 214, "5_32b_npu": 174, "5_7b_dapo_npu": 178, "5_7b_npu": 174, "5_math_7b_instruct": [94, 155], "5b": [13, 49, 55, 68, 82, 90, 96, 110, 116, 129, 143, 151, 157, 170, 174, 200, 210, 222, 231], "5d": [188, 219], "5e": [42, 48, 50, 58, 109, 111, 119, 174], "5e8": 9, "5gb": [44, 67, 99, 128, 160], "5hd": 214, "5kb": 184, "5m": [96, 157], "5m_cn": [96, 157], "5rc1": 13, "5s": [188, 219], "5us": 181, "5v": [96, 104, 157, 165], "60": [37, 52, 96, 113, 157, 170, 214], "600": [0, 39, 56, 63, 117, 124, 179, 180, 181], "6000": [96, 157], "60000": [175, 179], "6001": 214, "6003e": 214, "6004": 214, "60050": [175, 179], "6008e": 214, "601": [60, 121], "6014": 214, "6021": 214, "6027": 214, "6031": 214, "6033e": 214, "6035": 214, "6048e": 214, "6051": 214, "6052e": 214, "6064e": 214, "6068": 214, "607": [96, 157], "6072": 214, "6079": 214, "6080": 214, "6084e": 214, "6085e": 214, "6086e": 214, "6087e": 214, "6088": 214, "6089": [96, 157, 249], "609": [96, 157], "6096": 214, "6099e": 214, "60gb": [56, 117], "60gib": [56, 105, 117, 166], "60k": [96, 157], "61": [37, 96, 157], "61000": [175, 179], "61050": [175, 179], "6106": [96, 157], "6113e": 214, "6119": 200, "6122e": 214, "6126": 249, "6129e": 214, "6134e": 214, "6135": 214, "6143e": 214, "6144e": 214, "615": [60, 96, 121, 157], "6150e": 214, "6153": 214, "6155031323432922": 249, "6157": 237, "6159": 249, "616": [96, 157], "6161e": 214, "6162": 214, "6166": 214, "6167": [68, 129], "6172": 214, "6172e": 214, "6182e": 214, "6189": 237, "619": [96, 157], "6191": [96, 157, 214], "6191915273666382": 249, "6192e": 214, "6193": 214, "6196": 214, "6199e": 214, "61it": 228, "61s": [102, 163], "62": [96, 157, 207, 214, 237], "620": [96, 157], "6201": 214, "6205e": 214, "6206": 214, "62135": 249, "6214": 200, "6215e": 214, "622": [96, 157], "6220334768295288": 249, "6223": 214, "6225": 214, "6225000023841858": 249, "6225e": 214, "623": [214, 228], "623302": [96, 157], "6234e": 214, "624255": [96, 157], "6244e": 214, "6248273253440857": 249, "6249": 214, "625": 249, "6250": 214, "6254": 214, "6269999742507935": 249, "6279": 214, "627b": [96, 157], "6282": 214, "6284": 249, "6289e": 214, "6290e": 214, "6292": 214, "62930297851562": 249, "6299e": 214, "63": [50, 96, 111, 157, 214, 234], "630": [96, 157], "6300": 214, "6302": 214, "6304e": 214, "6305e": 214, "6311e": 214, "6316": 214, "632": 256, "6326e": 214, "6330": 214, "6332e": 214, "6335": 214, "6338": 214, "6343e": 214, "6345e": 214, "635": [96, 157, 249], "6354e": 214, "6367": 214, "6370e": 214, "6372e": 214, "6379": 9, "638": [96, 157], "638149": [96, 157], "6385e": 214, "6392844319343567": 249, "6398493647575378": 249, "64": [58, 67, 70, 82, 89, 92, 96, 119, 128, 131, 143, 150, 153, 157, 174, 177, 181, 185, 194, 207, 210, 214, 218, 222, 234, 243], "6406e": 214, "641": [96, 157], "6412": [96, 157], "6418e": 214, "6419e": 214, "6426e": 214, "6428": 214, "6429e": 214, "6431e": 214, "6432e": 214, "6436e": 214, "6439999938011169": 249, "6446e": 214, "645": [96, 157], "6455e": 214, "6456e": 214, "6457e": 214, "6458": 214, "6460000276565552": 249, "6461e": 214, "6467e": 214, "6470": 214, "6475e": 214, "6487e": 214, "6493e": 214, "6494": 214, "6497": 214, "649k": 184, "64g": [55, 116], "64gb": [105, 166], "64k": [96, 157], "65": [96, 157, 188, 194, 207, 214], "650000": 241, "6504e": 214, "6509e": 214, "6513": 214, "6515e": 214, "6520": 214, "6523e": 214, "6524": 214, "6528e": 214, "6530": 214, "6536e": 214, "6540e": 214, "6543": 214, "6549e": 214, "65535": 214, "65536": [55, 116], "6558": 214, "656": [96, 157], "6560": 214, "6562e": 214, "6565": 214, "6565e": 214, "6568": 214, "657": [96, 157], "6572": 214, "6575": 214, "6575000286102295": 249, "6578": 214, "6578e": 214, "6587": 214, "6590e": 214, "6592e": 214, "6594": 234, "6594e": 214, "6598": 249, "65b": [96, 157], "66": [82, 96, 143, 157, 188, 214, 249], "6600000262260437": 249, "6602": 214, "6607e": 214, "6608": 214, "6620": 214, "6623e": 214, "6624": 200, "6626e": 214, "6632e": 214, "6636e": 214, "6637": 214, "6641": 214, "6650": 214, "6650e": 214, "6655": [96, 157], "6655e": 214, "6657": 214, "6658": 214, "666": [60, 96, 121, 157], "6660e": 214, "6663e": 214, "6665e": 214, "6668": 214, "6669": 214, "6677e": 214, "6678": 214, "6679e": 214, "6680e": 214, "6683e": 214, "6685": 214, "66862": [96, 157], "6689": 214, "6691": 214, "6694": 200, "6695e": 214, "6699e": 214, "66k": [96, 157], "67": [66, 82, 96, 127, 143, 157, 188, 214], "6700000166893005": 249, "6702e": 214, "6703e": 214, "6709": 214, "6711e": 214, "6714e": 214, "6719e": 214, "671b": [96, 157, 174], "6722e": 214, "6723e": 214, "6725e": 214, "6734e": 214, "6739": [96, 157], "6741": 214, "6743e": 214, "6748e": 214, "6759": 214, "676": [60, 121], "6760e": 214, "6766": [179, 180, 181], "6768e": 214, "6771": 214, "6780e": 214, "6781": 237, "6785e": 214, "6787": 214, "6787e": 214, "6788": 214, "6797e": 214, "67b": [96, 157], "68": [50, 96, 111, 157, 214, 237, 256], "6800": 200, "6809": 214, "6816": 214, "6830": 214, "6831e": 214, "6832": 214, "6833e": 214, "6840": 214, "6846e": 214, "685": [60, 121], "6852e": 214, "6858e": 214, "6859": 214, "6868e": 214, "6872e": 214, "6875e": 214, "6878": 214, "6880": 214, "6890e": 214, "68912": [96, 157], "6893": 214, "68mb": 184, "69": [70, 82, 96, 131, 143, 157, 194, 214], "6904": 214, "6904e": 214, "6912": 214, "6915e": 214, "693": [96, 157], "6931": 214, "6931e": 214, "6932e": 214, "6934": 214, "693987": [96, 157], "694": [96, 157], "6940": 214, "6943e": 214, "6944": 214, "6944e": 214, "6947": 214, "6953": 214, "6953e": 214, "6956e": 214, "6965": 214, "6968e": 214, "6971": 214, "6976": 214, "6980e": 214, "6981e": 214, "6984029412269592": 249, "6992e": 214, "6993": 214, "699462890625": 249, "699999988079071": 249, "69kb": 184, "6b": [49, 59, 96, 110, 120, 157, 191], "6f7db241d2f8ba7457bac5ca9753331f0c266917": 224, "6k": [96, 157], "6s": [56, 105, 117, 166], "6v": [96, 157], "70": [50, 96, 111, 157, 172, 173, 177], "7000": 214, "70000": [96, 157], "7002": 214, "7009": 214, "701": 222, "7011": 214, "7012e": 214, "7016": 214, "7017e": 214, "7021": 214, "7031e": 214, "7033e": 214, "7036": 214, "7046": 214, "7046e": 214, "7051": 214, "7062e": 214, "7068e": 214, "7070e": 214, "7076": 214, "7078e": 214, "708": 234, "7096e": 214, "7098e": 214, "70b": [91, 96, 152, 157], "70g": [56, 117], "70gib": [102, 163], "71": [55, 96, 116, 157, 214], "7101e": 214, "7109": 214, "7109e": 214, "7112e": 214, "7114": 214, "7119e": 214, "71312": [96, 157], "7133": 214, "7134": 214, "7141": 214, "7160": 214, "7160e": 214, "7168": 177, "7168e": 214, "7169e": 214, "7171": 214, "7173767089844": 249, "7173e": 214, "7176669239997864": 249, "7176e": 214, "7178": 214, "7185e": 214, "7187": 214, "7197e": 214, "719s": 234, "72": [37, 60, 66, 96, 121, 127, 157, 184, 212, 214, 256], "7217": 214, "723": [96, 157], "7240013480186462": 249, "7240e": 214, "7243": 214, "72441": [96, 157], "7251e": 214, "7262": 214, "7264e": 214, "7271e": 214, "7275e": 214, "7280e": 214, "7283e": 214, "7288e": 214, "729": [66, 127], "7291": 214, "72b": [79, 88, 96, 140, 149, 157], "72gib": [104, 165], "73": [50, 96, 111, 157, 249], "7300000190734863": 249, "7302e": 214, "7305e": 214, "7308": 214, "733": [60, 121], "73426": 184, "7343": 214, "736572265625": 249, "7368": 214, "7378": 214, "7380": 214, "7383e": 214, "7388e": 214, "7398e": 214, "74": [96, 157, 214, 249], "7402e": 214, "7404e": 214, "7407e": 214, "7415": 214, "7424671645634816e": 249, "7428e": 214, "7429e": 214, "7431e": 214, "7437": 214, "7441": 214, "7443": 214, "7447": 214, "7450": 214, "7458": 214, "7464": 214, "747": [96, 157], "7471": 214, "7473": [96, 157], "7474e": 214, "74771": [96, 157], "7477e": 214, "7485e": 214, "7490e": 214, "75": [16, 96, 157, 184, 210, 214, 234, 249, 256], "750": 234, "7500": [96, 157, 214], "7512e": 214, "7522": 214, "7531e": 214, "7557e": 214, "7560e": 214, "7568": 214, "7570": 214, "7571": 214, "7573": 214, "7573e": 214, "7576e": 214, "7577209472656": 249, "7585": 48, "759": [66, 127], "7595e": 214, "7596e": 214, "75kb": 184, "76": [50, 111, 214, 249], "7605": 214, "761": [60, 121], "7611": 214, "7611e": 214, "7614": 214, "7617": 214, "7617e": 214, "7623": 214, "7624e": 214, "7633e": 214, "76437": [96, 157], "7645e": 214, "7646e": 214, "7649": 214, "7656e": 214, "7662e": 214, "766357421875": 249, "7666": 214, "7676": 214, "7678": 214, "768": [7, 35, 67, 128, 207, 214], "7681": 214, "7682e": 214, "7689": [96, 157], "76898193359375": 249, "769": [96, 157], "7699e": 214, "76b": [96, 157], "76gib": [103, 164], "77": [50, 82, 96, 111, 143, 157, 184, 214], "7703e": 214, "7711": 214, "7718e": 214, "7725": 214, "7725e": 214, "7733": 214, "7736284": [96, 157], "774658768993046e": 249, "7748": [96, 157], "7754": 214, "7754e": 214, "7755e": 214, "7761": 214, "7764": 214, "7776e": 214, "7779e": 214, "7783": 214, "7783e": 214, "7784": 214, "7790": 214, "7790046334266663": 249, "7793": 214, "7793089151382446": 249, "78": [50, 96, 111, 157, 214, 234, 249], "7802e": 214, "7816e": 214, "7820e": 214, "7821": 214, "7822e": 214, "7832": 214, "7842e": 214, "7846": 214, "7847": 214, "7849": 214, "78577": [96, 157], "7860": [67, 128], "7861": 214, "7862e": 214, "7868e": 214, "7874": 214, "7877e": 214, "7878": 214, "7881e": 214, "789354427392000": 241, "78b": [96, 157], "79": [94, 96, 155, 157, 184, 214], "7900e": 214, "7902e": 214, "790m": [96, 157], "7915e": 214, "7920": 214, "7920e": 214, "7922e": 214, "7929": 214, "793": [60, 121], "7939": 214, "7939e": 214, "7941e": 214, "7942e": 214, "7943e": 214, "7951e": 214, "7959": 214, "7966e": 214, "7967e": 214, "7969": 214, "7974e": 214, "7975": 214, "7977": 214, "7982e": 214, "7985e": 214, "7986": 214, "7987264394760132": 249, "7b": [13, 21, 49, 51, 53, 55, 58, 60, 63, 67, 86, 89, 90, 91, 94, 96, 98, 99, 102, 104, 105, 110, 112, 114, 116, 119, 121, 124, 128, 147, 150, 151, 152, 157, 159, 160, 163, 165, 166, 174, 194, 197, 222, 243, 245], "7b_dapo": 178, "7bx8": [96, 157], "7e": [70, 131], "7e5la4178elcjcu": 245, "7eoxlqbqcsdqmcx0ve8oia3qej": 245, "7eoyk38o9nnlkxwoka7yqxwvuvrqibvmjyhke8x": 245, "7ermo7m6ii595puox7o3bvypfyqf1syrp05xcr9t2": 245, "7k": 184, "80": [52, 96, 113, 157, 177, 214, 249, 256], "800": [3, 194], "8000": [21, 26, 50, 51, 52, 58, 67, 70, 88, 90, 91, 96, 99, 111, 112, 113, 119, 128, 131, 149, 151, 152, 157, 160, 194, 231], "8001": [70, 131], "8003e": 214, "8005": 179, "800i": [214, 230], "800t": [174, 175, 176, 179, 180, 181, 197], "801": [96, 157, 241], "8012e": 214, "8014705882352942": 184, "8023e": 214, "8027": 214, "802816": [70, 131], "8030e": 214, "8033": 214, "8040": 214, "8046e": 214, "8049e": 214, "806199": [96, 157], "8064": [96, 157], "806850373422611e": 249, "8073": 214, "8078e": 214, "8081": 214, "8084": 214, "8090": 214, "80b": [40, 96, 157], "80g": [79, 140], "80gb": [105, 166], "80gib": [56, 57, 104, 105, 117, 118, 165, 166], "80k": [96, 157], "81": [55, 82, 96, 116, 143, 157, 210, 214], "8105": 214, "8118": 214, "8123e": 214, "8130187988281": 249, "8133e": 214, "8135": 214, "8136e": 214, "814": 241, "8141e": 214, "8142e": 214, "815": [96, 157], "8154": 214, "8159": 214, "8164": 214, "8166": 214, "8170": 214, "8184": 214, "8185": 214, "8188e": 214, "8192": [43, 56, 58, 63, 70, 71, 90, 103, 117, 119, 124, 131, 132, 151, 164, 179, 194, 214], "81kb": 184, "82": [55, 82, 96, 116, 143, 157, 214], "820": [96, 157], "8202": 214, "8204": 214, "8222e": 214, "8232e": 214, "8233e": 214, "8240e": 214, "8252": 214, "8260": [179, 180, 181], "8262": 214, "8262e": 214, "8267e": 214, "8271": 214, "8271e": 214, "8279": 214, "8280e": 214, "8281": 214, "8281e": 214, "8293e": 214, "83": [50, 94, 96, 111, 155, 157, 214, 256], "8300e": 214, "8307": [96, 157], "8309": 214, "8311": 214, "8312": [96, 157, 219], "83132": [96, 157], "832": [96, 157], "8327e": 214, "8332e": 214, "8333": [50, 111], "8344": 214, "8347": 214, "8347e": 214, "8350": 214, "8355176448822021": 249, "8359e": 214, "8370": 214, "8378e": 214, "8380": 214, "8389": 214, "8390": 214, "839041977852176e": 249, "8390e": 214, "8391e": 214, "84": [50, 111, 179, 188, 219, 249], "8402e": 214, "8407": 214, "8407e": 214, "8418e": 214, "8423e": 214, "8432e": 214, "8433": 214, "8434": 214, "8438e": 214, "8439306358381503": 184, "8442e": 214, "8444": 214, "8446": 214, "8447e": 214, "8450e": 214, "8452e": 214, "8477": 214, "8483": [96, 157], "8488e": 214, "8492e": 214, "8498": 214, "85": [50, 56, 67, 96, 111, 117, 128, 157, 249], "850": 175, "8500": 214, "8500e": 214, "8501": 214, "8506": 214, "8506e": 214, "8509e": 214, "8511e": 214, "8518e": 214, "8519e": 214, "8522e": 214, "8528": 214, "853": [60, 121], "8535": 214, "8535e": 214, "8542e": 214, "8548": 214, "8558e": 214, "8561": 214, "8562e": 214, "85658": [96, 157], "8567e": 214, "8569": 214, "857": [96, 157], "8571": 214, "8575": 214, "8578431372549019": 184, "8584": 214, "8585e": 214, "859": [96, 157], "8594": 214, "859494": [96, 157], "86": [50, 111, 214, 234], "8600e": 214, "8609": 214, "8621": 214, "8627e": 214, "8632e": 214, "8633e": 214, "8651e": 214, "8658e": 214, "8660e": 214, "8669": 214, "8669e": 214, "8678e": 214, "8692": 214, "87": [50, 96, 111, 157, 214, 234, 249, 256], "8700980392156863": 184, "8703": 214, "8703e": 214, "87123358228174e": 249, "8715": 214, "8717e": 214, "8721": 214, "8730e": 214, "8737e": 214, "8742e": 214, "8744": 214, "875": 234, "8750": 214, "8753": 214, "8765": 214, "8770": 214, "8770e": 214, "8773": 214, "878154695": 234, "8784e": 214, "8787e": 214, "8789e": 214, "8792e": 214, "88": [70, 96, 131, 157, 177, 214, 249], "8800e": 214, "8806": 214, "8809e": 214, "8816e": 214, "882": 185, "8838e": 214, "8848e": 214, "8857e": 214, "886": [60, 121], "8866e": 214, "8879": 214, "8882": 214, "8886": 214, "8886e": 214, "8887e": 214, "8888e": 214, "8889": [68, 129], "888970": [96, 157], "8889e": 214, "8890": 214, "89": [177, 234], "8909e": 214, "8911": 214, "8911e": 214, "8917e": 214, "892": 249, "8925e": 214, "89263": 241, "893": 249, "893929": [96, 157], "89394": 231, "8943e": 214, "8945": 214, "8951": 214, "8951e": 214, "8952": 214, "8955e": 214, "89598": [96, 157], "896": [67, 96, 128, 157], "896215": [96, 157], "8975265017667845": 184, "8978271484375": 249, "8990e": 214, "8_visual_toolbox_v2": [79, 140], "8b": [9, 10, 16, 17, 20, 21, 23, 24, 34, 44, 49, 55, 56, 58, 59, 66, 67, 71, 94, 95, 96, 103, 110, 116, 117, 119, 120, 127, 128, 132, 155, 156, 157, 164, 174, 175, 194, 197, 210, 230, 239, 240, 241, 243, 245, 246], "8bit": [96, 157, 214], "8e": [70, 131], "8e707118": 194, "8h": [70, 131], "8k": [52, 96, 105, 113, 157, 166], "8kb": 184, "8s": [104, 165], "8x": 117, "8x22b": [96, 157], "8x2b": [96, 157], "8x7b": [96, 157], "8xh20": [117, 163], "90": [52, 57, 60, 96, 113, 118, 121, 157, 181, 213, 214, 249, 255], "900": [55, 116, 174, 175, 176, 178, 179, 180, 181, 222], "9009": [96, 157], "9011e": 214, "9013e": 214, "9021e": 214, "9023": 214, "9031982421875": 249, "9031e": 214, "9032": 214, "903425186711305e": 249, "9034e": 214, "9037e": 214, "9040": 214, "9041": 214, "9043": 214, "905": [96, 157], "9050e": 214, "9053e": 214, "906": [96, 157], "9069e": 214, "9070": 214, "9072e": 214, "9073e": 214, "9074": 194, "9075": 214, "9076": 214, "9080e": 214, "9081e": 214, "9083e": 214, "9086e": 214, "9087779690189329": 184, "9089e": 214, "9094e": 214, "9097e": 214, "90b": [96, 157], "91": [56, 94, 96, 105, 117, 155, 157, 166, 179, 184, 214], "9101e": 214, "9102": 214, "9103": 214, "9109e": 214, "910b": [170, 183, 197], "910b1": 13, "910b3": [55, 116], "9111e": 214, "9112": 214, "9113": 214, "9117431640625": 249, "9123e": 214, "9137": 214, "9137e": 214, "9141e": 214, "9144e": 214, "9146e": 214, "91485": 241, "9151": 214, "9160": 214, "9162": 214, "9179": 214, "9179e": 214, "9183e": 214, "9196e": 214, "91998291015625": 249, "92": [55, 94, 96, 116, 155, 157, 214, 219, 241], "9202e": 214, "9207": 214, "9209": 214, "9209e": 214, "9216": 214, "9219": 214, "9220": 214, "9233e": 214, "9238": 214, "9238e": 214, "924": [66, 127], "9240": 214, "92430": [96, 157], "9248e": 214, "9250e": 214, "9259e": 214, "926": 234, "9269e": 214, "9277": 214, "9279": 214, "9281": 214, "9288e": 214, "9290e": 214, "9297e": 214, "9298e": 214, "93": [96, 157, 214, 234], "930": 256, "9306": [96, 157], "9324e": 214, "9326": 214, "9326e": 214, "9332": 214, "9333e": 214, "9336e": 214, "9342e": 214, "9346e": 214, "9348": 214, "9355e": 214, "93561679114087e": 249, "9359e": 214, "936": [96, 157], "9362e": 214, "9366e": 214, "9369": 214, "938": [96, 157], "9385e": 214, "9386e": 214, "9393e": 214, "9395e": 214, "9396e": 214, "94": [70, 96, 131, 157, 214, 256], "9404": 214, "9404e": 214, "9410": 214, "9410e": 214, "9411e": 214, "9412e": 214, "9419": 214, "942": 234, "9424": 214, "9434e": 214, "9441": 214, "9448": 214, "9451": [96, 157], "9458e": 214, "9459e": 214, "946": [70, 131], "9468": 214, "9478": 214, "9479e": 214, "9480e": 214, "9482": 214, "9485": [96, 157], "9492": 214, "9493e": 214, "9496": 214, "95": [7, 67, 92, 95, 96, 99, 128, 153, 156, 157, 160, 210, 231, 255, 256], "950": 194, "951": [96, 157], "9511": 214, "9515": 214, "9516": 214, "9516e": 214, "9519e": 214, "9521e": 214, "9527e": 214, "9545e": 214, "9551e": 214, "9552": 214, "9559e": 214, "9565": 214, "9566": 214, "9569": 214, "9572": 214, "9580": 214, "9582": 214, "9585e": 214, "9594e": 214, "9595": 214, "9596e": 214, "96": [50, 55, 70, 96, 111, 116, 131, 157, 194, 214, 234], "960": 234, "9601": 214, "9605e": 214, "9607": 214, "9608": 214, "9609": 214, "9612e": 214, "9614e": 214, "9619e": 214, "9624": 214, "9626e": 214, "9636": 214, "9652e": 214, "9662e": 214, "9663": 214, "96641540527344": 249, "9666e": 214, "9670e": 214, "9674": 214, "9674e": 214, "967808395570435e": 249, "9683e": 214, "9688": 214, "9697": 214, "9698e": 214, "9699": 214, "97": [96, 157, 193, 194, 207, 214, 234], "9707": 214, "9711e": 214, "9718e": 214, "9726": 214, "9730e": 214, "9734e": 214, "9738": 214, "9746": 214, "97484": [96, 157], "975": 241, "9763": 214, "9763e": 214, "9769e": 214, "9774e": 214, "9775": 214, "9778": 214, "9780": 214, "9784e": 214, "9788": 214, "9793": 214, "9795e": 214, "98": [55, 96, 116, 157, 193, 214, 234], "980": [96, 157], "9800e": 214, "9812e": 214, "9827e": 214, "9829": 214, "9833e": 214, "9834e": 214, "9844e": 214, "9845e": 214, "9850e": 214, "9854": 214, "9857": 214, "9857e": 214, "9863": 214, "987": [96, 157], "9874": 214, "9876e": 214, "988115": [96, 157], "9883e": 214, "9895": 214, "99": [50, 55, 96, 111, 116, 157, 214, 222, 256], "9901": 9, "9902": 214, "9909": 214, "991": [67, 128], "9911e": 214, "9913": 214, "9915e": 214, "9916e": 214, "9919e": 214, "992": 214, "9931e": 214, "9932e": 214, "9941": [96, 157, 207], "9943": 214, "99441528320312": 249, "9946": 214, "994618": 241, "9948e": 214, "9959e": 214, "9961": 214, "9971": 214, "9988": 214, "999": [188, 219], "9990": 214, "9990e": 214, "9998704791069031": 244, "999999": 214, "9b": [66, 96, 127, 157], "9gb": [63, 91, 124, 152], "9h": [70, 131], "__": [87, 188, 219], "____": [68, 129], "__all__": 46, "__builtins__": [50, 111], "__call__": [50, 52, 62, 85, 86, 87, 88, 95, 111, 113, 123, 146, 147, 148, 149, 156, 184], "__init__": [28, 36, 37, 39, 62, 70, 83, 86, 88, 93, 95, 123, 131, 144, 147, 149, 154, 156, 172, 173, 188, 214, 215, 219], "__main__": [43, 53, 60, 93, 114, 121, 154, 188, 197, 204, 214, 215, 219, 231], "__name__": [43, 53, 60, 93, 114, 121, 154, 188, 197, 204, 214, 215, 219, 231], "__new__": 222, "__post_init__": 219, "__version__": [196, 206, 209, 214, 219, 233, 236, 252], "_ascend": 170, "_ascend_pt": [172, 173], "_attn_implement": 41, "_babi": [53, 114], "_before_": 219, "_bia": 214, "_build": 26, "_check_messag": [70, 131], "_compute_chord_loss": [72, 133], "_compute_log_prob": [172, 173], "_concat_text_position_id": [53, 114], "_data_col": [53, 61, 114, 122], "_data_collator_mm_data": [53, 114], "_deepstack_process": 46, "_default": [53, 114], "_dev": [68, 129], "_dynamo": 214, "_encod": [53, 61, 114, 122], "_experimentalconfig": [98, 159, 172, 173], "_extend_token": [53, 114], "_forward_micro_batch": [172, 173], "_gather": 46, "_generate_and_score_complet": [89, 150], "_get_backend": 214, "_get_bbox_str": [53, 114], "_get_default_group": 214, "_get_inputs_embeds_hf": [53, 114], "_get_last_hidden_st": [70, 131], "_get_mm_input": 11, "_get_new_audio_token": [53, 114], "_get_new_token": [53, 114], "_get_new_tokens_use_audio_in_video": [53, 114], "_get_position_id": [53, 114], "_glibcxx_use_cxx11_abi": 218, "_grid_thw": [53, 114], "_here_": 222, "_lazy_import": 41, "_lazymodul": 219, "_linux": 14, "_local_rank": [188, 219], "_moe_implement": [40, 46], "_most_": 219, "_mp_fn": 219, "_no_split_modul": 43, "_npu_dropout": [214, 217], "_old": [73, 89, 134, 150], "_optimizer_step": [172, 173], "_orig_mod": 219, "_origin_train_step": [98, 159], "_patch": 39, "_patch_word_embed": [98, 159], "_post_encod": [53, 61, 114, 122], "_prepare_dataset": [93, 154], "_prepare_model1": [93, 154], "_prepare_model2": [93, 154], "_preprocessor_registri": 37, "_ref": [89, 150], "_replace_data_iter": [98, 159], "_self": [98, 159], "_set_static_graph": [70, 131], "_sokoban": 222, "_subclass": 214, "_tensor": 46, "_token": [53, 114], "_val": [68, 129], "_video": [53, 114], "a10": [56, 63, 64, 117, 124, 125], "a100": [63, 64, 91, 104, 105, 124, 125, 152, 165, 166], "a10b": [96, 157], "a13b": [96, 157], "a14b": [96, 157], "a17b": [40, 96, 157], "a2": [14, 15, 55, 96, 116, 157, 170, 174, 175, 176, 178, 179, 185, 193, 197, 214, 222, 230], "a22b": [56, 96, 102, 117, 157, 163], "a28b": [96, 157], "a2rbr": [67, 128], "a3": [14, 15, 174, 175, 176, 179, 180, 181, 214, 230], "a35b": [96, 157], "a3b": [27, 28, 29, 30, 35, 40, 55, 56, 57, 96, 103, 104, 105, 116, 117, 118, 157, 164, 165, 166, 170, 174, 179, 180], "a4": [96, 157], "a47b": [96, 157], "a4b": [96, 157], "a800": [56, 105, 117, 166], "aaaaa": [66, 127], "aarch64": [14, 170, 181, 185, 194, 197, 218, 224, 230], "ab": [52, 113], "ab527a9a6d347f364e3d185ba6d714e22d80cb3c": 224, "abbr": 179, "abbrevi": 114, "abc": [66, 83, 86, 88, 127, 144, 147, 149], "abi": 191, "abil": [117, 141], "abl": [128, 184, 244], "abo": [52, 113], "about": [35, 43, 45, 50, 56, 66, 83, 86, 87, 111, 114, 116, 117, 118, 121, 127, 133, 144, 147, 148, 153, 157, 158, 160, 213, 219, 237], "abov": [38, 113, 117, 121, 123, 127, 128, 129, 132, 148, 151, 155, 172, 219], "abs": [50, 111], "absl": [185, 206, 209, 233], "absolut": [39, 114, 118, 121, 128, 142], "abspath": 219, "abstract": [38, 144, 147], "abstract_algebra": 200, "abstractmethod": [83, 144], "ac": 256, "academic_sourc": 29, "acc": [52, 62, 65, 67, 123, 128, 180, 200, 234], "acc_reward": [79, 140], "acc_strategi": [70, 131], "acceler": [0, 15, 48, 58, 91, 96, 109, 111, 113, 117, 119, 124, 128, 130, 142, 151, 152, 157, 160, 162, 165, 166, 184, 185, 188, 209, 219, 241], "accelerate_multinode_config": 9, "accelerate_singlenode_config": 9, "accelerator_project_config": 219, "acceleratorst": 219, "accelr": 184, "accept": [121, 128, 158, 188, 219], "access": [34, 43, 50, 66, 111, 112, 121, 123, 127, 128, 148, 158, 172], "accomplish": 111, "accord": [33, 38, 45, 46, 52, 109, 110, 113, 117, 120, 121, 123, 127, 128, 130, 132, 136, 140, 143, 154, 156, 160, 204, 219], "account": [99, 128, 130, 160, 194, 219], "accumul": [48, 67, 70, 89, 99, 109, 128, 150, 160, 162, 219], "accur": [128, 155, 219], "accuraci": [39, 52, 56, 67, 68, 70, 83, 85, 86, 99, 111, 113, 117, 126, 128, 129, 144, 146, 147, 149, 153, 155, 158, 160, 179, 184, 188, 210, 219, 241, 249], "achiev": [50, 111, 113, 128, 132, 139, 140, 145, 160, 166, 237], "acid": 129, "acl_format": 214, "aclnn": 214, "aclopexecut": 214, "acltensor": 214, "acquir": 157, "acquisit": 111, "across": [34, 35, 38, 39, 45, 46, 52, 67, 70, 110, 111, 113, 121, 128, 145, 150, 151, 152, 160, 219], "act": [99, 160], "act2fn": [28, 39], "act_fn": 28, "action": [60, 66, 70, 83, 121, 127, 131, 144, 150, 170, 188, 219], "activ": [2, 16, 32, 33, 38, 39, 42, 55, 57, 67, 97, 98, 99, 116, 118, 128, 140, 153, 158, 159, 160, 172, 173, 175, 178, 191, 196, 206, 209, 212, 214, 221, 224, 230, 233, 236, 239, 244, 252], "activate_adapt": [97, 158], "activitynet": 29, "actor": [171, 174, 177, 178, 179, 180, 181, 250], "actor_compute_log_prob": [172, 173], "actor_inf": 222, "actor_lr": 178, "actor_max_token_len_per_gpu": 178, "actor_optim": [172, 173], "actor_ppo_max_token_len": [180, 181], "actor_rollout_ref": [172, 173, 174, 175, 178, 179, 180, 181], "actor_train": 222, "actual": [46, 109, 110, 120, 121, 123, 128, 129, 131, 142, 143, 156, 160], "actual_seq_length": 214, "actual_seq_lengths_kv": 214, "actual_shared_prefix_len": 214, "actualseqlength": 214, "ad": [52, 113], "adalora": [97, 158], "adam": [7, 9, 67, 99, 128, 160, 181, 188, 214, 219], "adam_beta1": 219, "adam_beta2": 219, "adam_epsilon": 219, "adam_mod": 214, "adam_weight_decay": 219, "adamw": [42, 99, 160, 219], "adamw8bit": 219, "adamw_torch": [67, 128], "adamw_torch_fus": [67, 128], "adapt": [7, 18, 39, 46, 53, 55, 56, 57, 63, 65, 67, 69, 90, 91, 97, 99, 102, 103, 104, 114, 116, 117, 118, 124, 126, 128, 130, 151, 152, 155, 158, 160, 163, 164, 165, 194, 219], "adapter_fold": 7, "adapter_id_or_path": [67, 128], "adapter_model": [67, 128], "adapter_nam": [97, 158], "adapter_name_or_path": [7, 8, 20, 21, 23], "adaptive_capt": 37, "adaptive_preprocessor": 37, "adaptive_sourc": 37, "adc": [52, 113], "add": [14, 33, 37, 38, 40, 43, 45, 50, 52, 56, 57, 67, 97, 99, 109, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 123, 126, 128, 130, 138, 142, 144, 146, 147, 148, 151, 152, 153, 156, 158, 159, 160, 172, 213, 214, 219, 230, 256], "add_argu": [188, 213, 219], "add_config_argu": [188, 219], "add_generation_prompt": [11, 53, 57, 114, 118, 191, 246], "add_imag": 219, "add_import": 39, "add_nois": 219, "add_weighted_adapt": [97, 158], "addit": [16, 28, 35, 36, 37, 50, 53, 61, 97, 110, 111, 113, 114, 117, 121, 122, 123, 124, 126, 128, 130, 131, 133, 140, 142, 144, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 166, 172, 214], "additional_saved_fil": [53, 114], "additional_target": [7, 18], "addr": [48, 67, 109, 128, 179, 180, 181], "address": [9, 35, 112, 128, 135, 139, 142, 147, 149, 151, 156, 160, 179, 180, 181], "adher": 111, "adjac": [7, 18], "adjust": [31, 39, 109, 110, 111, 118, 120, 127, 128, 132, 144, 148, 152, 155, 157, 159, 160, 166, 219], "adopt": [36, 45, 47, 154, 172], "ador": [57, 118], "adv": 222, "adv_estim": [174, 178, 181, 222], "advanc": [36, 46, 121, 128, 129, 131, 250], "advantag": [67, 73, 75, 81, 89, 99, 125, 128, 134, 135, 136, 137, 139, 142, 145, 149, 150, 160, 172], "advantage_clip": 222, "advantage_estim": [67, 76, 77, 99, 128, 137, 138, 160], "adventur": 237, "advertisegen": [96, 157], "advic": 246, "aesbench_test": [68, 70, 129, 131], "aesbench_v": [68, 70, 129, 131], "affair": 241, "affect": [9, 35, 39, 46, 57, 118, 126, 128, 131, 135, 142, 148, 158, 160, 164], "affected_fil": 170, "affin": [5, 34, 48, 55, 109, 116], "aforement": [121, 151], "afqmc": [68, 70, 129, 131], "after": [35, 38, 41, 42, 43, 45, 46, 51, 89, 111, 112, 113, 114, 116, 117, 118, 119, 124, 126, 127, 128, 150, 151, 154, 156, 159, 160, 164, 165, 172, 184, 219, 241], "afterward": [156, 219], "ag": 185, "again": [35, 219], "against": [39, 57, 112, 118, 219], "age": 19, "agent": [63, 67, 70, 83, 90, 91, 96, 105, 124, 128, 131, 144, 151, 152, 157, 166, 172, 173, 220], "agent_templ": [53, 60, 66, 114, 121, 127], "agentflan": [67, 128], "agentic_pipelin": 222, "agentic_sokoban": 222, "agentic_val_sokoban": 222, "agentica": 179, "agentinstruct_copi": [96, 157], "aggreg": [38, 128, 160], "agiev": [68, 70, 129, 131], "agnost": 38, "agre": 219, "aha": [73, 134], "ai": [0, 9, 31, 52, 53, 55, 56, 57, 63, 68, 70, 82, 90, 91, 94, 95, 96, 98, 102, 103, 104, 105, 113, 114, 116, 117, 118, 124, 129, 131, 143, 151, 152, 155, 156, 157, 159, 163, 164, 165, 166, 172, 173, 175, 177, 181, 185, 224, 225, 231, 236], "ai2d_test": [68, 70, 129, 131], "aic_metr": [98, 159], "aicmetr": [98, 159], "aicor": [55, 116, 185, 214], "aidc": [70, 96, 131, 157], "ailab": [105, 166], "aim": [50, 111, 123, 158, 179], "aime_2024": [178, 181], "aime_2025": 178, "aiohttp": [87, 148], "air": [96, 121, 127, 157], "ais_bench": 179, "aisbench": 179, "aisbenchmark": 179, "aishel": 253, "aishell_data_prep": 253, "aiv": [171, 178], "al": [52, 113], "alabama": [52, 113], "albeit": 128, "albument": 219, "alert": [57, 118], "alfworlddbkgmind2weboswebshop": [96, 157], "algo": [42, 99, 160], "algorithm": [42, 55, 67, 85, 117, 124, 128, 132, 136, 142, 146, 153, 155, 158, 160, 162, 164, 172, 174, 178, 180, 181, 201], "alia": [121, 230], "alias": [37, 41], "alibaba": [56, 57, 66, 96, 117, 118, 127, 157, 221], "alibi": 214, "align": [17, 42, 50, 53, 61, 63, 67, 76, 89, 91, 96, 99, 110, 111, 120, 121, 122, 123, 124, 126, 128, 132, 137, 150, 151, 152, 153, 157, 160, 163, 164, 250], "aliyun": [55, 56, 116, 117], "aliyunc": [53, 57, 64, 70, 90, 91, 95, 105, 114, 118, 125, 131, 151, 152, 156, 166, 179], "all": [7, 9, 14, 17, 18, 24, 29, 37, 38, 39, 41, 43, 44, 45, 46, 48, 50, 51, 53, 56, 57, 58, 63, 64, 67, 68, 84, 91, 93, 96, 97, 99, 102, 103, 104, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 129, 134, 135, 136, 137, 139, 142, 144, 145, 147, 148, 150, 151, 152, 154, 155, 157, 158, 160, 162, 163, 164, 165, 172, 188, 219, 222, 228, 237, 240], "all2al": 46, "all_attention_funct": [39, 41], "all_exhaust": 128, "all_experts_funct": 40, "all_featur": 214, "all_gath": [39, 46], "all_rank": [172, 173], "all_reduc": [39, 128, 214], "allenai": [96, 157], "allevi": 172, "allgath": [35, 99, 160, 214], "allgather_bucket_s": [9, 48, 109, 188, 219], "allgather_partit": [9, 48, 109, 188, 219], "allmask": 214, "alloc": [5, 34, 67, 128, 154, 162, 179, 180, 181, 204], "allocatedstringptr": 204, "allocatorwithdefaultopt": 204, "allow": [34, 36, 38, 44, 50, 109, 111, 113, 121, 123, 124, 127, 128, 129, 131, 146, 149, 151, 152, 155, 160, 172, 219], "allow_extra_arg": 7, "allow_tf32": 219, "allowed_pattern": [50, 111], "allreduc": [99, 160], "allreducestrategi": [48, 109], "alltoal": [99, 160, 214], "almost": [57, 118, 150], "alon": [50, 111], "along": [35, 38, 46, 128, 147, 151, 156, 219], "alongsid": 39, "alpaca": [53, 56, 57, 60, 63, 68, 70, 90, 91, 95, 96, 98, 102, 105, 114, 117, 118, 121, 124, 129, 131, 151, 152, 156, 157, 159, 163, 166], "alpaca_en": 9, "alpaca_en_demo": [8, 9, 20, 21, 24], "alpaca_finance_en": [96, 157], "alpaca_zh_demo": 19, "alpacapreprocessor": [60, 121], "alpha": [67, 92, 96, 99, 104, 128, 153, 157, 160, 165, 214], "alpha002": 187, "alpha003": 252, "alpindal": [96, 157], "alreadi": [35, 37, 40, 41, 110, 111, 113, 114, 128, 130, 132, 133, 140, 154, 155, 162, 164, 166, 178, 184, 219], "alright": [56, 117], "also": [32, 33, 35, 36, 38, 45, 46, 50, 51, 56, 110, 111, 112, 113, 114, 117, 121, 122, 127, 128, 130, 135, 142, 144, 147, 150, 151, 152, 153, 154, 156, 158, 160, 163, 164, 166, 219], "alter": 159, "altern": [128, 131, 151, 166, 234], "although": [152, 156, 172], "alway": [35, 37, 41, 66, 127, 128, 141, 142, 150, 155, 160, 219, 246], "am": [56, 91, 105, 117, 152, 166], "amax": [99, 160], "american": 256, "amino": 129, "aml": [35, 46], "among": [38, 50, 110, 111, 121, 127, 128, 129, 150, 152, 160], "amount": [45, 155, 160], "amp": [7, 207, 219, 234], "amper": 219, "amplifi": 139, "amus": [57, 118], "an": [35, 36, 37, 38, 39, 46, 47, 50, 51, 52, 56, 57, 90, 91, 110, 111, 112, 113, 114, 117, 118, 121, 123, 124, 126, 127, 128, 129, 132, 133, 138, 140, 144, 147, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 162, 163, 164, 166, 172, 188, 219], "anaconda": [224, 236], "analys": [172, 173], "analyse_flag": [172, 173], "analysi": [136, 155, 172, 173, 177, 244], "analyt": 172, "analyz": [37, 44], "anatomi": [200, 225], "anchor": [49, 110, 214], "anchor_box": 214, "and": [3, 11, 12, 16, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 50, 51, 52, 53, 55, 56, 57, 59, 60, 66, 70, 74, 79, 83, 86, 87, 90, 91, 97, 99, 109, 110, 112, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 134, 135, 136, 138, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 158, 159, 160, 161, 162, 163, 165, 166, 170, 180, 184, 188, 191, 194, 199, 206, 207, 209, 213, 214, 215, 219, 222, 230, 231, 233, 237, 241, 244, 246, 249, 250, 256], "anger": 241, "angl": [52, 113, 214], "ani": [0, 7, 35, 43, 50, 51, 52, 53, 57, 60, 70, 83, 86, 91, 110, 111, 112, 113, 114, 118, 121, 127, 128, 144, 147, 151, 152, 160, 219, 234, 237, 246], "anim": [90, 91, 129, 151, 152], "anneal": 160, "annot": [29, 30, 96, 132, 154, 157], "annoy": 35, "annualtitl": [96, 157], "anoth": [38, 50, 111, 123, 219], "answer": [37, 50, 51, 52, 56, 57, 59, 60, 62, 66, 68, 83, 86, 87, 89, 91, 95, 110, 111, 112, 113, 117, 118, 120, 121, 123, 127, 128, 140, 144, 147, 148, 150, 152, 153, 156, 243], "answer1": [70, 131], "answerdotai": [96, 157], "antarctica": 129, "anti_qu": 214, "antiqu": 214, "antiquant_group_s": 214, "antiquant_mod": 214, "antiquant_offset": 214, "antiquant_offset1": 214, "antiquant_offset2": 214, "antiquant_offset_i": 214, "antiquant_scal": 214, "antiquant_scale1": 214, "antiquant_scale2": 214, "antiquant_scale_i": 214, "antiquantmod": 214, "antiquantoffset": 214, "antiquantscal": 214, "anyprecis": 42, "anyth": [56, 117, 219], "anytim": [57, 118], "anywher": [37, 110, 241], "aoe_config": 214, "aoe_mod": 214, "aot": 237, "ap": 170, "apach": 219, "apex": [105, 166], "api": [7, 35, 47, 51, 66, 67, 87, 89, 90, 95, 97, 112, 127, 128, 148, 150, 151, 156, 158, 172, 173, 179, 204, 209, 213, 217, 249], "api_bas": [58, 70, 119, 131], "api_call_exampl": 21, "api_host": 7, "api_key": [7, 21, 70, 88, 90, 91, 131, 149, 151, 152, 222], "api_model_nam": 7, "api_port": [7, 21], "api_serv": 197, "api_url": [70, 131], "api_verbos": 7, "apivers": [48, 109], "apollo_layerwis": 7, "apollo_proj": 7, "apollo_proj_typ": 7, "apollo_rank": 7, "apollo_scal": 7, "apollo_scale_front": 7, "apollo_scale_typ": 7, "apollo_target": 7, "apollo_update_interv": 7, "apolog": 241, "app": [60, 64, 65, 66, 90, 91, 121, 125, 126, 127, 151, 152, 193], "appeal": [57, 118], "appear": [39, 51, 57, 90, 110, 112, 118, 128, 141], "append": [29, 30, 37, 39, 50, 52, 53, 62, 85, 88, 111, 113, 114, 123, 128, 146, 149, 188, 219], "appl": 121, "appli": [35, 37, 39, 41, 45, 46, 89, 99, 118, 123, 128, 132, 135, 137, 139, 140, 142, 146, 148, 150, 153, 155, 158, 160, 161, 194], "applic": [88, 90, 117, 120, 126, 132, 148, 149, 151, 160, 172, 188, 219, 228, 231], "apply_chat_templ": [11, 53, 57, 67, 114, 118, 128, 191, 199, 246], "apply_logprobs_patch": 39, "apply_ops_patch": 39, "apply_rotary_pos_emb": 39, "apply_xpu_patch": 39, "approach": [38, 44, 45, 56, 111, 117, 121, 123, 128, 134, 136, 140, 142, 149, 150, 154, 155, 160, 163, 237], "appropri": [36, 111, 121, 128, 151, 160, 166], "approx": [81, 133, 142], "approxim": [43, 50, 111, 128, 160, 214], "apt": [22, 32, 33, 181, 185], "aqi": [60, 66, 121, 127], "aqlm": [22, 23, 63, 91, 96, 124, 152, 157], "ar": 256, "arang": [53, 114], "arb2r": [67, 128], "arbitrari": 117, "arbitrarili": 154, "arbr": [67, 128], "arc": [52, 68, 94, 113, 129, 155], "arc_": [68, 70, 129, 131], "arc_c": [68, 70, 129, 131], "arch": [14, 61, 122, 185, 194], "architectur": [36, 38, 46, 53, 61, 67, 70, 114, 119, 120, 122, 128, 131, 160, 162, 164, 175, 194], "archiv": 224, "arctic": 129, "ardeesfridjakoptruthvi": [96, 157], "are": [7, 11, 21, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 50, 51, 52, 53, 55, 56, 57, 60, 61, 63, 66, 83, 86, 87, 88, 90, 91, 102, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 121, 122, 123, 124, 127, 128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 172, 180, 184, 188, 191, 197, 219, 222, 228, 241, 243, 244, 246, 249], "are____": 129, "area": 132, "aren": [51, 112], "arena_extend_strategi": 204, "arg": [9, 14, 36, 37, 38, 43, 46, 47, 50, 52, 53, 62, 63, 66, 67, 68, 70, 83, 86, 91, 93, 98, 99, 102, 103, 111, 113, 114, 123, 124, 127, 128, 129, 131, 144, 147, 152, 154, 159, 160, 163, 164, 172, 173, 188, 213, 214, 215, 219, 241], "argc": [204, 213], "argmax": [204, 214, 219, 241], "argmax_overlap": 214, "argpars": [188, 207, 213, 219], "argu": [135, 136], "argument": [19, 37, 39, 60, 66, 109, 117, 121, 126, 127, 136, 138, 144, 147, 148, 150, 188, 219, 237], "argumentpars": [188, 213, 219], "argv": [204, 213, 219], "aris": 155, "arithmet": [50, 111], "arm": 230, "arm64": 181, "arm_fma": [194, 256], "around": [41, 45, 57, 111, 113, 118, 128, 151, 154, 219], "arr": 194, "arrang": [50, 111], "array": 204, "art": 155, "articl": 111, "artifact": 237, "artifici": [56, 91, 117, 152], "artist": [57, 118], "arvix": 92, "arxiv": [94, 97, 153, 155, 158, 178], "as": [27, 29, 30, 35, 36, 37, 38, 39, 40, 45, 46, 47, 50, 52, 53, 55, 56, 57, 66, 70, 83, 86, 87, 88, 90, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 126, 127, 128, 129, 132, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 152, 153, 154, 155, 156, 158, 159, 160, 161, 163, 164, 165, 166, 172, 188, 204, 207, 213, 214, 215, 219, 221, 228, 231, 234, 237, 240, 241, 246], "asap": 243, "asarray": 219, "ascend": [5, 7, 14, 15, 18, 32, 48, 63, 64, 67, 109, 124, 125, 128, 170, 177, 180, 181, 183, 185, 193, 197, 201, 203, 204, 212, 213, 214, 215, 220, 222, 224, 227, 231, 236, 248, 250], "ascend910b3": 237, "ascend_8": 176, "ascend_cann": 187, "ascend_cann_package_path": 212, "ascend_instal": [14, 183, 230], "ascend_profiler_output": 177, "ascend_profiling_zh": 179, "ascend_rt_visible_devic": [7, 15, 24, 55, 70, 91, 116, 131, 152, 175, 179, 253], "ascend_toolkit_instal": 170, "ascend_visible_devic": 197, "ascendai": [2, 183, 193, 212, 236], "ascendcl": [172, 173], "asctim": 219, "asdict": 43, "asdsip": 14, "ask": [56, 83, 86, 87, 91, 117, 144, 147, 148, 152, 241, 246, 256], "aspect": 138, "aspect_ratio_id": 11, "aspect_ratio_mask": 11, "asr": [253, 256], "asr_dummi": 243, "assert": [37, 46, 53, 114, 215, 219], "assertionerror": [70, 131], "asset": 224, "assign": [35, 112, 127, 142, 147, 148, 153, 154, 160, 219], "assigned_gt_ind": 214, "assist": [7, 11, 19, 37, 48, 50, 52, 53, 56, 57, 59, 60, 61, 63, 66, 67, 83, 86, 87, 88, 90, 91, 102, 105, 109, 111, 113, 114, 117, 118, 120, 121, 122, 124, 127, 128, 140, 144, 147, 148, 149, 151, 152, 163, 166, 231, 243, 246], "assistant_messag": [70, 131], "assistant_tag": 19, "associ": [121, 128, 130, 157], "assum": [37, 140, 147], "ast": 39, "astramindai": [96, 157], "astronomi": 200, "astyp": [204, 213, 214], "asym_clip": 222, "asymmetr": [132, 135], "async": [67, 70, 83, 86, 87, 99, 101, 128, 131, 144, 147, 160, 162, 178], "async_api": [87, 148], "async_en": 38, "async_gener": [52, 101, 113, 162], "async_io": 187, "async_op": 38, "async_sav": [99, 160], "async_sglang_serv": 175, "async_ulysses_output_project": 38, "async_ulysses_qkv_project": 38, "asyncapireward": [87, 148], "asyncengin": [86, 147], "asynchron": [124, 128, 147, 148, 151, 160], "asyncio": [87, 148], "asyncllm": [172, 173], "asyncorm": [87, 148], "at": [11, 31, 35, 37, 39, 41, 42, 44, 46, 50, 52, 57, 86, 91, 110, 113, 117, 118, 120, 121, 128, 133, 136, 139, 140, 141, 142, 143, 145, 147, 150, 151, 152, 154, 155, 156, 158, 160, 162, 166, 172, 177, 184, 187, 188, 213, 215, 219, 222, 237, 241, 244, 249], "atan_sub_flag": 214, "atb": [14, 174, 175, 197], "atb_llm_lcoc_en": 171, "atb_matmul_shuffle_k_en": 171, "atlas": [14, 15, 55, 116, 174, 175, 176, 178, 179, 180, 181, 185, 193, 197, 214, 222, 230], "atmospher": 151, "atom": [96, 155, 157], "atomgit": 181, "attach": [128, 158, 160], "attempt": [128, 134, 135], "atten": 214, "atten_mask": 214, "atten_out": 214, "attenmask": 214, "attent": [7, 9, 22, 35, 38, 39, 45, 57, 63, 67, 99, 105, 109, 118, 123, 124, 128, 160, 166, 174, 177, 191, 194, 214, 221, 230, 231], "attention_backend": [56, 57, 70, 99, 103, 104, 117, 118, 131, 160, 164, 165, 175, 231], "attention_mask": [53, 98, 114, 159, 214, 241], "attentionout": 214, "attenu": [139, 145], "attn": [7, 41, 53, 56, 67, 70, 91, 99, 105, 114, 117, 128, 131, 152, 160, 166, 194, 256], "attn_dim_per_head": 214, "attn_head_num": 214, "attn_impl": [53, 56, 57, 58, 67, 91, 99, 104, 114, 117, 118, 119, 128, 152, 160, 165], "attn_implement": [53, 57, 114, 118, 222], "attn_mask": 214, "attn_r": 214, "attn_scor": 214, "attr": [179, 185, 206, 209, 214, 230, 233], "attribut": [35, 147, 214, 219], "audienc": 194, "audio": [11, 19, 32, 33, 37, 49, 53, 60, 66, 67, 83, 86, 90, 96, 99, 110, 114, 121, 124, 127, 128, 144, 147, 151, 152, 157, 243], "audio2": [96, 157], "audio_bo": [53, 114], "audio_chunk_index": [53, 114], "audio_emb": [53, 114], "audio_eo": [53, 114], "audio_feature_length": [53, 114], "audio_idx": [53, 114], "audio_length": [53, 114], "audio_lengths_origin": [53, 114], "audio_mask": [53, 114], "audio_r": [53, 114], "audio_seq_length": [53, 114], "audio_token": [53, 114], "audio_token_id": [53, 114], "audio_token_index": [53, 114], "audio_token_indic": [53, 114], "audio_tow": [53, 114, 128, 160], "audioinput": 11, "audioread": [53, 114], "augment": [128, 155], "aura": 3, "auth": [51, 112, 219], "authent": [57, 118, 128, 219], "author": [35, 46, 67, 128, 143, 153, 219], "authorit": 121, "auto": [7, 9, 37, 39, 43, 48, 53, 57, 67, 70, 99, 109, 114, 118, 128, 131, 160, 175, 191, 199, 204, 210, 219, 222, 241, 246], "auto_awq": 197, "auto_config": [48, 109], "auto_gptq": [69, 130], "auto_math_textkhanacademyopenstaxstanfordstoriesweb_samples_v1web_samples_v2wikihow": [96, 157], "auto_model_cl": [53, 114], "auto_tun": [48, 109], "autoawq": [69, 70, 130, 131], "autocast": [207, 219], "autocast_ctx": 219, "autoclean": 22, "autoconfig": [44, 58, 119, 219], "autodispatchbelowadinplaceorview": 249, "autodispatchbelowautograd": 249, "autoencoderkl": 219, "autoglm": [96, 157], "autogptq": [69, 130], "autom": [38, 128, 160], "automat": [35, 36, 37, 43, 44, 46, 114, 118, 121, 122, 124, 127, 128, 130, 140, 142, 147, 148, 150, 152, 160, 161, 164, 172, 219, 243, 253, 256], "automatic1111": 224, "automodel_class": [70, 131], "automodelforcausallm": [43, 58, 119, 191, 219, 241, 242], "automodelforsequenceclassif": 244, "autonom": 133, "autononvariabletypemod": 249, "autopreprocessor": [60, 67, 121, 128], "autoprocessor": [11, 44, 57, 118], "autoregress": 172, "autotoken": [11, 43, 191, 219, 241, 244, 246], "autotp": [67, 128], "autotp_s": 9, "aux": [67, 99, 128, 131, 160], "aux_loss": 7, "auxiliari": [128, 160], "av": [96, 157], "avail": [37, 38, 39, 50, 111, 117, 128, 144, 151, 152, 153, 154, 160, 219, 234, 244], "averag": [67, 110, 128, 142, 145, 150, 160, 237], "average_checkpoint": 253, "average_num": 253, "averageaccuraci": [68, 129], "avg": [99, 160], "avg_loss": 219, "avoid": [34, 35, 40, 41, 45, 46, 53, 110, 114, 117, 120, 128, 133, 135, 138, 147, 152, 155, 156, 158, 160, 172, 184, 219, 241], "avx": [194, 256], "avx2": [194, 256], "avx512": [194, 256], "avx512_bf16": 194, "avx512_vbmi": 194, "avx512_vnni": 194, "avx_vnni": 194, "await": [87, 148], "awar": [16, 35, 41, 99, 149, 152, 160, 166], "away": 219, "awesom": [65, 126], "awk": [179, 180, 181, 230], "awq": [9, 22, 23, 63, 67, 69, 90, 91, 96, 124, 128, 130, 151, 152, 157], "ax_b": [68, 70, 129, 131], "ax_g": [68, 70, 129, 131], "axi": [67, 128, 204, 214, 241], "axpy_v2": 214, "aya": [96, 157], "aya_collect": [96, 157], "aya_dataset": [96, 157], "azure99": [96, 157], "b030": [55, 116], "b1": 214, "b2": 214, "b64encod": [90, 151], "b86k": 207, "baai": [96, 157], "babi": [53, 57, 90, 114, 118, 151], "bac009s0002w0122": 253, "back": [35, 38, 41, 46, 83, 86, 123, 128, 142, 144, 147, 158, 160, 161, 166, 172, 219, 241], "backbon": [96, 97, 157, 158], "backbonecallerplannersummar": [96, 157], "backend": [39, 41, 48, 67, 68, 70, 89, 90, 99, 109, 118, 124, 128, 129, 132, 150, 160, 172, 178, 188, 197, 207, 214, 219, 222, 230, 231, 250, 256], "backend_config": 197, "background": [57, 90, 118, 126, 151, 250], "backoff": [96, 157], "backpropag": [123, 128, 219], "backtrack": 143, "backup": [96, 157], "backward": [35, 43, 45, 46, 70, 89, 93, 128, 131, 150, 154, 160, 172, 173, 188, 214, 215, 219], "backward_pr": [9, 15], "bad": [39, 225, 241], "badam": 22, "badam_mask_mod": [7, 18], "badam_mod": [7, 18], "badam_start_block": [7, 18], "badam_switch_interv": [7, 18], "badam_switch_mod": [7, 18], "badam_update_ratio": [7, 18], "badam_verbos": [7, 18], "baichuan": [96, 157], "baichuan2": [96, 157], "baidu": [96, 157], "baikebaike_clsopen_qaopen_qa_clsnlpcc_dbqanlpcc_dbqa_clsfinancefinance_clsmedicinemedicine_clslawlaw_clspsychologypsychology_cl": [96, 157], "baind": [96, 157], "balanc": [42, 99, 128, 132, 133, 139, 154, 160, 172], "band": 214, "bandspars": 214, "bandwidth": [48, 109, 214, 237], "bao": [52, 113], "bar": [77, 138, 219], "bark": 243, "barrier": [164, 188, 219], "base": [3, 36, 37, 38, 39, 42, 45, 50, 52, 53, 56, 59, 60, 66, 67, 90, 91, 92, 94, 95, 96, 98, 99, 109, 110, 111, 112, 113, 114, 116, 117, 119, 120, 121, 122, 123, 126, 127, 133, 134, 135, 136, 138, 140, 142, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 157, 158, 159, 160, 174, 177, 184, 188, 210, 214, 219, 243, 244, 250, 256], "base64": [60, 90, 121, 151], "base64_encod": [60, 90, 121, 151], "base_imag": [14, 170], "base_model": [53, 114, 219], "base_url": [21, 88, 90, 91, 95, 149, 151, 152, 156], "baseargu": [91, 152], "basehelp": [96, 157], "baselin": [76, 81, 97, 137, 142, 158, 222], "basem": 177, "basemodel": [97, 158], "basen": 177, "basenam": 219, "baseplugin": 11, "baseppoactor": [172, 173], "bash": [9, 14, 15, 27, 28, 29, 30, 31, 38, 43, 48, 70, 109, 131, 170, 175, 178, 179, 180, 181, 183, 197, 224, 230, 236, 253], "bashrc": [14, 174, 245], "bashsudo": 185, "basi": 219, "basic": [50, 111, 126, 128, 129, 138, 160], "basic_modul": [35, 43], "basicconfig": [191, 219], "basketbal": 121, "bat": [67, 128], "batch": [7, 9, 42, 43, 45, 48, 49, 50, 52, 53, 59, 62, 67, 72, 75, 76, 89, 90, 91, 92, 93, 94, 99, 101, 109, 110, 111, 114, 120, 123, 128, 135, 136, 137, 141, 147, 150, 151, 152, 153, 154, 155, 160, 162, 172, 173, 177, 181, 188, 207, 210, 214, 219, 222, 228, 231, 234, 241], "batch_correct": [188, 219], "batch_decod": [53, 57, 114, 118], "batch_first": 214, "batch_id": 214, "batch_idx": [172, 173], "batch_siz": [7, 11, 20, 28, 38, 46, 67, 82, 113, 128, 143, 179, 188, 199, 200, 207, 214, 219, 240], "batchd": 256, "batchmatmul": 214, "batchsiz": [45, 214], "bb6e834e9c70d9c27d0dc3ecedeebeaeb1ffad6b": 224, "bbh": [68, 70, 129, 131], "bbox": [53, 57, 60, 67, 70, 79, 114, 118, 121, 128, 140, 214], "bbox_2d": [57, 60, 118, 121], "bbox_format": [53, 114], "be": [29, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 57, 59, 66, 67, 86, 90, 109, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 152, 153, 154, 155, 156, 158, 160, 161, 162, 164, 165, 166, 171, 172, 180, 184, 187, 188, 193, 194, 204, 219, 222, 237, 241, 243, 244, 246, 249], "beach": 121, "beam": [67, 94, 128, 155, 256], "beam_search": 7, "bear": 237, "bearer": 219, "beauti": [57, 118], "becam": 237, "becaus": [35, 46, 114, 128, 129, 164, 166, 222], "becom": [35, 37, 51, 112, 113, 128, 135, 142, 147, 150, 158, 160], "bed": [57, 90, 118, 151], "bedroom": [57, 118], "been": [46, 70, 128, 129, 131, 140, 155, 184, 219], "befor": [38, 40, 41, 43, 44, 45, 46, 114, 116, 117, 118, 121, 122, 123, 128, 152, 153, 154, 159, 160, 172, 184, 219, 237], "before_rank_mask": 46, "began": 237, "begin": [39, 50, 62, 66, 74, 76, 81, 89, 111, 123, 127, 128, 135, 137, 142, 150, 159, 160, 214], "begin_mask": 214, "begin_of_text": [11, 194], "behav": [109, 110, 128, 160], "behavior": [39, 40, 57, 70, 114, 118, 124, 128, 131, 142, 147, 150, 152, 160, 172, 219], "behind": [57, 118, 219, 237, 241], "beij": [64, 70, 105, 121, 125, 127, 129, 131, 166], "being": [28, 31, 56, 114, 117, 121, 126, 127, 128, 144, 145, 146, 155, 160, 191, 219], "beit": 243, "bellegroup": [96, 157], "belong": [46, 146, 147], "below": [36, 111, 113, 114, 116, 117, 118, 121, 127, 128, 129, 136, 140, 146, 147, 148, 150, 151, 154, 157, 158, 159, 160, 163, 164, 165, 172, 219, 249], "bench": [96, 157, 193], "bench_al": [68, 70, 129, 131], "bench_all_mi": [68, 70, 129, 131], "bench_val": [68, 70, 129, 131], "bench_val_mi": [68, 70, 129, 131], "benchmark": [57, 58, 96, 118, 119, 157, 179], "benefit": [35, 39], "bert": [69, 88, 90, 91, 96, 130, 149, 151, 152, 157, 184, 244], "bertforsequenceclassif": [184, 244], "berttokenizerfast": 184, "besid": [35, 122, 128], "bespok": [96, 157], "bespokelab": [96, 157], "best": [57, 66, 67, 95, 99, 122, 127, 128, 152, 159, 160, 163, 165, 166, 256], "best_model": [128, 160], "beta": [7, 50, 52, 67, 70, 71, 75, 76, 77, 89, 92, 96, 99, 100, 111, 113, 128, 131, 132, 136, 137, 138, 150, 153, 157, 160, 161, 188, 214, 219, 243], "beta1": [67, 99, 128, 160, 197, 214, 219], "beta1_pow": 214, "beta2": [67, 99, 128, 160, 214, 219], "beta2_pow": 214, "better": [39, 67, 70, 99, 120, 128, 130, 131, 153, 160, 164, 219], "between": [37, 42, 46, 50, 83, 86, 87, 110, 111, 113, 114, 118, 119, 120, 121, 127, 128, 130, 132, 135, 142, 144, 146, 147, 148, 150, 151, 153, 160, 161, 162, 163, 164, 219], "beyond": [128, 149, 153], "bf16": [7, 8, 9, 15, 17, 24, 48, 96, 99, 109, 157, 160, 188, 214, 219, 222], "bfloat16": [7, 44, 48, 50, 51, 52, 53, 56, 57, 58, 63, 67, 68, 91, 99, 102, 103, 105, 109, 111, 112, 113, 114, 117, 118, 119, 124, 128, 129, 152, 160, 163, 164, 166, 188, 214, 219, 241, 246], "bfloat16_en": [188, 219], "bge": [96, 157], "bias": [12, 28, 38, 67, 99, 128, 135, 138, 142, 153, 160, 184, 214, 241, 244], "bias1": 214, "bias2": 214, "bias3": 214, "bias_dropout_fus": [98, 159], "bias_flag": 214, "bias_hidden": 214, "bias_i": 214, "bias_input": 214, "bias_swiglu_fus": [98, 159], "bicub": 234, "bidirect": [164, 214], "big": [35, 50, 111], "bigcod": [96, 157], "bigger": [89, 150], "bigl": [81, 142], "bigr": [81, 142], "bilater": 160, "bin": [7, 14, 15, 22, 32, 33, 35, 48, 70, 92, 109, 131, 153, 183, 185, 193, 194, 207, 212, 214, 219, 221, 224, 234, 236, 243, 253, 255, 256], "binar": [96, 157], "binari": [51, 112, 120, 214, 224], "bind": 34, "bird": [96, 157, 188, 219, 243], "birthdat": 19, "bit": [6, 7, 9, 16, 23, 67, 128, 214, 219, 256], "bit0": 214, "bit1": 214, "bitmask": 214, "bitsandbyt": [7, 22, 69, 96, 130, 157, 219], "bitwis": 42, "black": [39, 57, 118, 151], "blas": [194, 256], "bleu": [20, 68, 129], "blink": [68, 70, 129, 131], "blip": [3, 219, 224], "blk": 46, "blob": [11, 40, 63, 81, 105, 124, 128, 142, 166, 175], "block": [9, 28, 34, 46, 67, 97, 99, 110, 112, 127, 128, 158, 160, 214, 219], "block_count": 194, "block_diag_attn": 7, "block_loc": 214, "block_siz": [214, 219, 222], "block_tabl": 214, "blocksiz": 214, "blocktabl": 214, "blockwis": [99, 160], "blog": [71, 132, 219], "blood": [129, 241], "blossom": [55, 96, 116, 157], "blue": [57, 118, 151], "bluelm": [96, 157], "blur": [57, 118], "bmm": 214, "bmm1": 214, "bmm2": 214, "bmm_score_transpose_a": 214, "bmm_score_transpose_b": 214, "bnb": [63, 67, 69, 90, 91, 96, 124, 128, 130, 151, 152, 157, 219], "bnhs": 214, "bnpo": [67, 74, 99, 128, 135, 160], "bnsd": 214, "bnss": 214, "bo": [52, 113], "board": 241, "boardcast": 214, "bodi": [131, 234], "boft_block_s": [67, 128], "bone": [67, 128], "book": [57, 90, 118, 151, 237], "bool": [7, 18, 38, 42, 43, 53, 62, 71, 72, 74, 83, 86, 100, 114, 123, 132, 133, 135, 144, 147, 161, 214, 219], "boolean": [67, 128, 160], "boolq": [68, 70, 129, 131], "bori": 237, "borrow": 114, "bos": [61, 122, 194], "bos_token": 11, "bos_token_id": 194, "both": [32, 33, 36, 38, 41, 43, 46, 52, 57, 90, 110, 111, 113, 118, 127, 128, 129, 136, 138, 142, 146, 148, 150, 151, 160, 164, 165, 172, 219], "bottleneck": [46, 128, 160], "bottom": [52, 113, 128, 131, 160], "bound": [121, 128, 135, 150, 160], "boundari": 45, "box": [46, 48, 60, 62, 83, 86, 109, 121, 123, 128, 144, 147, 214], "box1": 214, "box16": [174, 175, 176], "box2": 214, "box_end": [53, 60, 67, 114, 121, 128], "box_responsible_flag": 214, "box_scor": 214, "box_start": [53, 60, 67, 114, 121, 128], "boxes1": 214, "boxes2": 214, "boy": 237, "bp": 62, "bpe": 194, "bpw": 194, "branch": [41, 105, 125, 131, 143, 166, 170, 172, 174, 199, 219, 224, 230, 234], "break": [83, 86, 144, 147, 151, 179, 180, 181, 219], "breakdown": [57, 118], "brew": 32, "bridg": [41, 55, 67, 99, 116, 128, 160], "bridge_cl": [103, 164], "brief": 204, "briefli": 110, "bright": [57, 118, 234], "bring": [50, 111, 164], "broadcast": [142, 214], "broadcast_to": [53, 114], "brokenpipeerror": [188, 219], "brown": [52, 57, 118, 228, 234, 237], "browser": [172, 237], "bs": 214, "bsh": 214, "bsnd": 214, "bsz": [42, 43, 45, 219], "bsz_warmup_init_mbtoken": 43, "bsz_warmup_ratio": 43, "btensor": 214, "buaadream": [96, 157], "bubbl": [147, 160], "bucket": [67, 99, 128, 160], "budget": 45, "buffer": [7, 43, 67, 128, 160, 194, 256], "buffer_s": 7, "build": [4, 8, 13, 39, 43, 47, 56, 105, 117, 119, 147, 166, 178, 193, 194, 197, 203, 212, 230, 236, 249, 250, 255, 256], "build_chat_templ": 43, "build_custom_dataset": 43, "build_dataload": 43, "build_dataset": 43, "build_doc": 212, "build_exampl": 212, "build_foundation_model": [36, 43], "build_lr_schedul": 43, "build_mapping_dataset": 43, "build_multisource_dataset": 37, "build_opencv_dnn": 212, "build_opencv_fac": 212, "build_opencv_features2d": 212, "build_opencv_wechat_qrcod": 212, "build_opencv_xfeatures2d": 212, "build_optim": 43, "build_parallelize_model": 43, "build_pi": 236, "build_shared_lib": 203, "build_token": 43, "builder": 184, "built": [37, 111, 113, 117, 121, 122, 124, 128, 140, 144, 147, 150, 151, 160, 193, 194, 212, 255], "bulk": 155, "burden": 40, "bus": [55, 116, 185], "business_eth": 200, "bustm": [68, 70, 129, 131], "but": [37, 40, 41, 42, 45, 46, 50, 56, 110, 111, 117, 120, 121, 122, 127, 128, 130, 138, 142, 145, 147, 149, 152, 155, 160, 161, 163, 164, 166, 215, 219, 237, 241, 243], "button": 126, "by": [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 52, 56, 57, 62, 66, 67, 70, 83, 86, 91, 97, 99, 105, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 160, 161, 162, 164, 166, 172, 180, 184, 204, 219, 222, 228, 237], "bypass": [121, 123], "byte": [42, 44], "byted": [32, 33, 35, 46, 96, 157, 178], "bytedancedouyincont": [96, 157], "bytedtsinghua": [178, 179, 181], "bz2": 181, "bzb2023": [96, 157], "c0": 214, "c1": [55, 116, 185, 214], "c10": 249, "c10d": [38, 70, 131], "c1_len": 214, "c2": [55, 116], "c3": [68, 70, 129, 131], "c4": [96, 157], "c4_demo": [17, 23], "c4_test": 240, "c4ai": [96, 157], "c4b6f0": 179, "c98cb8cc": 179, "ca": [66, 127], "cach": [34, 42, 57, 67, 74, 87, 99, 105, 118, 128, 135, 143, 148, 160, 166, 170, 181, 194, 219, 230, 231, 237, 256], "cache_dir": [7, 70, 131, 207, 219, 245], "cache_fil": [67, 95, 128, 156], "cache_max_entry_count": [67, 128], "cache_request": 199, "cached_dataset": [67, 128], "cached_dataset_path": [67, 128], "caida": 243, "calcul": [43, 46, 50, 62, 85, 89, 99, 109, 110, 111, 117, 120, 121, 123, 127, 128, 135, 136, 142, 144, 146, 148, 150, 153, 160, 162, 164, 214, 219, 237], "calculate_ag": 19, "calculate_entropi": [172, 173], "calendar": [60, 66, 121, 127], "calibr": [16, 130], "call": [11, 35, 37, 40, 41, 43, 46, 51, 60, 66, 70, 82, 87, 96, 105, 112, 114, 121, 122, 123, 127, 128, 140, 143, 147, 148, 149, 152, 154, 155, 157, 158, 159, 160, 166, 172, 184, 191, 214, 219], "callabl": [93, 121, 154], "callback": [48, 67, 99, 109, 128, 160], "calledprocesserror": 221, "can": [31, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 52, 56, 59, 66, 70, 83, 86, 91, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 171, 172, 184, 188, 193, 194, 214, 219, 222, 228, 230, 249, 256], "can_refresh": 214, "cancel": 170, "candid": [57, 109, 118, 120], "candidate_label": 243, "cann": [2, 4, 5, 55, 116, 170, 172, 173, 174, 175, 176, 177, 178, 180, 181, 183, 185, 191, 193, 194, 199, 203, 204, 206, 209, 212, 213, 218, 221, 227, 230, 233, 236, 239, 248, 252, 255, 256], "cann_dir": 212, "cann_include_dir": 212, "cann_interfac": 213, "cann_librari": 212, "cann_opt": 204, "cann_path": 33, "cann_vers": 185, "canncommerci": 175, "cannexecutionprovid": 204, "cannot": [35, 39, 128, 136, 149, 150, 151, 152, 160, 164, 197, 219], "cap": [14, 29, 234], "cap100k": [29, 30], "capabl": [34, 38, 56, 87, 117, 119, 121, 123, 124, 125, 127, 130, 132, 135, 140, 148, 151, 152, 155, 164, 172], "capac": [46, 99, 111, 128, 160, 188, 219], "capacity_factor": [188, 219], "capit": [56, 117, 118, 121, 129, 151, 152, 231, 243], "captcha": [96, 157], "caption": [3, 37, 91, 96, 152, 157, 219, 243], "caption_column": [3, 219], "captionground": [96, 157], "captiongroundingvqa": [96, 157], "captioningvisu": [96, 157], "captiv": [57, 118], "captur": [57, 118, 181], "capturelogg": 219, "car": [188, 219], "carbon": 129, "card": [128, 201], "care": [45, 46, 50, 111, 121], "carlo": 155, "carri": 147, "carrion": 234, "cartoon": 151, "cascad": [67, 128], "case": [35, 39, 45, 51, 70, 74, 81, 110, 111, 112, 120, 123, 127, 128, 131, 135, 139, 142, 147, 150, 153, 154, 155, 158, 160, 161, 172, 180, 184, 212, 219, 249], "cashier": 241, "casper": [69, 130], "cast": [177, 219], "cat": [22, 37, 46, 53, 57, 60, 68, 90, 114, 118, 121, 129, 151, 170, 185, 188, 204, 207, 214, 219, 225], "categori": [52, 113, 121, 128], "caus": [45, 70, 113, 118, 128, 139, 142, 148, 150, 160, 164, 166, 249], "causal": [67, 99, 128, 160, 194, 214, 219], "causal_lm": [67, 128], "causallm": [59, 120], "cb": [68, 70, 129, 131], "cc": 194, "ccbench": [68, 70, 129, 131], "cchfjzgdpcmlqjhpk6qfck4twgmdyxmg__": 245, "ccl": [67, 128], "ccnl": [96, 157], "cd": [8, 13, 14, 22, 32, 33, 55, 64, 68, 95, 105, 116, 125, 129, 156, 166, 174, 175, 176, 178, 179, 180, 181, 184, 193, 196, 197, 212, 221, 224, 228, 230, 236, 239, 245, 249, 253, 255], "cdf": 214, "cdot": [71, 72, 73, 75, 76, 77, 78, 80, 81, 84, 132, 133, 134, 136, 137, 138, 139, 141, 142, 145], "cdot10": [51, 112], "ce": [62, 123], "ceil": [214, 219], "celsius": [60, 66, 121, 127], "center": [57, 67, 99, 118, 128, 154, 160, 219], "center_crop": 219, "center_rewards_coeffici": [92, 153], "centercrop": 219, "centric": [0, 35], "cerebra": [96, 157], "certain": [121, 123, 128, 132, 133, 134, 135, 150, 153], "ceval": [68, 70, 129, 131], "ceval_valid": [7, 20], "cf": 219, "cf1d67a6fd5ea1aa600c4df58e5b47da45f6bdbf": 224, "cffi": [185, 206, 209, 233], "cfg": 194, "cgroup": 14, "chain": [39, 87, 117, 128, 134, 140, 148, 155, 219], "challeng": [113, 250], "chanc": 219, "chang": [34, 39, 41, 70, 110, 111, 113, 117, 141, 147, 148, 150, 151, 152, 155, 158, 159, 160, 164, 203, 204, 219], "change_coordinate_fram": 214, "channel": [7, 11, 34, 48, 67, 70, 99, 109, 128, 131, 160, 214, 219], "chapter": 172, "char": [204, 213], "charact": [51, 96, 110, 112, 121, 123, 152, 157], "character": 113, "characterist": [132, 172], "charad": 29, "charm": [57, 118], "chart": [79, 117, 126, 140], "chartqa": [96, 157], "chartqa_digit_r1v_format": [96, 157], "chartqa_test": [68, 70, 129, 131], "chat": [8, 13, 21, 42, 58, 61, 67, 88, 90, 91, 92, 96, 119, 122, 128, 149, 151, 152, 153, 157, 179, 197, 210, 231, 237, 243], "chat_respons": [88, 149], "chat_sep": [53, 114], "chat_templ": [11, 42, 43, 194], "chatbot": 246, "chatcompletionresponsechoic": [86, 147], "chatglm2": [96, 157], "chatglm3": [96, 157], "chatglm4": [96, 157], "chatglm4v": [96, 157], "chatgpt": [70, 131], "chatmessag": [83, 86, 144, 147], "chatml": [49, 96, 110, 157], "chattempl": 43, "check": [36, 37, 38, 44, 48, 50, 52, 56, 67, 70, 82, 99, 105, 109, 110, 111, 113, 116, 117, 121, 122, 123, 125, 127, 128, 143, 147, 148, 149, 155, 157, 160, 166, 170, 219], "check_env": 197, "check_finish": [86, 147], "check_integr": 199, "check_min_vers": 219, "check_model": [70, 91, 131, 152], "check_output": 221, "checkout": [55, 116, 170, 174, 179, 180, 181, 224], "checkpoint": [3, 39, 40, 42, 43, 48, 53, 55, 56, 57, 62, 63, 67, 69, 91, 97, 99, 102, 103, 104, 105, 109, 114, 116, 117, 118, 123, 124, 128, 130, 152, 155, 158, 160, 163, 164, 165, 166, 178, 181, 184, 219, 225, 234, 244], "checkpoint_600": [70, 131], "checkpoint_config": 222, "checkpoint_dir": [67, 91, 128, 152], "checkpointing_step": [3, 219], "checkpoints_total_limit": 219, "cheek": [57, 118], "chenshawn": [79, 140], "chi2_seq": [81, 89, 142, 150], "chi2_token": [81, 89, 142, 150], "chid": [68, 70, 129, 131], "child": [57, 114, 118], "childhood": [57, 118], "china": [129, 131, 151, 197], "chines": [56, 96, 103, 117, 128, 157, 164], "chinese_traditionalcoig_pcexamfinancedoubanhuman_valuelogi_qaruozhibasegmentfaultwikiwikihowxhszhihu": [96, 157], "chinesealpacagroup": [96, 157], "chip": [55, 116, 185], "chip_typ": 14, "chmod": 14, "choic": [8, 16, 17, 21, 37, 53, 57, 86, 88, 90, 91, 114, 117, 118, 131, 132, 147, 149, 151, 152, 166, 188, 219, 231], "choos": [33, 35, 40, 45, 113, 124, 128, 130, 138, 151, 152, 153, 160, 166, 172, 194, 219], "chord": [63, 124], "chord_enable_phi_funct": [72, 133], "chord_mu_decay_step": [72, 133], "chord_mu_peak": [72, 133], "chord_mu_valley": [72, 133], "chord_mu_warmup_step": [72, 133], "chord_sft_dataset": [72, 133], "chord_sft_per_device_train_batch_s": [72, 133], "chore": [237, 246], "chosen": [7, 19, 92, 128, 153, 219, 249], "chrome": 121, "chunk": [57, 90, 91, 118, 151, 152, 214, 219], "chunked_prefil": 175, "chunked_prefill_s": 175, "chunkloss": 33, "ci": 221, "cifar": [188, 219], "cifar10": [188, 219], "cinepil": [96, 157], "ciou": 214, "circl": [52, 113], "circumst": 160, "cispo": [63, 67, 124, 128], "citi": [60, 66, 121, 127], "ckpt": [3, 67, 94, 97, 99, 128, 131, 160, 219], "ckpt_dir": [97, 158], "ckpts": [179, 180], "ckpts_dir": [179, 180], "cl": [9, 219], "cl1wvzg93bmxvywq2lmxsyw1hbwv0ys5uzxrclyoilcjdb25kaxrpb24ionsirgf0zuxlc3nuagfuijp7ikfxuzpfcg9jafrpbwuioje3mty0mzyymtf9fx1dfq__": 245, "clamp": [73, 134], "clamped_ratio": [73, 134], "clang": 218, "clarif": 37, "clariti": [134, 137, 138], "class": [11, 28, 35, 36, 37, 43, 46, 50, 52, 53, 60, 62, 83, 85, 86, 87, 88, 93, 95, 111, 113, 114, 120, 121, 123, 128, 144, 146, 147, 148, 149, 154, 156, 172, 173, 188, 204, 214, 215, 219], "class_correct": [188, 219], "class_replac": 39, "class_tot": [188, 219], "classes_path": 204, "classic": [57, 118, 138, 243], "classical_chinese_transl": [96, 157], "classif": [42, 67, 96, 99, 123, 124, 128, 149, 152, 157, 160, 166, 188, 219, 243], "classifi": [155, 160, 184, 219, 243, 244], "classnam": [39, 219], "clavariacea": 234, "clean": [22, 26, 83, 96, 131, 144, 157, 170, 236, 246], "clean_up_tokenization_spac": [53, 57, 114, 118], "cleaner": 219, "clear": [37, 39, 41, 42, 50, 56, 57, 90, 111, 113, 117, 118, 151, 155, 241], "cleariti": 35, "clevr": 52, "clevr_cogen_a_train": [52, 96, 113, 157], "clevrorm": [52, 113], "clevrpreprocessor": [52, 113], "cli": [7, 8, 13, 14, 15, 20, 21, 22, 23, 24, 25, 48, 79, 109, 140, 193, 194, 219, 237, 240, 245], "click": [60, 66, 121, 124, 125, 126, 127, 147, 222], "client": [21, 67, 88, 90, 91, 95, 127, 128, 149, 156, 179], "clientsess": [87, 148], "climb": 113, "clinical_knowledg": 200, "clinton": [96, 157], "clip": [0, 35, 42, 49, 50, 67, 78, 81, 84, 87, 89, 92, 96, 99, 110, 111, 128, 139, 142, 145, 148, 150, 153, 157, 160, 180, 206, 207, 224], "clip_grad_norm": 35, "clip_grad_norm_": 219, "clip_ratio": [70, 131], "clip_ratio_c": 178, "clip_ratio_high": [178, 180, 181], "clip_ratio_low": [178, 180, 181], "clipped_frac": [81, 89, 142, 150], "clipped_ratio": [89, 150], "cliprang": [67, 92, 128, 153], "cliptextmodel": 219, "cliptoken": 219, "clm": 219, "clock": [121, 127], "clone": [8, 13, 22, 32, 33, 55, 60, 61, 64, 67, 68, 91, 95, 105, 116, 121, 122, 125, 128, 129, 152, 156, 166, 174, 175, 178, 179, 181, 184, 193, 196, 197, 212, 221, 224, 228, 230, 236, 239, 245, 249, 255], "close": [40, 50, 57, 83, 111, 118, 123, 126, 131, 144, 152, 153, 159], "close_matmul_k_shift": 171, "closer": [50, 111, 128, 142], "cloth": [57, 118], "cloud": [7, 56, 66, 67, 117, 127, 128, 151], "cls": [61, 62, 67, 96, 99, 122, 123, 128, 157, 160], "cls_index": 219, "clue": [96, 157], "cluewsc": [68, 70, 129, 131], "cluster": [67, 109, 128, 154, 155, 160, 179, 180, 181, 234], "cmake": [193, 212, 221, 255], "cmake_build_typ": 212, "cmake_install_prefix": 212, "cmakedir": 221, "cmakefil": 249, "cmb": [67, 68, 70, 128, 129, 131], "cmd": 22, "cmmlu": [68, 70, 129, 131], "cmmlu_test": [7, 20], "cmnli": [68, 70, 96, 129, 131, 157], "cmrc": [68, 70, 129, 131], "cms": 194, "cmvn": 251, "cn": [2, 49, 53, 56, 57, 64, 67, 90, 91, 96, 105, 110, 114, 117, 118, 125, 128, 151, 152, 157, 166, 179, 181, 183, 184, 185, 206, 209, 227, 230, 233, 244, 248], "cncl": [67, 128], "cnrefcocorefcoco": [96, 157], "co": [9, 40, 160, 178, 179, 181, 219, 239, 243, 245, 256], "coach": 121, "coars": 34, "coat": [151, 237], "coco": [29, 30, 96, 157, 243], "coco2017": 30, "coco_2014_capt": [71, 96, 132, 157], "coco_v": [68, 70, 129, 131], "cocodataset": 243, "cocovqa": [96, 157], "code": [9, 28, 29, 34, 38, 41, 43, 44, 46, 51, 52, 56, 70, 83, 85, 86, 96, 110, 111, 113, 114, 117, 120, 122, 123, 126, 127, 128, 133, 134, 136, 140, 143, 144, 146, 147, 148, 150, 155, 156, 157, 160, 172, 173, 200, 219, 221, 231, 249], "code_alpaca_en": [96, 157], "code_format": [51, 112], "code_reward": [51, 85, 112, 146], "codealpaca": [96, 157], "codealpaca_20k": [96, 157], "codeexercis": [96, 157], "codefus": [96, 157], "codegeex2": [96, 157], "codegeex4": [96, 157], "codegen": 39, "codellama": [96, 157], "codeparrot": [96, 157], "codeqwen1": [96, 157], "coder": [96, 157], "coderandomreward": [85, 146], "codestr": [96, 157], "coef": [67, 92, 128, 131, 153], "coeff": [99, 160], "coeffici": [42, 67, 99, 110, 128, 132, 133, 134, 137, 138, 153, 160, 161], "cogag": [96, 157], "cogen": 52, "cognit": [56, 63, 67, 91, 96, 98, 102, 103, 105, 115, 117, 124, 128, 152, 157, 159, 163, 164, 166], "cognitivecomput": [96, 157], "cogvlm": [96, 157], "cogvlm2": [67, 96, 128, 157], "cohereforai": [96, 157], "coig": [96, 157], "col": 213, "cold": 237, "collaps": [81, 113, 128, 136, 142, 150, 160, 180], "collat": [46, 219], "collate_fn": [43, 53, 114, 219], "collect": [34, 38, 46, 93, 96, 147, 154, 157, 160, 204, 219, 250], "collector": 160, "college_biolog": 200, "college_chemistri": 200, "college_computer_sci": 200, "college_mathemat": 200, "college_medicin": 200, "college_phys": 200, "colloc": [70, 131], "coloc": [67, 86, 99, 100, 101, 128, 147, 160, 161, 162], "color": [52, 57, 113, 118, 151, 234], "colossalai": [96, 157], "column": [19, 60, 67, 79, 117, 121, 128, 140, 144, 146, 147, 148, 149, 150, 153, 219], "column_nam": 219, "columnparallellinear": [70, 131], "com": [8, 11, 13, 14, 22, 32, 33, 40, 48, 53, 55, 56, 57, 63, 64, 68, 69, 70, 75, 81, 87, 90, 91, 93, 94, 95, 97, 102, 105, 109, 114, 116, 117, 118, 124, 125, 128, 129, 130, 131, 133, 136, 140, 142, 148, 151, 152, 154, 155, 156, 158, 163, 166, 170, 174, 175, 178, 179, 181, 184, 193, 196, 197, 199, 200, 212, 219, 221, 224, 228, 230, 236, 239, 245, 248, 249, 255, 256], "combin": [28, 46, 50, 57, 111, 118, 121, 127, 128, 131, 132, 136, 142, 152, 154, 160, 166, 219], "come": [113, 123, 128, 134, 142, 150, 155, 219], "comet_ml": 219, "comfort": 246, "comm": [38, 48, 99, 109, 160], "comm_quant_scale_1": 214, "comm_quant_scale_2": 214, "comm_turn": 214, "comma": 160, "command": [38, 48, 96, 109, 114, 116, 117, 118, 121, 122, 123, 124, 126, 129, 140, 144, 147, 149, 150, 151, 152, 154, 155, 156, 157, 158, 161, 162, 163, 164, 172, 219, 221, 237], "commandlinepars": 213, "comment": [39, 219], "commit": [67, 128, 174, 179, 180, 181, 219], "commit_messag": 219, "commitid": [178, 180, 181], "commlib": 175, "common": [37, 40, 45, 96, 127, 128, 131, 147, 149, 155, 157], "common_util": 214, "communic": [35, 45, 46, 128, 160, 166, 172], "communiti": [14, 96, 111, 117, 124, 129, 157, 191, 219], "compar": [52, 113, 120, 121, 128, 134, 140, 142, 148, 152, 160, 162, 163, 172], "comparison": [117, 137, 138, 166], "compat": [37, 41, 44, 95, 114, 121, 127, 128, 144, 150, 151, 156, 157, 158, 160, 161, 162, 164, 187], "compens": 128, "competit": 94, "competition_math": [68, 95, 96, 129, 155, 156, 157], "compil": [187, 214, 219, 230, 237], "compilation_config": 181, "compile_custom_kernel": 221, "compiler_config": 214, "compiler_depend": [228, 249], "compilerconfig": 214, "complet": [21, 36, 37, 39, 43, 45, 46, 50, 52, 58, 60, 67, 74, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 99, 101, 117, 119, 121, 122, 124, 127, 128, 132, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 156, 158, 160, 161, 162, 164, 165, 166, 172, 204, 231, 240], "completion_length": [70, 113, 131], "completion_mask": [81, 142], "completion_token": 231, "completions1": [88, 149], "completions2": [88, 149], "completit": 52, "complex": [37, 39, 40, 111, 121, 123, 126, 128, 129, 134, 141, 163], "complianc": 219, "complic": [35, 131], "compon": [3, 36, 41, 46, 114, 119, 128, 158, 160], "compos": [4, 43, 188, 219], "comprehens": 163, "compress": 147, "comput": [22, 35, 38, 39, 43, 45, 46, 67, 83, 86, 90, 95, 99, 110, 111, 113, 117, 120, 121, 123, 127, 128, 132, 133, 134, 135, 136, 139, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 156, 159, 160, 161, 166, 172, 175, 194, 219, 228, 241, 243, 249, 256], "compute_acc_metr": [62, 123], "compute_accuraci": 7, "compute_cmvn_stat": 253, "compute_dream_and_update_lat": 219, "compute_dtyp": 7, "compute_environ": [9, 15], "compute_log_prob": 250, "compute_loss": [67, 128], "compute_metr": [219, 241], "compute_nlg_metr": [62, 123], "compute_scor": [79, 140, 178], "compute_score_math": [79, 140], "compute_snr": 219, "compute_train_step": 43, "computer_secur": 200, "computing_embed": 228, "compvi": 219, "con": 39, "concat": [7, 53, 114, 177], "concaten": [45, 121, 127, 160, 219], "concatenate_dataset": [67, 128], "concatenated_exampl": 219, "concentr": [57, 118, 132], "concept": [38, 121, 128], "conceptual_phys": 200, "concern": 219, "concis": [43, 56, 117, 148], "conclud": [50, 111], "concret": [131, 147], "concurr": [70, 126, 128, 131, 158, 170, 219], "conda": [2, 48, 55, 70, 109, 116, 131, 175, 178, 179, 196, 206, 209, 212, 218, 221, 223, 230, 233, 236, 239, 244, 252], "condit": [39, 50, 111, 142, 147, 155, 214, 219], "conduct": [31, 111, 113, 159], "conf": [5, 34, 48, 67, 109, 128, 219], "confid": 164, "config": [9, 27, 28, 29, 30, 31, 35, 36, 38, 39, 41, 42, 43, 46, 48, 53, 55, 61, 67, 68, 70, 83, 96, 97, 98, 99, 103, 105, 109, 114, 116, 122, 128, 129, 131, 144, 157, 158, 159, 160, 164, 166, 171, 172, 173, 174, 179, 184, 188, 193, 203, 210, 214, 219, 222, 243, 245], "config1": 9, "config_cl": [70, 131], "config_class": 36, "config_ev": [70, 131], "config_fil": [9, 15, 239, 240], "config_kwarg": 219, "config_manag": 240, "config_map": 219, "config_nam": [39, 219, 222], "config_overrid": 219, "config_path": [36, 43, 222], "configur": [34, 37, 38, 41, 44, 53, 113, 114, 116, 117, 118, 119, 120, 127, 128, 129, 144, 150, 152, 154, 162, 181, 188, 204, 219, 221, 234, 250], "configuration_qwen3_vl_mo": 46, "confirm": 37, "conflict": [39, 130, 139, 172, 209], "conform": [96, 128, 157], "confus": 35, "congliu": [96, 157], "conjunct": [128, 154], "connect": [55, 57, 88, 97, 116, 118, 128, 149, 158, 160, 172, 179, 180, 181], "consecut": [121, 127, 160], "conserv": [138, 199], "consid": [35, 44, 50, 70, 110, 111, 128, 131, 144, 155], "consider": 46, "consist": [51, 53, 112, 113, 114, 117, 121, 123, 126, 128, 132, 136, 138, 142, 150, 153], "consol": [174, 178], "consolid": 160, "consreftintervent": [67, 128], "const": [29, 204], "constant": [3, 11, 24, 42, 53, 99, 114, 128, 133, 134, 160, 219], "constant_with_warmup": 219, "constexpr": 204, "constrain": [38, 128, 142], "constraint": [40, 50, 110, 111, 128], "construct": [31, 37, 38, 128, 147, 149, 215], "constructed_convers": 37, "constructor": 156, "consult": 147, "consum": [38, 43, 44, 155, 160, 166], "consumpt": [45, 124, 128, 152, 158, 160], "contact": 34, "contain": [35, 37, 39, 44, 48, 51, 109, 112, 113, 114, 117, 120, 121, 123, 124, 127, 128, 129, 135, 146, 147, 149, 152, 156, 160, 163, 170, 176, 185, 219, 221, 230, 237], "container_nam": 14, "content": [11, 19, 21, 34, 37, 47, 49, 52, 53, 56, 57, 59, 60, 62, 66, 67, 83, 86, 87, 88, 90, 91, 95, 110, 113, 114, 117, 118, 120, 121, 122, 123, 127, 128, 135, 144, 147, 148, 149, 151, 152, 156, 159, 160, 170, 172, 173, 191, 194, 219, 231, 243, 246], "content_match": [52, 113], "content_split": 42, "content_tag": 19, "context": [38, 42, 43, 53, 62, 67, 96, 97, 99, 114, 123, 128, 132, 141, 144, 147, 149, 152, 157, 158, 160, 161, 162, 166, 172, 173, 214, 219], "context_dim": [58, 119], "context_lay": 214, "context_length": 194, "context_manag": [83, 144], "context_parallel_degre": 240, "context_parallel_s": 43, "context_typ": [62, 123], "contextlib": 219, "contextmanag": [83, 144, 219], "contextmanga": 83, "contexttyp": [62, 123], "contigu": [40, 45, 46, 128, 214], "contiguous_format": 219, "contiguous_gradi": [9, 48, 109, 188, 219], "continu": [42, 50, 52, 57, 90, 91, 111, 113, 117, 118, 126, 130, 135, 147, 151, 152, 155, 214], "contrast": [134, 137, 138, 141, 153], "contrib": 214, "contribut": [46, 121, 133, 134, 141, 142], "control": [31, 35, 53, 62, 97, 114, 116, 121, 123, 124, 128, 132, 133, 135, 137, 138, 139, 141, 145, 148, 158, 159, 160, 161, 163, 241, 250], "conv": [47, 256], "conv1": [188, 219], "conv2": [188, 219], "conv2d": [188, 219], "conv3d": [57, 64, 67, 118, 125, 128], "conveni": [114, 118, 121, 122, 172, 240], "convent": 37, "converg": [40, 111, 113], "convers": [19, 40, 42, 53, 56, 60, 83, 86, 87, 91, 110, 114, 117, 121, 128, 144, 147, 148, 151, 152, 158, 160, 162, 163, 166, 188, 219, 243], "convert": [7, 37, 39, 42, 67, 70, 99, 110, 114, 118, 121, 127, 128, 148, 154, 158, 160, 164, 166, 188, 204, 214, 219, 256], "convert_hf_to_gguf": 194, "convert_tokens_to_id": 246, "converter_hf_to_mcor": 179, "convolut": [188, 214, 219], "cookbook": [60, 67, 121, 128], "coordin": [114, 118, 121, 127, 128], "copa": [68, 70, 129, 131], "copi": [29, 30, 39, 40, 43, 44, 53, 86, 114, 119, 147, 172, 219], "copy_": [58, 119], "copy_memory_": [214, 217], "copy_to": 219, "copyright": 219, "coral": 234, "corda_config": [70, 131], "core": [34, 45, 70, 99, 105, 120, 121, 131, 132, 133, 134, 138, 139, 142, 147, 150, 160, 166, 172, 173, 181, 214], "core_attn": [99, 160], "core_r0": [105, 166], "core_v0": [55, 116, 174], "coreml": 256, "corr": [81, 142], "correct": [37, 43, 44, 46, 50, 52, 67, 81, 87, 89, 110, 111, 112, 113, 116, 123, 128, 129, 132, 134, 136, 140, 147, 148, 150, 151, 152, 155, 159, 160, 188, 219], "correct_count": 219, "correct_pr": 219, "correl": [110, 130], "correspond": [36, 42, 46, 51, 52, 112, 113, 114, 121, 122, 123, 126, 127, 128, 130, 137, 138, 147, 148, 149, 151, 152, 155, 157, 158, 160, 166, 214, 219], "corrupt": [128, 131, 160], "cos": [39, 46, 67, 128, 214], "cosin": [8, 9, 17, 24, 42, 49, 56, 67, 99, 117, 128, 160, 219, 222, 234], "cosine_with_min_lr": [67, 70, 128, 131], "cosine_with_restart": 219, "cosmet": 160, "cosmopedia": [96, 157], "cost": [123, 128, 155, 160, 172, 214], "cot": [94, 96, 103, 117, 155, 157, 164, 180], "cot_zh": [96, 157], "could": [41, 50, 111, 148, 219, 237, 249], "coundown": 50, "coundownorm": 50, "coundowntaskpreprocessor": [50, 111], "count": [46, 52, 67, 113, 128, 131, 147, 157, 160, 162, 179, 180, 181, 188, 214, 219, 234], "countdown": [50, 96, 111, 157], "countdownorm": [50, 111], "counter": 160, "countri": 256, "cours": [122, 219], "cout": 204, "cover": [56, 71, 117, 124, 132, 140, 143, 152, 162, 164], "coyo": [96, 157], "cozi": [57, 118], "cp": [43, 63, 99, 100, 101, 105, 124, 160, 161, 162, 166, 240], "cp311": [14, 230], "cp_size": 43, "cpfs_0": 222, "cpo": [63, 67, 91, 124, 128, 152], "cpp": [0, 70, 131, 194, 256], "cpp_ext": [70, 105, 131, 166], "cpt": [55, 56, 63, 67, 104, 105, 116, 117, 124, 128, 165, 166], "cpu": [2, 5, 7, 9, 23, 28, 34, 36, 42, 44, 48, 55, 63, 64, 67, 89, 93, 97, 98, 99, 100, 102, 103, 109, 116, 124, 125, 128, 150, 154, 158, 159, 160, 161, 163, 164, 172, 173, 174, 177, 181, 185, 190, 194, 206, 209, 212, 213, 214, 218, 219, 221, 224, 227, 230, 233, 236, 239, 241, 244, 246, 248, 252, 255, 256], "cpu_adagrad": 187, "cpu_adam": 187, "cpu_affinity_conf": 181, "cpu_antiquantoffset": 214, "cpu_antiquantscal": 214, "cpu_lion": 187, "cpu_model": 214, "cpu_offload": [188, 219], "cpu_weight": 214, "cpu_weight1": 214, "cpu_weight2": 214, "cpu_x": 214, "cpu_x1": 214, "cpu_x2": 214, "cpu_x2_t_29": 214, "cpuexecutionprovid": 204, "cqia": [96, 157], "cr": [64, 70, 105, 125, 131, 166], "creat": [2, 21, 34, 38, 43, 44, 46, 50, 55, 56, 57, 66, 67, 88, 90, 91, 96, 99, 111, 113, 114, 116, 117, 118, 119, 123, 127, 128, 130, 149, 151, 152, 153, 157, 158, 159, 160, 164, 175, 178, 188, 191, 194, 196, 206, 209, 212, 215, 219, 221, 224, 230, 231, 233, 234, 236, 239, 244, 252], "create_custom_optim": [62, 123], "create_model_and_transform": 207, "create_model_card": 219, "create_moe_param_group": [188, 219], "create_new_adapt": [7, 18], "create_optimizer_param_group": [97, 158], "create_patch_from_extern": 39, "create_profil": 43, "create_repo": 219, "createcannprovideropt": 204, "createcpu": 204, "createtensor": 204, "creation": [38, 123, 219], "creativeml": 219, "creatur": 3, "crib": [57, 118], "criteria": 149, "criterion": [188, 219], "critic": [41, 70, 131, 134, 141, 180, 199, 250], "critic_warmup": 174, "crop": [67, 128, 140, 219], "crop_mod": 234, "crop_pct": 234, "cross": [7, 57, 99, 110, 118, 120, 123, 128, 160, 166, 188, 219, 256], "cross_entropi": 39, "cross_entropy_loss_fus": [56, 57, 70, 98, 102, 103, 104, 105, 117, 118, 131, 159, 163, 164, 165, 166], "crossentropyloss": [43, 188, 219], "crosslab": 219, "crowsonkb": 224, "crucial": [123, 134, 156, 166], "csl": [68, 70, 129, 131], "csrc": [70, 131], "csv": [56, 60, 67, 68, 117, 121, 128, 129, 177, 207, 210, 219], "ctc": 253, "ctrl": [88, 149, 210, 219, 231], "ctx": [83, 194], "ctx_config": [83, 144], "ctx_name": [83, 144], "cu": [42, 45], "cu129": [105, 166], "cu_seq_lens_k": 46, "cu_seq_lens_q": [45, 46], "cu_seqlen": 46, "cube": [52, 177], "cuda": [7, 32, 36, 42, 57, 58, 64, 67, 69, 70, 97, 99, 105, 118, 119, 125, 128, 130, 131, 158, 160, 166, 181, 187, 191, 196, 207, 213, 215, 219, 224, 256], "cuda12": [64, 70, 105, 125, 131, 166], "cuda129": 99, "cuda_12": 22, "cuda_ext": [70, 105, 131, 166], "cuda_visible_devic": [7, 9, 21, 24, 48, 50, 51, 52, 53, 56, 57, 58, 63, 68, 71, 79, 83, 88, 89, 90, 91, 98, 102, 103, 104, 105, 109, 111, 112, 113, 114, 117, 118, 119, 124, 129, 132, 140, 144, 149, 150, 151, 152, 159, 163, 164, 165, 166], "cudagraph": 181, "cudagraph_capture_s": 181, "cudagraph_mod": 181, "cuh": [70, 131], "cumsum": [28, 46, 214], "cumul": [46, 128, 153], "curios": [57, 118], "curious": [57, 118, 237], "curl": [90, 91, 151, 152, 231], "current": [31, 38, 39, 40, 41, 42, 46, 47, 66, 86, 110, 112, 120, 121, 123, 125, 126, 127, 128, 129, 132, 133, 135, 136, 142, 144, 145, 146, 147, 148, 150, 154, 155, 156, 158, 160, 162, 163, 164, 165, 172, 179, 180, 181, 184, 201, 219, 228, 234], "current_datetime_hostnam": 219, "current_devic": [206, 209, 233, 252], "current_hidden_st": 28, "current_ip": [179, 180, 181], "current_logp": [89, 150], "current_policy_model": [89, 150], "current_st": 28, "current_turn": [86, 147], "curv": [112, 113], "custom": [36, 39, 42, 46, 53, 62, 67, 70, 95, 109, 110, 111, 113, 114, 117, 118, 120, 124, 128, 143, 147, 152, 153, 154, 158, 160, 166, 194, 219, 241], "custom_all_reduc": [70, 131], "custom_attr": 39, "custom_cl": 178, "custom_cli": 179, "custom_ctx": [83, 144], "custom_dataset_info": [60, 70, 121, 131], "custom_env": [83, 144, 222], "custom_eval_config": [70, 131], "custom_loss": [62, 123], "custom_loss_func": [62, 123], "custom_metr": [62, 123], "custom_ocr": 37, "custom_op_exec": 214, "custom_output": 214, "custom_preprocess": [62, 123], "custom_reward_funct": 178, "customapimodel": [58, 70, 119, 131], "customcallback": [62, 123], "customoptim": [62, 123], "custompreprocessor": [60, 121], "customprm": [95, 156], "customrlhfdataset": 178, "customschedul": [62, 123], "customtempl": 43, "customtrainingargu": 43, "cute": [3, 41, 57, 118, 151, 225], "cutoff_len": [7, 8, 17, 20, 24], "cv": 213, "cv2": 213, "cxx": [193, 255], "cxx11_abi": 218, "cyan": 52, "cylind": 52, "cython": 185, "d50d76daa670286dd6cacf3bcd80b5e4823fc8e1": 224, "d62da4950573d7a4b7ef2362337952e7ab59e78d": 178, "d_": 178, "d_jsd": [71, 132], "da971c37640de20f97b4d774e77e6f8d5c00b40a": 11, "damo": [96, 157], "damo_nlp": [96, 157], "dao": [105, 166], "dapo": [56, 63, 67, 87, 96, 117, 124, 128, 148, 157, 172, 173, 174, 178, 179, 181], "dapo_math_17k": 178, "dapo_qwen3_vl_30b_fsdp2_npu": 180, "dark": [57, 118], "dashboard": [9, 179, 180, 181], "dashscop": [95, 156], "daslab": [96, 157], "data": [3, 7, 9, 11, 14, 19, 23, 25, 27, 29, 30, 37, 38, 45, 46, 47, 53, 56, 57, 58, 60, 63, 66, 67, 68, 70, 75, 79, 88, 90, 91, 93, 95, 96, 98, 99, 102, 103, 105, 110, 113, 114, 118, 119, 120, 121, 124, 127, 129, 132, 135, 136, 140, 142, 144, 145, 146, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 166, 174, 178, 179, 180, 184, 188, 194, 197, 201, 204, 207, 214, 219, 222, 234, 250, 253], "data_0": [79, 140], "data_aishel": 253, "data_arg": [70, 131, 219, 222], "data_col": [46, 219], "data_dict": [83, 86, 144, 147], "data_dir": 219, "data_fil": 219, "data_indic": 214, "data_info": 25, "data_iter": [43, 98, 159], "data_max": 214, "data_min": 214, "data_parallel_mod": [27, 35, 43], "data_parallel_replicate_degre": 240, "data_parallel_replicate_s": 43, "data_parallel_s": 43, "data_parallel_shard_degre": 240, "data_parallel_shard_s": 43, "data_path": [37, 43, 70, 131], "data_preprocess": [170, 174, 180], "data_ptr": 219, "data_quant_scal": 214, "data_quant_zero_point": 214, "data_root": 178, "data_se": [67, 128], "data_shared_file_system": 7, "data_sourc": [79, 140], "data_thinklite_reasoning_acc": [79, 140], "data_transform": [43, 46], "data_typ": 42, "data_upd": 214, "data_v0": [79, 140], "data_var": 214, "data_x": 214, "dataargu": 43, "databas": 148, "databrick": [12, 96, 157], "dataclass": [11, 43, 219], "datacollatorwithpack": 43, "datacollatorwithpad": [43, 219], "datacollatorwithpositionid": 43, "datacomp": 207, "dataengin": [96, 157], "dataformat": 219, "datafram": 219, "dataload": [42, 53, 67, 93, 99, 114, 128, 154, 160, 172, 173, 188, 219], "dataloader_batch_s": 43, "dataloader_num_work": [8, 48, 50, 51, 52, 53, 56, 57, 58, 63, 67, 70, 102, 103, 104, 105, 109, 111, 112, 113, 114, 117, 118, 119, 124, 128, 131, 163, 164, 165, 166, 219], "dataloader_typ": [30, 42], "dataparallelppoactor": [172, 173], "dataproto": [172, 173], "dataset": [7, 8, 9, 16, 17, 20, 21, 24, 37, 42, 48, 50, 51, 52, 53, 55, 56, 57, 58, 60, 62, 63, 65, 67, 68, 71, 79, 82, 89, 91, 93, 95, 96, 98, 99, 102, 103, 104, 105, 109, 112, 114, 116, 117, 118, 119, 122, 123, 124, 126, 128, 130, 132, 133, 140, 143, 144, 146, 148, 149, 150, 151, 152, 154, 155, 156, 159, 160, 161, 163, 164, 165, 166, 170, 178, 179, 180, 181, 184, 188, 209, 210, 219, 234, 240, 241, 243, 249], "dataset1": [67, 128], "dataset2": [67, 128], "dataset_arg": [70, 131, 219], "dataset_column": 219, "dataset_config_nam": 219, "dataset_dir": [7, 60, 121], "dataset_id": [60, 67, 121, 128], "dataset_id_or_path": [70, 128, 131], "dataset_info": [7, 19, 79, 140], "dataset_map": [60, 121], "dataset_meta": [60, 121], "dataset_nam": [3, 19, 43, 60, 121, 219], "dataset_name_map": 219, "dataset_num_proc": [48, 51, 53, 56, 57, 58, 70, 102, 103, 104, 105, 109, 112, 114, 117, 118, 119, 131, 163, 164, 165, 166], "dataset_path": [56, 60, 63, 67, 70, 91, 117, 121, 124, 128, 131, 152], "dataset_path1": [60, 67, 121, 128], "dataset_path2": [60, 67, 121, 128], "dataset_shuffl": [67, 70, 99, 128, 131, 160], "dataset_stream": 219, "dataset_tag": 219, "datasetload": [60, 121], "datasetmeta": [50, 52, 60, 111, 113, 121], "datasets_typ": [30, 42, 43], "datatrainingargu": 219, "datatyp": [188, 219], "date": [178, 204], "datefmt": 219, "datset": 42, "davinci": [14, 230], "davinci0": [14, 15, 193, 230], "davinci1": [14, 15, 230], "davinci10": 230, "davinci11": 230, "davinci12": 230, "davinci13": 230, "davinci14": 230, "davinci15": 230, "davinci2": [14, 230], "davinci3": [14, 230], "davinci4": [14, 230], "davinci5": [14, 230], "davinci6": [14, 230], "davinci7": [14, 183, 230], "davinci8": 230, "davinci9": 230, "davinci_manag": [14, 15, 183, 193, 230], "day": [35, 124, 231, 237, 241, 243, 246], "day0": 63, "db": [172, 173], "dbrx": [96, 157], "dcmake_build_typ": 193, "dcmi": [14, 183, 193], "dcp_checkpoint": 44, "dcp_checkpoint_path": 44, "dd": 19, "ddp": [9, 15, 42, 43, 55, 63, 67, 90, 91, 99, 116, 124, 128, 151, 152, 160, 240], "ddp_find_unused_paramet": [70, 131], "ddp_model": 215, "ddp_timeout": [8, 17, 20, 24], "ddpmschedul": 219, "deactiv": 158, "deactivate_adapt": [97, 158], "deadlock": 184, "deb": 14, "debian": [32, 33], "debug": [7, 9, 15, 39, 42, 53, 67, 68, 83, 91, 102, 114, 128, 129, 144, 152, 153, 159, 163, 172, 191, 199, 203, 210, 214, 219], "debug_model": 240, "debugg": [98, 159], "decay": [42, 67, 99, 128, 133, 139, 160, 219], "decenc": 241, "decent": 241, "decid": [45, 147], "decis": 141, "declar": [5, 39], "declin": 150, "decod": [7, 35, 42, 46, 80, 90, 99, 128, 141, 151, 160, 172, 173, 177, 181, 191, 221, 246, 256], "decoder_first_pipeline_num_lay": [103, 164], "decoder_input": [98, 159], "decompos": [7, 18, 128, 154], "decomposit": [128, 154], "decor": [37, 39, 55, 116, 154, 185, 206, 209, 230, 233], "decord": [53, 57, 96, 114, 118, 157], "decoupl": [74, 87, 135, 148, 180], "decreas": [111, 116, 139, 148, 152], "dedic": [41, 150], "deep": [39, 134], "deep_ep": [175, 230], "deep_ep_cpp": 230, "deepctrl": [96, 157], "deepep": [99, 160, 175], "deepep_mod": 175, "deeper": 237, "deepey": [82, 86, 143, 147], "deepli": 148, "deepresearch": [96, 157], "deepscal": 179, "deepseek": [6, 50, 52, 56, 63, 67, 81, 87, 91, 94, 95, 96, 99, 105, 111, 113, 117, 124, 128, 142, 148, 152, 155, 156, 157, 160, 166, 177], "deepseek_v3_megatron_npu": 174, "deepseekmath": [94, 155], "deepseekmo": 42, "deepseekr1": 177, "deepseekv3": 174, "deepspe": [0, 4, 8, 15, 18, 22, 48, 50, 51, 52, 53, 56, 57, 58, 63, 64, 67, 87, 91, 101, 105, 109, 111, 112, 113, 114, 117, 118, 119, 124, 125, 128, 148, 152, 162, 166, 201, 217, 221, 222, 252], "deepspeed_config": 9, "deepspeed_config_or_typ": [48, 109], "deepspeed_elast": [48, 67, 109, 128], "deepspeed_multinode_launch": 9, "deepspeed_not_impl": 187, "deepspeed_plugin": 219, "deepspeed_train": 222, "deepspeed_zero": 222, "deepspeed_zero2": 222, "deepspeed_zero3": 222, "deepspeed_zero3_cpuoffload": 222, "deepspeed_zero_init_disabled_context_manag": 219, "deepspeedai": 48, "deepspeedengin": [188, 219], "deepstack_image_emb": 46, "deer": [188, 219], "def": [11, 28, 36, 37, 38, 39, 43, 46, 47, 50, 52, 53, 60, 62, 83, 85, 86, 87, 88, 93, 95, 98, 111, 113, 114, 121, 123, 144, 146, 147, 148, 149, 154, 156, 159, 172, 173, 188, 204, 207, 214, 215, 219, 231, 241], "default": [11, 34, 35, 39, 42, 43, 44, 50, 52, 53, 60, 61, 67, 68, 83, 88, 91, 93, 96, 97, 109, 110, 111, 113, 114, 117, 120, 121, 122, 123, 124, 128, 129, 130, 132, 135, 136, 137, 138, 139, 142, 144, 147, 148, 149, 150, 152, 153, 154, 157, 158, 160, 161, 166, 172, 180, 181, 188, 194, 203, 210, 214, 215, 219, 222, 228, 231, 241], "default3_5m": [96, 157], "default_data_col": 219, "default_factori": 43, "default_local_dir": 178, "default_pg": 214, "default_sh": [179, 180, 181], "default_system": [7, 53, 60, 67, 91, 114, 121, 128, 152], "defaultaddit": [96, 157], "defaultcl": [96, 157], "defaultclean": [96, 157], "defaultembrerank": [96, 157], "defaulten": [96, 157], "defaultgrpo": [96, 157], "defaulthuman_handwritehuman_handwrite_printsynthetic_handwritesmal": [96, 157], "defaultmask": 214, "defaultmini": [96, 157], "defaultpositivegeneratereg": [96, 157], "defaultqwen3empty_think": [96, 157], "defaultrmplugin": [88, 149], "defaultsubset": [96, 157], "defaultv3_formatzh_38k_format": [96, 157], "defin": [35, 50, 111, 113, 121, 122, 123, 128, 129, 132, 144, 147, 148, 149, 150, 154, 172, 188, 194, 215, 219, 222], "definit": [35, 37, 39, 123, 128, 133, 172], "deform": [214, 225], "deformable_group": 214, "deformableconv2d": 214, "degrad": [128, 142, 155], "degre": [35, 38, 43, 52, 113, 128, 142, 150, 160], "del": 219, "delay": [99, 160], "deleg": 41, "delet": [67, 99, 121, 128, 147, 158, 160, 199], "deliber": [57, 118], "delic": [57, 118], "delight": [57, 118, 246], "delta": [57, 67, 81, 90, 91, 99, 118, 128, 142, 151, 152, 160, 164, 214], "deltat": [67, 128], "demeanor": [57, 118], "demo": [57, 67, 70, 90, 118, 128, 131, 151, 210], "demo_gsm8k": 210, "demo_gsm8k_base_gen": 210, "demo_gsm8k_chat_gen": 210, "demo_math": 210, "demo_math_base_gen": 210, "demo_math_chat_gen": 210, "demonstr": [46, 117, 121, 123, 130, 141, 151, 152, 156, 165], "demystifi": [81, 87, 142, 148], "denomin": 110, "denot": [38, 128, 136, 160], "dens": [38, 96, 105, 157, 160, 166, 181, 237], "dep": [22, 69, 130, 175, 224], "depend": [26, 32, 33, 39, 114, 116, 117, 125, 128, 130, 131, 132, 150, 155, 157, 159, 160, 166, 170, 172, 175, 187, 206, 209, 219, 221, 233], "depict": [57, 118, 151], "deploy": [55, 58, 67, 79, 87, 88, 89, 90, 91, 109, 110, 111, 113, 124, 125, 126, 132, 140, 148, 150, 160, 164, 196, 201], "deprec": [35, 219, 249], "depth": [8, 13, 22, 160, 170, 174, 214, 221, 230], "deq_scale1": 214, "deq_scale2": 214, "deqscal": 214, "deqscale1": 214, "deqscale2": 214, "dequant_scal": 214, "dequant_scale1": 214, "dequant_scale2": 214, "dequantscale1": 214, "dequantscale2": 214, "derek": [96, 157], "deriv": [35, 121, 219], "desc": 219, "descend": [7, 18, 214], "descent": [89, 150], "describ": [37, 57, 90, 114, 116, 118, 121, 128, 132, 133, 151, 152, 153, 154, 160, 165, 197, 219], "descript": [19, 37, 39, 42, 44, 60, 66, 113, 120, 121, 126, 127, 128, 131, 132, 139, 142, 160, 161, 162, 172, 174, 188, 213, 219, 221], "design": [3, 36, 56, 117, 127, 128, 135, 137, 143, 146, 151, 152, 160, 194, 246], "desir": [67, 92, 99, 128, 153, 154, 160], "desktop": [60, 66, 121, 127], "destabil": 142, "det": 214, "detach": [46, 73, 75, 84, 134, 136, 145, 219], "detail": [3, 32, 33, 36, 37, 39, 43, 45, 57, 70, 109, 111, 112, 114, 116, 117, 118, 121, 123, 128, 129, 131, 144, 145, 147, 150, 151, 152, 155, 160, 163, 166, 172, 175, 181, 188, 219, 234, 249], "detect": [91, 96, 121, 128, 148, 150, 152, 157, 160, 249], "determin": [42, 46, 67, 83, 86, 114, 120, 122, 123, 128, 131, 140, 141, 144, 146, 147, 148, 160], "determinist": [42, 160], "dev": [14, 15, 22, 48, 71, 96, 109, 132, 157, 178, 180, 181, 183, 185, 187, 193, 224, 230], "dev0": [96, 157, 219, 233, 252], "dev20250310": 236, "devel": [14, 185], "develop": [14, 22, 56, 57, 91, 105, 110, 117, 118, 121, 123, 149, 152, 154, 155, 166, 199], "deviat": [111, 113, 128, 135, 137, 138, 150, 153, 160], "devic": [9, 14, 15, 28, 35, 36, 42, 43, 46, 48, 53, 55, 58, 63, 67, 70, 89, 90, 91, 93, 99, 102, 109, 114, 116, 119, 120, 124, 128, 133, 149, 150, 151, 152, 154, 158, 160, 163, 174, 175, 177, 178, 179, 180, 181, 183, 188, 191, 193, 194, 197, 199, 200, 206, 207, 209, 214, 215, 219, 230, 231, 233, 234, 237, 241, 243, 244, 246, 250, 252], "device_count": [55, 116, 179, 180, 181, 215], "device_group": [93, 154], "device_id": [194, 204, 215], "device_map": [7, 53, 57, 58, 70, 90, 114, 118, 119, 128, 131, 151, 191, 210, 222, 241, 243, 246], "device_nam": [188, 214, 219, 228], "device_typ": 197, "devicemesh": 43, "devmm_svm": [14, 15, 183, 193], "devop": 193, "devstral": [96, 157], "dfrac": [74, 135], "dft": [67, 99, 128, 160], "dggml_cann": 193, "dh": 214, "diagnost": [128, 160], "diagram": [36, 207], "dialog": [96, 149, 157], "dialogu": [96, 122, 123, 144, 147, 151, 152, 157], "dialogvisu": [96, 157], "dict": [7, 11, 35, 37, 42, 43, 50, 52, 53, 60, 62, 67, 83, 86, 97, 111, 113, 114, 121, 123, 144, 147, 158, 172, 173, 179, 219], "dictionari": [42, 123, 127, 128, 150, 158, 188, 219], "did": [121, 150, 155, 219], "didn": [60, 121, 237, 241], "diff": [39, 103], "differ": [34, 35, 36, 37, 40, 45, 46, 50, 51, 52, 70, 89, 110, 112, 113, 114, 118, 119, 120, 121, 123, 124, 127, 128, 130, 132, 136, 139, 142, 144, 145, 146, 150, 151, 152, 153, 154, 156, 157, 158, 160, 161, 164, 194, 209], "difficult": [39, 121, 131, 135], "difficulti": [153, 172], "diffstarvisual_story_tel": [96, 157], "diffus": [0, 3, 31, 42, 97, 158, 217, 225], "diffusionpipelin": [2, 3, 219], "digitallearninggmbh": [96, 157], "dilat": 214, "dilemma": 139, "dim": [35, 38, 46, 53, 58, 114, 119, 207, 214, 219], "dimens": [38, 40, 46, 114, 119, 145, 219], "dimension": 43, "dimension_count": 194, "dingtalk": [67, 128], "diou": 214, "dioxid": 129, "dir": [39, 42, 44, 48, 56, 60, 67, 69, 70, 91, 97, 99, 105, 109, 117, 121, 128, 130, 131, 160, 166, 178, 179, 197, 199, 219, 222, 230, 245, 249], "direct": [36, 37, 39, 40, 41, 46, 57, 67, 111, 113, 117, 118, 119, 121, 122, 123, 126, 128, 129, 132, 137, 138, 142, 144, 147, 149, 150, 151, 152, 159, 160, 164, 172, 214], "directori": [29, 31, 33, 36, 39, 43, 47, 48, 70, 97, 109, 117, 119, 126, 128, 130, 150, 152, 156, 158, 160, 166, 172, 176, 178, 213, 219, 237], "direftintervent": [67, 128], "disabl": [7, 34, 45, 67, 105, 124, 128, 142, 150, 152, 160, 166, 173, 180, 184, 219, 250], "disable_custom_all_reduc": [70, 131], "disable_gradient_checkpoint": [7, 222], "disable_shuffl": 7, "disable_version_check": 7, "disast": 155, "disc": [96, 157], "discard": [42, 128, 134, 141, 142, 147, 148, 160], "discopop": [67, 92, 128, 153], "discord": [67, 128], "discount": 153, "discoveri": [57, 118], "discret": [173, 250], "discuss": [35, 111, 117, 155, 219], "disk": [47, 128, 131, 160, 166], "dispatch": [40, 41, 93, 99, 154, 160], "display": [126, 204], "disrupt": 155, "dist": [99, 103, 105, 160, 164, 166, 207, 214, 215], "dist_in22k_ft_in1k": 234, "distanc": 110, "distbackenderror": [70, 131], "distil": [56, 67, 93, 95, 96, 100, 103, 117, 121, 128, 154, 155, 156, 157, 161, 164], "distill_dataset": [56, 117], "distinct": [51, 52, 112, 219], "distinguish": [35, 37, 114, 132, 135, 146, 153, 172], "distrib": [99, 160], "distrib_id": 22, "distrib_releas": 22, "distribut": [0, 9, 37, 38, 39, 43, 44, 45, 46, 70, 99, 105, 116, 124, 128, 132, 136, 141, 142, 150, 152, 153, 154, 155, 160, 161, 166, 172, 188, 213, 214, 215, 219, 222], "distributed_c10d": 214, "distributed_train": 234, "distributed_typ": [9, 15], "distributeddataparallel": [9, 215], "distributionstrategi": [48, 109], "dit": [31, 32], "div": [50, 111], "diverg": [89, 99, 111, 113, 138, 141, 150, 153, 155, 160, 161], "divers": [89, 143, 150, 155], "divid": [28, 38, 50, 111, 119, 128, 145, 156, 160, 172, 219, 222], "divis": [50, 111, 128, 150, 160], "dlc": [56, 91, 117, 152], "dlrover": [48, 67, 109, 128], "dn": 92, "do": [35, 37, 38, 39, 40, 42, 46, 56, 57, 66, 70, 94, 113, 117, 118, 121, 123, 126, 127, 128, 134, 139, 149, 151, 155, 158, 160, 166, 179, 180, 181, 194, 219, 241, 246, 256], "do_ev": 219, "do_predict": 20, "do_res": [53, 57, 114, 118], "do_sampl": [7, 57, 118, 210, 243, 246], "do_train": [8, 9, 17, 18, 24, 219], "doc": [9, 31, 96, 97, 110, 128, 157, 158, 160, 177, 178, 181, 219], "docci": [96, 157], "docker": [4, 15, 64, 70, 125, 131, 176, 183, 185, 193, 197, 218, 250], "docker_buildkit": 197, "docker_imag": 14, "dockerfil": [14, 34, 175, 179, 193, 197, 230, 250], "dockerfile_aarch64_ascend": 197, "dockerfile_build_guid": 175, "docowl2": [96, 157], "docqa": [96, 157], "docqueri": 243, "docstr": [37, 47], "document": [19, 33, 34, 37, 39, 40, 47, 57, 59, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 128, 132, 133, 134, 135, 140, 141, 142, 144, 147, 148, 150, 151, 152, 153, 154, 157, 158, 160, 161, 162, 163, 164, 165, 166, 175, 181, 219], "docvqa_test": [68, 70, 129, 131], "docvqa_v": [68, 70, 129, 131], "doe": [35, 37, 38, 39, 40, 41, 46, 50, 70, 111, 117, 121, 122, 126, 127, 128, 129, 130, 134, 145, 146, 147, 149, 150, 152, 153, 155, 159, 160, 163, 164, 172, 204, 219], "doesn": [50, 51, 111, 112, 114, 128, 219], "dog": [60, 121, 128, 188, 207, 219, 228], "doing": [62, 123, 219], "dolli": [96, 157], "dolma": [96, 157], "dolphin": [96, 157], "domain": [96, 155, 157, 166, 194], "domest": [124, 246], "domin": 141, "don": [39, 50, 111, 114, 121, 123, 219], "done": [83, 114, 121, 128, 144, 152, 179, 180, 181, 193, 194, 204], "dora": [63, 67, 70, 97, 124, 128, 131, 158], "dot": [96, 110, 157], "dot_product_attent": [105, 166], "dots1": [96, 157], "doubl": [7, 67, 128, 214], "double_quant": 7, "down": [35, 40, 57, 83, 86, 118, 126, 128, 132, 144, 147, 151, 152, 160, 184, 244], "down_proj": [28, 40, 46, 67, 99, 128, 160], "down_proj_t": 46, "downcast_bf16": [9, 15], "download": [14, 22, 28, 33, 43, 67, 70, 79, 116, 117, 122, 124, 128, 140, 152, 160, 166, 172, 174, 179, 184, 188, 191, 219, 221, 224, 230, 237, 245, 256], "download6": 245, "download_hf_model": [27, 28, 29, 30, 31], "download_mod": [7, 20, 67, 70, 128, 131], "download_model": [103, 164], "download_token": 239, "downloadmod": [7, 20], "downloadsourc": 11, "downstream": 140, "dp": [43, 67, 89, 90, 99, 101, 105, 128, 150, 151, 160, 162, 166, 175, 177, 179, 181, 215], "dp_actor": [172, 173], "dp_group": 43, "dp_mesh": 43, "dp_mode": 43, "dp_replicate_s": 43, "dp_shard_siz": 43, "dp_size": [43, 100, 101, 161, 162], "dpm": 225, "dpo": [0, 4, 7, 19, 24, 55, 56, 62, 63, 67, 91, 93, 94, 96, 102, 104, 105, 116, 117, 123, 124, 128, 152, 154, 155, 157, 163, 165, 166, 222, 249], "dpo_en_demo": 17, "dpo_label_smooth": 7, "dpo_loss": [67, 99, 128, 160], "dpo_megatron": 222, "dpo_train": 249, "dpython3_execut": 212, "dpython_librari": 212, "dr": [35, 67, 81, 99, 128, 142], "dr_grpo": [84, 145, 160], "draft": [67, 128], "dragon": 3, "drastic": 150, "draw": [57, 118, 121], "drawback": 39, "drawn": 142, "drcd": [68, 70, 129, 131], "dream": [219, 243], "dream_detail_preserv": 219, "dream_train": 219, "dreami": [57, 118], "dri": 39, "drift": [39, 138], "drive": 172, "driver": [14, 15, 22, 183, 185, 193, 230], "driver_": 14, "driver_25": 14, "drop": [35, 43, 99, 111, 113, 128, 160, 166, 219], "drop_last": [42, 43], "drop_out_domask_v3": 214, "dropmask": 214, "dropout": [7, 18, 67, 99, 128, 160, 214], "dropout_mask": 214, "dropout_mask_input": 214, "dropout_prob": 214, "dropoutmask": 214, "drun": 230, "ds": 187, "ds2_autotp": 9, "ds3": [67, 128], "ds_build_op": 187, "ds_config": [9, 48, 109, 188, 219], "ds_report": 187, "ds_z0_config": 9, "ds_z2_config": 9, "ds_z2_offload_config": 9, "ds_z3_config": [8, 9, 18], "ds_z3_offload_config": 9, "dsa": [96, 157, 214], "dsl": 39, "dst": 214, "dst_dtype": 214, "dsw": [65, 126], "dtensor": [9, 35], "dtw": 256, "dtype": [7, 28, 39, 46, 53, 57, 61, 67, 70, 97, 99, 114, 118, 122, 128, 131, 158, 160, 188, 191, 213, 214, 219, 222], "dual": [89, 133, 150], "dual_clip_loss": 222, "due": [35, 111, 113, 114, 119, 142, 150, 152, 158, 166, 219], "duet": [96, 157], "dule": [70, 131], "dummi": [87, 96, 148, 157], "dummy_data": 46, "dummy_forward": 46, "dummy_imag": [53, 114], "dummylengthrewardfunct": [87, 148], "dump": [29, 30, 194], "dump_path": [98, 159], "duo": [185, 214], "durat": 177, "dure": [34, 35, 38, 40, 46, 51, 53, 70, 109, 111, 112, 113, 114, 116, 117, 121, 122, 123, 124, 126, 127, 128, 132, 133, 135, 136, 139, 140, 141, 142, 147, 150, 151, 152, 153, 155, 157, 158, 159, 160, 162, 163, 164, 166, 172, 219], "dureader_robust": [96, 157], "dvts": [94, 155], "dw": 214, "dwith_cann": 212, "dwith_cuda": 212, "dx": 214, "dx_transpos": 214, "dy": 214, "dyn": [42, 45], "dyn_bsz": 43, "dyn_bsz_buffer_s": 43, "dyn_bsz_margin": 43, "dynam": [7, 39, 42, 43, 45, 67, 87, 99, 109, 128, 143, 144, 147, 148, 150, 155, 160, 180, 181, 214, 219, 237], "dynamic_sampl": [74, 135], "dynamicgruv2": 214, "dynamicrnn": 214, "dynamo": 214, "e2b": [96, 112, 157], "e2b_api_key": [51, 112], "e4b": [96, 157], "e4m3": [67, 99, 128, 160], "e5m2": [67, 128], "e_threshold": 214, "each": [35, 37, 38, 42, 45, 46, 50, 51, 52, 66, 67, 75, 110, 111, 112, 113, 116, 117, 120, 121, 122, 123, 126, 127, 128, 129, 132, 133, 136, 137, 138, 140, 141, 142, 145, 147, 150, 152, 153, 154, 156, 158, 160, 172, 188, 209, 219, 222, 228, 243], "eager": [40, 46, 67, 99, 128, 160, 197], "eager_mod": 197, "eagl": [67, 96, 128, 157], "eagle2": [67, 128], "eagle3": [67, 128], "earli": [57, 67, 118, 128, 143], "earlier": [45, 118, 121, 123, 144, 147, 155], "early_stop": [67, 128], "earlystop": [62, 123], "earthstar": 234, "eas": 149, "easi": [16, 39, 67, 121, 127, 128, 163, 164, 219], "easier": [32, 33, 35, 38, 40, 114, 246], "easili": [38, 43, 136, 219], "east": 230, "easydict": [96, 157], "eat": 152, "eaten": 241, "echo": [174, 178, 179, 180, 181, 236, 245], "econometr": 200, "ecosystem": 152, "edg": [57, 96, 118, 157, 249], "edibl": 234, "edit": [39, 97, 130, 158], "edu": [2, 183, 184, 185, 206, 209, 227, 233, 244, 248], "eetq": [7, 22, 63, 67, 91, 124, 128, 152], "effect": [35, 41, 50, 57, 59, 89, 110, 111, 117, 118, 120, 121, 124, 127, 128, 129, 136, 139, 148, 149, 150, 156, 158, 160, 162, 172, 237], "effective_batch_s": [89, 150], "effici": [0, 16, 34, 35, 38, 46, 97, 99, 120, 128, 135, 139, 140, 142, 147, 158, 160, 164, 219, 246], "effort": 35, "eg": [32, 33], "egg": [64, 121, 125], "ego4d": 29, "egoschema": [96, 157], "eight": 166, "either": [50, 111, 122, 128, 153, 184, 219], "elaps": [70, 131], "elapsed_tim": [70, 131], "elast": [67, 128], "elasticjob": [48, 109], "electrical_engin": 200, "eleg": 3, "element": [123, 127, 128], "elementary_mathemat": 200, "elementws": 177, "eleph": [118, 121], "eleutherai": [96, 157, 199], "elif": [37, 43, 46, 53, 71, 98, 114, 132, 159, 188, 207, 219], "elimin": [46, 166, 172], "ellipsis_mask": 214, "els": [28, 37, 46, 50, 52, 53, 56, 57, 62, 71, 79, 85, 87, 111, 113, 114, 117, 118, 123, 132, 140, 146, 148, 172, 173, 178, 179, 180, 181, 188, 214, 219, 221, 241, 244, 246], "em": [96, 157], "ema": [67, 128, 219], "ema_unet": 219, "email": [57, 67, 118, 128], "emamodel": 219, "emaon": 225, "emb": [39, 46, 67, 70, 96, 98, 128, 131, 157, 159], "embed": [0, 7, 39, 63, 67, 91, 96, 97, 98, 99, 105, 124, 128, 149, 152, 157, 158, 159, 160, 166, 219, 228], "embed_dim": 207, "embed_token": [53, 67, 114, 128], "embedding_length": 194, "embedding_s": 219, "embeddinggemma": [96, 157], "emergenc": 155, "emergent": 140, "emoji": [96, 157], "emot": [57, 118], "emphas": 133, "emphasi": 123, "employ": [135, 152], "empti": [28, 36, 37, 40, 42, 51, 58, 66, 67, 70, 88, 90, 91, 112, 119, 121, 122, 127, 128, 149, 151, 152, 172, 174, 219, 221, 230], "empty_cach": 219, "empty_lik": 191, "empty_with_format": [214, 217], "emptydir": [48, 109], "emptyformatt": 11, "emu3": [96, 157], "en": [7, 20, 56, 60, 63, 65, 66, 67, 91, 96, 98, 102, 105, 117, 121, 124, 126, 127, 128, 152, 157, 159, 160, 163, 166, 219, 243, 250, 256], "enabl": [9, 34, 35, 36, 42, 43, 45, 48, 56, 67, 99, 109, 110, 114, 116, 117, 121, 123, 127, 128, 129, 133, 134, 135, 138, 140, 144, 147, 149, 150, 152, 155, 160, 161, 163, 166, 172, 173, 178, 180, 181, 188, 204, 219, 228, 234, 249], "enable_aclnn": 214, "enable_audio_output": [53, 114], "enable_cann_graph": 204, "enable_channel_loss": [60, 70, 121, 131], "enable_chunked_prefil": [174, 178], "enable_cpu_affin": 9, "enable_default_handl": 219, "enable_dp_attent": 175, "enable_explicit_format": 219, "enable_filter_group": 180, "enable_fsdp_float8_all_gath": 240, "enable_fsdp_offload": 43, "enable_full_shard": 43, "enable_gradient_checkpoint": [43, 174, 178, 181, 219], "enable_liger_kernel": [6, 7], "enable_mixed_precis": 43, "enable_overlong_buff": 180, "enable_prefix_cach": 222, "enable_profil": 43, "enable_reshard_after_forward": 43, "enable_short_consol": 7, "enable_sleep_mod": [70, 131], "enable_think": 191, "enable_xformers_memory_efficient_attent": 219, "enable_xxx": 43, "encapsul": 129, "enclos": [83, 86, 87, 144, 147, 148], "encod": [29, 30, 42, 43, 53, 60, 66, 67, 86, 114, 121, 127, 128, 147, 160, 184, 215, 219, 256], "encode_imag": 207, "encode_messag": 43, "encode_text": 207, "encoded_input": 241, "encoder_hidden_st": 219, "encompass": 122, "encount": [44, 113, 118, 125, 128, 151, 152, 157, 164, 166], "encourag": [56, 117, 135, 148, 153], "end": [11, 31, 35, 38, 42, 46, 50, 57, 74, 76, 81, 86, 89, 90, 91, 99, 110, 111, 118, 128, 129, 135, 137, 140, 142, 144, 147, 150, 151, 152, 160, 214, 219, 243, 250], "end_mask": 214, "end_step": 43, "end_train": 219, "endear": [57, 118], "endedimagenet": [96, 157], "endl": 204, "endoftext": [49, 53, 61, 110, 114, 122], "endpoint": [48, 51, 109, 112, 156], "endswith": 219, "energi": 219, "enforc": [67, 99, 128, 160], "enforce_eag": [178, 181], "engag": [56, 57, 91, 117, 118, 152], "engin": [3, 53, 55, 57, 67, 86, 88, 89, 90, 91, 95, 99, 105, 114, 116, 118, 124, 128, 142, 147, 149, 150, 151, 152, 160, 172, 181, 188, 219, 221, 230, 231], "engine_kwarg": [95, 156, 175, 181], "english": [70, 96, 110, 128, 157], "engross": [57, 118], "enhanc": [36, 38, 119, 124, 143, 158, 160], "enjoy": [57, 118, 125, 219], "enorm": 237, "enp1s0": 15, "ensur": [31, 35, 37, 38, 44, 46, 110, 113, 117, 118, 123, 128, 130, 134, 135, 140, 143, 146, 147, 148, 150, 153, 155, 160, 162, 166, 214, 222, 246], "ensure_ascii": [29, 30], "enter": [46, 151], "entir": [39, 124, 128, 132, 136, 144, 160], "entri": [37, 41, 67, 113, 121, 127, 128, 152, 164], "entropi": [67, 70, 89, 99, 120, 123, 128, 150, 160, 162, 172, 173, 180, 188, 219], "entropy_checkpoint": [178, 181], "entropy_coeff": 174, "entropy_from_logits_with_chunk": [178, 181], "entropy_loss_coef": 222, "entrypoint": 40, "enum": [66, 127, 222], "enumer": [46, 53, 114, 172, 173, 188, 219], "env": [32, 33, 83, 90, 144, 151, 170, 175, 187, 204, 212, 219, 221, 222, 230, 240], "env_config": [83, 144], "env_local_rank": 219, "env_nam": [83, 144], "env_typ": 222, "environ": [5, 53, 56, 57, 60, 70, 83, 90, 91, 110, 112, 120, 121, 124, 126, 140, 147, 148, 151, 158, 159, 160, 163, 165, 170, 172, 184, 187, 188, 201, 209, 214, 215, 219, 230], "enxin": [96, 157], "enzh": [96, 157], "eo": [179, 180, 181], "eom": 11, "eos": [61, 67, 122, 128, 194], "eos_token": 128, "eos_token_id": [11, 61, 122, 194, 246], "eot": [11, 194], "eot_id": [194, 246], "ep": [34, 63, 67, 90, 99, 100, 101, 103, 105, 124, 128, 151, 160, 161, 162, 164, 166, 175, 188, 204, 219], "ep_en": 46, "ep_plan": [35, 46], "ep_siz": [43, 188, 219], "ep_world_s": [188, 219], "episod": 144, "epoch": [42, 43, 45, 50, 52, 67, 99, 111, 113, 128, 160, 172, 173, 184, 188, 207, 219, 234, 241, 249], "epoch_": 219, "eprstmt": [68, 70, 129, 131], "eps": [38, 39, 99, 160, 188, 214, 219], "epsilon": [38, 67, 73, 74, 75, 78, 81, 84, 89, 99, 128, 134, 135, 136, 139, 142, 145, 150, 160, 214, 219], "epsilon_high": [73, 74, 75, 134, 135, 136, 160], "eq": [179, 180, 181], "eqs": 136, "equal": [46, 50, 56, 110, 111, 117, 121, 123, 128, 142, 147, 148, 150, 160, 222], "equat": [50, 85, 111, 128, 146], "equip": [117, 140], "equiv": [81, 142], "equival": [32, 33, 42, 117, 121, 127, 128, 136, 138, 152, 160, 164], "erni": [96, 157], "ernie4": [96, 157], "errno": [70, 131], "erron": 128, "error": [40, 41, 44, 53, 67, 111, 113, 114, 120, 128, 132, 134, 150, 152, 158, 160, 164, 166, 174, 178, 184, 199, 219], "especi": [128, 160], "ess": [89, 150], "essenti": [120, 154], "estim": [38, 67, 89, 128, 136, 137, 138, 142, 150, 249], "etc": [14, 22, 39, 50, 53, 111, 113, 114, 121, 123, 124, 127, 128, 129, 141, 142, 144, 148, 154, 155, 158, 160, 163, 164, 172, 183, 185, 219, 230], "eth0": 15, "etp": [55, 63, 103, 105, 116, 124, 164, 166], "euclidean": 110, "euler": 225, "eval": [0, 8, 20, 50, 64, 67, 68, 99, 110, 111, 125, 128, 129, 160, 188, 194, 199, 207, 210, 219, 237, 249], "eval_backend": [58, 68, 119, 129], "eval_base_demo": 210, "eval_chat_demo": 210, "eval_config": [58, 70, 119, 131], "eval_dataset": [7, 8, 20, 67, 68, 70, 128, 129, 131, 219, 241], "eval_dataset_arg": [68, 129], "eval_generation_config": [68, 129], "eval_it": [56, 117], "eval_limit": [68, 70, 129, 131], "eval_logit": 249, "eval_logp": 249, "eval_loss": [219, 249], "eval_num_beam": 7, "eval_on_each_dataset": 7, "eval_pr": [219, 241], "eval_result": [70, 131], "eval_reward": 249, "eval_runtim": 249, "eval_sampl": 219, "eval_samples_per_second": 249, "eval_step": [8, 24, 48, 50, 51, 52, 53, 55, 56, 57, 58, 63, 67, 68, 70, 99, 103, 104, 109, 111, 112, 113, 114, 116, 117, 118, 119, 124, 128, 129, 131, 160, 164, 165, 222], "eval_steps_per_second": 249, "eval_strategi": [8, 24, 52, 68, 113, 129, 241], "eval_use_evalscop": [68, 129], "evalscop": [55, 58, 63, 64, 67, 68, 116, 119, 124, 125, 128, 129], "evalu": [7, 20, 50, 55, 70, 83, 86, 89, 110, 111, 116, 123, 124, 125, 140, 144, 147, 149, 150, 151, 155, 160, 184, 198, 200, 209, 219, 237, 241], "even": [37, 38, 41, 110, 128, 135, 136, 142, 143, 150, 152, 155, 160, 172, 241], "event": 160, "eventu": [111, 113], "ever": 237, "everest": 129, "everi": [46, 128, 147, 188, 219], "everyth": [39, 219, 241], "evid": [57, 118], "evok": [57, 118], "evol": [96, 157], "evolv": 111, "exacerb": 139, "exact": [35, 37, 39, 46, 50, 70, 110, 111, 127, 131, 142], "exact_match": [58, 70, 119, 131], "examin": [57, 111, 118], "exampl": [3, 8, 9, 11, 15, 18, 20, 21, 23, 24, 31, 35, 36, 38, 40, 41, 43, 45, 46, 47, 50, 51, 52, 53, 56, 60, 61, 62, 63, 65, 68, 70, 87, 89, 93, 109, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 126, 127, 128, 129, 132, 133, 137, 139, 140, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 160, 164, 170, 174, 179, 180, 184, 188, 215, 219, 222, 228, 231, 241, 249, 250, 253], "example_dev": [68, 129], "example_v": [68, 129], "exceed": [38, 46, 50, 51, 111, 112, 120, 128, 142, 147, 148, 160], "excel": 164, "except": [50, 52, 88, 109, 111, 113, 119, 128, 149, 152, 155, 160, 219, 221], "excess": [110, 128, 142, 148, 150, 160], "exchang": [96, 157], "exclud": [39, 48, 109, 121, 127, 128, 135, 150, 219, 237], "exclude_from_output": 39, "exclus": [141, 219], "exec": [14, 197], "execut": [34, 40, 93, 112, 131, 143, 148, 154, 170, 172, 193, 219, 255], "execute_model": [172, 173], "executorch": 237, "exhaust": 67, "exhibit": [113, 139, 172], "exist": [35, 36, 37, 38, 41, 42, 43, 67, 99, 121, 123, 128, 129, 130, 131, 154, 155, 156, 158, 160, 172, 173, 178, 219], "exist_ok": 219, "exit": [90, 151, 160, 199, 221, 237], "exit_cod": [98, 159], "exp": [41, 67, 73, 75, 81, 89, 96, 99, 128, 134, 136, 142, 150, 157, 160, 214, 219], "exp_avg": 214, "exp_nam": [179, 180, 222], "expand": [10, 114, 120, 147], "expand_a": [53, 114], "expand_dim": 204, "expandable_seg": [33, 34, 53, 56, 57, 67, 70, 98, 102, 103, 104, 105, 114, 117, 118, 128, 131, 159, 163, 164, 165, 166, 228], "expans": [96, 97, 131, 157, 158, 181], "expect": [37, 40, 46, 50, 70, 89, 91, 111, 112, 131, 132, 142, 143, 150, 152, 219, 241], "expens": 219, "experi": [42, 116, 117, 127, 128, 141, 160, 172, 241], "experienc": [128, 160], "experiment": [35, 134, 160], "experiment_nam": [174, 178], "experimental_config": [98, 159, 172, 173], "expert": [27, 28, 36, 39, 40, 42, 43, 67, 99, 128, 139, 160, 161, 162, 164, 166, 188, 214, 219], "expert_dim": 46, "expert_hit": 28, "expert_idx": 28, "expert_lay": 28, "expert_mask": [28, 46], "expert_model_parallel_s": [56, 57, 103, 104, 117, 118, 164, 165, 222], "expert_parallel_s": [35, 43, 180], "expert_token": 214, "expert_tokens_index": 214, "expir": [128, 160], "explain": [37, 44, 56, 112, 113, 117, 134, 137, 138, 142, 147, 154], "explan": [43, 117, 150, 153, 219], "explicit": [35, 40, 114, 128, 148, 150, 152, 160, 184, 230], "explor": [50, 57, 111, 118, 133, 135, 143, 237], "exploratori": 135, "explos": 142, "exponenti": [99, 128, 160], "export": [3, 8, 15, 23, 33, 34, 37, 46, 48, 53, 55, 56, 57, 63, 67, 69, 71, 99, 102, 105, 109, 114, 116, 117, 118, 124, 132, 150, 163, 166, 170, 171, 174, 175, 178, 179, 180, 181, 184, 200, 218, 219, 221, 228, 230, 237, 240, 245, 253], "export_devic": [7, 23], "export_dir": [7, 8, 23], "export_hub_model_id": 7, "export_jit": 253, "export_legacy_format": [7, 23], "export_model_parallel_s": [102, 163], "export_quantization_bit": [7, 23], "export_quantization_dataset": [7, 23], "export_quantization_maxlen": 7, "export_quantization_nsampl": 7, "export_s": [7, 23], "export_typ": [172, 173], "export_weight": [103, 164], "exporttyp": [172, 173], "expos": [35, 41, 131, 132, 219], "express": [50, 57, 83, 86, 111, 118, 123, 127, 128, 142, 144, 147, 151, 160, 219, 246], "ext": 191, "extend": [34, 38, 43, 70, 121, 128, 131, 160, 172], "extens": [34, 37, 43, 47, 70, 111, 124, 131, 181, 187, 219, 227, 248], "extern": [50, 52, 67, 70, 112, 113, 117, 121, 122, 128, 131, 147], "external_code_format": [51, 112], "external_code_reward": [51, 112], "external_code_reward_by_judge0": [51, 112], "external_countdown": [50, 111], "external_plugin": [50, 51, 52, 53, 60, 61, 83, 86, 87, 88, 111, 112, 113, 114, 121, 122, 144, 147, 148, 149], "external_r1v_acc": [52, 113], "extra": [9, 11, 20, 32, 33, 38, 40, 41, 46, 67, 121, 123, 128, 144, 147, 148, 149, 150, 158, 174, 219, 256], "extra_arg": [70, 131], "extra_callback": [62, 123], "extra_dict": [86, 147], "extra_eval_arg": [68, 70, 129, 131], "extract": [27, 29, 37, 39, 50, 52, 111, 113, 120, 128, 131, 147, 148, 149], "extract_boxed_result": [62, 123], "extract_non_reasoning_cont": 179, "extrem": [3, 38, 128, 132, 135, 160, 219], "eye": [57, 118, 151, 237], "eyjtdgf0zw1lbnqiolt7invuaxf1zv9oyxnoijoibgjuyxc0bzdry2pqnnoxexz1n3hmcmnviiwiumvzb3vyy2uioijodhrwczp": 245, "f1": 184, "f16": 194, "f16c": [194, 256], "f2b0977e": [174, 176], "f32": 194, "f_clamp_kqv": 194, "f_logit_scal": 194, "f_max_alibi_bia": 194, "f_norm_ep": 194, "f_norm_rms_ep": 194, "fa": [15, 41, 55, 116, 174, 177, 214], "fa2": [6, 7, 15, 41, 222], "fa3": [41, 99, 160], "fa4": 41, "face": [0, 7, 9, 13, 46, 49, 57, 59, 67, 110, 118, 120, 128, 130, 151, 152, 157, 160, 163, 165, 166, 172, 180, 181, 191, 194, 234, 237, 249], "facilit": [121, 128, 160], "factor": [43, 67, 99, 128, 153, 160, 214, 219], "factori": [0, 6, 7, 9, 10, 11, 12, 14, 15, 18, 21, 23, 24, 25, 193], "fahrenheit": [60, 66, 121, 127], "fail": [41, 50, 52, 70, 88, 111, 113, 128, 148, 149, 152, 156, 160, 179, 180, 181, 221, 241], "failur": [41, 111, 172], "fake": 110, "fake_deepstack": 46, "fake_emb": 46, "fake_model": 46, "fake_tensor": 214, "faketensor": 214, "faketensormod": 214, "falcon": [96, 157], "fall": [41, 52, 113, 128, 135, 142, 160, 161], "fallback": [41, 256], "fals": [7, 8, 9, 11, 14, 15, 18, 19, 23, 24, 28, 29, 30, 34, 38, 42, 43, 46, 48, 49, 52, 53, 56, 57, 58, 60, 61, 63, 67, 69, 71, 72, 76, 77, 79, 86, 88, 89, 91, 92, 97, 98, 99, 100, 102, 103, 104, 105, 109, 110, 113, 114, 117, 118, 119, 121, 122, 124, 128, 130, 132, 133, 137, 138, 140, 147, 149, 150, 152, 153, 158, 159, 160, 161, 163, 164, 165, 166, 172, 173, 174, 175, 178, 179, 181, 184, 188, 191, 197, 214, 219, 222, 228, 240, 243, 253], "famili": [40, 55, 116, 124, 234], "faq": [210, 217], "far": [50, 111, 138], "fashion": 35, "fast": [41, 128, 172, 184, 219], "fast_gelu": [214, 217], "fast_pos_embed_interpol": 46, "fast_token": 7, "fastapi": 7, "fastapi_root_path": 7, "faster": [32, 33, 111, 118, 128, 139, 160, 184, 219], "fasterrcnn": 214, "fastest": 166, "fastgelu": 214, "fatima": [96, 157], "fc1": [188, 219], "fc1_1_weight": [28, 40, 46], "fc1_2_weight": [28, 40, 46], "fc2": [188, 219], "fc2_weight": [28, 40, 46], "fc3": [188, 219], "fc4": [188, 219], "featmap_s": 214, "featur": [3, 33, 34, 36, 46, 57, 116, 118, 121, 123, 126, 127, 128, 131, 151, 154, 156, 160, 162, 188, 214, 219, 222, 228], "feature_attention_mask": [53, 114], "feature_extractor": [53, 114, 243], "fed": 140, "feed": [188, 219], "feed_forward_length": 194, "feedback": [17, 147], "feedforward_modul": [62, 123], "feel": [56, 57, 91, 117, 118, 151, 152, 246], "feet": 90, "fellow": 256, "felt": 241, "fengshenbang": [96, 157], "fengyao": [81, 142], "fetch": [128, 170], "fetch_imag": [53, 79, 114, 140], "fetch_video": [53, 114], "few": [7, 20, 43, 46, 129, 141], "few_shot_num": [68, 129], "fewer": [128, 160], "fewshot": [20, 68], "fewshot_as_multiturn": 199, "ffdec": [53, 114], "ffmpeg": [32, 33, 256], "ffmpegaudiofil": [53, 114], "ffn": [45, 67, 128, 177, 214], "fi": [178, 179, 180, 181], "fia": 214, "fibonacci": [85, 146], "field": [43, 110, 111, 113, 117, 120, 121, 127, 128, 144, 151, 157, 158, 160, 164, 172, 219], "figur": [38, 113, 147], "file": [27, 29, 30, 31, 35, 36, 38, 39, 42, 43, 44, 47, 48, 49, 61, 67, 70, 109, 110, 114, 121, 122, 123, 124, 127, 128, 129, 140, 148, 152, 156, 157, 159, 160, 163, 164, 172, 178, 179, 180, 197, 199, 207, 213, 219, 222, 230, 245], "file_format": 47, "file_nam": 19, "file_system": 222, "file_typ": 194, "filenam": [47, 128, 129, 156, 245], "filesystem": 219, "fill": [46, 121, 135, 160, 213], "filter": [44, 48, 67, 68, 70, 89, 96, 99, 109, 114, 122, 128, 129, 131, 141, 155, 157, 160, 188, 200, 214, 219], "filter_group": 180, "filter_groups_metr": 180, "filter_height": 214, "filter_overlong_prompt": [174, 178], "filter_width": 214, "filtered_data": [29, 30], "final": [39, 46, 50, 51, 52, 66, 67, 98, 110, 111, 112, 113, 117, 120, 121, 124, 127, 128, 133, 140, 144, 159, 160, 165, 166, 219], "final_hidden_st": 28, "final_result": [83, 86, 144, 147], "finalizeacl": 213, "financ": [96, 157], "finance_en": [96, 157], "financefinance_clsmedicinemedicine_cl": [96, 157], "financi": [96, 157], "financial_classif": [60, 121], "find": [35, 41, 50, 52, 67, 70, 83, 86, 111, 113, 114, 117, 118, 121, 128, 141, 144, 147, 152, 153, 160, 181], "find_all_linear": [62, 123], "findal": [50, 53, 111, 114], "fine": [0, 24, 34, 67, 97, 99, 118, 119, 124, 128, 133, 136, 140, 149, 151, 156, 158, 160, 161, 162, 165, 166, 201, 219, 250], "finetun": [3, 56, 57, 97, 99, 102, 103, 104, 105, 117, 118, 131, 158, 160, 163, 164, 165, 166, 219], "finetuned_from": 219, "finetuning_typ": [7, 8, 9, 17, 18, 20, 21, 23, 24], "fineweb": [96, 157, 219], "finish": [45, 82, 143, 144, 188, 219], "finish_reason": [83, 86, 144, 147, 231], "fire": 231, "firefli": [96, 157], "firmwar": [14, 185, 230], "firmware_": 14, "firmware_7": 14, "first": [27, 35, 36, 38, 40, 43, 44, 50, 51, 52, 60, 67, 83, 86, 87, 93, 99, 110, 111, 112, 113, 114, 116, 118, 121, 123, 127, 128, 132, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 160, 161, 162, 166, 172, 188, 214, 219, 237], "first2000": 27, "first_epoch": 219, "first_exhaust": 128, "fit": [44, 45, 50, 110, 111, 131, 155], "five": [52, 148, 241], "fix": [3, 7, 18, 45, 109, 113, 114, 145, 148, 219], "fixed_triu_mask": 214, "flac": 243, "flag": [39, 128, 160, 172, 219], "flag_seq": 214, "flagalpha": [96, 157], "flan1m": [96, 157], "flash": [22, 38, 39, 53, 56, 57, 63, 67, 91, 96, 99, 103, 104, 105, 114, 117, 118, 124, 128, 152, 157, 160, 164, 165, 166, 174, 191, 221, 256], "flash_attention_2": [39, 53, 57, 114, 118, 128, 221], "flash_attention_3": [99, 128, 160], "flash_attn": [6, 7, 15, 41, 53, 56, 57, 58, 64, 67, 91, 104, 105, 114, 117, 118, 119, 125, 128, 152, 160, 165, 166, 174, 194, 221], "flash_attn_func": 41, "flash_attn_interfac": 41, "flash_attn_kwarg": 46, "flash_attn_varlen_func": 41, "flashattent": [7, 38, 45, 46, 214], "flashcomm": 181, "flashdecod": 214, "flatten": [45, 67, 93, 128, 154, 160, 219], "flattenparamt": 35, "flaviagiammarino": [96, 157], "fleshi": 234, "flex": [99, 160], "flexattent": 45, "flexibl": [35, 36, 37, 43, 97, 121, 149, 155, 158], "flexible_format_preprocessor": 37, "flexible_sourc": 37, "fli": [16, 128], "flip": [213, 219], "flmc": [96, 157], "float": [7, 18, 38, 42, 50, 52, 62, 67, 71, 74, 78, 83, 88, 95, 100, 111, 113, 123, 128, 132, 135, 139, 144, 149, 156, 161, 204, 214, 219, 249], "float16": [2, 3, 7, 67, 99, 128, 160, 191, 214, 219], "float32": [7, 39, 55, 67, 70, 99, 116, 128, 131, 160, 188, 204, 214, 219, 234], "float8": 240, "floatarr": 204, "floattensor": 214, "floor": [57, 118], "flop_count": 207, "flopcountermod": 207, "florenc": [96, 157], "flow": [35, 144], "fluctuat": [111, 128, 160], "fluffi": [57, 118, 151], "flush": [57, 90, 91, 118, 151, 152, 160], "fma": [194, 256], "focal": [57, 118], "focus": [35, 38, 57, 90, 109, 113, 117, 118, 123, 151, 164], "fold": 166, "folder": [119, 121, 124, 128, 129, 152, 156, 158, 163, 172, 219], "folder_path": 219, "follow": [33, 35, 37, 38, 43, 44, 45, 46, 47, 51, 66, 83, 86, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 166, 172, 173, 184, 188, 219], "food": 241, "for": [11, 14, 16, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 57, 58, 62, 66, 67, 75, 82, 83, 85, 86, 87, 88, 90, 91, 93, 97, 99, 103, 109, 111, 112, 113, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 172, 173, 175, 179, 180, 181, 184, 188, 191, 194, 204, 209, 213, 214, 219, 227, 228, 231, 234, 237, 240, 241, 244, 248, 249, 256], "foral": [104, 165], "forc": [128, 160, 170, 179, 180, 181, 219, 222, 241], "forcausallm": 46, "force_check_import": 7, "force_redownload": [67, 128], "force_torchrun": [7, 9], "forcibl": [128, 135], "foreach": 219, "foreach_ema": 219, "forecast": [121, 127], "forehead": [57, 118], "forest": 237, "forget": [131, 155], "fork": [48, 109, 184], "forkserv": [48, 109], "form": [40, 45, 48, 50, 89, 109, 111, 114, 120, 121, 127, 128, 138, 144, 150, 160, 172, 214, 231, 234], "formal_log": 200, "format": [11, 19, 42, 47, 50, 52, 66, 67, 70, 96, 99, 109, 111, 112, 113, 117, 118, 124, 128, 144, 150, 151, 152, 153, 154, 156, 157, 158, 160, 163, 164, 165, 166, 172, 177, 178, 194, 214, 215, 219], "format_assist": 11, "format_assit": 11, "format_funct": 11, "format_observ": 11, "format_penalti": 222, "format_prefix": 11, "format_system": 11, "format_tool": 11, "format_us": 11, "former": [111, 113], "formul": 219, "formula": [111, 132, 135, 141, 145, 150, 162], "forsequenceclassif": 46, "fortokenclassif": 46, "forward": [28, 35, 36, 38, 39, 40, 43, 45, 49, 53, 67, 70, 92, 93, 98, 99, 100, 110, 114, 128, 131, 153, 154, 159, 160, 161, 172, 173, 188, 214, 215, 219], "forward_and_optim": [93, 154], "forward_backward_batch": [172, 173], "forward_backward_func": [98, 159], "forward_batch": [172, 173], "forward_model2": [93, 154], "forward_step_func": [98, 159], "found": [41, 110, 113, 117, 120, 123, 125, 128, 129, 140, 143, 147, 148, 152, 154, 155, 160, 166, 213, 219], "foundat": 153, "four": [52, 75, 111, 121, 128, 129, 136, 151, 153], "fourier": [67, 128], "fourierft": [70, 97, 131, 158], "fox": 228, "fp16": [3, 9, 16, 48, 96, 99, 109, 157, 160, 177, 188, 194, 214, 219], "fp16_enabl": [188, 219], "fp16_master_weights_and_grad": [188, 219], "fp16_va": [194, 256], "fp32": [7, 70, 96, 99, 131, 157, 160, 177, 188, 214, 219], "fp4": [7, 67, 128], "fp64": [99, 160], "fp8": [63, 67, 69, 96, 99, 102, 105, 124, 128, 130, 157, 160, 163, 166], "fps": [67, 128], "fps_max_fram": [53, 57, 58, 67, 90, 103, 114, 118, 119, 128, 151, 164], "fqn": 35, "frac": [50, 57, 71, 73, 74, 75, 76, 77, 78, 80, 81, 84, 89, 92, 104, 111, 118, 132, 134, 135, 136, 137, 138, 139, 141, 142, 145, 150, 153, 165], "fractal_nz": 214, "fractal_z": 214, "fractal_zn_lstm": 214, "fraction": [67, 99, 128, 141, 142, 150, 160], "fragil": 39, "fragment": 128, "frame": [67, 70, 90, 121, 128], "framework": [35, 36, 37, 39, 43, 124, 128, 129, 142, 147, 150, 164, 172, 209, 228, 250], "franc": [231, 243], "francisco": [66, 127], "free": [44, 53, 56, 57, 60, 67, 91, 99, 114, 117, 118, 121, 125, 128, 151, 152, 160, 181, 246], "free_cache_engin": 181, "freedomintellig": [96, 157], "freez": [15, 24, 67, 89, 99, 114, 119, 128, 150, 160, 219], "freeze_align": [53, 57, 58, 67, 70, 99, 103, 104, 114, 118, 119, 128, 131, 160, 164, 165], "freeze_extra_modul": [7, 18], "freeze_llm": [53, 58, 67, 70, 99, 103, 104, 114, 119, 128, 131, 160, 164, 165], "freeze_multi_modal_projector": 7, "freeze_paramet": [67, 128], "freeze_parameters_ratio": [67, 128], "freeze_parameters_regex": [67, 128], "freeze_trainable_lay": [7, 18], "freeze_trainable_modul": [7, 18], "freeze_vision_tow": 7, "freeze_vit": [53, 57, 58, 67, 99, 103, 104, 114, 118, 119, 128, 160, 164, 165], "freq_bas": 194, "freq_base_train": 194, "freq_scal": 194, "freq_scale_train": 194, "frequenc": [67, 128, 172, 207], "frequency_penalti": 194, "frequent": [34, 128, 150], "fresh": 121, "fri": 121, "friction": 40, "friend": [28, 56, 117, 237, 241, 246], "frighten": 237, "frog": [188, 219], "from": [2, 3, 11, 13, 17, 19, 21, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 57, 58, 60, 62, 66, 67, 71, 75, 79, 81, 85, 87, 88, 89, 90, 91, 93, 97, 98, 103, 110, 111, 112, 113, 114, 116, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 161, 163, 164, 166, 170, 172, 179, 180, 181, 184, 188, 191, 194, 197, 204, 207, 212, 214, 215, 219, 221, 234, 237, 239, 241, 243, 244, 245, 246, 256], "from_config": 219, "from_gener": 219, "from_numpi": 214, "from_peft_typ": [70, 131], "from_pretrain": [2, 3, 11, 43, 53, 57, 58, 62, 67, 91, 97, 114, 118, 119, 123, 128, 152, 158, 191, 219, 241, 244, 246], "from_tf": 219, "from_train": 219, "front": [204, 241], "frontier": [81, 142], "frozen": [114, 128, 160, 219], "frozenlak": 222, "frozenlakethink": 222, "fs": 14, "fsdp": [4, 15, 35, 38, 42, 43, 55, 63, 67, 91, 116, 124, 128, 152, 174, 175, 178, 179, 240, 250], "fsdp1": [9, 34, 35, 42, 43, 55, 116], "fsdp2": [4, 15, 27, 34, 42, 43, 55, 63, 67, 116, 124, 128, 174, 180], "fsdp2_config": 9, "fsdp_actor_update_profil": [172, 173], "fsdp_auto_wrap_polici": [9, 15], "fsdp_backward_prefetch": [9, 15], "fsdp_config": [9, 15, 174, 178, 180, 181], "fsdp_config_multiple_nod": [9, 15], "fsdp_cpu_ram_efficient_load": [9, 15], "fsdp_enabl": 46, "fsdp_forward_prefetch": [9, 15], "fsdp_offload_param": [9, 15], "fsdp_qlora": 9, "fsdp_reshard_after_forward": 9, "fsdp_sharding_strategi": [9, 15], "fsdp_state_dict_typ": [9, 15], "fsdp_sync_module_st": [9, 15], "fsdp_use_orig_param": [9, 15], "fsdp_version": 9, "fsdpextens": 35, "fsvd": [7, 18], "ft": [95, 96, 156, 157], "ft22k": 243, "ftype": [194, 256], "full": [4, 7, 8, 9, 14, 24, 38, 42, 43, 46, 50, 52, 55, 56, 57, 58, 67, 92, 99, 102, 103, 105, 111, 113, 114, 116, 117, 118, 122, 123, 124, 125, 147, 150, 151, 152, 153, 160, 161, 162, 163, 164, 166, 172, 181, 209, 219, 222, 231], "full_eval_dataset": 241, "full_shard": [9, 15], "full_state_dict": [9, 15], "full_streaming_dataset": 219, "full_train_dataset": 241, "fullgraph": 214, "fulli": [9, 35, 39, 99, 111, 127, 142, 147, 160, 201], "fully_shard": 35, "fullyshardeddataparallel": 215, "fun": 151, "funasr": [96, 157], "func": [46, 60, 67, 70, 87, 88, 89, 99, 121, 128, 131, 149, 150, 160], "func_nam": 39, "function": [11, 19, 34, 41, 47, 52, 53, 57, 60, 66, 70, 85, 88, 89, 93, 96, 110, 114, 116, 117, 118, 121, 122, 123, 124, 127, 133, 134, 135, 136, 137, 140, 142, 144, 146, 149, 150, 153, 154, 155, 157, 158, 159, 160, 163, 172, 188, 204, 214, 215, 219, 228], "function_cal": 19, "function_replac": 39, "functionformatt": 11, "functool": [43, 53, 114], "fungi": 234, "fungus": 234, "fur": [57, 118, 237], "furnitur": 90, "further": [38, 46, 117, 130, 150, 151, 152], "fuse": [27, 28, 35, 39, 99, 116, 160], "fused_adam": 187, "fused_mo": 40, "fused_moe_forward": [28, 40, 46], "fused_weight_gradient_mlp_cuda": [70, 131], "fusion": [28, 39, 70, 99, 131, 159, 160], "futur": [38, 114, 128, 131, 136, 160, 161, 162], "ga": [63, 124], "gae": [92, 153], "galor": [22, 63, 97, 124, 158], "galore_layerwis": [7, 18], "galore_proj_typ": [7, 18], "galore_rank": [7, 18], "galore_scal": [7, 18], "galore_target": [7, 18], "galore_update_interv": [7, 18], "game": [50, 51, 111, 112], "gamma": [67, 92, 128, 153, 214, 219], "gaokaobench": [68, 70, 129, 131], "gap": [67, 128], "garag": [96, 157], "garbag": 160, "garbage265": [96, 157], "gate": [35, 40, 46, 70, 78, 128, 131, 145, 188, 219], "gate_proj": [28, 40, 46, 67, 99, 128, 160], "gate_proj_out": 28, "gate_proj_t": 46, "gate_up_proj": [40, 46], "gather": [35, 38, 46, 67, 87, 89, 99, 128, 148, 150, 160, 219, 240], "gather_heads_scatter_seq": [38, 46], "gather_list": [53, 114], "gather_seq_scatter_head": [38, 46], "gather_seq_scatter_heads_qkv": 38, "gaussian": [67, 128], "gaussnois": 213, "gaze": [57, 118], "gb": [7, 42, 55, 67, 116, 128, 187, 237], "gb0": 256, "gc": [99, 160], "gcc": [22, 185, 212, 218], "gd": [67, 128], "gdpo": [67, 99, 128, 160], "ge": 214, "ge_api": 214, "ge_concrete_graph": 214, "geastracea": 234, "geglu": 214, "gelu": [204, 214], "gelu_fast": 191, "gemm": [99, 160], "gemma": [6, 96, 157], "gemma2": [96, 157], "gemma3": [96, 157], "gemma3n": [96, 157], "gen": [90, 91, 96, 151, 152, 157, 179, 210], "gen_batch_s": 180, "gen_kwarg": [199, 200, 219], "gen_list": [57, 90, 118, 151], "gen_mask_parallel": 214, "gen_prompt_bsz": 180, "general": [7, 42, 56, 60, 70, 96, 100, 117, 121, 122, 123, 128, 129, 131, 134, 155, 157, 160, 161, 187, 194, 204], "general_mcq": [68, 129], "general_qa": [68, 70, 129, 131], "generat": [3, 11, 29, 40, 42, 44, 50, 52, 53, 56, 57, 67, 68, 71, 89, 92, 93, 94, 95, 96, 97, 99, 101, 111, 112, 113, 114, 117, 118, 121, 122, 124, 129, 132, 135, 136, 137, 138, 139, 140, 141, 143, 144, 147, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 164, 165, 166, 172, 173, 184, 191, 194, 204, 210, 219, 222, 224, 225, 228, 231, 237, 243, 246], "generate_id": [53, 114, 128], "generate_wan_dataset": 31, "generated_chat_0": [96, 157], "generated_id": [57, 118, 191], "generated_ids_trim": [57, 118], "generated_modeling_nam": 39, "generated_text": 243, "generating_arg": 222, "generation_batch_s": [89, 101, 150, 162], "generation_config": [11, 70, 128, 131], "generation_kwarg": 179, "generation_ratio": 37, "generative_rerank": 128, "generative_reranker_negative_token": [59, 120], "generative_reranker_positive_token": [59, 120], "generic": [57, 114, 118], "generictemporalconsist": [96, 157], "genqa": [96, 157], "genrat": 29, "genrm": [87, 148], "genrmplugin": [88, 149], "gentl": [57, 118, 237], "genus": 234, "geo": [81, 142], "geo170k": [52, 113], "geo3k": [170, 180], "geometr": 142, "geometry3k": [96, 157, 170, 180], "geoqa_r1v_train_8k": [52, 113], "germani": 231, "get": [5, 9, 29, 30, 32, 33, 38, 43, 46, 50, 52, 53, 66, 70, 86, 87, 89, 90, 98, 111, 113, 114, 121, 127, 147, 148, 150, 151, 159, 171, 184, 185, 188, 204, 213, 219, 231, 239, 241, 243], "get_acceler": [188, 219], "get_arg": [98, 159], "get_audio_featur": [53, 114], "get_base_model": [53, 114], "get_chunked_index": [53, 114], "get_config": [53, 114], "get_current_weath": [66, 127], "get_device_nam": 214, "get_ds_config": [188, 219], "get_env_arg": [53, 114], "get_hccl_comm_nam": 214, "get_image_featur": 46, "get_input": 204, "get_input_embed": 219, "get_jinja_templ": 43, "get_kernel": 191, "get_last_lr": 219, "get_length_grouped_indic": [67, 99, 128, 160], "get_logg": [53, 114, 219], "get_loss_scal": [62, 123], "get_mcore_model": [103, 164], "get_metr": [62, 123], "get_mm_input": 11, "get_mm_plugin": 11, "get_model": [53, 114], "get_model_info": 231, "get_model_processor": [53, 91, 114, 152], "get_model_tokenizer_with_flash_attn": [70, 131], "get_model_tokenizer_xxx": [70, 131], "get_npu_backend": 214, "get_npu_devic": 214, "get_npu_format": 214, "get_output": 204, "get_packed_seq_param": [53, 114], "get_parallel_plan": [35, 46], "get_parallel_st": [43, 46], "get_peft_model": [62, 123], "get_per_token_logp": [89, 150], "get_position_id": 46, "get_position_id_func": 46, "get_process_log_level": 219, "get_processor": [53, 60, 66, 103, 114, 121, 127, 164], "get_rank": [188, 219], "get_rope_index": [46, 53, 114], "get_schedul": 219, "get_templ": [53, 60, 66, 91, 114, 121, 127, 152], "get_token": 207, "get_trainable_paramet": [97, 158], "get_veloc": 219, "getapi": 204, "getattr": [43, 219], "getinputcount": 204, "getinputnamealloc": 204, "getinputtypeinfo": 204, "getlogg": 219, "getoutputcount": 204, "getoutputnamealloc": 204, "getshap": 204, "gettensormutabledata": 204, "gettensortypeandshapeinfo": 204, "gflop": 207, "ggerganov": [193, 255, 256], "ggml": [194, 256], "ggml_cann": 255, "gguf": [194, 256], "gib": [67, 70, 128, 131, 194], "gigant": 241, "giou": 214, "git": [8, 13, 22, 32, 33, 55, 60, 61, 64, 67, 68, 91, 95, 105, 116, 121, 122, 125, 128, 129, 152, 156, 166, 174, 175, 178, 179, 180, 181, 184, 193, 196, 197, 199, 212, 219, 221, 224, 228, 230, 239, 248, 249, 255], "git711fa080": 236, "git_lfs_skip_smudg": 245, "gitcd": 224, "gitcod": [55, 116, 174, 181, 230], "gite": 179, "github": [8, 11, 13, 22, 32, 33, 40, 45, 48, 53, 55, 56, 63, 64, 67, 68, 69, 75, 81, 91, 93, 94, 95, 96, 97, 102, 105, 109, 114, 116, 117, 124, 125, 128, 129, 130, 133, 136, 140, 142, 152, 154, 155, 156, 157, 158, 163, 166, 170, 174, 175, 178, 181, 184, 187, 193, 196, 197, 199, 212, 219, 221, 224, 228, 230, 236, 239, 245, 248, 249, 255], "githubusercont": 197, "give": [50, 57, 111, 118, 128, 151, 241], "given": [50, 59, 66, 111, 113, 120, 127, 128, 132, 136, 140, 141, 188, 219, 237], "gkd": [56, 63, 91, 103, 105, 117, 124, 152, 164, 166], "gkd_loss": [67, 128], "glass": [57, 118, 151], "glm": [66, 96, 127, 157], "glm4": [63, 66, 67, 96, 99, 103, 104, 105, 124, 127, 128, 157, 160, 164, 165, 166], "glm4v": [96, 157], "glob": 170, "global": [42, 43, 46, 48, 50, 55, 89, 99, 109, 111, 116, 128, 133, 137, 138, 145, 150, 160, 161, 162, 173, 174, 214, 250], "global_batch_s": [27, 43, 56, 57, 70, 99, 100, 101, 102, 103, 104, 105, 117, 118, 131, 160, 161, 162, 163, 164, 165, 166], "global_fact": 200, "global_grad_norm": 214, "global_profil": [172, 173, 179], "global_rank": 43, "global_step": [43, 70, 82, 87, 131, 143, 148, 219, 241], "global_step_372": 178, "gloo": [67, 99, 128, 160, 180, 181], "gloo_socket_ifnam": [179, 180, 181], "glyph": [96, 157], "gme": [49, 96, 110, 157], "gmmmodel": 214, "gmmswigluqu": 177, "gnu": [181, 194], "go": 241, "goal": [45, 50, 111, 113], "goe": 121, "goi": [96, 157], "goiclevrclevr": [96, 157], "going": 219, "gone": 237, "gongji": [96, 157], "good": [39, 121, 127, 128, 152, 246], "goodtitl": [96, 157], "googl": [47, 96, 121, 157], "got": [96, 157, 184, 215], "govern": 219, "gpqa": [68, 129], "gpro": [67, 128], "gpt": [19, 37, 70, 94, 96, 99, 131, 155, 157, 160, 191, 219], "gpt2": [194, 219, 243], "gpt4": [29, 30, 53, 56, 57, 63, 68, 70, 90, 91, 95, 96, 98, 102, 105, 114, 117, 118, 124, 129, 131, 151, 152, 156, 157, 159, 163, 166], "gpt4all": [96, 157], "gpt4o": [52, 113], "gpt4v": [96, 157], "gpt_lora_sft": 8, "gpt_merg": 8, "gptq": [9, 22, 23, 63, 67, 69, 90, 91, 96, 124, 128, 130, 151, 152, 157], "gptqmodel": [69, 130], "gpu": [7, 9, 15, 20, 22, 35, 38, 41, 42, 44, 45, 48, 50, 52, 56, 64, 67, 82, 89, 90, 91, 93, 99, 100, 101, 102, 103, 109, 111, 113, 117, 118, 124, 125, 126, 128, 143, 150, 151, 152, 154, 158, 160, 161, 162, 163, 164, 166, 170, 174, 180, 181, 194, 197, 210, 219, 256], "gpu1": 9, "gpu_devic": 256, "gpu_id": 9, "gpu_memory_util": [174, 178, 181, 222], "gpus": [0, 9, 22, 35, 38, 42, 46, 48, 70, 109, 111, 113, 117, 125, 128, 152, 154, 160, 165, 166, 210, 219], "gqa": [96, 157, 177, 214], "graceful_exit": [48, 67, 109, 128], "grad": [35, 42, 52, 67, 70, 99, 128, 131, 160, 214], "grad_norm": [98, 113, 128, 159, 160, 172, 173, 249], "gradient": [18, 39, 42, 43, 45, 46, 48, 67, 75, 89, 97, 99, 109, 111, 128, 133, 134, 135, 136, 138, 139, 141, 142, 145, 150, 151, 152, 158, 160, 162, 180, 181, 188, 219], "gradient_accumul": 18, "gradient_accumulation_fus": [70, 105, 131, 166], "gradient_accumulation_step": [8, 9, 17, 24, 48, 50, 51, 52, 53, 55, 56, 57, 58, 63, 67, 68, 70, 89, 100, 101, 109, 111, 112, 113, 114, 116, 117, 118, 119, 124, 128, 129, 131, 150, 161, 162, 219, 222], "gradient_accumulation_stepsm": [101, 162], "gradient_checkpoint": [57, 67, 91, 118, 128, 152, 219], "gradient_checkpointing_kwarg": [67, 70, 91, 99, 128, 131, 152, 160], "gradient_clip": [9, 48, 109, 188, 219], "gradio": [7, 64, 125], "gradio_ipv6": 7, "gradio_root_path": 7, "gradio_server_nam": 7, "gradio_server_port": 7, "gradio_shar": 7, "gradscal": 207, "gradual": [133, 162], "grain": [34, 136, 149, 250], "gram": [67, 87, 128, 148], "grammar": 193, "granular": [99, 139, 142, 160, 172], "graph": [7, 67, 70, 111, 128, 131, 181, 194, 204, 214], "graph_dump": 214, "graph_output": 214, "graphic": [151, 172], "grass": [118, 121], "grassi": 151, "gray": [52, 57, 118, 151], "grayish": [57, 118], "great": 149, "greater": [67, 99, 121, 128, 153, 160, 219], "greedi": [7, 42, 70], "green": [52, 57, 118, 151], "grep": [179, 180, 181, 185, 230], "gretelai": [96, 157], "grew": 237, "grid_thw": [46, 53, 114], "grit": [96, 157], "grm": [95, 96, 156, 157], "grok": [96, 157], "ground": [50, 52, 53, 54, 57, 67, 90, 91, 96, 111, 113, 114, 115, 118, 128, 140, 151, 152, 157, 214, 219], "ground_truth": [52, 62, 89, 95, 113, 123, 150, 156], "ground_truth_box": 214, "group": [16, 35, 38, 41, 46, 50, 52, 57, 59, 61, 62, 67, 73, 76, 77, 81, 89, 93, 94, 96, 97, 99, 101, 110, 111, 113, 118, 120, 122, 123, 128, 134, 135, 137, 138, 142, 151, 152, 154, 155, 157, 158, 160, 162, 170, 188, 200, 201, 214, 215, 219, 222], "group_bi": 222, "group_list": 214, "group_siz": [214, 222], "group_text": 219, "groupadd": 185, "groupedlinear": [99, 160], "groupedmatmul": 214, "groupgemm": [27, 28], "groupsiz": 214, "grow": 234, "grpo": [55, 56, 63, 71, 72, 73, 74, 75, 76, 77, 78, 80, 86, 87, 91, 93, 94, 96, 103, 104, 105, 116, 117, 124, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 147, 148, 152, 154, 155, 157, 164, 165, 166, 172, 173, 174, 178, 181, 222], "grpo_clevr_countdown": [52, 113], "grpo_countdown": [50, 111], "grpo_geoqa": [52, 113], "grpo_train": 179, "grpotrain": [52, 72, 73, 74, 76, 77, 88, 89, 113, 133, 134, 135, 137, 138, 149, 150], "gsm8k": [68, 70, 94, 96, 129, 131, 155, 157, 170, 174, 210], "gsm8k_multiturn_sft": 170, "gspo": [63, 67, 75, 78, 99, 124, 128, 139, 160], "gt": [11, 39, 44, 50, 55, 64, 71, 111, 116, 125, 132, 166, 180, 181, 214], "gt_argmax_overlap": 214, "gt_bbox": 214, "gt_max_assign_al": 214, "gt_max_overlap": 214, "gtbox": 214, "gte": [49, 59, 96, 110, 120, 157], "guanaco_belle_merge_v1": [96, 157], "guanacodataset": [96, 157], "guarante": [51, 112, 219], "guard": [96, 157], "guid": [32, 36, 44, 46, 47, 56, 111, 116, 117, 124, 128, 131, 147, 149, 163, 165, 181, 250], "guidanc": [160, 246, 250], "guidance_scal": 3, "gym_env": [83, 144], "gym_schedul": [83, 144], "gymschedul": [83, 144], "gyromitra": 234, "gz": 29, "h100": [63, 64, 124, 125], "h20": [56, 102], "had": [158, 237, 241], "half": [16, 52, 113, 188, 214, 219, 224], "hallusionbench": [68, 70, 129, 131], "halo": [57, 118], "han": [96, 157], "hand": [57, 90, 118, 130, 150, 151, 241], "handl": [34, 36, 38, 39, 41, 53, 114, 121, 128, 134, 139, 145, 146, 147, 149, 152, 158, 160, 164, 188, 214, 219], "handler": 219, "hang": [46, 114, 118, 166, 249], "hangzhou": [53, 56, 57, 64, 70, 90, 91, 105, 114, 117, 118, 121, 125, 131, 151, 152, 166], "hansen": [69, 130], "happi": [121, 246], "har": 200, "hard": [39, 49, 78, 110, 128, 139, 145], "hardwar": [14, 32, 38, 55, 116, 124, 149, 154, 174, 222, 237], "harmless": [118, 121, 144], "harn": 199, "has": [35, 39, 41, 46, 51, 52, 57, 110, 111, 112, 113, 118, 120, 121, 122, 127, 128, 129, 130, 132, 138, 140, 144, 152, 153, 154, 155, 158, 160, 164, 166, 172, 184, 213, 219, 241], "has_bias": 214, "hasattr": [53, 114, 219], "hasher": 219, "hasn": 131, "hat": [50, 73, 74, 76, 77, 81, 89, 111, 134, 135, 137, 138, 142, 150, 225], "have": [35, 36, 37, 38, 39, 41, 46, 50, 57, 66, 67, 91, 109, 110, 111, 113, 114, 118, 120, 121, 127, 128, 130, 134, 135, 140, 144, 147, 151, 152, 155, 158, 160, 164, 175, 188, 209, 219, 241, 243, 245, 246], "hbm": [55, 116, 185], "hc3": [96, 157], "hccl": [15, 67, 128, 171, 180, 181, 207, 214, 215], "hccl_async_error_handl": [179, 181], "hccl_connect_timeout": [179, 180, 181], "hccl_determinist": 171, "hccl_exec_timeout": [179, 181], "hccl_host_socket_port_rang": [175, 179], "hccl_npu_socket_port_rang": [175, 179], "hccl_op_expansion_mod": [171, 178, 181], "hccl_socket_ifnam": [15, 179, 180, 181], "hcclug": 175, "hcclug_000091": 175, "hccs": [55, 116], "hcom": 214, "hcom_info": 214, "hd": [67, 128], "hdfs_root": 178, "hdk": [14, 175], "he": [51, 112, 237], "head": [9, 38, 46, 67, 92, 99, 120, 149, 153, 170, 179, 180, 181, 214], "head_count": 194, "head_count_kv": 194, "head_dim": [38, 46, 58, 119], "head_dimens": 38, "head_num": 214, "header": 39, "header_end": 11, "header_start": 11, "headnum": [177, 214], "health": [55, 116, 185], "heartwarm": [57, 118], "heavi": 166, "heavili": 155, "height": [11, 46, 53, 114, 121, 225], "helen": 246, "hellaswag": [68, 70, 129, 131], "hello": [37, 56, 57, 96, 117, 118, 121, 157, 231], "help": [7, 34, 39, 43, 48, 50, 51, 53, 56, 57, 60, 61, 63, 66, 88, 91, 96, 102, 105, 109, 111, 112, 114, 117, 118, 121, 122, 124, 127, 128, 144, 149, 152, 153, 157, 160, 163, 164, 166, 188, 199, 213, 219, 237, 246], "helper": [37, 43, 81, 114, 142], "henc": [70, 110, 131, 138], "here": [36, 37, 39, 45, 46, 50, 56, 57, 60, 62, 83, 86, 87, 95, 110, 111, 113, 114, 116, 117, 118, 120, 121, 123, 124, 125, 127, 128, 129, 130, 131, 132, 134, 138, 144, 147, 148, 150, 151, 152, 153, 155, 156, 160, 163, 166, 204, 219, 222, 246], "herm": [53, 60, 66, 67, 114, 121, 127, 128, 178], "hessian": 131, "heterogen": [131, 139, 160], "heun": 225, "heurist": 128, "hey": 243, "hf": [21, 39, 40, 42, 60, 67, 89, 96, 99, 103, 104, 105, 121, 128, 150, 157, 160, 164, 166, 170, 179, 184, 199, 200, 210, 219, 239, 242], "hf_ckpt": 44, "hf_config": [103, 164], "hf_dataset_id": [60, 121], "hf_endpoint": [170, 179, 184, 200, 245], "hf_hub_download": 245, "hf_hub_enable_hf_transf": 170, "hf_hub_log_arg": 199, "hf_hub_token": 7, "hf_infer": 222, "hf_internlm2_1_8b": 210, "hf_internlm2_chat_1_8b": 210, "hf_model": [44, 197], "hf_model_path": 179, "hf_qwen2_1_5b": 210, "hf_qwen2_1_5b_instruct": 210, "hf_token": [230, 239], "hf_weight": 180, "hfargumentpars": 219, "hfdataset": [60, 121], "hfl": [96, 157], "hfrl": [96, 157], "hh": [96, 157], "hh_rlhf_cn": [96, 157], "hh_rlhfharmless_base_cnharmless_base_enhelpful_base_cnhelpful_base_en": [96, 157], "hi": [37, 121], "hiascend": [14, 175, 181], "hidden": [35, 38, 39, 40, 46, 58, 70, 119, 131], "hidden_act": 28, "hidden_dim": [28, 40], "hidden_new": 214, "hidden_s": [28, 39, 46, 58, 119, 188, 219], "hidden_st": [28, 38, 39, 40, 46, 53, 114], "hierarch": 152, "high": [50, 67, 73, 84, 89, 99, 111, 126, 128, 132, 134, 135, 136, 138, 139, 142, 145, 148, 150, 152, 155, 160, 164, 172, 180, 214, 241], "high_perform": 204, "high_school_biolog": 200, "high_school_chemistri": 200, "high_school_computer_sci": 200, "high_school_european_histori": 200, "high_school_geographi": 200, "high_school_government_and_polit": 200, "high_school_macroeconom": 200, "high_school_mathemat": 200, "high_school_microeconom": 200, "high_school_phys": 200, "high_school_psycholog": 200, "high_school_statist": 200, "high_school_us_histori": 200, "high_school_world_histori": 200, "higher": [42, 121, 123, 128, 142, 160, 166, 174, 180, 219, 249], "highest": [50, 111, 128, 129, 141, 219], "highlight": [56, 117, 151], "hilab": [96, 157], "hill": 151, "him": [51, 112, 237], "hing": 7, "his": [51, 112, 237, 241], "hisi_hdc": [14, 15, 183, 193, 230], "hist": 214, "histc": 214, "histor": [125, 128, 166], "histori": [19, 60, 67, 83, 99, 121, 128, 144, 147, 149, 151, 160], "hit": [34, 45], "hiyouga": [8, 11, 13, 14, 15, 22, 96, 157, 170], "hjh0119": [96, 157], "hjt": [96, 157], "hmmm": 219, "hold": [35, 38, 57, 90, 118, 128, 151], "hole": 39, "home": [14, 170, 174, 179, 180, 185, 194, 246, 249], "hood": 121, "hook": [35, 219], "horizont": [121, 127, 219], "hors": [188, 219], "host": [9, 14, 15, 55, 67, 70, 90, 99, 116, 128, 131, 151, 160, 172, 179, 180, 183, 184, 194, 214, 230, 231, 237], "host2devic": 177, "host_ip": 179, "host_port": 179, "hostbound": 181, "hostcpu": 181, "hostfil": 9, "hostnam": [9, 179, 180, 181], "hostname1": 9, "hostpath": [48, 109], "hot": 214, "hou": [96, 157], "hour": 116, "household": [57, 118, 246], "housekeep": 246, "how": [35, 37, 43, 44, 45, 46, 50, 52, 56, 105, 111, 112, 113, 114, 116, 117, 118, 121, 122, 123, 128, 140, 147, 148, 150, 152, 153, 154, 158, 160, 166, 197, 219, 237], "howard": [96, 157], "howev": [35, 38, 43, 45, 50, 73, 111, 123, 128, 134, 135, 136, 139, 142, 149, 155, 160, 164], "hpcai": [96, 157], "hpp": 213, "hpz": [67, 128], "hqq": [7, 22, 63, 67, 91, 124, 128, 152], "hsdp": 215, "html": [26, 56, 117, 175, 181, 213, 219], "http": [9, 21, 26, 53, 57, 58, 67, 70, 88, 90, 91, 99, 114, 118, 119, 128, 131, 149, 151, 152, 160, 179, 213, 219, 231, 243], "https": [2, 8, 9, 11, 13, 14, 22, 32, 33, 40, 47, 48, 49, 53, 55, 56, 57, 63, 64, 67, 68, 69, 75, 81, 87, 90, 93, 94, 95, 97, 102, 105, 110, 114, 116, 117, 118, 124, 125, 128, 129, 130, 133, 136, 140, 142, 148, 151, 154, 155, 156, 158, 160, 163, 166, 170, 174, 175, 178, 179, 181, 183, 184, 185, 193, 196, 197, 199, 200, 206, 209, 212, 219, 221, 224, 227, 228, 230, 233, 236, 239, 243, 244, 245, 248, 249, 255, 256], "httpsconnectionpool": 184, "huang": [67, 91, 128, 152], "huangjintao": [96, 157], "hub": [0, 7, 14, 41, 56, 61, 67, 70, 97, 99, 117, 122, 128, 131, 158, 160, 191, 219, 234, 245], "hub_kernel": 41, "hub_model_id": [53, 56, 57, 63, 69, 114, 117, 118, 124, 130, 219], "hub_private_repo": [69, 130], "hub_token": [53, 56, 57, 63, 69, 114, 117, 118, 124, 130, 219], "hub_util": 219, "hug": [0, 7, 9, 13, 46, 49, 59, 67, 96, 110, 120, 128, 130, 152, 157, 160, 163, 165, 166, 180, 181, 191, 194, 234, 237], "huge": [96, 157], "hugepag": [55, 116, 185], "huggingfac": [7, 9, 11, 13, 21, 24, 36, 39, 40, 42, 46, 53, 56, 60, 61, 63, 67, 69, 79, 91, 96, 99, 114, 117, 121, 122, 124, 128, 131, 140, 160, 178, 179, 181, 184, 190, 191, 210, 219, 237, 239, 242, 243, 248, 249, 256], "huggingface_hub": [219, 245], "huggingfacefw": [96, 157, 219], "huggingfaceh4": [96, 157, 243], "huggingfacem4": [96, 157], "huggingfacetb": [96, 157], "human": [17, 19, 37, 60, 96, 121, 123, 124, 126, 128, 153, 157, 200, 237], "human_ag": 200, "human_handwrit": [53, 57, 103, 104, 114, 118, 164, 165], "human_sexu": 200, "humanev": [68, 70, 129, 131], "humanllm": [96, 157], "humor": [57, 118], "hunyuan": [96, 157], "hunyuanocr": [96, 157], "hwcn": 214, "hwhiaiuser": [14, 185], "hwhiaiusersudo": 185, "hx": 214, "hybrid": [99, 128, 160], "hybridengin": 181, "hydra": 222, "hydra_full_error": [179, 181], "hyperparamet": [89, 113, 126, 128, 136, 150, 153, 155, 157, 219], "hysteresi": [9, 48, 109, 188, 219], "i32": 194, "ia3": [62, 123], "ia3_config": [62, 123], "ia3config": [62, 123], "icecream": [96, 157], "icl_gen_inferenc": 210, "icl_inferenc": 210, "ictnlp": [96, 157], "id": [42, 46, 48, 53, 55, 56, 57, 60, 61, 63, 67, 68, 69, 70, 71, 86, 88, 90, 91, 94, 96, 97, 99, 100, 109, 114, 116, 117, 118, 121, 122, 124, 128, 129, 130, 131, 132, 149, 151, 152, 155, 157, 158, 160, 161, 174, 179, 180, 181, 185, 210, 219, 231, 245, 246], "idea": [45, 96, 120, 133, 134, 142, 157], "ideal": 142, "idefics3": [96, 157], "ident": [8, 20, 24, 128, 136, 142, 154, 160, 222], "identifi": [35, 41, 117, 120, 219], "idl": [38, 45], "ids": [42, 43, 45, 46, 66, 67, 70, 122, 128, 131], "idx": 28, "idx_list": [53, 114], "ieityuan": [96, 157], "if": [28, 29, 30, 34, 35, 36, 37, 38, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 56, 57, 58, 60, 62, 67, 70, 71, 79, 81, 85, 86, 87, 90, 91, 93, 98, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 135, 140, 142, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 170, 172, 173, 175, 178, 179, 180, 181, 184, 187, 188, 197, 203, 204, 207, 213, 214, 215, 219, 221, 222, 231, 241, 244, 245, 246, 249], "ifa": 214, "ifconfig": [15, 179, 180, 181], "ifev": [68, 129], "ifmr": 214, "ifnam": [179, 180, 181], "ifnotpres": [48, 109], "ignor": [48, 61, 66, 67, 109, 113, 117, 120, 122, 127, 128, 147, 160, 170, 219, 241], "ignore_data_skip": [67, 128], "ignore_empty_think": [56, 66, 67, 117, 127, 128], "ignore_error": [68, 129], "ignore_index": 45, "ignore_non_elastic_batch_info": [48, 109], "ignore_pad_token_for_loss": 7, "ignore_pattern": 219, "ih": 214, "iic": [49, 96, 110, 157], "ill": [234, 241], "illustr": [38, 147, 148], "ilsvrc2012_val_00005844": 234, "im_end": [49, 53, 59, 61, 66, 110, 114, 120, 122, 127, 210], "im_start": [53, 59, 61, 66, 114, 120, 122, 127, 210], "imag": [3, 11, 19, 29, 30, 33, 34, 38, 42, 48, 49, 52, 53, 57, 58, 59, 60, 66, 67, 83, 86, 89, 90, 91, 96, 97, 104, 109, 110, 113, 114, 118, 119, 120, 124, 125, 127, 128, 144, 147, 150, 151, 152, 157, 158, 160, 164, 165, 166, 170, 172, 176, 188, 194, 197, 204, 207, 213, 219, 230, 233, 243], "image_capt": [96, 157], "image_column": 219, "image_dataset": 219, "image_dummi": 243, "image_emb": 46, "image_featur": 207, "image_gflop": 207, "image_grid": 219, "image_grid_thw": [11, 46, 53, 114], "image_input": [57, 118], "image_interpolation_mod": 219, "image_key": 42, "image_load": 219, "image_mask": 46, "image_mask_1d": 46, "image_max_pixel": 7, "image_max_token_num": [57, 67, 103, 118, 128, 164], "image_mcq": [70, 131], "image_min_pixel": 7, "image_mparam": 207, "image_nam": 230, "image_patch_s": [57, 118], "image_path": [29, 30, 204], "image_path1": [52, 113], "image_path2": [52, 113], "image_processor": [53, 114], "image_s": 207, "image_token": 11, "image_width": 207, "image_zoom_in_tool": [79, 140], "imagefold": 219, "imageinput": 11, "imagenet": [207, 234], "imagenet1k": 37, "imagenet_class": 204, "imagepath": 213, "imagepullpolici": [48, 109], "images1": [49, 110], "images2": [49, 110], "images_emb": [53, 114], "imagetoimagepipelin": 243, "imagin": [57, 118], "imbal": [128, 160], "img": [79, 140, 204, 213, 219, 243], "img2img": 225, "img_siz": [58, 70, 119, 131, 234], "img_str": 219, "imgcodec": 213, "imglen": 11, "imit": 133, "iml": [48, 109], "immedi": [35, 37, 172], "impact": [38, 117, 128, 160], "imper": 39, "impira": 243, "impl": [67, 85, 99, 128, 160, 214], "implement": [28, 35, 38, 39, 43, 82, 85, 112, 114, 117, 122, 123, 128, 132, 133, 135, 136, 137, 142, 144, 145, 146, 147, 148, 149, 150, 154, 156, 159, 160, 164, 219, 249], "impli": [83, 86, 128, 144, 147, 219], "implicit": [153, 160], "import": [2, 3, 11, 14, 21, 27, 29, 30, 36, 37, 38, 40, 41, 43, 45, 46, 52, 53, 55, 56, 57, 58, 59, 60, 65, 66, 67, 78, 79, 81, 85, 87, 88, 89, 90, 91, 93, 97, 98, 99, 103, 110, 111, 113, 114, 116, 117, 118, 119, 120, 121, 123, 126, 127, 128, 136, 139, 140, 145, 146, 148, 149, 150, 151, 152, 154, 155, 156, 158, 159, 160, 164, 172, 173, 179, 188, 191, 196, 197, 204, 206, 207, 209, 213, 214, 215, 218, 219, 222, 230, 231, 233, 234, 236, 237, 239, 241, 243, 244, 245, 246, 252], "import_util": 219, "importance_sampling_level": [75, 136], "importance_weight": [73, 75, 134, 136], "importerror": [41, 219], "impos": [135, 153], "imposs": 133, "impract": 154, "impress": [57, 118], "impressionist": [57, 118], "improv": [34, 38, 46, 82, 94, 97, 111, 113, 119, 124, 128, 132, 139, 143, 148, 149, 150, 152, 153, 155, 158, 160, 172, 214], "imread": 213, "imssokn1ijbaraz0ilawdfsutbvdjmz9j": 245, "imwrit": 213, "in": [9, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 56, 57, 58, 62, 66, 67, 71, 72, 79, 80, 83, 85, 86, 87, 88, 90, 91, 92, 93, 99, 103, 104, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 170, 173, 179, 180, 181, 187, 188, 191, 193, 194, 204, 213, 219, 222, 230, 231, 234, 237, 241, 243, 246, 249, 250], "in_channel": 214, "in_height": 214, "in_id": [57, 118], "in_proj": [97, 158], "in_width": 214, "inaccur": 155, "inc": [96, 157, 219], "incentiv": [87, 128, 148, 160], "includ": [9, 32, 33, 36, 39, 46, 47, 56, 57, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132, 135, 138, 147, 148, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 162, 164, 166, 172, 188, 194, 204, 212, 213, 219, 237, 241, 245], "include_effective_tokens_per_second": 7, "include_path": 199, "inclusionai": [96, 157], "incompat": [114, 131, 160], "inconsist": [131, 166, 219], "incorpor": [150, 155, 166], "incorrect": [43, 89, 128, 135, 148, 150], "incr": [99, 160], "incre_flash_attent": 214, "increas": [70, 111, 113, 121, 123, 128, 134, 135, 139, 148, 152, 160, 166], "incred": 237, "increflashattent": 214, "increment": [128, 152, 160, 163, 164], "incur": [38, 131], "inde": 131, "indent": [29, 30], "independ": [57, 118, 120, 122, 124, 126, 128, 136, 137, 138, 141, 149, 150, 160, 231], "index": [44, 51, 53, 55, 58, 60, 83, 86, 112, 114, 116, 119, 121, 127, 129, 144, 147, 154, 172, 174, 214, 219, 221, 224, 230, 231], "index_add_": 28, "indic": [40, 52, 109, 111, 113, 117, 121, 122, 127, 128, 131, 135, 142, 145, 146, 151, 153, 156, 158, 160, 188, 214, 219], "individu": [50, 52, 111, 128, 147], "inductor": 237, "ineffect": 128, "inet": [179, 180, 181], "inf": [49, 110, 219], "infer": [3, 21, 45, 47, 49, 53, 55, 56, 57, 58, 62, 63, 67, 68, 71, 86, 88, 89, 90, 91, 100, 102, 103, 104, 105, 111, 120, 121, 122, 123, 124, 125, 126, 129, 130, 132, 140, 148, 149, 150, 155, 158, 160, 161, 162, 164, 165, 166, 172, 184, 201, 204, 210, 219, 222, 234, 237, 244, 249, 250], "infer_async": [90, 151], "infer_backend": [7, 21, 55, 56, 58, 63, 67, 68, 71, 79, 90, 91, 116, 117, 119, 124, 128, 129, 132, 140, 151, 152], "infer_batch_s": 222, "infer_dtyp": 7, "infer_engin": [53, 57, 62, 90, 91, 114, 118, 123, 151, 152], "infer_hf": [53, 114], "infer_ppo_max_token_len": [180, 181], "infer_request": [53, 57, 62, 79, 83, 86, 90, 91, 95, 114, 118, 123, 140, 144, 147, 151, 152, 156], "infer_tp": 178, "inferargu": [70, 131], "infercli": [70, 90, 131, 151], "inference_config": 21, "inference_param": [98, 159], "inferencemod": 249, "inferenceparam": [98, 159], "inferencesess": 204, "inferrequest": [53, 57, 62, 90, 91, 95, 114, 118, 123, 151, 152, 156], "inferstat": [90, 151], "infin": [96, 157], "infiniai": [96, 157], "infinig": [96, 157], "influenc": 142, "info": [7, 14, 35, 48, 55, 60, 61, 67, 70, 83, 86, 88, 109, 116, 121, 122, 128, 131, 140, 144, 147, 149, 170, 183, 185, 187, 193, 199, 210, 219, 230, 231], "info_onc": [53, 114], "info_rank0": 43, "infom": 35, "infonc": [67, 128], "infonce_fake_neg_margin": [49, 110], "infonce_hard_neg": [49, 110], "infonce_include_dd": [49, 110], "infonce_include_qq": [49, 110], "infonce_mask_fake_neg": [49, 110], "infonce_temperatur": [49, 110], "infonce_use_batch": [49, 110], "inform": [42, 46, 56, 91, 114, 116, 117, 118, 120, 121, 127, 128, 129, 131, 140, 143, 144, 146, 148, 151, 152, 155, 157, 158, 159, 160, 163, 166, 172, 188, 219, 246], "infovqa_test": [68, 70, 129, 131], "infovqa_v": [68, 70, 129, 131], "infrastructur": 46, "ing": 128, "inher": 131, "inherit": [36, 39, 43, 114, 128, 160], "init": [41, 42, 43, 55, 62, 67, 95, 99, 116, 123, 128, 160, 172, 173, 180, 181, 219, 224], "init_devic": [27, 31, 43], "init_distribut": [188, 219], "init_kl_coef": 222, "init_lora_weight": [70, 131], "init_megatron_env": [55, 116], "init_method": 214, "init_parallel_st": 43, "init_process_group": [214, 215], "init_processor": [53, 114], "init_track": 219, "initacl": 213, "initi": [36, 38, 42, 67, 70, 99, 111, 113, 114, 123, 126, 128, 131, 138, 144, 148, 149, 153, 156, 160, 170, 172, 173, 184, 188, 204, 215, 219, 237, 244], "initial_global_step": 219, "initial_scale_pow": [9, 48, 109, 188, 219], "initil": [88, 149], "inlin": 39, "inner": [83, 86, 110, 144, 147], "inner_k_til": 214, "inner_precis": 214, "inner_sqrt": [83, 86, 144, 147], "innerprecis": 214, "innoc": [57, 118], "innov": 38, "inplac": [53, 114], "input": [11, 19, 37, 38, 42, 46, 51, 53, 57, 60, 66, 67, 80, 86, 88, 90, 93, 99, 110, 111, 112, 113, 114, 118, 120, 121, 127, 128, 132, 140, 141, 144, 147, 148, 149, 150, 151, 153, 154, 160, 188, 191, 204, 207, 213, 214, 219, 228, 249], "input1": 214, "input_": [98, 159, 214], "input_data": 204, "input_data_s": 204, "input_dir": 219, "input_dtyp": 39, "input_emb": [46, 53, 114], "input_featur": [53, 114], "input_id": [36, 46, 53, 57, 60, 66, 98, 114, 118, 121, 127, 128, 159, 191, 219, 241, 246], "input_ids_hf": [53, 114], "input_ids_swift": [53, 114], "input_layout": 214, "input_nam": 204, "input_names_ptr": 204, "input_node_nam": 204, "input_node_shap": 204, "input_path": 27, "input_perturb": 219, "input_prepar": 204, "input_s": 234, "input_tensor": [204, 214], "inputlayout": 214, "inputs_emb": [46, 53, 90, 114, 151], "inquiri": [91, 122, 152], "insepar": 237, "insert": [53, 114, 121, 127, 128], "insid": [35, 83, 86, 110, 120, 131, 144, 147, 149, 150, 159, 172], "insight": [172, 173, 177, 179], "inspir": [36, 39], "inst": [60, 96, 121, 157], "instabl": [45, 111, 113, 139, 142], "instal": [2, 5, 8, 13, 14, 22, 26, 39, 41, 43, 48, 53, 55, 56, 57, 60, 61, 64, 68, 69, 70, 90, 91, 95, 98, 105, 114, 117, 118, 121, 122, 126, 129, 130, 151, 152, 156, 160, 166, 170, 174, 175, 178, 179, 181, 183, 184, 185, 187, 188, 190, 194, 196, 199, 201, 203, 204, 206, 209, 212, 219, 221, 222, 224, 227, 230, 233, 236, 239, 241, 244, 245, 248, 252], "install_deepspe": 14, "install_requir": 236, "install_sglang_mcore_npu": 175, "instanc": [35, 50, 111, 117, 121, 125, 128, 158, 159, 172, 219], "instantan": 219, "instanti": [123, 219], "instead": [28, 35, 39, 41, 44, 46, 117, 118, 121, 122, 128, 136, 142, 145, 152, 159, 160, 164, 166, 172, 219, 237, 241, 243, 249], "instinwild": [96, 157], "instruct": [9, 10, 11, 16, 17, 19, 20, 21, 23, 24, 27, 29, 30, 34, 40, 43, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 63, 67, 68, 79, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 110, 111, 112, 113, 116, 117, 118, 119, 120, 121, 124, 128, 129, 140, 144, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 163, 164, 165, 166, 170, 174, 178, 180, 194, 200, 210, 222, 230, 231, 241, 243, 245, 246], "instructionninput": 19, "instruet": [70, 131], "instrument": 172, "insuffici": [120, 166], "int": [7, 11, 18, 20, 38, 40, 42, 43, 44, 50, 53, 67, 70, 71, 74, 86, 100, 104, 111, 114, 128, 131, 132, 135, 147, 161, 165, 179, 180, 181, 188, 204, 213, 214, 219], "int16": 214, "int32": [46, 214], "int32_t": 214, "int4": [7, 90, 96, 151, 157, 214], "int64": 214, "int64_t": [204, 214], "int8": [96, 157, 214], "int_max": 214, "int_nax": 214, "integ": [51, 60, 66, 112, 121, 127, 150, 154, 162], "integr": [28, 37, 38, 40, 41, 53, 85, 110, 114, 123, 124, 131, 133, 137, 138, 146, 149, 150, 157, 160, 162, 164, 172, 193, 219], "intel": [96, 157], "intellect": [67, 99, 128, 160], "intellig": [56, 91, 117, 124, 152, 237], "intend": [34, 37, 128, 160], "intens": [57, 118, 128, 131], "inter": 135, "interact": [35, 66, 124, 127, 128, 140, 143, 149, 151, 152, 172, 237], "intercept": 41, "interconnect": 116, "interest": [35, 151, 188, 214, 219], "interf": 158, "interfac": [46, 123, 124, 126, 128, 140, 149, 151, 152, 159, 172], "interleav": [7, 37, 67, 128, 131], "interleave_dataset": [67, 128], "interleave_ov": 7, "interleave_prob": [7, 70], "interleave_und": 7, "intermedi": [35, 38, 160, 164], "intermediate_dim": 40, "intermediate_s": [28, 58, 119], "intermediate_tensor": [172, 173], "intern": [96, 114, 119, 128, 133, 154, 157, 158, 159, 172, 249], "internal_vqa": 37, "international_law": 200, "internet": 47, "internlm": [96, 157, 196, 197, 210], "internlm2": [96, 157, 197, 210], "internlm2_5": 197, "internlm3": [63, 70, 96, 124, 131, 157], "interns1": [96, 157], "internvl": [96, 157], "internvl2": [60, 70, 96, 121, 131, 157, 197], "internvl3": [55, 63, 71, 96, 104, 116, 124, 132, 157, 165], "internvl3_5": [104, 165], "interpol": [132, 160, 161, 219, 234], "interpolationmod": 219, "interpret": 128, "intersect": [52, 113, 214], "interv": [48, 67, 109, 128, 135, 142, 148, 160, 188, 219], "intervent": [67, 128], "into": [28, 37, 41, 45, 50, 52, 56, 75, 83, 86, 110, 111, 113, 117, 119, 120, 121, 122, 123, 127, 128, 133, 136, 137, 138, 140, 143, 144, 147, 148, 150, 152, 153, 154, 156, 158, 160, 164, 172, 214, 219, 234, 237], "intra": [128, 137, 138, 150], "intric": [3, 234], "introduc": [35, 38, 40, 45, 56, 110, 111, 114, 116, 117, 118, 121, 122, 123, 128, 133, 135, 136, 138, 139, 151, 153, 157, 160, 163, 164, 165, 166, 197, 246], "introduct": [121, 128], "inttensor": 214, "intuit": 172, "invalid": [42, 70, 140, 154, 162, 219], "inventori": 237, "invers": [99, 160], "invis": [128, 160], "invoc": 151, "invoic": 243, "invok": [123, 140, 151], "involv": [38, 46, 111, 119, 123, 128, 129, 144, 148, 153, 155, 166, 172], "io": [14, 48, 56, 109, 117, 176, 181], "iof": 214, "iostream": [204, 213], "iou": 214, "iou_threshold": 214, "ip": [7, 9, 15, 89, 179, 180, 181], "ipc": 230, "iphon": 243, "ipo": [7, 99, 160], "ipv6": 7, "ipynb": [63, 124], "ipython": 11, "iqaactivitynet": [96, 157], "iquest": [96, 157], "iquestcod": [96, 157], "iquestlab": [96, 157], "iquiz": [68, 129], "iron": 246, "irrelev": [120, 139], "irrelevant_doc1": [59, 120], "irrelevant_doc2": [59, 120], "is": [28, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 57, 61, 62, 66, 67, 75, 83, 85, 86, 89, 90, 91, 98, 99, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 172, 173, 174, 179, 180, 181, 184, 188, 191, 197, 213, 214, 219, 221, 222, 230, 231, 241, 243, 244, 246, 249], "is_avail": [14, 207, 219, 241, 244, 246], "is_compiled_modul": 219, "is_cross": 214, "is_deepspeed_en": [53, 114], "is_deepspeed_zero3_en": [53, 114], "is_initi": 219, "is_last_round": [62, 123], "is_local_main_process": 219, "is_main_process": 219, "is_multimod": [53, 114], "is_npu_avail": 175, "is_peft_format": [103, 164], "is_ratio": [89, 150], "is_torch_npu_avail": [55, 116], "is_torch_xla_avail": 219, "is_trac": 46, "is_train": [53, 114, 219], "is_wandb_avail": 219, "is_weight_mean": [81, 89, 142, 150], "is_xformers_avail": 219, "isident": [96, 157], "isinst": [37, 53, 114, 219], "isn": [50, 111], "isol": [8, 13, 56, 105, 117, 166], "issu": [35, 40, 45, 46, 52, 56, 57, 64, 67, 70, 87, 88, 89, 90, 105, 109, 113, 114, 117, 118, 125, 128, 134, 135, 139, 142, 147, 148, 149, 150, 151, 152, 155, 156, 157, 160, 164, 166], "issuecom": [75, 136], "ista": [96, 157], "it": [14, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 50, 51, 52, 56, 57, 83, 86, 87, 96, 102, 103, 104, 105, 110, 111, 112, 113, 114, 117, 118, 120, 121, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 135, 136, 137, 138, 140, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 172, 184, 188, 193, 194, 197, 203, 213, 214, 219, 230, 241, 243, 244, 249], "itd": [14, 15, 183], "item": [29, 30, 46, 52, 55, 57, 110, 113, 116, 118, 120, 122, 160, 188, 214, 219], "iter": [30, 37, 42, 43, 67, 70, 82, 89, 98, 99, 101, 128, 131, 143, 150, 155, 159, 160, 162, 172, 173, 179, 188, 219, 237], "iter_xxx": [105, 166], "iterabledataset": [37, 67, 128, 219], "iterabledatasetdict": 219, "iterativedataset": [42, 43], "itertool": 219, "itm": [96, 157], "itmcoco": [96, 157], "its": [35, 37, 46, 53, 57, 109, 110, 111, 114, 118, 119, 122, 123, 128, 129, 131, 134, 138, 142, 147, 155, 160, 164, 243], "itself": [117, 127, 132, 138, 141, 155], "iw": 214, "ixcomposer2": [96, 157], "j5": 212, "janus": [91, 96, 152, 157], "jave": [96, 157], "jax": 0, "jd": [96, 157], "jemalloc": 180, "jensen": [100, 161], "jexp": 214, "jfk": 256, "jia": [35, 178, 181], "jiahao": 194, "jina": [96, 157], "jinaai": [96, 157], "jingyaogong": [96, 157], "jinja": [43, 67, 70, 128, 131], "jit": [7, 46, 187], "jitter": [188, 219], "jllllll": 22, "job": [9, 48, 109, 170], "job_id": 170, "join": [215, 219], "joint": 119, "josephuscheung": [96, 157], "jpeg": [197, 234], "jpg": [29, 49, 57, 59, 60, 70, 110, 118, 120, 121, 131, 204, 207, 243], "jsd": [99, 100, 160, 161], "jsd_loss": [99, 160], "json": [7, 8, 9, 11, 18, 19, 23, 25, 29, 30, 42, 44, 47, 48, 49, 56, 61, 63, 66, 67, 68, 79, 87, 90, 91, 96, 97, 99, 102, 109, 110, 117, 122, 124, 127, 128, 129, 140, 148, 151, 152, 154, 157, 158, 160, 163, 179, 184, 193, 199, 219, 231, 245, 253], "json_fil": 219, "json_path": 179, "json_to_parquet": 179, "jsonl": [56, 57, 60, 67, 68, 71, 83, 95, 117, 118, 121, 128, 129, 132, 144, 156, 219], "jsonlin": 68, "jsonstr": [67, 93, 128], "judg": [58, 59, 119, 120, 121], "judge0_endpoint": [51, 112], "judge0_x_auth_token": [51, 112], "judge_kwarg": [70, 131], "judgment": [120, 135, 143], "juicer": [70, 131], "jump": 228, "junctur": 141, "juntian": 46, "jupyt": [67, 128, 172, 173], "jupyterlab": [172, 173], "jurisprud": 200, "just": [37, 43, 46, 57, 118, 140, 151, 184, 187, 219, 230, 245], "jxi": [96, 157], "jxu124": [96, 157], "k1": 214, "k15qrjlykifslz": 245, "k2": [96, 157, 214], "k2hdnftkt9kladg8hhfqmgwuhdtjsvcezjirkwptzrf0dohepoiohocqw": 245, "k3": [81, 89, 142, 150], "k3_kl": [81, 89, 142, 150], "k8s": [48, 70, 109, 131], "k_bia": 38, "k_proj": [67, 99, 128, 160], "k_weight": 38, "kahneman": 17, "kaim": 67, "kaiming_norm": 128, "kaiming_uniform": [18, 128], "kd": [67, 99, 128, 160], "keep": [39, 40, 41, 46, 52, 56, 67, 70, 95, 110, 113, 117, 128, 147, 160, 166, 214, 219], "keep_linebreak": 219, "keep_prob": 214, "keepdim": [207, 214], "keepprob": 214, "kept": [41, 46, 156], "kernel": [0, 2, 34, 39, 41, 45, 55, 56, 63, 67, 97, 116, 117, 124, 128, 158, 160, 174, 175, 176, 177, 181, 185, 193, 197, 199, 206, 209, 212, 221, 227, 233, 236, 239, 248, 249, 252, 255], "kernel_config": 191, "kernel_map": 191, "kernel_s": 214, "kernelconfig": 191, "kernels_8": 14, "key": [5, 7, 35, 38, 40, 42, 49, 50, 51, 53, 56, 58, 60, 62, 67, 95, 96, 97, 99, 110, 111, 112, 113, 114, 117, 119, 121, 123, 126, 128, 134, 138, 141, 143, 144, 147, 148, 150, 156, 157, 158, 160, 194, 204, 214, 219, 245, 253], "key_antiquant_mod": 214, "key_antiquant_offset": 214, "key_antiquant_scal": 214, "key_bia": 214, "key_lay": 214, "key_r": 214, "key_shared_prefix": 214, "key_transpos": 214, "key_weight": 214, "keyerror": [70, 131], "keys_to_ignore_at_infer": [53, 114], "keyword": [121, 127], "kh": 214, "kid": 241, "kill": [70, 81, 126, 131, 142], "kimi": [83, 96, 104, 144, 157, 165], "kind": [48, 109, 219, 237], "kitten": [57, 118, 121, 151], "kl": [7, 50, 52, 67, 75, 89, 92, 94, 99, 100, 111, 113, 128, 136, 150, 153, 155, 160, 161, 177, 181], "kl_coef": [174, 178], "kl_ctrl": [174, 178], "kl_in_reward": [67, 76, 77, 99, 128, 137, 138, 160], "kl_loss_coef": [174, 178, 181], "kl_loss_typ": 174, "kl_penalti": [89, 150], "knextpoweroftwo": 204, "know": [39, 56, 57, 66, 83, 86, 117, 118, 121, 127, 144, 147, 219], "knowledg": [71, 100, 132, 155, 161], "known": [128, 160], "kol": [96, 157], "kt": 214, "kto": [7, 24, 56, 63, 67, 91, 96, 104, 105, 117, 124, 128, 152, 157, 165, 166], "kto_chosen_weight": 7, "kto_en_demo": 17, "kto_pair": 7, "kto_rejected_weight": 7, "kto_tag": 19, "ktoconfig": 160, "ktyc": 245, "kubernet": [48, 109, 131], "kv": [7, 67, 82, 128, 177, 181, 194, 214, 230, 256], "kv_padding_s": 214, "kvcach": 214, "kvpaddings": 214, "kw": 214, "kwai": [96, 157], "kwarg": [36, 45, 46, 47, 50, 52, 53, 56, 62, 67, 85, 86, 87, 88, 95, 97, 98, 99, 111, 113, 114, 117, 123, 128, 146, 147, 148, 149, 156, 158, 159, 160, 172, 173, 210, 219], "l1": [96, 157], "l111": [49, 110], "l118": [105, 166], "l2": [92, 99, 153, 160], "l24": 128, "l264": 11, "l6": 228, "lab": [52, 57, 71, 96, 113, 117, 118, 132, 157], "label": [19, 38, 43, 45, 49, 53, 57, 60, 62, 66, 67, 92, 98, 99, 104, 110, 114, 118, 121, 123, 127, 128, 153, 159, 160, 161, 165, 188, 204, 207, 214, 215, 219, 234, 241, 243, 244, 249], "label_pad_token_id": 249, "laboratori": [96, 157], "lag": 172, "laion": [96, 157], "lam": [67, 92, 128, 153], "lambada": [68, 70, 129, 131], "lambda": [67, 71, 92, 128, 132, 153, 188, 219], "lambdalab": 219, "lampoon": 243, "lanczo": 219, "lang": [7, 20, 65, 67, 126, 128, 256], "langboat": [96, 157], "languag": [16, 38, 51, 56, 57, 58, 71, 81, 97, 105, 112, 117, 118, 120, 128, 132, 135, 141, 142, 155, 158, 166, 194, 219, 237], "language_model": [40, 46, 53, 67, 98, 114, 128, 159], "larg": [38, 39, 42, 43, 44, 45, 46, 52, 56, 57, 81, 96, 97, 117, 118, 119, 120, 121, 123, 124, 128, 134, 139, 140, 141, 142, 149, 150, 151, 152, 153, 155, 158, 160, 162, 164, 165, 166, 172, 173, 194, 219, 245, 256], "larger": [35, 89, 110, 111, 113, 128, 134, 139, 142, 148, 150, 153, 155, 160, 219], "largersokoban": 222, "largest": 128, "lark": [67, 128], "last": [43, 45, 51, 63, 67, 99, 105, 111, 112, 121, 123, 124, 128, 144, 147, 160, 163, 166, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 219, 230], "last_hidden_st": [49, 53, 110, 114], "last_model": [128, 160], "last_round": [67, 86, 128, 147], "lastroundlossscal": [62, 123], "latenc": 38, "latent": 219, "latent_dist": 219, "later": [34, 46, 111, 131], "latest": [14, 15, 56, 117, 124, 128, 150, 170, 176, 181, 194, 197, 199, 212, 219, 224, 230, 236, 252], "latest_checkpointed_iter": [105, 166], "latex": [54, 57, 104, 115, 118, 165], "latex_ocr": [53, 57, 96, 103, 104, 114, 118, 157, 164, 165], "latter": [111, 113, 128], "launch": [9, 15, 26, 37, 38, 43, 112, 113, 117, 126, 128, 129, 150, 152, 159, 160, 163, 172, 219, 231], "launch_serv": [179, 230, 231], "launcher": [188, 219], "laundri": 246, "law": [96, 157, 219], "lawyer_llama_data": [96, 157], "layer": [7, 16, 18, 35, 38, 40, 45, 46, 67, 97, 99, 110, 114, 128, 150, 151, 152, 158, 159, 160, 164, 166, 172, 188, 194, 219], "layer_idx": 39, "layer_norm": 214, "layer_norm_rms_epsilon": 194, "layer_num": 46, "layernorm": [7, 38, 99, 160, 214], "layerwis": [97, 158], "layout": [40, 99, 160, 194, 214], "lazi": [67, 91, 99, 128, 152, 160, 228], "lazy_token": [70, 128, 131], "lccl": 171, "lccl_determinist": 171, "lcsts": [68, 70, 129, 131], "ld": [67, 92, 128, 153], "ld_library_path": 230, "ld_preload": [178, 180, 181], "ldot": [71, 132], "le": [51, 112], "lead": [50, 111, 128, 134, 135, 136, 139, 148, 153, 155, 156, 160, 172, 222], "leaf": 35, "leaf_vari": [53, 114], "leakag": 110, "learn": [17, 42, 50, 57, 67, 71, 97, 99, 110, 111, 113, 118, 120, 123, 126, 128, 133, 134, 138, 139, 144, 147, 152, 153, 155, 158, 160, 184, 219, 241, 248, 249], "learning_r": [3, 8, 9, 17, 24, 48, 50, 51, 52, 53, 55, 56, 57, 58, 63, 68, 70, 109, 111, 112, 113, 114, 116, 117, 118, 119, 124, 128, 129, 131, 160, 219, 222, 249], "learnt": 219, "least": [117, 121, 140, 215, 219], "leav": 219, "leetcod": [96, 157], "left": [7, 18, 50, 53, 67, 71, 73, 75, 77, 78, 81, 84, 89, 92, 99, 111, 114, 125, 128, 132, 134, 136, 138, 139, 141, 142, 145, 150, 153, 160, 210, 219], "leftupcasu": 214, "leftupcaus": 214, "leg": [57, 118, 151], "legaci": [40, 53, 60, 67, 114, 121, 128], "legend": [52, 55, 113, 116], "len": [43, 45, 50, 53, 57, 67, 87, 99, 111, 114, 118, 128, 148, 160, 180, 191, 210, 214, 219], "len_train_dataloader_after_shard": 219, "length": [38, 42, 43, 45, 46, 50, 51, 52, 67, 74, 86, 87, 89, 91, 99, 110, 111, 112, 113, 121, 127, 128, 135, 145, 147, 148, 150, 152, 153, 160, 166, 194, 214, 219, 222, 241], "length_penalti": 7, "leonardpku": [96, 157], "leq": [74, 81, 135, 142], "less": [40, 120, 128, 131, 142, 158, 160, 172], "let": [35, 38, 46, 50, 52, 56, 57, 62, 111, 117, 118, 123, 153, 171, 188, 219, 243], "level": [15, 39, 41, 45, 67, 70, 75, 76, 78, 81, 84, 89, 98, 99, 101, 111, 126, 128, 131, 136, 137, 139, 142, 145, 150, 153, 154, 159, 160, 162, 172, 173, 180, 191, 213, 219], "level0": [172, 173], "level1": [98, 159, 172, 173, 177], "level2": [172, 173], "level_non": [172, 173], "levelnam": 219, "leverag": [121, 140, 150, 172], "lf": 194, "li2zhi": [82, 143], "lib": [48, 109, 178, 180, 181, 187, 212, 222], "lib64": [193, 212, 230], "libascend_h": 197, "libjemalloc": [178, 180, 181], "libjemalloc2": 181, "librari": [39, 53, 70, 114, 118, 128, 148, 149, 151, 152, 158, 160, 166, 214, 219], "librarian": [57, 118], "librosa": [32, 33, 53, 96, 114, 157], "libtorch": 253, "licenc": 245, "licens": [213, 219, 245], "lie": [121, 128, 137, 141, 153], "life": 246, "lift": [57, 118], "liger": [7, 55, 56, 63, 67, 97, 116, 117, 124, 128, 158, 174], "liger_kernel": 39, "ligerkernel": 39, "ligerrmsnorm": 39, "ligerswiglumlp": 39, "light": [3, 151], "lightblu": [96, 157], "lightev": [96, 157], "lightheart": [57, 118], "lightweight": [124, 152], "like": [28, 29, 35, 40, 41, 42, 43, 46, 47, 50, 56, 57, 96, 109, 111, 113, 114, 117, 118, 121, 122, 123, 126, 127, 128, 141, 142, 146, 149, 151, 152, 154, 155, 157, 164, 219, 234], "limit": [35, 38, 42, 48, 67, 68, 70, 99, 109, 111, 128, 129, 130, 131, 134, 135, 139, 140, 142, 148, 150, 160, 199, 200, 219], "limit10": 70, "line": [37, 39, 46, 51, 52, 90, 112, 113, 114, 117, 118, 121, 122, 124, 126, 129, 151, 152, 154, 156, 161, 162, 172, 204, 219, 222], "linear": [7, 24, 28, 42, 48, 53, 56, 57, 63, 67, 68, 99, 102, 103, 104, 109, 111, 114, 117, 118, 124, 128, 129, 135, 148, 160, 163, 164, 165, 188, 194, 215, 219], "linear_fc1": [99, 160], "linear_fc2": [99, 160], "linear_proj": [99, 160], "linear_qkv": [99, 160], "ling": [96, 157], "ling2": [96, 157], "lingual": [96, 157], "link": [38, 47, 116, 119, 151, 174, 193, 230, 255], "linux": [170, 172, 173, 177, 181, 185, 191, 194, 224, 236], "linux_aarch64": 230, "linxi": [96, 157], "lion": 121, "lisa": [63, 97, 124, 158], "list": [11, 37, 39, 43, 46, 49, 50, 52, 53, 57, 60, 62, 67, 87, 88, 90, 91, 93, 95, 97, 109, 110, 111, 113, 114, 118, 120, 121, 122, 123, 127, 128, 129, 148, 149, 151, 152, 154, 156, 160, 165, 166, 170, 172, 188, 214, 219, 222, 228, 236, 237, 253], "listdir": 219, "listen": 224, "listint": 214, "listwise_reranker_min_group_s": [59, 120], "listwise_reranker_temperatur": [59, 120], "lite": [96, 157, 197], "liter": [7, 18, 53, 93, 114, 154], "littl": [57, 118, 141, 160], "liu": 46, "liucong": [56, 96, 117, 157], "liuhaotian": [96, 157], "live": [129, 237, 243], "lixiang": [79, 140], "liyucheng": [96, 157], "ll": [46, 50, 57, 111, 118, 219], "llama": [0, 6, 7, 9, 11, 12, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 38, 95, 96, 97, 156, 157, 158, 170, 194, 230, 237, 239, 241, 243, 245, 246], "llama2": [96, 157, 197], "llama3": [7, 9, 10, 11, 17, 20, 21, 23, 24, 67, 94, 95, 96, 99, 105, 128, 155, 156, 157, 160, 166, 194, 197, 237, 239, 240, 245], "llama3_8b": [239, 240], "llama3_full_sft": 15, "llama3_full_sft_ds3": [9, 18], "llama3_gptq": 23, "llama3_lora_dpo": 15, "llama3_lora_ev": 20, "llama3_lora_predict": 20, "llama3_lora_pretrain": 15, "llama3_lora_reward": 15, "llama3_lora_sft": [9, 15, 21, 23, 24], "llama3_lora_sft_ds3": 9, "llama3_q_lora": 23, "llama4": [11, 63, 96, 99, 124, 157, 160], "llama4plugin": 11, "llama_factory_npu": [14, 15], "llama_kv_cache_init": 194, "llama_model_load": 194, "llama_new_context_with_model": 194, "llama_print_tim": 194, "llamacpp": 193, "llamafactori": [7, 8, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 25], "llamafactory_verbos": 7, "llamafil": 194, "llamaforcausallm": [70, 131], "llamameta": 245, "llamapro": [63, 124], "llamapro_num_new_block": [67, 128], "llava": [11, 21, 63, 67, 96, 124, 128, 157], "llava1": [96, 157], "llava1_5": 21, "llava_instruct": [96, 157], "llavabench": [68, 70, 129, 131], "llm": [0, 11, 45, 48, 49, 58, 59, 61, 62, 63, 67, 78, 91, 95, 96, 97, 99, 100, 101, 109, 110, 119, 120, 122, 123, 124, 128, 152, 156, 157, 158, 160, 177, 194, 195, 219, 222, 231, 240], "llm1": [96, 157], "llm_config": [9, 70, 131], "llm_load_print_meta": 194, "llm_load_tensor": 194, "llm_load_vocab": 194, "llms": [0, 87, 110, 128, 139, 148, 160, 161, 162, 196], "lm": [0, 55, 56, 67, 98, 99, 105, 116, 117, 128, 159, 160, 166, 170, 174, 176, 196, 200, 222, 237], "lm_dataset": 219, "lm_deploy": 195, "lm_eval": 200, "lm_head": [7, 44, 53, 58, 67, 114, 119, 128, 160], "lmbda": [67, 71, 99, 100, 128, 132, 160, 161], "lmdeploy": [0, 63, 64, 68, 69, 90, 91, 95, 124, 125, 129, 130, 151, 152, 156, 196, 197, 209], "lmdeploy_ascend_demo": 197, "lmdeployengin": [90, 91, 151, 152], "lmf": 7, "lmms": [52, 96, 113, 157], "lms": 225, "lmsys": [96, 157], "lmudata": [70, 131], "ln": [170, 230], "lnqa": [96, 157], "load": [3, 7, 29, 30, 35, 37, 41, 42, 44, 47, 53, 60, 67, 70, 99, 114, 116, 119, 121, 122, 128, 140, 148, 149, 150, 151, 152, 154, 155, 156, 158, 160, 163, 164, 188, 191, 194, 219, 228, 234, 237, 241, 256], "load_and_register_attn_kernel": 41, "load_arg": [63, 91, 124, 152], "load_audio": [53, 114], "load_data_arg": [53, 55, 57, 67, 91, 103, 104, 114, 116, 118, 128, 152, 164, 165], "load_dataset": [60, 121, 219, 241], "load_format": 222, "load_from_cache_fil": [50, 51, 52, 53, 56, 57, 58, 70, 103, 104, 111, 112, 113, 114, 117, 118, 119, 131, 164, 165, 219], "load_imag": 197, "load_lora_weight": 3, "load_model": 219, "load_model_hook": 219, "load_openai_model": 207, "load_or_create_model_card": 219, "load_pil_imag": [79, 140], "load_sourc": 39, "load_stat": 219, "load_state_dict": 219, "load_weight": [103, 164], "loader": [40, 41, 42, 43, 46, 61, 122, 188, 219], "loading_dataset": 219, "lobireftintervent": [67, 128], "local": [7, 14, 15, 22, 33, 35, 41, 46, 48, 50, 55, 67, 92, 99, 109, 111, 116, 121, 122, 128, 129, 140, 144, 147, 149, 151, 152, 153, 154, 158, 160, 170, 172, 174, 175, 178, 179, 180, 181, 183, 185, 188, 193, 197, 203, 215, 219, 230, 237, 240, 245, 253], "local_addr": [48, 109], "local_dataset_path": 170, "local_devic": [188, 219], "local_dir": [27, 28, 29, 30, 31, 178, 179, 180], "local_instal": 22, "local_machin": [9, 15], "local_path": [68, 70, 129, 131], "local_process_index": 219, "local_rank": [188, 219], "local_ranks_filt": [48, 109], "local_repo_path": [70, 91, 131, 152], "local_save_dir": 174, "localdomain_": [172, 173], "localhost": [9, 26, 58, 67, 90, 119, 128, 151, 172, 173, 179, 215, 231], "locat": [37, 52, 66, 113, 118, 121, 127, 151, 160, 174, 230, 241], "lock": [32, 33, 178, 214], "locutusqu": [96, 157], "log": [7, 42, 48, 67, 70, 71, 73, 75, 77, 80, 81, 84, 86, 92, 99, 109, 125, 126, 128, 132, 134, 136, 138, 141, 144, 145, 147, 151, 153, 160, 162, 166, 178, 179, 180, 181, 188, 191, 194, 207, 210, 214, 219, 222, 241], "log_complet": [50, 51, 52, 56, 89, 111, 112, 113, 117, 150], "log_dir": [48, 109, 178, 222], "log_entropi": [80, 89, 141, 150, 162], "log_fil": [70, 131, 178], "log_importance_weight": [75, 136], "log_interv": [188, 219], "log_level": 219, "log_metr": 219, "log_ppl_abs_diff": [81, 142], "log_ppl_diff": [81, 89, 142, 150], "log_ppl_diff_max": [81, 142], "log_ppl_diff_min": [81, 142], "log_prob": [172, 173], "log_prob_max_token_len_per_gpu": [178, 180], "log_prob_micro_batch_size_per_gpu": [174, 180], "log_prob_use_dynamic_bsz": 180, "log_rank": 240, "log_ratio": [73, 75, 134, 136], "log_rollout_offpolicy_metr": [81, 89, 142, 150], "log_sampl": 199, "log_val_gener": 178, "log_valid": 219, "log_with": 219, "logarithm": 142, "logger": [43, 53, 114, 128, 174, 178, 214, 219], "logging_dir": [219, 222], "logging_step": [8, 9, 17, 24, 48, 50, 51, 52, 53, 56, 57, 58, 63, 68, 70, 109, 111, 112, 113, 114, 117, 118, 119, 124, 129, 131, 222], "logic": [35, 37, 41, 43, 46, 57, 85, 114, 118, 128, 140, 143, 144, 146, 148, 149, 159, 172, 204], "logical_fallaci": 200, "login": [160, 219, 237], "logit": [38, 43, 59, 62, 67, 78, 80, 88, 120, 123, 128, 139, 141, 149, 181, 214, 219, 241, 249], "logits_to_keep": 128, "loglevel": 256, "logp": [65, 67, 78, 86, 92, 126, 128, 139, 147, 249], "logprob": [67, 81, 83, 86, 90, 128, 142, 144, 147, 151, 171, 177, 231], "logs_spec": [48, 109], "long": [37, 45, 57, 87, 96, 97, 118, 121, 124, 128, 134, 135, 139, 148, 152, 157, 158, 160, 172, 173, 180, 219], "longalpaca": [96, 157], "longcat": [96, 157], "longchat": [96, 157], "longcot": [96, 157], "longer": [35, 38, 110, 117, 130, 131, 155, 166, 219], "longlora": [63, 67, 97, 124, 128, 158], "longwrit": [96, 157], "loo": 138, "look": [35, 37, 50, 57, 111, 118, 121, 123, 151, 219, 249], "lookup": [37, 41], "loop": [28, 70, 110, 122, 172, 173, 188, 219], "loop_messag": 194, "loos": 139, "lora": [6, 9, 15, 17, 20, 21, 22, 24, 48, 51, 53, 55, 56, 57, 61, 62, 63, 66, 68, 89, 90, 97, 99, 100, 101, 105, 109, 112, 114, 116, 117, 118, 122, 123, 124, 127, 129, 150, 151, 158, 160, 161, 162, 166, 210, 219], "lora1": [91, 152], "lora2": [91, 152], "lora_a": [97, 158], "lora_adapt": [91, 152], "lora_alpha": [7, 18, 48, 51, 53, 56, 57, 63, 67, 68, 70, 102, 103, 104, 109, 112, 114, 117, 118, 124, 128, 129, 131, 163, 164, 165], "lora_checkpoint": [91, 152], "lora_dropout": [7, 18], "lora_dtyp": [67, 128], "lora_model_path": 3, "lora_rank": [7, 18, 48, 51, 53, 56, 57, 63, 68, 70, 89, 102, 103, 104, 109, 112, 114, 117, 118, 124, 129, 131, 150, 163, 164, 165], "lora_target": [7, 17, 18, 24], "loraconfig": [97, 158], "lorap": [67, 128], "loraplus_lr_embed": [7, 18], "loraplus_lr_ratio": [7, 18], "loreftintervent": [67, 128], "lose": 117, "loss": [7, 12, 38, 39, 46, 52, 56, 59, 65, 66, 67, 71, 72, 86, 89, 92, 93, 99, 100, 103, 105, 113, 117, 126, 127, 128, 133, 134, 137, 138, 142, 150, 153, 154, 160, 161, 164, 166, 172, 173, 180, 181, 188, 215, 219, 234, 241, 249], "loss_agg_mod": [180, 181], "loss_dict": [98, 159], "loss_fct": [38, 43], "loss_fn": 215, "loss_func": 43, "loss_map": [62, 123], "loss_mask": [86, 147], "loss_mod": 181, "loss_scal": [9, 48, 53, 56, 60, 83, 86, 91, 109, 114, 117, 121, 123, 144, 147, 152, 160, 188, 219], "loss_scale_window": [9, 48, 109, 188, 219], "loss_typ": [62, 73, 74, 78, 84, 123, 134, 135, 139, 145, 160], "lossscal": [62, 123], "lot": [52, 113], "love": [57, 60, 118, 121, 237], "low": [18, 41, 50, 89, 97, 111, 128, 132, 134, 135, 141, 150, 155, 158, 180, 214, 241], "low_cpu_mem_usag": 7, "low_var_kl": 174, "lower": [38, 40, 128, 135, 142, 150, 151, 160, 219], "lowercas": 37, "lowest": [50, 52, 111, 113, 156], "lowr": 225, "lr": [35, 42, 56, 57, 62, 67, 70, 97, 99, 102, 103, 104, 105, 117, 118, 128, 131, 158, 160, 163, 164, 165, 166, 174, 178, 188, 207, 214, 215, 219, 234], "lr_schedul": [3, 35, 43, 219], "lr_scheduler_kwarg": [67, 70, 128, 131], "lr_scheduler_typ": [8, 9, 17, 24, 67, 70, 128, 131, 222], "lr_warmup_fract": [56, 57, 70, 102, 103, 104, 105, 117, 118, 131, 163, 164, 165, 166], "lr_warmup_step": [3, 219], "lspci": 185, "lstm": 214, "lt": [11, 44, 55, 64, 116, 125, 166, 180, 181], "lvjianjin": [96, 157], "lvwerra": [96, 157], "lzkpxqmyy0xqw047tnn9iwx": 245, "m0": [96, 157], "m1": [73, 96, 134, 157], "m2": [96, 157], "m3": [96, 157], "m32": [96, 157], "m3it": [96, 157], "m_in": 214, "m_out": 214, "ma": [35, 46], "mac": 177, "macaw": 243, "machin": [44, 71, 118, 126, 132, 152, 160, 164, 166, 219], "machine_learn": 200, "machine_rank": [9, 15], "maco": 32, "made": [111, 113, 131], "madebyollin": 3, "magaer13": [96, 157], "magic": [3, 129], "magnific": 237, "magnitud": [128, 134, 135, 139, 150, 219], "magpi": [96, 157], "main": [7, 9, 14, 15, 42, 48, 57, 63, 64, 70, 81, 93, 94, 96, 99, 109, 113, 118, 120, 124, 125, 128, 133, 136, 137, 138, 140, 142, 145, 150, 154, 155, 157, 159, 160, 170, 175, 177, 178, 179, 180, 181, 184, 188, 191, 194, 197, 199, 204, 207, 213, 214, 215, 219, 231, 243, 248, 255, 256], "main_func": 46, "main_params_dtyp": [99, 160], "main_ppo": [174, 178, 181], "main_process_first": 219, "main_process_ip": [9, 15], "main_process_on": 219, "main_process_port": [9, 15], "main_training_funct": [9, 15], "mainstream": 164, "maintain": [35, 38, 39, 128, 142, 143, 160], "mainten": [39, 246], "major": [40, 141, 159], "make": [26, 33, 37, 38, 41, 44, 47, 50, 56, 57, 70, 97, 110, 111, 117, 118, 123, 128, 129, 130, 132, 135, 139, 142, 149, 152, 158, 160, 164, 175, 178, 181, 185, 212, 219, 241, 245, 246, 255], "make_image_grid": 219, "makedir": 219, "malform": 128, "malloc": [70, 131], "mamba": [96, 157], "man": [57, 118], "manag": [36, 37, 43, 46, 96, 131, 144, 147, 149, 157, 172, 194, 200, 209, 237, 241], "manage_context": [83, 144], "mani": [35, 43, 45, 46, 51, 52, 111, 112, 113, 128, 129, 139, 154, 160], "manipul": [35, 39], "manner": [50, 111], "manti": [96, 157], "manual": [35, 37, 39, 99, 117, 121, 122, 126, 127, 128, 144, 147, 152, 158, 160], "manual_gc": [99, 160], "manual_se": 219, "manufactur": 155, "manylinux_2_17_aarch64": 14, "manylinux_2_28_aarch64": 230, "map": [40, 41, 42, 43, 46, 52, 63, 67, 90, 91, 99, 102, 113, 121, 124, 127, 128, 151, 152, 160, 163, 184, 219, 241], "mapjack": [96, 157], "mappingdataset": [37, 42, 43], "marco": [96, 157], "margin": [7, 42, 43, 49, 60, 65, 67, 92, 110, 121, 126, 128, 153, 249], "mark": [3, 46, 57, 70, 91, 118, 128, 131, 151, 152], "markdown": [70, 131], "marker": [39, 128], "market": 200, "mask": [46, 49, 67, 70, 75, 86, 99, 110, 128, 136, 150, 160, 214], "mask_histori": 7, "masked_fil": [98, 159], "masked_scatt": [46, 53, 114], "massiv": 172, "master": [7, 9, 48, 49, 67, 109, 110, 128, 141, 172, 173, 179, 180, 181], "master_addr": [7, 9, 48, 67, 109, 128, 179, 180, 181, 215], "master_ip": 214, "master_port": [7, 9, 48, 52, 67, 109, 113, 128, 214, 215], "mat": 213, "mat1": 214, "mat2": 214, "match": [36, 37, 45, 46, 50, 52, 62, 70, 109, 110, 111, 113, 114, 119, 121, 122, 123, 127, 128, 138, 148, 150, 153, 160, 219], "matched_stop": 231, "math": [50, 52, 55, 60, 62, 68, 83, 85, 86, 94, 95, 96, 111, 113, 116, 121, 123, 129, 144, 146, 147, 155, 156, 157, 178, 179, 181, 210, 214, 219], "math360k": [52, 113], "math500_gen_0_shot_cot_chat_prompt": 179, "math_prm800k_500": 179, "math_reward": [85, 146], "math_verifi": [52, 56, 87, 113, 117, 148], "mathbb": [50, 71, 73, 77, 80, 81, 89, 111, 132, 134, 138, 141, 142, 150], "mathbf": [80, 141], "mathcal": [50, 71, 72, 73, 77, 81, 84, 89, 111, 132, 133, 134, 138, 142, 145, 150], "mathemat": [50, 111, 113, 123, 148, 155], "mathinstruct": [96, 157], "mathorm": [62, 123], "mathr": [96, 157], "mathrandomreward": [85, 146], "mathrm": [75, 78, 136, 139], "mathvis": [68, 70, 129, 131], "mathvision_mini": [68, 70, 129, 131], "mathvista_mini": [68, 70, 129, 131], "matmul": [28, 177, 214, 219], "matmul_int8": 194, "matric": [7, 18, 46, 128], "matrix": [128, 131, 160], "matt": 52, "mattshum": [96, 157], "maverick": [11, 96, 157], "max": [42, 43, 45, 46, 48, 49, 50, 52, 53, 67, 73, 74, 79, 84, 87, 89, 91, 94, 96, 99, 109, 110, 111, 114, 116, 128, 134, 135, 142, 145, 148, 150, 152, 155, 157, 160, 180, 188, 194, 210, 214, 219], "max_assistant_turn": 178, "max_batch_s": [88, 90, 91, 128, 149, 151, 152, 199], "max_completion_length": [50, 51, 52, 56, 67, 71, 86, 100, 111, 112, 113, 117, 128, 132, 135, 147, 161], "max_concurr": 7, "max_diverg": [82, 143], "max_env_num_per_work": 222, "max_epoch": [67, 70, 128, 131], "max_eval_sampl": 219, "max_fram": [57, 118], "max_gpus": [48, 109], "max_grad_norm": [24, 52, 113, 214, 219, 222], "max_image_num": 37, "max_image_til": 11, "max_job": [105, 166], "max_len": 219, "max_length": [7, 50, 51, 53, 56, 57, 58, 63, 67, 68, 96, 99, 102, 103, 104, 105, 111, 112, 114, 117, 118, 119, 124, 128, 129, 157, 160, 163, 164, 165, 166, 219, 241], "max_length_k": 46, "max_length_q": [45, 46], "max_memori": [67, 128], "max_model_len": [67, 128], "max_negative_sampl": [59, 120], "max_new_token": [7, 53, 55, 56, 57, 58, 63, 67, 71, 90, 91, 103, 104, 105, 114, 116, 117, 118, 119, 124, 128, 132, 151, 152, 164, 165, 166, 191, 222, 231, 243, 246], "max_num_batched_token": 178, "max_num_fram": [70, 131], "max_num_gen_batch": 180, "max_num_imag": 11, "max_num_seq": 178, "max_out_len": 179, "max_output_s": 214, "max_overlap": 214, "max_percentil": 214, "max_pixel": [52, 53, 57, 58, 60, 67, 79, 90, 104, 113, 114, 118, 119, 121, 128, 140, 151, 165], "max_pos_embed": 219, "max_position_embed": [67, 128, 219], "max_positive_sampl": [59, 120], "max_prompt_length": [67, 128, 174, 178, 181], "max_resample_tim": [74, 135], "max_response_length": [174, 178, 180, 181], "max_restart": [48, 109], "max_sampl": [7, 8, 17, 20, 24], "max_seq_len": [42, 43, 179], "max_seqlen": 46, "max_shap": 214, "max_shard_s": [58, 119], "max_size_per_class": 214, "max_step": [67, 87, 128, 148, 222], "max_token": [53, 57, 58, 67, 68, 70, 90, 91, 114, 118, 119, 128, 129, 131, 151, 152, 171], "max_tokens_per_step": 222, "max_total_s": 214, "max_train_batch_s": [48, 109], "max_train_sampl": 219, "max_train_step": 219, "max_tree_depth": [82, 143], "max_turn": [83, 86, 144, 147, 178], "max_user_turn": 178, "max_valu": 214, "max_window_lay": [58, 119], "maxblocknumperseq": 214, "maxim": [110, 133], "maximum": [39, 42, 44, 45, 48, 50, 109, 111, 120, 121, 128, 129, 131, 132, 135, 145, 147, 148, 150, 160, 161, 166, 219, 241], "maxpool2d": [188, 219], "maxwel": [178, 181], "may": [9, 35, 39, 40, 41, 45, 50, 66, 109, 110, 111, 117, 118, 123, 125, 127, 128, 131, 135, 139, 140, 142, 147, 148, 150, 152, 153, 155, 156, 158, 160, 164, 166, 180, 219, 246], "mayb": [56, 117], "maziyarpanahi": [96, 157], "mb": [55, 67, 99, 116, 128, 160, 185, 194, 256], "mbert_adam": 214, "mbpp": [68, 70, 129, 131], "mbridg": [174, 176, 179], "mbs": 42, "mc2": [96, 157, 214], "mccl": [67, 128], "mcdonald": 241, "mcore": [67, 98, 99, 128, 131, 159, 160, 179], "mcore_adapt": [70, 99, 102, 103, 160, 163, 164], "mcore_model": [70, 98, 99, 102, 103, 105, 131, 159, 160, 163, 164, 166], "mcore_model_path": 179, "mcore_ref_adapt": [99, 160], "mcore_ref_model": [99, 160], "md": [36, 175, 181, 219], "md5": [67, 128], "me": [43, 50, 56, 57, 91, 105, 111, 117, 118, 121, 144, 152, 166, 237, 241, 246], "meal": 241, "mean": [37, 42, 46, 49, 52, 53, 67, 74, 76, 77, 89, 99, 110, 113, 114, 121, 123, 127, 128, 129, 135, 137, 138, 141, 142, 150, 152, 154, 158, 160, 162, 172, 180, 181, 187, 204, 214, 219, 234, 243], "mean_diff": [103, 164], "mean_std": 222, "meaning": 149, "meaningless": 45, "means0": 214, "means1": 214, "means2": 214, "means3": 214, "measur": [52, 113, 132, 141, 142, 149, 150], "mechan": [121, 133, 134, 139, 142, 143, 150, 155], "med": [96, 157], "meddl": 241, "medgemma": [96, 157], "media": [70, 128, 131, 194], "media_dir": 7, "media_grid_thw": [53, 114], "media_input": [53, 114], "media_resourc": [70, 131], "media_typ": [53, 114], "medic": [96, 157], "medical_genet": 200, "medical_zh": [96, 157], "medium": [48, 96, 109, 157, 256], "meet": [50, 59, 111, 120, 148, 155, 187], "megatron": [55, 57, 63, 67, 78, 89, 91, 93, 96, 98, 100, 101, 102, 104, 116, 118, 124, 128, 139, 150, 152, 154, 157, 159, 161, 163, 165, 170, 174, 175, 176, 179, 222, 250], "megatron_actor": [172, 173], "megatron_actor_update_profil": [172, 173], "megatron_adaptor": [55, 116], "megatron_cor": 166, "megatron_lm_path": [55, 105, 116, 166], "megatron_model_meta": [103, 164], "megatron_output": [56, 57, 99, 102, 103, 104, 105, 117, 118, 160, 163, 164, 165, 166], "megatron_train": 222, "megatronargu": [103, 164], "megatronppoactor": [172, 173], "megrez": [96, 157], "meituan": [96, 157], "mel": [67, 128, 256], "mem": [67, 99, 128, 160], "memfabric_url": 230, "memor": [57, 118], "memori": [34, 38, 42, 43, 45, 46, 48, 55, 67, 70, 97, 99, 109, 111, 113, 116, 117, 118, 120, 124, 128, 152, 158, 159, 160, 161, 164, 166, 172, 173, 185, 187, 219, 237], "memory_format": 219, "memory_info": 204, "memoryinfo": 204, "mengzi": [96, 157], "mengzi3": [96, 157], "mention": [56, 111, 113, 117, 127, 129, 155, 160, 172], "merg": [27, 28, 35, 40, 46, 53, 55, 61, 63, 67, 97, 99, 103, 114, 116, 117, 122, 124, 158, 160, 164, 178, 194], "merge_and_unload": [97, 158], "merge_config": 23, "merge_dcp_to_hf": 44, "merge_hf_path": [27, 28], "merge_lora": [23, 55, 56, 63, 91, 102, 103, 104, 116, 117, 124, 152, 163, 164, 165], "merge_s": [53, 114], "merger": [53, 58, 114, 119], "merlin": 43, "mesh": [35, 43], "messag": [11, 19, 21, 37, 38, 39, 42, 43, 49, 52, 53, 56, 57, 59, 60, 62, 66, 67, 79, 83, 86, 87, 88, 90, 91, 95, 110, 113, 114, 117, 118, 120, 121, 123, 127, 128, 140, 144, 147, 148, 149, 151, 152, 156, 191, 194, 199, 219, 231, 237, 246], "messagespreprocessor": [60, 121], "met": 142, "meta": [0, 9, 10, 11, 16, 17, 20, 21, 23, 24, 27, 36, 42, 43, 60, 61, 95, 96, 97, 156, 157, 158, 194, 230, 239, 241, 242, 243, 246], "metabol": 129, "metadata": [39, 43, 44, 48, 109, 121, 122, 194, 219, 231], "metadataincompletebuff": [70, 131], "metainfershap": 214, "metal": [52, 256], "method": [8, 17, 18, 20, 33, 34, 35, 36, 38, 47, 48, 52, 67, 99, 109, 111, 113, 114, 117, 121, 122, 123, 124, 127, 128, 129, 130, 133, 137, 138, 140, 141, 142, 143, 145, 147, 149, 150, 151, 152, 154, 155, 159, 160, 161, 164, 172, 184, 214, 219, 222, 225], "method_overrid": 39, "metric": [8, 13, 22, 67, 68, 70, 90, 99, 110, 126, 128, 129, 149, 151, 153, 155, 160, 172, 179, 180, 200, 210, 219, 241], "metric_for_best_model": [67, 99, 128, 160], "metric_map": [62, 123], "metric_micro_batch": [172, 173], "metrics_to_gath": 150, "mf_adapt": 230, "mf_whl_name": 230, "mg": 194, "mg_model": [103, 164], "mib": 194, "micro": [42, 43, 45, 48, 99, 109, 160, 172, 173], "micro_batch": [43, 172, 173], "micro_batch_s": [30, 43, 48, 56, 57, 70, 99, 100, 101, 102, 103, 104, 105, 109, 117, 118, 131, 160, 161, 162, 163, 164, 165, 166], "microbatch": [99, 160], "microsoft": [22, 96, 157, 243], "mid": [50, 72, 75, 89, 111, 133, 136, 150], "midashenglm": [96, 157], "mideficsdataset": [96, 157], "might": [50, 56, 111, 113, 116, 117, 132, 188, 219], "migrat": 131, "mild": [121, 127], "mimick": [57, 118], "mimo": [67, 96, 128, 157], "min": [42, 48, 50, 67, 73, 78, 81, 84, 87, 89, 96, 99, 109, 111, 128, 134, 139, 142, 145, 148, 150, 157, 160, 188, 210, 214, 219], "min_bandwidth": [48, 109], "min_capac": [188, 219], "min_channel": [48, 109], "min_gpus": [48, 109], "min_loss_scal": [9, 48, 109, 188, 219], "min_lr": [56, 57, 67, 70, 102, 103, 104, 105, 117, 118, 128, 131, 163, 164, 165, 166], "min_p": 194, "min_percentil": 214, "min_pos_iou": 214, "min_tim": [48, 109], "min_valu": 214, "mind": [50, 83, 86, 87, 111, 144, 147, 148], "mind2web": [96, 157], "mindspe": [55, 116, 176, 181, 250], "mindstudio": [98, 159, 172, 173, 177, 179], "mine": 241, "mini": [7, 50, 67, 72, 89, 96, 111, 128, 133, 150, 157, 172, 173, 188, 219], "mini_batch": [172, 173], "minibatch": [75, 136, 214], "miniconda": [223, 236], "miniconda3": [187, 212, 221, 224, 236], "minicpm": [63, 96, 124, 157], "minicpm3": [96, 157], "minicpm4": [96, 157], "minicpmo": [96, 157], "minicpmo4": [96, 157], "minicpmv": [96, 157], "minicpmv2": [67, 96, 128, 157], "minicpmv4": [96, 157], "minilm": 228, "minim": [41, 44, 46, 51, 89, 110, 112, 117, 128, 131, 150, 160, 219], "minimax": [73, 96, 134, 157], "minimaxai": [96, 157], "minimind": [96, 157], "minimind2": [96, 157], "minimum": [42, 48, 89, 109, 120, 128, 148, 150, 154, 160, 188, 219, 249, 252], "ministr": [96, 157], "minor": [52, 113], "minut": [118, 124, 152, 165, 166, 170, 241], "mirostat": 194, "mirostat_": 194, "mirostat_lr": 194, "mirror": [55, 96, 116, 157, 170, 179, 184, 200, 242], "misalign": [151, 164], "miscellan": 200, "mismatch": [40, 46, 89, 99, 128, 131, 150, 157, 160], "mispeech": [96, 157], "miss": [41, 67, 110, 128, 219], "mistak": [71, 132, 241], "mistral": [6, 63, 96, 124, 157], "mistral3": [96, 157], "mistralai": [96, 157], "mit": [96, 157], "mitig": [117, 128, 131, 153], "mix": [42, 43, 57, 67, 96, 98, 114, 117, 118, 124, 127, 128, 132, 133, 153, 157, 159, 160, 161, 188, 219], "mix_strategi": 7, "mixed_precis": [3, 9, 15, 219], "mixin": [56, 117], "mixtral": [28, 96, 157], "mixtur": [27, 96, 128, 132, 157, 188, 219], "mixture_of_depth": 7, "mixup": [67, 128], "mizukiluk": [96, 157], "mkdir": [43, 178, 179, 180, 181, 212, 224, 236, 255], "mla": [99, 160, 177], "mlabonn": [96, 157], "mlflow": 8, "mlfoundat": 224, "mlk": 243, "mllama": 11, "mllm": [0, 7, 49, 59, 67, 99, 100, 101, 110, 120, 128, 160], "mllmguard_d": [68, 70, 129, 131], "mllms": [161, 162], "mlp": [18, 35, 38, 39, 40, 46, 62, 67, 99, 123, 128, 160, 181, 188, 219], "mlp_type": [188, 219], "mm": [19, 67, 99, 128, 160, 214, 218, 230, 239], "mm_gpt_model": [98, 159], "mm_plugin": 11, "mmbench": [68, 70, 129, 131], "mmbench_cn": [68, 70, 129, 131], "mmbench_cn_v11": [68, 70, 129, 131], "mmbench_dev_cn": [68, 70, 129, 131], "mmbench_dev_cn_v11": [68, 70, 129, 131], "mmbench_dev_en": [68, 70, 129, 131], "mmbench_dev_en_v11": [68, 70, 129, 131], "mmbench_test_cn": [68, 70, 129, 131], "mmbench_test_cn_v11": [68, 70, 129, 131], "mmbench_test_en": [68, 70, 129, 131], "mmbench_test_en_v11": [68, 70, 129, 131], "mmbench_v11": [68, 70, 129, 131], "mmdeploy": 197, "mmdu": [68, 70, 129, 131], "mme": [68, 70, 129, 131], "mmlab": 197, "mmlongbench_doc": [68, 70, 129, 131], "mmlu": [68, 129, 200], "mmlu_pro": [68, 129], "mmlu_test": [7, 20], "mmmu": [58, 119], "mmmu_dev_v": [58, 68, 70, 119, 129, 131], "mmmu_test": [68, 70, 129, 131], "mmprocessor": 11, "mmstar": [68, 70, 129, 131], "mmt": [68, 70, 129, 131], "mmvet": [68, 129], "mo": [56, 82, 96, 117, 143, 157], "mod": 7, "modal": [0, 42, 96, 114, 118, 121, 122, 124, 127, 128, 152, 157, 160], "mode": [37, 42, 43, 53, 58, 67, 70, 86, 95, 99, 114, 117, 119, 126, 128, 144, 147, 151, 156, 160, 162, 178, 179, 181, 194, 197, 210, 214, 219, 250], "model": [0, 3, 5, 7, 8, 11, 14, 16, 18, 20, 21, 23, 24, 28, 37, 40, 41, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 65, 66, 67, 68, 69, 71, 79, 81, 83, 86, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 109, 110, 111, 112, 113, 116, 117, 120, 121, 124, 125, 126, 127, 129, 133, 135, 138, 139, 140, 141, 142, 144, 146, 147, 148, 150, 151, 153, 155, 158, 159, 160, 161, 162, 163, 166, 170, 172, 174, 178, 179, 181, 184, 188, 191, 193, 194, 199, 200, 204, 207, 209, 210, 214, 215, 219, 222, 224, 230, 231, 233, 234, 237, 239, 240, 241, 243, 244, 246, 256], "model1": [93, 154], "model2": [93, 154], "model_arch": [53, 62, 114, 123], "model_arg": [199, 200, 219, 222], "model_author": [56, 63, 67, 70, 102, 103, 105, 117, 124, 128, 131, 163, 164, 166], "model_best": 234, "model_card": 219, "model_ckpt": 234, "model_cl": 219, "model_config": 219, "model_config_class": 219, "model_config_path": 44, "model_config_registri": 46, "model_descript": 219, "model_dir": [53, 57, 70, 91, 103, 114, 118, 131, 152, 164], "model_engin": [188, 219], "model_executor": [172, 173], "model_for_causal_lm_map": 219, "model_id": [62, 63, 70, 97, 103, 122, 123, 124, 131, 158, 164, 241, 244, 246], "model_id_or_path": [61, 67, 122, 128], "model_info": [53, 70, 103, 114, 131, 164], "model_input": 191, "model_kwarg": [53, 67, 70, 114, 128, 131, 246], "model_list": [88, 149], "model_map": [61, 122], "model_max_length": [7, 219], "model_merg": 178, "model_meta": [61, 62, 70, 91, 122, 123, 131, 152], "model_nam": [3, 56, 63, 67, 70, 102, 103, 105, 117, 124, 128, 131, 163, 164, 166, 191, 207, 219, 237], "model_name_or_path": [7, 8, 9, 16, 17, 20, 21, 23, 24, 219], "model_paramet": [188, 219], "model_path": [3, 27, 30, 31, 36, 38, 43, 63, 70, 122, 124, 131, 178, 179, 180, 193, 204, 231], "model_postprocessor": 179, "model_pr": 219, "model_processor_registri": 46, "model_revis": [7, 219], "model_runn": [172, 173], "model_suffix": [99, 160], "model_typ": [36, 48, 53, 58, 61, 67, 91, 103, 109, 114, 119, 122, 128, 152, 164, 219, 222], "modelargu": [43, 219], "modelclass": 36, "modelfil": [67, 70, 128, 131], "modelgroup": [53, 114], "modeling_flash_attention_util": 41, "modeling_kimi_v1": [70, 131], "modeling_qwen2_5_vl": [58, 119], "modeling_qwen3": 39, "modeling_qwen3_vl_mo": 46, "modeling_registri": 46, "modelingcodegener": 39, "modelkey": [62, 123], "modelload": [53, 61, 114, 122], "modelmeta": [53, 61, 114, 122], "modelrunn": [172, 173], "models_ckpt": 3, "modelscop": [7, 11, 22, 49, 52, 53, 55, 56, 57, 58, 59, 60, 61, 63, 64, 67, 68, 69, 71, 79, 90, 91, 93, 95, 96, 98, 99, 102, 103, 104, 105, 110, 113, 114, 116, 117, 118, 119, 120, 121, 122, 124, 125, 128, 129, 130, 132, 133, 140, 151, 152, 154, 156, 157, 159, 160, 163, 164, 165, 166], "modelscope1": [64, 70, 105, 125, 131, 166], "modelscope_cach": [67, 70, 105, 128, 131, 166], "modelst": 35, "modelsvit": 207, "modern": [96, 157], "modernbert": [49, 59, 96, 110, 120, 157], "modif": [46, 113, 114, 128, 160, 172], "modifi": [30, 36, 38, 39, 43, 44, 46, 110, 113, 117, 119, 121, 124, 127, 128, 138, 142, 147, 152, 156, 159, 160, 172, 219], "modified_init": 39, "modify_init": 39, "modul": [14, 28, 37, 38, 39, 40, 44, 46, 47, 62, 67, 97, 99, 114, 118, 119, 123, 124, 128, 151, 153, 158, 159, 160, 166, 172, 173, 188, 201, 212, 214, 215, 219], "modular_model_convert": 39, "modulelist": [28, 188, 219], "modules_to_sav": [67, 99, 128, 160], "moe": [7, 15, 27, 39, 42, 63, 67, 78, 89, 96, 99, 102, 105, 124, 128, 139, 150, 157, 160, 163, 166, 175, 179, 180, 188, 219], "moe_a2a_backend": 175, "moe_aux_loss_coef": 7, "moe_aux_loss_coeff": [56, 57, 103, 104, 117, 118, 164, 165], "moe_ckpt_merg": [27, 28, 40], "moe_expert_capacity_factor": [57, 99, 103, 118, 160, 164], "moe_grouped_gemm": [56, 57, 103, 104, 117, 118, 164, 165], "moe_implement": [27, 46], "moe_intermediate_s": 28, "moe_layer_list": [188, 219], "moe_merg": [27, 28, 40], "moe_param_group": [188, 219], "moe_permute_fus": [56, 57, 99, 103, 104, 117, 118, 160, 164, 165], "moe_shared_expert_intermediate_s": [99, 160], "moe_shared_expert_overlap": [56, 57, 103, 104, 117, 118, 164, 165], "moe_token_dispatcher_typ": [99, 160], "moeffn": 214, "molmo": [96, 157], "moment": [57, 118, 128, 160], "momentum": [99, 128, 160, 219], "monitor": [48, 109, 142], "monitor_interv": [48, 109], "monkeypatch": 191, "mont": 155, "mood": 241, "mooncak": 230, "moondream2": [96, 157], "moonlight": [96, 157], "moonshotai": [96, 157], "moral_disput": 200, "moral_scenario": 200, "more": [29, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 45, 50, 56, 57, 66, 96, 109, 110, 111, 113, 114, 116, 117, 118, 120, 121, 123, 125, 126, 127, 128, 129, 130, 131, 136, 142, 144, 148, 149, 150, 151, 152, 153, 155, 157, 160, 161, 162, 163, 166, 172, 209, 219, 241, 249], "morn": [121, 127], "most": [28, 43, 46, 57, 70, 99, 109, 111, 113, 118, 121, 125, 129, 131, 141, 155, 156, 160, 162, 164, 166, 219], "mount": 129, "mountain": [129, 151], "mountpath": [48, 109], "mouth": [57, 118], "move": [67, 90, 128, 151, 172, 204, 219], "move_model_batch": [89, 101, 128, 150, 162], "movement": [57, 118], "moviechat": [96, 157], "moviepi": [96, 157], "mp": [214, 215], "mp3": [60, 121], "mp4": [53, 57, 60, 90, 114, 118, 121, 151], "mparam": 207, "mpi": [67, 128], "mplug": [67, 96, 128, 157], "mpo": [67, 92, 96, 128, 153, 157], "mps": [63, 64, 124, 125, 219], "mqa": 214, "mrcivqamsrvtt": [96, 157], "mrope": [53, 99, 114, 160], "mrope_sect": [70, 131], "ms": [0, 48, 53, 55, 56, 57, 60, 61, 62, 63, 64, 65, 67, 68, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 93, 95, 96, 99, 100, 101, 102, 104, 105, 109, 110, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 128, 129, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 147, 148, 150, 151, 152, 154, 156, 157, 160, 161, 162, 163, 165, 166, 194, 212, 256], "ms_agent": [96, 157], "ms_agent_for_agentfabr": [96, 157], "ms_bench": [96, 157], "ms_coco_2017_url_text": 207, "ms_dataset_id": [50, 52, 60, 79, 111, 113, 121, 140], "ms_hub_token": 7, "msagent": [96, 157], "mse": [49, 110], "mse_loss": 219, "mse_loss_weight": 219, "mseloss": 215, "msg": 37, "mstt": 177, "mstx": 177, "mt": [96, 157], "mte2": 177, "mteb": [96, 157], "mtp": [99, 102, 160, 163, 177], "mtvqa_test": [68, 70, 129, 131], "mu": [38, 67, 72, 99, 128, 133, 160], "much": [113, 128, 151, 155, 160, 219], "mul": 214, "multi": [38, 42, 43, 46, 67, 86, 90, 93, 96, 99, 113, 117, 120, 121, 122, 123, 124, 126, 128, 140, 143, 144, 145, 151, 152, 154, 157, 160, 162, 163, 164, 166, 207, 210], "multi_gpu": 9, "multi_label_classif": 128, "multi_stream_memory_reus": 181, "multi_turn": [128, 178], "multi_turn_schedul": [83, 86, 101, 144, 147, 162], "multiheadattent": 214, "multilabel": [96, 157], "multilingu": [96, 157], "multilrschedul": 35, "multimod": [11, 29, 30, 37, 38, 43, 46, 53, 61, 62, 67, 96, 110, 118, 122, 123, 124, 127, 128, 129, 130, 140, 150, 151, 152, 153, 160, 162, 164, 166], "multimodalaccuracyorm": [52, 113], "multimodelkey": [53, 114], "multioptim": 35, "multipl": [28, 39, 42, 45, 46, 50, 55, 70, 89, 111, 113, 116, 117, 120, 121, 126, 127, 128, 135, 137, 145, 147, 150, 151, 152, 153, 158, 160, 162, 163, 172, 188, 219], "multipli": [46, 50, 83, 86, 111, 144, 145, 147, 160], "multiprocess": [46, 131, 214, 215, 219], "multirc": [68, 70, 129, 131], "multirol": [96, 157], "multisourcedataset": 37, "multiturn": 178, "multiturnthinkingtip": [86, 147], "mushroom": 234, "music": [60, 121], "must": [37, 42, 46, 51, 66, 70, 110, 112, 117, 121, 127, 128, 129, 147, 150, 155, 160, 162, 172, 219], "mute": [57, 118], "mv": 256, "mxfp8": [99, 160], "my": [37, 56, 57, 65, 117, 118, 125, 126, 194, 231, 241, 243, 246, 256], "my_custom_collect": [93, 154], "my_custom_slic": [93, 154], "my_custom_sourc": 37, "my_custom_source_preprocessor": 37, "my_data": 37, "my_imag": 219, "my_impl": 39, "my_model": 44, "my_preprocessor": 37, "my_qwen2_5_omni": [53, 114], "my_regist": [53, 114], "my_sourc": 37, "myaccesstoken": [56, 117], "myhuaweicloud": [170, 230], "mymodel": 214, "myself": [56, 117, 241, 246], "mytrain": [93, 154], "n0": [51, 112, 177], "n00000": [51, 112], "n00001": [51, 112], "n0001": [51, 112], "n001": [51, 112], "n0011": [51, 112], "n01": [51, 112], "n010": [51, 112], "n0111": [51, 112], "n1": [51, 52, 83, 86, 112, 144, 147, 177, 214], "n1000": [51, 112], "n101": [51, 112], "n12": [83, 86, 144, 147], "n123": [66, 127], "n2": [51, 52, 83, 86, 112, 144, 147, 214], "n3": [51, 52, 83, 86, 112, 144, 147], "n36": [83, 86, 144, 147], "n4": [51, 52, 83, 86, 112, 144, 147], "n5": 52, "n50": 50, "n70": 50, "n86": 50, "n_audio_ctx": 256, "n_audio_head": 256, "n_audio_lay": 256, "n_audio_st": 256, "n_batch": 194, "n_best_to_keep": [95, 156], "n_ctx": 194, "n_ctx_orig_yarn": 194, "n_ctx_train": 194, "n_e": [188, 219], "n_embd": [194, 219], "n_embd_head_k": 194, "n_embd_head_v": 194, "n_embd_k_gqa": 194, "n_embd_v_gqa": 194, "n_expert": 194, "n_expert_us": 194, "n_ff": 194, "n_gpu": 219, "n_gpus_per_nod": [174, 178, 180], "n_gqa": 194, "n_head": 194, "n_head_kv": 194, "n_keep": 194, "n_lang": 256, "n_layer": 194, "n_mel": 256, "n_merg": 194, "n_npus": 215, "n_param": 219, "n_predict": 194, "n_resp_per_prompt": 178, "n_resp_per_prompt_v": 178, "n_rot": 194, "n_shot": [7, 20], "n_swa": 194, "n_text_ctx": 256, "n_text_head": 256, "n_text_lay": 256, "n_text_stat": 256, "n_thread": [194, 256], "n_ubatch": 194, "n_vocab": [194, 256], "na": [55, 116], "nabc": [66, 127], "name": [11, 14, 15, 19, 29, 35, 36, 38, 39, 42, 48, 51, 52, 55, 56, 58, 60, 66, 67, 83, 89, 91, 96, 97, 99, 103, 106, 107, 108, 109, 112, 113, 116, 117, 119, 121, 127, 128, 129, 140, 144, 148, 150, 152, 154, 156, 157, 158, 160, 164, 167, 168, 169, 170, 174, 175, 178, 180, 181, 183, 185, 187, 188, 191, 193, 194, 197, 199, 204, 219, 222, 230, 231, 237, 246], "named_paramet": [58, 119], "namespac": [48, 109], "nan": [55, 64, 67, 89, 116, 125, 128, 150, 214], "nanswer": 117, "narg": [188, 219], "narsil": 243, "naruto": 219, "nation": 243, "nativ": [30, 40, 41, 42, 67, 68, 70, 99, 128, 129, 160, 201], "native_amp": 219, "nativeddp": 4, "natur": [57, 118, 123], "navig": 176, "nc1hwc0": 214, "nccl": [42, 67, 70, 99, 128, 131, 160], "nccl_debug": [70, 131], "ncclsystemerror": [70, 131], "nchw": 214, "nconsid": 50, "nd": 214, "ndarray": 219, "near": [38, 50, 89, 111, 113, 150, 241], "nearest": [50, 111, 120], "neat_pack": 7, "necessari": [35, 36, 43, 46, 116, 121, 127, 131, 140, 142, 154, 155, 219], "nectar": [96, 157], "need": [32, 33, 35, 37, 38, 39, 40, 43, 46, 50, 52, 53, 56, 57, 83, 86, 91, 109, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 163, 164, 166, 172, 175, 187, 188, 203, 204, 219, 230, 241, 243], "neftun": [67, 97, 128, 158], "neg": [49, 67, 78, 110, 128, 139], "negat": [49, 59, 110, 120, 128, 139, 142, 148, 150, 160, 225], "negative_audio": [49, 110], "negative_imag": [49, 59, 110, 120], "negative_images1": [49, 59, 110, 120], "negative_images2": [49, 59, 110, 120], "negative_images3": [49, 59, 110, 120], "negative_messag": [49, 59, 110, 120], "negative_video": [49, 110], "neglig": 160, "neither": [120, 128, 241], "nemo": [96, 157], "nemotron": [96, 157], "neon": [194, 256], "neq": [77, 81, 138, 142], "ner": [96, 157], "nest": 35, "nesterov": 214, "net": [14, 15, 185, 188, 219, 245], "net1": 215, "net2": 215, "network": [48, 97, 109, 128, 158, 175, 183, 188, 219, 230], "neural": [175, 188, 219], "never": [48, 109, 114, 241], "new": [37, 39, 43, 60, 67, 70, 99, 103, 110, 114, 116, 119, 121, 122, 123, 128, 131, 134, 150, 156, 160, 161, 162, 164, 172, 214, 219, 230, 231], "new_axis_mask": 214, "new_config": [58, 119], "new_config_dir": [58, 119], "new_data": 29, "new_data_iter": [98, 159], "new_item": [29, 30], "new_llm_model": [58, 119], "new_merg": [58, 119], "new_messag": [60, 121], "new_nois": 219, "new_on": [53, 114], "new_special_token": 7, "new_visual_config": [58, 119], "new_vl_model": [58, 119], "new_zero": [53, 114], "newest": [55, 116], "newli": [119, 156, 164, 184, 244], "news": [96, 157], "next": [35, 39, 40, 43, 44, 51, 52, 63, 96, 99, 111, 112, 113, 114, 124, 127, 147, 157, 160, 166, 237, 243], "next_observ": [83, 144], "next_stat": 46, "next_tocken": 214, "next_token": 214, "nextn": [67, 128], "nextqa": 29, "nexttoken": 214, "nf": [179, 180, 181], "nf4": [7, 67, 96, 128, 157], "nfinal": [50, 83, 86, 144, 147], "nfinal_result": [83, 86, 144, 147], "nfirst": [50, 83, 86, 144, 147], "ngener": 231, "ngiven": [52, 113], "ngl": [193, 194], "ngpu": 240, "ngram": [67, 128], "ngrok": 224, "nh": 38, "nhwc": [214, 219], "ni": [121, 127, 241], "nice": [121, 219], "nif": 50, "night": [151, 230, 236], "nimport": [83, 86, 144, 147], "ninja": 187, "ninner_sqrt": [83, 86, 144, 147], "nkv": 214, "nl2sql": [96, 157], "nlet": [50, 83, 86, 144, 147], "nlg": [62, 67, 123, 128], "nlg_eval": 20, "nll": [67, 92, 99, 128, 153, 160], "nlp": [96, 97, 157, 158, 184], "nlp_exampl": 184, "nlp_pipelin": 244, "nlp_polylm_multialpaca_sft": [96, 157], "nltk": [70, 131], "nltk_data": [70, 131], "nms": 214, "nmsed_box": 214, "nmsed_class": 214, "nmsed_num": 214, "nmsed_scor": 214, "nmultipli": 50, "nn": [28, 39, 40, 43, 46, 47, 62, 67, 70, 97, 123, 128, 131, 158, 188, 214, 215, 219], "nnal": [174, 175, 197, 221, 230], "nnal_": 197, "nnal_8": 14, "nnext": [50, 83, 86, 144, 147], "nnode": [7, 9, 48, 56, 58, 67, 109, 117, 119, 128, 174, 178, 179, 180, 181], "nnow": [83, 86, 144, 147], "no": [3, 8, 9, 13, 15, 22, 35, 37, 39, 40, 41, 45, 46, 48, 50, 51, 56, 59, 67, 69, 95, 99, 105, 109, 110, 111, 112, 113, 114, 117, 118, 120, 124, 125, 127, 128, 130, 137, 147, 150, 152, 155, 156, 160, 166, 172, 175, 187, 188, 219, 224, 230, 241], "no_grad": [46, 172, 173, 188, 207, 214, 219], "no_load_optim": [70, 99, 131, 160], "no_load_rng": [70, 99, 131, 160], "no_robot": [96, 157], "no_save_optim": [56, 57, 70, 99, 102, 103, 104, 105, 117, 118, 131, 160, 163, 164, 165, 166], "no_save_rng": [56, 57, 70, 102, 103, 104, 105, 117, 118, 131, 163, 164, 165, 166], "no_shard": 9, "no_think": [56, 117], "node": [7, 9, 34, 48, 55, 67, 93, 109, 116, 117, 128, 152, 154, 160, 163, 166, 179, 180, 181, 194, 204], "node_num": [48, 109], "node_rank": [7, 9, 48, 56, 58, 67, 109, 117, 119, 128], "node_unit": [48, 109], "nodireftintervent": [67, 128], "nohup": [70, 131], "nois": [67, 128, 135, 136, 219], "noise_offset": 219, "noise_schedul": 219, "noisi": [97, 139, 158, 188, 219], "noisy_gate_polici": [188, 219], "noisy_lat": 219, "nomask": 214, "non": [34, 35, 41, 44, 48, 67, 85, 109, 117, 128, 132, 142, 146, 154, 160, 161, 214, 219, 221], "non_block": [214, 219], "non_ema": 219, "non_ema_revis": 219, "none": [7, 8, 9, 11, 18, 20, 22, 28, 37, 38, 39, 42, 43, 44, 46, 47, 48, 50, 53, 55, 57, 60, 61, 62, 67, 68, 76, 81, 83, 85, 86, 90, 91, 93, 97, 98, 99, 109, 111, 114, 116, 118, 121, 122, 123, 128, 129, 137, 142, 144, 146, 147, 151, 152, 154, 158, 159, 160, 172, 173, 188, 194, 200, 214, 219], "nonetyp": 37, "nonmaxsuppress": 214, "nonzero": 150, "nor": 128, "noreftintervent": [67, 128], "norm": [35, 38, 42, 52, 67, 70, 96, 99, 128, 131, 157, 177, 207, 219], "norm1": [60, 121], "norm1000": [53, 67, 114, 128], "norm_bbox": [53, 114], "norm_k_bia": 38, "norm_k_weight": 38, "norm_q_bia": 38, "norm_q_weight": 38, "norm_typ": 38, "normal": [9, 38, 41, 46, 49, 67, 89, 110, 114, 118, 121, 128, 135, 136, 138, 150, 153, 160, 188, 213, 219], "normalize_typ": 214, "normalized_shap": [38, 214], "nose": [57, 118, 151], "not": [28, 31, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 53, 57, 91, 98, 110, 111, 113, 114, 117, 118, 120, 121, 122, 123, 126, 127, 128, 129, 130, 134, 140, 145, 146, 147, 149, 150, 151, 152, 153, 155, 156, 158, 159, 160, 162, 163, 164, 166, 172, 174, 180, 184, 187, 194, 201, 204, 219, 221, 222, 234, 241, 243, 244, 249, 256], "notat": 138, "note": [32, 33, 34, 35, 36, 38, 40, 43, 59, 70, 110, 111, 112, 113, 114, 116, 117, 120, 121, 122, 123, 125, 126, 127, 128, 129, 131, 132, 133, 136, 138, 140, 143, 146, 147, 149, 150, 151, 152, 153, 156, 158, 160, 161, 162, 163, 164, 166, 170, 172, 181, 184, 187, 188, 194, 219, 222, 249], "notebook": [63, 65, 67, 91, 124, 126, 128, 152], "noth": 110, "nothink": [96, 157], "notic": [38, 50, 111, 155], "notif": [67, 128], "notimplementederror": [62, 86, 123, 147], "notion": [81, 142], "nov": [96, 157], "novel": [96, 157], "now": [35, 37, 38, 39, 43, 46, 50, 51, 56, 66, 111, 112, 113, 117, 121, 124, 127, 219], "np": [204, 213, 214, 219, 241], "np_imag": 219, "nprint": [83, 86, 144, 147], "nproc": [9, 48, 58, 67, 70, 93, 109, 119, 128, 131, 154, 214, 215], "nproc_per_nod": [7, 9, 48, 50, 51, 52, 53, 55, 56, 57, 58, 67, 70, 71, 93, 98, 102, 103, 104, 105, 109, 111, 112, 113, 114, 116, 117, 118, 119, 128, 131, 132, 154, 159, 163, 164, 165, 166, 207], "nproduct": [83, 86, 144, 147], "npu": [0, 2, 3, 4, 5, 7, 22, 36, 42, 48, 63, 64, 67, 91, 109, 124, 125, 128, 152, 172, 173, 174, 175, 176, 177, 178, 179, 180, 183, 184, 185, 188, 190, 191, 193, 194, 197, 200, 201, 203, 204, 205, 208, 210, 213, 214, 215, 218, 219, 228, 231, 232, 237, 238, 240, 241, 244, 246, 249, 252, 253, 256], "npu0": [55, 116], "npu1": [55, 116], "npu2": [55, 116], "npu3": [55, 116], "npu4": [55, 116], "npu5": [55, 116], "npu6": [55, 116], "npu7": [55, 116], "npu_alloc_float_status": [214, 217], "npu_anchor_response_flag": [214, 217], "npu_anti_qu": [214, 217], "npu_apply_adam": [214, 217], "npu_attn_r": 214, "npu_attn_scor": 214, "npu_backend": 214, "npu_batch_nm": [214, 217], "npu_bert_apply_adam": [214, 217], "npu_bmmv2": [214, 217], "npu_bounding_box_decod": [214, 217], "npu_bounding_box_encod": [214, 217], "npu_broadcast": [214, 217], "npu_ciou": [214, 217], "npu_clear_float_status": [214, 217], "npu_confusion_transpos": [214, 217], "npu_context": 214, "npu_contigu": 214, "npu_conv2d": [214, 217], "npu_conv3d": [214, 217], "npu_conv_transpose2d": [214, 217], "npu_convert_weight_to_int4pack": [214, 217], "npu_convolut": [214, 217], "npu_convolution_transpos": [214, 217], "npu_count": [179, 180, 181], "npu_count_int": [179, 180, 181], "npu_deformable_conv2d": [214, 217], "npu_devic": 175, "npu_diou": [214, 217], "npu_dropout_mask": 214, "npu_dropout_with_add_softmax": [214, 217], "npu_dtype_cast": [214, 217], "npu_ffn": [214, 217], "npu_format_cast": [214, 217], "npu_format_cast_": [214, 217], "npu_fused_attention_scor": [214, 217], "npu_fused_infer_attention_scor": [214, 217], "npu_fusion_attent": [214, 217], "npu_geglu": [214, 217], "npu_get_float_status": [214, 217], "npu_giou": [214, 217], "npu_grid_assign_posit": [214, 217], "npu_grouped_matmul": [214, 217], "npu_gru": [214, 217], "npu_ifmr": [214, 217], "npu_incre_flash_attent": [214, 217], "npu_index": [214, 217], "npu_iou": [214, 217], "npu_jit_compil": 7, "npu_key_r": 214, "npu_layer_norm_ev": [214, 217], "npu_linear": [214, 217], "npu_lstm": [214, 217], "npu_masked_fill_rang": [214, 217], "npu_max": [214, 217], "npu_mem_limit": 204, "npu_min": [214, 217], "npu_mish": [214, 217], "npu_mm_all_reduce_bas": [214, 217], "npu_multi_head_attent": [214, 217], "npu_nms_rot": [214, 217], "npu_nms_v4": [214, 217], "npu_nms_with_mask": [214, 217], "npu_normalize_batch": [214, 217], "npu_one_hot": [214, 217], "npu_out": 214, "npu_output": 214, "npu_pad": [214, 217], "npu_prompt_flash_attent": [214, 217], "npu_ps_roi_pool": [214, 217], "npu_ptiou": [214, 217], "npu_quant_matmul": [214, 217], "npu_quant_scatt": [214, 217], "npu_quant_scatter_": [214, 217], "npu_query_r": 214, "npu_random_choice_with_mask": [214, 217], "npu_reshap": [214, 217], "npu_result": 214, "npu_rms_norm": [214, 217], "npu_roi_align": [214, 217], "npu_rotary_mul": [214, 217], "npu_rotated_box_decod": [214, 217], "npu_rotated_box_encod": [214, 217], "npu_rotated_iou": [214, 217], "npu_rotated_overlap": [214, 217], "npu_scaled_masked_softmax": [214, 217], "npu_scatt": [214, 217], "npu_scatter_nd_upd": [214, 217], "npu_scatter_nd_update_": [214, 217], "npu_sign_bits_pack": [214, 217], "npu_sign_bits_unpack": [214, 217], "npu_silu": [214, 217], "npu_slic": [214, 217], "npu_softmax_cross_entropy_with_logit": [214, 217], "npu_sort_v2": [214, 217], "npu_stride_add": [214, 217], "npu_swiglu": [214, 217], "npu_trans_quant_param": [214, 217], "npu_transpos": [214, 217], "npu_unit_test": 170, "npu_value_r": 214, "npu_weight_quant_batchmatmul": [214, 217], "npu_yolo_boxes_encod": [214, 217], "npufusedmo": 15, "npufusedrmsnorm": 15, "npufusedrop": 15, "npufusedswiglu": 15, "npugraph": 230, "npus": [0, 128, 180, 181, 201, 215, 222], "npus_per_nod": [179, 180, 181], "npuwork": [172, 173], "nq": [68, 70, 129, 131, 214], "nrespons": [90, 91, 151, 152], "nsentence1": [60, 121], "nsentence2": [60, 121], "nsinc": [52, 113], "nso": [50, 52, 83, 86, 113, 144, 147], "nsys": [172, 173], "nthat": 50, "nthe": [52, 56, 83, 86, 113, 117, 144, 147, 241], "nthen": 50, "nthere": 52, "ntherefor": [50, 52, 113], "nthus": [50, 83, 86, 144, 147], "nto": [52, 113], "nucleus": 128, "null": [8, 172, 173, 179, 218, 222, 231], "nullcontext": 219, "nullptr": [204, 214], "num": [31, 38, 42, 43, 50, 52, 67, 68, 70, 89, 92, 99, 101, 111, 128, 129, 131, 150, 153, 160, 162, 188, 210, 214, 219, 222], "num_anchor": 214, "num_attention_head": [58, 119], "num_base_anchor": 214, "num_beam": [7, 222], "num_box": 214, "num_class": [46, 214], "num_env_group": 222, "num_expert": [28, 40, 46, 188, 219], "num_fewshot": [199, 200], "num_gener": [50, 51, 52, 56, 76, 77, 82, 89, 101, 111, 112, 113, 117, 128, 137, 138, 143, 150, 160, 162], "num_gpus": 9, "num_gpus_per_nod": 222, "num_groups_partit": 222, "num_gt": 214, "num_head": 214, "num_hidden_lay": [58, 119], "num_imag": [11, 79, 140], "num_images_in_batch": 11, "num_inference_step": [3, 219], "num_input_nod": 204, "num_items_in_batch": [62, 123], "num_iter": [50, 52, 111, 113], "num_key_value_head": [58, 119, 214], "num_label": [67, 128], "num_lay": 214, "num_machin": [9, 15], "num_nextn_predict_lay": [99, 160], "num_nod": 9, "num_npus": 234, "num_output_nod": 204, "num_patch": 11, "num_proc": 219, "num_process": [9, 15, 50, 89, 111, 150, 219], "num_processes_per_machin": 9, "num_prompts_per_dp_group": [101, 162], "num_return_sequ": [95, 156, 222], "num_rollout_prompt": [101, 162], "num_slot": 9, "num_til": 11, "num_to_remov": 219, "num_token": 40, "num_tokens_in_batch": [67, 128], "num_train_epoch": [3, 8, 9, 17, 24, 43, 48, 50, 51, 52, 53, 55, 56, 57, 58, 63, 67, 68, 99, 102, 103, 104, 105, 109, 111, 112, 113, 114, 116, 117, 118, 119, 124, 128, 129, 160, 163, 164, 165, 166, 219], "num_train_prompt": [101, 162], "num_train_timestep": 219, "num_training_step": 219, "num_training_steps_for_schedul": 219, "num_update_steps_per_epoch": 219, "num_valid_token": 38, "num_visual_token": 46, "num_warmup_step": 219, "num_warmup_steps_for_schedul": 219, "num_work": [9, 30, 42, 43, 188, 219], "num_zeros_in_grad": [98, 159], "numa": [34, 48, 55, 109, 116], "number": [9, 11, 35, 38, 42, 43, 45, 48, 50, 51, 52, 67, 89, 109, 110, 111, 112, 113, 114, 116, 119, 120, 121, 127, 128, 129, 132, 133, 135, 137, 138, 139, 140, 142, 145, 147, 148, 149, 150, 153, 154, 157, 158, 160, 162, 188, 204, 214, 219, 243, 249], "numel": 219, "numer": [45, 51, 112, 124, 128, 142, 149, 160, 234], "numina": [96, 157], "numinamath": [56, 82, 96, 117, 143, 157], "numpi": [99, 160, 185, 204, 206, 209, 213, 214, 219, 230, 233, 241], "nutrit": 200, "nv": 177, "nvcc": 22, "nvidia": [22, 48, 55, 96, 105, 109, 116, 157, 166, 174, 219], "nvlink": [105, 166], "nwe": [50, 83, 86, 144, 147], "nz": [177, 180], "o1": [96, 157], "o_proj": [67, 99, 128, 160], "oa": [52, 113], "oab": [52, 113], "ob00001111": 214, "ob10011111": 214, "obj": 47, "object": [19, 37, 38, 41, 47, 52, 53, 57, 60, 66, 83, 86, 89, 91, 113, 114, 118, 121, 127, 133, 136, 141, 142, 144, 147, 150, 152, 160, 197, 219, 222, 231], "object_ref_end": [53, 60, 67, 114, 121, 128], "object_ref_start": [53, 60, 67, 114, 121, 128], "obqa": [68, 70, 129, 131], "obs": 230, "observ": [19, 66, 83, 127, 144, 155, 219], "obtain": [46, 83, 86, 112, 114, 116, 117, 130, 144, 147, 152, 153, 157, 159, 160, 219], "occasion": [57, 118, 128, 241], "occupi": [45, 128, 150], "occur": [53, 111, 114, 116, 121, 128, 150, 166, 172], "ocn": [68, 70, 129, 131], "ocnli_fc": [68, 70, 129, 131], "ocr": [54, 57, 91, 96, 104, 115, 118, 152, 157, 165], "ocr2": [96, 157], "ocrbench": [68, 70, 129, 131], "ocrvqa_test": [68, 70, 129, 131], "ocrvqa_testcor": [68, 70, 129, 131], "octan": 3, "odd": [92, 153], "of": [0, 9, 16, 27, 28, 29, 31, 33, 34, 37, 39, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 66, 67, 71, 75, 81, 83, 85, 86, 87, 89, 90, 97, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 172, 184, 188, 191, 199, 204, 213, 214, 219, 228, 231, 234, 237, 241, 243, 244, 249, 250, 256], "off": [67, 70, 71, 75, 78, 86, 89, 99, 128, 131, 132, 136, 139, 147, 150, 160, 172, 212, 241], "off_policy_sequence_mask_delta": [81, 142], "off_valu": 214, "offer": [43, 51, 112, 118, 121, 125, 128, 150, 152, 172], "offici": [33, 34, 35, 57, 116, 118, 121, 125, 128, 140, 143], "offlin": [40, 117, 128, 152, 160, 166, 172, 214], "offload": [7, 42, 43, 67, 97, 99, 100, 128, 158, 160, 161, 164, 178, 181, 219], "offload_bridg": [89, 103, 150, 164], "offload_ema": 219, "offload_fold": 7, "offload_model": [56, 89, 117, 150], "offload_optim": [9, 48, 56, 89, 109, 117, 150], "offload_optimizer_devic": 9, "offload_param": 9, "offload_param_devic": 9, "offpolici": [67, 99, 128, 160], "offset": [46, 214, 219], "offset1": 214, "offset2": 214, "offset_i": 214, "often": [35, 45, 135, 139, 155, 234, 237], "ogg": 256, "oh": [56, 117], "oi": 74, "oint": [70, 131], "ok": [55, 67, 96, 99, 116, 128, 157, 160, 185, 231], "okay": [56, 117, 187], "okvqa": [96, 157], "okvqaviquaetextcapdocvqasci": [96, 157], "ol": [96, 157], "old": [73, 75, 78, 81, 84, 89, 134, 135, 136, 139, 142, 145, 150, 172], "old_config": [58, 119], "old_logp": [89, 150], "old_per_token_logp": [73, 75, 81, 134, 136, 142], "old_policy_logp": [67, 99, 128, 160], "old_policy_model": [89, 150], "older": 131, "ollama": [67, 128], "olmo": [96, 157], "olmocr": [96, 157], "olora": [70, 131], "om_hub_token": 7, "omit": [110, 166, 172], "omni": [30, 31, 37, 38, 40, 43, 53, 55, 60, 63, 67, 96, 99, 103, 104, 114, 116, 121, 124, 128, 157, 160, 164, 165], "omnidata": [96, 157], "omnidatacollatorwithpack": 43, "omnidatacollatorwithpad": 43, "omnistor": 42, "omp_num_thread": [57, 67, 118, 128], "on": [16, 34, 35, 36, 38, 39, 41, 42, 46, 47, 50, 52, 53, 56, 57, 59, 60, 67, 81, 88, 89, 90, 94, 99, 104, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 163, 164, 165, 166, 170, 175, 184, 188, 193, 194, 201, 207, 210, 212, 219, 221, 230, 231, 241, 243, 244, 250, 255], "on_sav": [62, 123], "on_trace_readi": [98, 159, 172, 173], "on_train_begin": [62, 123], "on_valu": 214, "onboard": 40, "onc": [37, 46, 50, 70, 91, 111, 128, 136, 152, 219, 237], "one": [33, 35, 36, 39, 40, 44, 45, 47, 50, 51, 57, 60, 66, 70, 110, 111, 112, 113, 117, 118, 121, 123, 124, 127, 128, 129, 132, 140, 147, 149, 152, 155, 156, 158, 160, 172, 214, 219, 237, 241, 243], "one_": [214, 217], "one_hot": [46, 214], "one_step_off_polici": 174, "ones_lik": [53, 114, 219], "onevis": [96, 157], "onevision1": [96, 157], "onli": [34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 50, 51, 59, 67, 91, 110, 111, 112, 114, 119, 120, 121, 123, 124, 126, 127, 128, 132, 136, 139, 141, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 158, 160, 161, 162, 163, 164, 166, 172, 179, 181, 188, 219, 230, 249], "onlin": [49, 132, 161, 172, 178], "onlinehelp": [96, 157], "onnx": [0, 204], "onnxruntim": [203, 204], "onnxruntime_cxx_api": 204, "onto": [131, 158], "oom": [44, 52, 56, 67, 89, 90, 95, 103, 105, 113, 117, 128, 150, 151, 156, 164, 166, 180, 181], "op": [38, 41, 179, 180, 181, 187, 214], "op_select_impl_mod": 204, "open": [0, 28, 29, 30, 51, 53, 57, 70, 81, 90, 91, 96, 112, 114, 118, 121, 127, 128, 131, 142, 151, 152, 157, 197, 204, 206, 207, 241, 243], "open_cliop": 206, "open_clip": [207, 209, 224, 233, 234, 252], "open_clip_pytorch_model": 207, "openai": [8, 21, 63, 79, 83, 88, 89, 90, 91, 95, 96, 124, 140, 144, 149, 150, 151, 152, 156, 157, 170, 207, 209, 219, 224, 256], "openai_api_key": [95, 156], "openaichatstreamcli": 179, "openaichatstreamsglangcli": 179, "openbmb": [96, 157], "openbuddi": [96, 157], "openbuddy2": [96, 157], "openclip": 206, "opencompass": [0, 55, 67, 68, 116, 128, 129, 179], "opencv": [0, 213], "opencv2": 213, "opencv_contrib": 212, "opencv_extra_modules_path": 212, "opencv_test_cannop": 212, "openeul": [33, 185], "openeuler20": 185, "opengvlab": [71, 96, 104, 132, 157, 165, 197], "openherm": [96, 157], "openicl": 210, "openmind": 7, "openo1": [96, 157], "openorca": [96, 157], "openrail": 219, "openslr": 253, "openthought": [96, 157], "openvino": 256, "openwebtext_dataset": [96, 157], "oper": [28, 38, 46, 50, 51, 53, 111, 112, 114, 116, 118, 125, 128, 131, 134, 142, 148, 150, 159, 160, 166, 172, 228, 249], "operator_detail": 177, "operatornam": [50, 89, 111, 150], "oppos": 160, "opposit": 139, "ops": [40, 46, 116, 187], "opt": [48, 70, 109, 131], "opt_param_schedul": [98, 159], "optim": [9, 17, 27, 28, 34, 35, 38, 39, 42, 67, 74, 76, 77, 81, 87, 89, 92, 98, 99, 105, 116, 124, 128, 135, 137, 138, 141, 142, 148, 152, 153, 159, 160, 162, 166, 172, 174, 178, 188, 191, 215, 219], "optim_torch": 7, "optimized_rotary_pos_emb": 39, "optimizedqwen3model": 39, "optimizedrmsnorm": 39, "optimizemod": [48, 109], "optimizer_cl": 219, "optimizer_cpu_offload": [99, 160], "optimizer_group": [97, 158], "optimizer_grouped_paramet": [62, 123], "optimizer_kwarg": [62, 123], "optimizer_offload": [174, 178, 181], "optimizer_offload_fract": [99, 160], "optimizernam": [67, 128], "optimizers_map": [62, 123], "optimum": [69, 130], "option": [7, 11, 18, 32, 33, 38, 39, 47, 53, 62, 70, 86, 105, 109, 112, 114, 116, 117, 118, 121, 123, 125, 127, 128, 129, 130, 144, 147, 153, 160, 166, 170, 172, 199, 204, 219, 237, 243], "optypelist_for_implmod": 204, "or": [5, 9, 34, 36, 37, 38, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 57, 59, 62, 65, 66, 67, 88, 89, 90, 91, 109, 110, 111, 112, 114, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130, 132, 133, 138, 140, 141, 142, 143, 144, 146, 147, 149, 150, 151, 152, 153, 154, 155, 158, 160, 161, 162, 174, 175, 188, 214, 219, 230, 237, 240, 246, 249, 250], "orca": [96, 157], "orca_dpo_pair": [96, 157], "orchestr": 46, "order": [39, 40, 51, 110, 112, 128, 132, 149, 194, 219, 234, 241], "org": [14, 94, 96, 155, 157, 174, 178, 179, 213, 219, 221, 224, 230, 243], "organiz": [113, 117, 121, 124, 130, 143, 246], "orient": 35, "origin": [28, 34, 38, 41, 46, 66, 82, 83, 86, 110, 113, 116, 119, 123, 127, 128, 137, 143, 144, 147, 148, 153, 154, 155, 158, 159, 160, 172, 219, 239, 245], "origin_forward": [98, 159], "origin_train_step_out": [98, 159], "original_init": 39, "orion": [96, 157], "orionstarai": [96, 157], "orm": [50, 52, 60, 67, 85, 87, 88, 93, 94, 99, 111, 113, 121, 128, 146, 148, 149, 154, 155, 160], "orm_model": [95, 156], "orpo": [7, 17, 19, 24, 63, 67, 91, 96, 124, 128, 152, 157], "ort": 204, "ort_logging_level_warn": 204, "ortallocatortyp": 204, "ortarenaalloc": 204, "ortcannprovideropt": 204, "orth": [67, 128], "orthogon": [67, 128], "ortmemtypedefault": 204, "ortsessionopt": 204, "os": [53, 57, 60, 65, 70, 90, 91, 114, 118, 121, 126, 131, 151, 152, 188, 191, 214, 215, 219], "oscil": [111, 113, 155], "oss": [47, 53, 57, 70, 90, 91, 96, 99, 114, 118, 131, 151, 152, 157, 160, 179, 191], "oss_bucket_0": 222, "osunlp": [96, 157], "other": [32, 33, 35, 38, 40, 43, 44, 46, 50, 57, 109, 110, 111, 112, 113, 114, 116, 117, 118, 121, 123, 124, 126, 127, 129, 130, 134, 136, 137, 138, 139, 141, 144, 147, 148, 149, 150, 152, 155, 157, 158, 159, 160, 161, 166, 188, 194, 200, 209, 219, 243, 246], "other_config": [83, 144], "otherwis": [35, 47, 51, 70, 81, 112, 120, 123, 128, 131, 142, 148, 160, 166], "our": [46, 50, 110, 111, 114, 131, 146, 188, 219], "out": [28, 35, 46, 57, 110, 113, 114, 118, 120, 128, 135, 136, 139, 147, 150, 156, 160, 166, 184, 210, 214, 219], "out1": 214, "out_channel": 214, "out_height": 214, "out_hidden_s": [58, 119], "out_id": [57, 118], "out_proj": 214, "out_proj_bia": 214, "out_proj_weight": 214, "out_tensor": 204, "out_width": 214, "outcom": [50, 76, 111, 128, 137, 155], "outer": [110, 234], "outgelu": 214, "outlin": 121, "output": [8, 11, 17, 19, 20, 38, 42, 43, 46, 48, 50, 51, 52, 53, 55, 56, 57, 58, 60, 62, 63, 67, 69, 83, 86, 89, 91, 97, 99, 103, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 127, 128, 130, 132, 135, 137, 140, 141, 144, 147, 148, 149, 150, 151, 152, 153, 155, 156, 160, 161, 164, 172, 173, 188, 194, 204, 210, 213, 214, 215, 219, 222, 230, 231, 243, 246], "output1": 214, "output2": 214, "output2tensor": 214, "output3": 214, "output_c": 214, "output_dim": 214, "output_dir": [3, 8, 9, 17, 20, 23, 24, 25, 39, 43, 48, 50, 51, 52, 53, 55, 56, 57, 58, 63, 67, 70, 97, 99, 102, 103, 104, 105, 109, 111, 112, 113, 114, 116, 117, 118, 119, 124, 128, 131, 158, 160, 163, 164, 165, 166, 179, 219, 222, 241], "output_directori": 44, "output_dtyp": 214, "output_fil": [67, 128], "output_h": 214, "output_id": 191, "output_iou": 214, "output_lay": [99, 160], "output_nam": 204, "output_names_ptr": 204, "output_node_nam": 204, "output_pad": 214, "output_path": [27, 44, 70, 131, 179, 199], "output_postprocess": 204, "output_s": 214, "output_subdir": 222, "output_tensor": 204, "output_text": [57, 118], "outputpath": 213, "outputtensor": 214, "outsid": [41, 70, 109, 131], "outtensor": 214, "ov": [96, 157], "over": [38, 57, 70, 111, 113, 118, 121, 128, 135, 141, 142, 145, 147, 160, 166, 188, 219, 228, 241], "overal": [35, 36, 38, 57, 118, 119, 133, 150, 160], "overemphas": 133, "overflowerror": 219, "overhead": [34, 40, 128, 131, 143, 160, 172], "overlap": [35, 38, 99, 105, 128, 149, 160, 166, 177, 214], "overlap_comm": [9, 48, 109, 188, 219], "overlength": 150, "overlong": [67, 89, 99, 128, 160, 180], "overlong_buff": 180, "overlong_buffer_len": 180, "overlong_filt": [56, 74, 89, 117, 135, 150], "overlong_penalty_factor": 180, "overrid": [11, 35, 67, 122, 128, 160, 194, 219, 222, 240], "override_method": 39, "override_transformer_config": 174, "overs": 128, "overwrit": [37, 43, 128, 160, 219], "overwrite_cach": [7, 8, 9, 17, 20, 24, 219], "overwrite_output_dir": [8, 17, 20, 24], "ovis1": [67, 96, 128, 157], "ovis2": [55, 63, 96, 116, 124, 157], "owl": [96, 157], "owl2": [96, 157], "owl3": [67, 96, 128, 157], "own": [39, 43, 62, 67, 110, 121, 123, 128, 131, 143, 147, 156, 160, 204, 219], "p2p": [55, 99, 116, 160], "p6dens": 42, "p_student": [71, 132], "p_teacher": [71, 132], "pack": [7, 43, 53, 56, 57, 60, 63, 67, 91, 99, 103, 104, 105, 114, 117, 118, 121, 124, 128, 152, 160, 164, 165, 166], "packag": [14, 37, 41, 48, 109, 116, 128, 172, 185, 187, 219, 236], "package_refer": 219, "packed_seq_param": [53, 98, 114, 159], "packedseqparam": [98, 159], "packing_num_proc": [67, 99, 128, 160], "packing_row": [53, 114], "packsequnc": 214, "pad": [7, 38, 42, 43, 53, 60, 67, 99, 114, 121, 128, 160, 184, 210, 214, 219, 241, 256], "pad_packed_to_length": 45, "pad_to_max_output_s": 214, "pad_token_id": [53, 114], "pad_valu": 46, "padding_fre": [53, 57, 67, 99, 114, 118, 128, 160], "padding_mask": 214, "padding_sid": 210, "padding_to": [53, 114], "paddingmask": 214, "paddl": [96, 157], "paddleocr": [96, 157], "paddlepaddl": [96, 157], "page": [41, 55, 57, 90, 97, 116, 118, 126, 128, 130, 151, 158, 185, 214, 219], "pageattent": 214, "pai": [56, 117], "paint": [57, 118], "painter": [57, 118], "pair": [35, 48, 67, 96, 109, 120, 123, 128, 157, 158, 160, 194, 245], "pairwis": [96, 110, 157], "paligemma": [11, 96, 157], "paligemma2": [96, 157], "panda": [207, 219], "panqiwei": [69, 130], "pant": 151, "paper": [38, 75, 113, 123, 128, 132, 133, 134, 136, 138, 139, 140, 141, 142, 143, 148, 153, 155, 160, 219], "paradigm": [97, 116, 158], "paragraph": [96, 157], "parallel": [9, 36, 39, 42, 67, 89, 99, 117, 118, 121, 124, 127, 128, 148, 150, 151, 152, 158, 160, 161, 162, 163, 164, 165, 166, 184, 188, 201, 203, 215, 219, 237, 240], "parallel_mod": 219, "parallel_plan": [35, 46], "parallel_st": 43, "parallelize_modul": 35, "parallelplan": [35, 46], "param": [58, 67, 97, 99, 119, 128, 158, 160, 188, 194, 204, 219, 234], "param_count": 234, "param_group": [67, 128], "param_offload": [174, 178, 181], "paramet": [19, 28, 31, 34, 35, 38, 39, 40, 42, 43, 44, 46, 60, 66, 67, 97, 99, 103, 109, 110, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 133, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 156, 158, 159, 163, 164, 165, 166, 172, 181, 188, 215, 219], "parameter": 141, "parameterless": 156, "parent": [166, 172], "parenthes": [50, 111], "pari": [231, 243], "parodist": 243, "parquet": [27, 29, 79, 140, 174, 179, 180], "parrot": 243, "pars": [52, 113, 121, 122, 123, 128, 131, 148, 172, 219], "parse_arg": [43, 188, 213, 219], "parse_args_into_dataclass": 219, "parse_json_fil": 219, "parser": [67, 128, 188, 213, 219], "part": [38, 50, 53, 57, 70, 110, 111, 114, 117, 118, 119, 121, 122, 123, 127, 128, 147, 150, 160, 213, 219], "part1": 38, "part2": 38, "parti": [152, 241], "partial": [43, 46, 53, 114, 117, 172, 214, 219], "particip": [46, 114, 121, 123, 127, 134, 145, 160], "particular": [110, 122, 128, 219], "partit": [35, 38, 46, 67, 75, 128, 136, 152, 154, 160, 219], "pass": [35, 39, 43, 52, 60, 62, 67, 70, 83, 95, 98, 99, 103, 110, 111, 113, 114, 117, 121, 122, 123, 128, 144, 146, 147, 150, 153, 154, 156, 158, 159, 160, 164, 172, 173, 188, 212, 215, 219, 228, 237, 243], "passag": [59, 120], "passiv": 219, "passthrough": [128, 158, 160], "past_key_valu": 219, "pastor": 151, "patch": [40, 41, 67, 70, 98, 128, 131, 159], "patch16": 243, "patch_dim": 11, "patch_emb": [53, 114], "patch_get_input_embed": [53, 114], "patch_modul": 39, "patch_qwen_vl_util": [53, 114], "patch_spec": 39, "patchconfig": 39, "patched_modeling_qwen3_gpu": 39, "patcher": [53, 114], "patchgen": 39, "path": [3, 36, 37, 39, 40, 41, 42, 43, 44, 46, 47, 48, 55, 56, 57, 58, 60, 61, 67, 68, 70, 79, 90, 91, 96, 99, 103, 109, 110, 112, 113, 116, 117, 118, 119, 121, 122, 128, 129, 132, 140, 141, 151, 152, 157, 160, 161, 164, 166, 170, 174, 176, 178, 179, 180, 187, 194, 203, 204, 207, 210, 212, 213, 219, 221, 230, 234, 245, 250, 256], "path_to_merged_model": [20, 21], "path_to_model": 194, "path_to_train_fil": 219, "path_to_validation_fil": 219, "path_to_your_model": 193, "pathlib": 219, "pathlib2": [185, 206, 209, 233], "pathto": 221, "pattern": [35, 46, 50, 57, 61, 62, 70, 111, 113, 118, 122, 123, 128, 131, 148, 164], "pay": [109, 160], "pbtxt": 214, "pcie": [55, 116], "pcm_s16le": 256, "pd": 207, "pde": 225, "pdf": [94, 155, 178], "peak": [72, 132, 133, 172], "pearson": [49, 110], "peft": [62, 64, 67, 91, 97, 105, 116, 123, 125, 128, 152, 158, 166, 174, 210], "peft_model": [103, 164], "peftconfig": [97, 158], "peftmodel": [62, 91, 97, 123, 152, 158], "penal": 148, "penalis": 147, "penalti": [67, 87, 89, 128, 135, 148, 150, 153, 194, 214], "penalty_factor": 180, "penalty_for_step": 222, "pend": [123, 131, 160], "penguin": 129, "peopl": 241, "per": [9, 35, 38, 40, 42, 45, 46, 48, 67, 89, 93, 99, 109, 111, 120, 128, 133, 135, 137, 138, 150, 154, 160, 161, 162, 180, 181, 188, 194, 214, 219, 256], "per_device_eval_batch_s": [8, 20, 24, 48, 50, 51, 52, 53, 56, 57, 63, 68, 70, 89, 109, 111, 112, 113, 114, 117, 118, 124, 129, 131, 150, 219], "per_device_train_batch_s": [8, 9, 17, 24, 48, 50, 51, 52, 53, 56, 57, 58, 59, 63, 67, 68, 70, 89, 101, 109, 111, 112, 113, 114, 117, 118, 119, 120, 124, 128, 129, 131, 150, 162, 219, 222], "per_featur": 214, "per_round": [67, 128], "per_token_logp": [73, 75, 134, 136], "per_token_loss": [73, 134], "percentag": [52, 70, 113, 128, 219], "percentil": 141, "perchannel": 214, "perf": [48, 109], "perform": [39, 42, 45, 57, 99, 104, 111, 114, 116, 117, 118, 119, 120, 128, 129, 130, 132, 136, 139, 140, 142, 147, 148, 150, 151, 152, 153, 155, 156, 160, 164, 165, 166, 178, 181, 214, 219, 250], "pergroup": 214, "perhap": [57, 118, 241], "peridium": 234, "period": [128, 219], "perm": 214, "permiss": [130, 170, 219], "permut": [99, 111, 160, 214], "perpendicular": [52, 113], "perplex": [150, 193, 219], "persist": [67, 99, 128, 160], "person": 241, "pertain": 219, "pertensor": 214, "pertoken": 214, "pertoken_scal": 214, "perturb": 219, "petrel": 47, "pfa": 214, "pg_clip": 222, "phallal": 234, "phase": [89, 150, 160, 162, 250], "phb": [55, 116], "phenomenon": 155, "phi": [6, 72, 96, 133, 157], "phi2": [96, 157], "phi3": [67, 96, 128, 157], "phi4": [62, 96, 123, 157], "philosophi": [151, 152, 200], "philox": 214, "phone": [96, 157, 243], "photo": 3, "pi": [35, 46, 50, 72, 73, 75, 76, 77, 78, 80, 81, 84, 89, 104, 111, 133, 134, 136, 137, 138, 139, 141, 142, 145, 150, 165], "piassa": [70, 131], "pick": 219, "pickl": [47, 219], "pid": [172, 173], "piec": [128, 194], "pierc": 237, "pil": [79, 140, 204, 207, 243], "pile": [96, 157], "pilimag": [188, 219], "pillow": [151, 204], "pin": [42, 43, 67, 99, 128, 160], "pin_memori": [9, 42, 43, 48, 109, 214, 219], "pink": [57, 118, 151], "pip": [1, 5, 8, 13, 14, 22, 26, 48, 53, 55, 56, 57, 60, 61, 64, 68, 69, 70, 90, 91, 95, 98, 105, 109, 114, 116, 117, 118, 121, 122, 125, 129, 130, 131, 151, 152, 156, 159, 166, 170, 174, 175, 178, 179, 183, 184, 185, 187, 188, 190, 199, 204, 206, 209, 218, 219, 221, 222, 224, 227, 230, 233, 236, 239, 241, 244, 245, 248, 252], "pip3": [32, 33, 70, 131, 185, 203, 206, 209, 233, 244], "pip_index": 14, "pipe": [3, 197, 243], "pipelin": [2, 3, 42, 43, 67, 99, 124, 128, 131, 152, 160, 161, 162, 166, 170, 197, 219, 220, 242, 244], "pipeline_model_parallel_s": [56, 103, 117, 160, 164, 222], "pipeline_parallel_degre": 240, "pipeline_parallel_s": 43, "pipeutil": [98, 159], "piqa": [68, 70, 129, 131], "pissa": [7, 67, 128], "pissa_convert": [7, 18], "pissa_init": [7, 18], "pissa_it": [7, 18], "pissa_niter_": [67, 128], "pix": [55, 116], "pixel": [67, 70, 79, 128, 131, 234], "pixel_valu": [11, 46, 53, 114, 219], "pixel_values_video": 46, "pixelpros": [96, 157], "pixtral": [96, 157], "pkill": [179, 180, 181], "place": [111, 113, 114, 120, 123, 144, 151, 163, 241], "placehold": [46, 121, 122, 128], "placeholder_token": [53, 114], "placement": [128, 160], "placement_fn": 35, "plain": [121, 160], "plaintext": 42, "plan": [35, 44, 111], "plane": [188, 219], "planner": 144, "platform": [32, 150, 172, 219], "platypus": [96, 157], "play": [51, 57, 96, 112, 118, 121, 141, 157], "player": [51, 112], "plead": [57, 118], "pleas": [32, 34, 35, 37, 43, 47, 51, 70, 88, 110, 112, 116, 117, 118, 120, 121, 124, 126, 127, 128, 129, 130, 131, 132, 135, 137, 144, 145, 147, 148, 149, 150, 151, 152, 153, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166, 184, 197, 214, 219, 246, 249], "pleisto": [96, 157], "plot_loss": [7, 8, 9, 17, 24], "plugin": [50, 51, 52, 62, 67, 70, 79, 87, 88, 95, 96, 99, 101, 111, 112, 113, 117, 124, 127, 128, 131, 140, 143, 146, 147, 148, 156, 157, 160, 162, 172], "plus": [96, 133, 157], "pm10": [60, 66, 121, 127], "pm2": [60, 66, 121, 127], "pmmeval": [70, 131], "png": [3, 53, 57, 60, 66, 90, 91, 113, 114, 118, 121, 127, 151, 152, 213, 219, 243], "podc": [55, 116, 174, 175, 176, 222], "poetri": [96, 157, 178], "point": [37, 40, 41, 44, 52, 56, 57, 110, 111, 113, 117, 118, 120, 121, 136, 139, 140, 142, 152, 156, 158, 160, 166, 219, 249], "pointer": [219, 245], "poison": [96, 157], "pokemon": [3, 219], "polici": [17, 67, 74, 76, 77, 86, 87, 89, 92, 94, 99, 128, 129, 135, 137, 138, 141, 147, 148, 150, 153, 155, 160, 162, 172, 180, 181, 188, 219, 245], "policy_logp": [67, 99, 128, 160], "policy_loss": [89, 150, 181], "polit": 246, "poll": 243, "poll_parrot": 243, "pollut": [121, 127], "polycarp": [51, 112], "polylm": [96, 157], "polynomi": [24, 219], "pool": [34, 128, 188, 194, 214, 219], "pooled_height": 214, "pooled_width": 214, "poor": [154, 241], "pop": [29, 30, 46, 50, 53, 111, 114, 219], "pope": [68, 70, 129, 131], "popinjay": 243, "popul": 150, "popular": 124, "populate_model_card": 219, "port": [9, 48, 67, 70, 90, 99, 109, 128, 131, 149, 151, 160, 179, 180, 181, 184, 230, 231], "portion": [46, 122, 128, 155, 164], "portrait": [57, 118], "pos": [39, 42, 45, 46, 49, 67, 78, 110, 128, 139], "pos_emb": 46, "pos_iou_thr": 214, "posit": [39, 42, 43, 45, 49, 59, 99, 110, 120, 121, 127, 128, 139, 141, 142, 160, 214, 237, 244], "position_embed": [39, 46], "position_id": [39, 46, 53, 98, 114, 159], "position_id_per_second": [53, 114], "positive_audio": [49, 110], "positive_imag": [49, 59, 110, 120], "positive_messag": [49, 59, 110, 120], "positive_similar": [49, 110], "positive_video": [49, 110], "possibl": [50, 111, 128, 152, 160, 166, 184, 219], "post": [16, 23, 42, 43, 87, 96, 131, 148, 155, 157, 231], "post1": [13, 56, 64, 70, 90, 117, 125, 131, 151, 224], "post2": [22, 175], "post3": 230, "post6": [227, 248], "potenti": [128, 142, 155, 219], "power": [43, 55, 116, 185], "powerinf": [96, 157], "pp": [63, 67, 90, 99, 100, 101, 103, 105, 124, 128, 151, 160, 161, 162, 164, 166, 240], "pp_size": 43, "ppl": [67, 89, 99, 128, 150, 160], "ppl_ratio": [81, 89, 142, 150], "ppo": [0, 7, 24, 55, 56, 62, 65, 72, 74, 81, 89, 91, 93, 94, 116, 117, 123, 126, 133, 135, 142, 150, 152, 154, 155, 172, 173, 174, 180, 181], "ppo_buffer_s": 7, "ppo_epoch": [7, 172, 173, 222], "ppo_max_token_len_per_gpu": [178, 180], "ppo_megatron_train": [172, 173], "ppo_micro_batch_size_per_gpu": [174, 180], "ppo_mini_batch_s": [174, 178], "ppo_score_norm": 7, "ppo_target": 7, "ppo_train": [172, 173], "ppo_whiten_reward": 7, "pq": 27, "pr": [67, 89, 90, 99, 109, 128, 150, 151, 160, 219], "practic": [41, 45, 46, 50, 111, 122, 132, 135, 141, 142, 152, 159, 163, 165, 166], "pre": [43, 46, 80, 99, 119, 120, 124, 128, 141, 151, 160, 161, 166, 194, 200, 214, 230], "pre_forward_hook": [53, 114], "pre_group": 214, "pre_process": [98, 159], "pre_tocken": 214, "pre_token": 214, "preced": [120, 128], "precheck": [48, 109], "precis": [16, 42, 43, 67, 99, 128, 160, 163, 164, 166, 188, 214, 219, 241], "precisiondebugg": [98, 159], "precomput": 46, "pred": 219, "pred_idx": 204, "pred_postprocessor": 179, "predefin": [35, 129, 241], "predict": [20, 40, 62, 67, 123, 128, 133, 142, 160, 184, 188, 204, 210, 219, 234, 241, 244], "predict_on": 199, "predict_with_gener": [20, 67, 128], "prediction_typ": 219, "predomin": [57, 118], "pref_beta": [7, 17], "pref_ftx": 7, "pref_loss": [7, 17], "prefer": [96, 121, 124, 153, 157, 166, 224], "preferenti": 142, "prefetch": [43, 67, 99, 128, 160, 181], "prefetch_factor": [42, 43], "prefil": [177, 231, 237], "prefix": [44, 53, 61, 67, 99, 114, 117, 122, 126, 128, 142, 150, 153, 158, 160, 181, 214], "prehistori": 200, "preload": 41, "prepar": [5, 62, 118, 124, 131, 159, 160, 164, 172, 188, 191, 194, 201, 204, 219], "prepare_mcore_model": [103, 164], "prepare_model": [62, 97, 123, 158], "prepend": 110, "preprocess": [40, 42, 46, 50, 52, 60, 111, 113, 114, 117, 118, 121, 123, 128, 140, 152, 160, 166, 170, 204, 207, 219], "preprocess_func": [50, 52, 60, 111, 113, 121], "preprocess_logits_for_acc": [62, 123], "preprocess_logits_for_metr": 219, "preprocess_train": 219, "preprocessing_batch_s": 7, "preprocessing_num_work": [7, 8, 17, 20, 24, 219], "preprocessor": [52, 70, 113, 121, 131], "prescale_gradi": [188, 219], "presenc": [140, 158], "presence_penalti": 194, "present": [111, 129, 156, 219], "preserv": [39, 117, 128, 134, 139, 160, 219], "preset": 131, "press": [88, 149, 231], "pressur": 128, "pretend": [57, 118], "pretoken": 214, "pretrain": [24, 28, 42, 43, 58, 62, 71, 96, 128, 132, 157, 160, 166, 200, 207, 219, 222, 228, 234], "pretrained_model": 44, "pretrained_model_name_or_path": [3, 219], "pretrained_vae_model_name_or_path": 3, "pretrainedconfig": [36, 53, 114], "pretrainedmodel": [36, 53, 114, 243], "pretrainedtoken": 243, "prev": [35, 67, 128], "preval": 38, "prevent": [34, 42, 46, 110, 113, 126, 128, 138, 140, 150, 151, 160], "preview": [39, 96, 157, 179], "previous": [42, 51, 112, 113, 117, 128, 147, 155, 160, 219], "primari": [116, 246], "primarili": [129, 150, 151], "principl": [109, 120], "print": [11, 14, 21, 39, 43, 51, 53, 55, 57, 60, 66, 87, 88, 90, 91, 103, 112, 114, 116, 118, 121, 127, 128, 148, 149, 151, 152, 160, 164, 166, 179, 180, 181, 188, 191, 196, 197, 204, 206, 207, 209, 214, 218, 219, 230, 231, 233, 236, 239, 241, 243, 244, 246, 252], "print_param_status": 7, "printmessag": 213, "prior": [121, 141, 160], "priorit": [128, 155, 160], "prioriti": [120, 121, 128, 131, 132], "privat": [41, 67, 128, 130, 219], "privileg": [14, 230], "prm": [67, 90, 93, 94, 96, 128, 151, 154, 155, 157], "prm800k": [96, 157], "prm_model": [95, 156], "prms": [95, 156], "prng": [67, 128], "pro": [7, 91, 96, 97, 152, 157, 158], "prob": [67, 99, 128, 131, 160, 207, 214, 234], "probabl": [40, 51, 86, 89, 112, 120, 128, 132, 133, 134, 135, 141, 142, 147, 150, 151, 153, 160, 161, 172, 184, 214, 244], "probe": [98, 159], "problem": [45, 50, 51, 52, 60, 67, 83, 86, 96, 99, 111, 112, 113, 120, 121, 128, 142, 144, 147, 157, 160, 172, 219, 243], "problem_typ": [67, 70, 131], "problemat": 136, "proc": [67, 99, 128, 160], "procedur": 45, "proceed": [46, 116, 119, 153, 188, 219], "process": [11, 32, 33, 35, 36, 37, 38, 42, 43, 44, 48, 50, 52, 67, 83, 84, 86, 87, 88, 89, 96, 109, 112, 113, 114, 117, 118, 119, 120, 121, 126, 127, 128, 129, 130, 132, 140, 142, 144, 145, 146, 147, 148, 149, 150, 152, 154, 155, 156, 157, 159, 160, 163, 166, 172, 184, 185, 204, 210, 213, 214, 215, 219, 231, 234, 249, 256], "process_messag": 11, "process_mm_info": [53, 114], "process_pretrain_exampl": 43, "process_sampl": [37, 46], "process_sft_exampl": 43, "process_vision_info": [57, 118], "processgroup": 38, "processgroupnccl": [70, 131], "processing_class": 219, "processing_llama4": 11, "processing_qwen2_5_omni": [53, 114], "processing_qwen3_vl_mo": 46, "processor": [11, 44, 46, 53, 57, 60, 61, 67, 103, 114, 118, 121, 122, 128, 164, 256], "prod": [11, 53, 114], "produc": [39, 50, 111, 112, 114, 128, 149, 249], "product": [14, 34, 50, 83, 86, 110, 111, 129, 142, 144, 147], "prof": [98, 159], "prof_config": 179, "prof_npu": [172, 173], "professional_account": 200, "professional_law": 200, "professional_medicin": 200, "professional_psycholog": 200, "profil": [14, 42, 98, 159, 172, 179, 207, 250], "profile_end_step": 43, "profile_memori": [43, 98, 159, 172, 173], "profile_model": 207, "profile_profile_memori": 43, "profile_record_shap": 43, "profile_start_step": 43, "profile_trace_dir": 43, "profile_with_stack": 43, "profiler_level": [98, 159, 172, 173], "profiler_npu": [172, 173], "profiler_path": [172, 173], "profiler_result": 207, "profileract": [98, 159, 172, 173], "profilerlevel": [98, 159, 172, 173], "program": [51, 57, 112, 118, 146, 148, 160], "progress": [39, 97, 121, 141, 155, 158, 170, 219], "progress_bar": 219, "proj": [38, 53, 67, 99, 103, 114, 128, 160, 164], "proj_bia": 38, "proj_weight": 38, "project": [13, 18, 31, 35, 37, 38, 42, 46, 55, 67, 97, 99, 116, 128, 158, 160, 170, 174, 175, 177, 213, 221, 222, 230], "project_config": 219, "project_dir": 219, "project_nam": [174, 178, 179, 180, 219], "projectconfigur": 219, "projector": [67, 99, 128, 160], "promin": [57, 118], "prompt": [3, 7, 11, 17, 19, 37, 51, 52, 53, 56, 60, 61, 62, 67, 77, 79, 85, 87, 88, 89, 92, 97, 99, 101, 110, 112, 113, 114, 117, 121, 122, 123, 128, 138, 140, 144, 146, 147, 148, 149, 150, 151, 152, 153, 158, 160, 162, 177, 181, 191, 194, 219, 222, 225, 231, 237, 241, 256], "prompt_flash_attent": 214, "prompt_token": 231, "prompt_tokens_detail": 231, "promptflashattent": 214, "propag": 172, "proper": [116, 117, 118, 148, 152, 162, 219], "properti": [19, 52, 60, 66, 113, 121, 127, 141, 219], "proport": [42, 128, 132, 150, 153, 160, 161, 219], "propos": [38, 132, 133, 134, 139, 140, 141, 143, 155, 214], "pros": 39, "protein": 129, "protobuf": [185, 206, 209, 219, 233], "prove": [111, 113], "prover": [96, 157], "provid": [32, 34, 37, 38, 44, 47, 50, 52, 56, 59, 66, 83, 86, 87, 91, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 133, 134, 136, 140, 143, 144, 147, 148, 149, 151, 152, 153, 155, 156, 158, 160, 172, 204, 214, 219, 241, 246], "provinc": 151, "proxim": [17, 92, 153], "prune": 225, "pse": 214, "pse_shift": 214, "pse_shiftpadding_mask": 214, "pseudo": [38, 126, 134, 136], "pseudocod": [132, 150], "psutil": [185, 206, 209, 230, 233], "pt": [4, 7, 14, 17, 24, 53, 55, 57, 62, 67, 89, 91, 93, 96, 105, 114, 116, 118, 123, 128, 150, 152, 154, 157, 166, 191, 207, 219, 246, 256], "pt22k": 243, "pta_nam": 230, "pta_url": 230, "pta_vers": 230, "pth": 234, "ptmoddevg": 181, "public": 219, "public_rel": 200, "puffbal": 234, "pull": [14, 48, 53, 56, 75, 102, 114, 117, 131, 136, 163, 219], "pull_request": 170, "punkt": [70, 131], "punkt_tab": [70, 131], "pupil": [57, 118], "puppi": [118, 121, 213], "pure": [110, 114, 121, 127, 129, 132, 160, 161, 172], "pure_bf16": [7, 18], "purpl": [3, 52], "purpos": [56, 113, 117, 121, 127, 131, 150, 194, 219], "push": [67, 81, 114, 117, 118, 124, 128, 142, 160, 170, 219], "push_back": 204, "push_to_hub": [24, 53, 56, 57, 63, 69, 114, 117, 118, 124, 130, 219], "put": [51, 56, 112, 117, 131, 207], "pwd": [174, 178, 212], "pxb": [55, 116], "py": [3, 9, 11, 15, 20, 21, 27, 28, 29, 30, 31, 35, 36, 37, 38, 39, 40, 43, 44, 48, 49, 50, 51, 52, 53, 60, 61, 62, 67, 81, 87, 88, 98, 99, 103, 105, 109, 110, 111, 112, 113, 114, 121, 122, 123, 128, 142, 147, 148, 149, 159, 160, 164, 166, 170, 172, 173, 174, 175, 178, 179, 180, 184, 185, 194, 206, 207, 209, 219, 221, 222, 228, 231, 233, 234, 236, 237, 239, 240, 249, 253, 256], "py3": [14, 22, 70, 131, 170], "py310": [64, 125], "py311": [64, 70, 105, 125, 131, 166], "pyarrow": [27, 70, 131], "pyav": [32, 33], "pybind11": [105, 166, 221], "pybind11_cmake_path": 221, "pypi": [2, 13, 14, 55, 116, 183, 184, 185, 206, 209, 227, 230, 233, 244, 248], "pyproject": [32, 33], "pyruv": 129, "pytest": [170, 230], "python": [1, 14, 20, 21, 26, 31, 39, 41, 44, 47, 48, 51, 53, 55, 58, 63, 64, 83, 85, 86, 96, 99, 105, 109, 112, 114, 116, 119, 124, 125, 144, 146, 147, 157, 160, 166, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 184, 185, 191, 194, 196, 203, 205, 207, 208, 210, 218, 219, 220, 222, 224, 228, 231, 232, 234, 236, 237, 238, 244, 249, 251, 256], "python3": [3, 27, 28, 29, 30, 31, 48, 109, 174, 178, 185, 187, 196, 207, 212, 221, 222, 230], "python310": 224, "python_decontamin": [96, 157], "python_execut": 221, "python_include_dir": 212, "pythonpath": [55, 116, 170, 174, 191], "pythonunbuff": 178, "pytorch": [0, 5, 7, 9, 14, 22, 34, 44, 46, 48, 55, 67, 96, 98, 99, 105, 109, 116, 118, 128, 157, 159, 160, 166, 174, 181, 187, 196, 197, 207, 214, 215, 219, 221, 224, 227, 228, 230, 233, 236, 239, 240, 246, 248], "pytorch2": 230, "pytorch6": 181, "pytorch_cuda_alloc_conf": [53, 56, 57, 67, 70, 98, 102, 103, 104, 105, 114, 117, 118, 128, 131, 159, 163, 164, 165, 166], "pytorch_model": 234, "pytorch_npu_alloc_conf": [33, 228], "pytorch_vers": 230, "pytorchengin": 197, "pytorchengineconfig": 197, "pytorchvideo": [96, 157], "pyyaml": [185, 206, 209, 230, 233], "q4_0": 194, "q5_0": 256, "q5_1": 256, "q8_0": 194, "q_bia": 38, "q_proj": [67, 99, 128, 160], "q_s": 214, "q_weight": 38, "qa": [70, 96, 131, 157], "qagqatext": [96, 157], "qaimagenetimagenet": [96, 157], "qamsrvttsscoco": [96, 157], "qamsvd": [96, 157], "qg": [96, 157], "qian": [35, 46], "qk": [99, 160, 214], "qkv": [38, 99, 103, 160, 164], "qlobal": [70, 131], "qlora": [6, 9, 23, 55, 63, 67, 69, 90, 91, 116, 124, 128, 130, 151, 152], "qntvr": 256, "qpi": [55, 116], "qquad": [80, 141], "qrad": [70, 131], "quad": [81, 142], "quadrat": 16, "qualifi": 35, "qualiti": [57, 96, 118, 121, 127, 132, 135, 149, 155, 156, 157], "quant": [67, 96, 128, 157], "quant_axi": 214, "quant_bit": [67, 128], "quant_method": [67, 128], "quant_offset": 214, "quant_offset2": 214, "quant_scal": 214, "quant_scale1": 214, "quant_scale2": 214, "quant_scla": 214, "quant_zero_point": 214, "quantil": [67, 70, 128, 131, 141], "quantiti": 131, "quantiz": [7, 16, 23, 67, 116, 124, 151, 152, 194, 255], "quantization_bit": [7, 16, 23], "quantization_device_map": 7, "quantization_method": [7, 16], "quantization_typ": 7, "quantization_vers": 194, "quanto": [67, 128], "quantoffset": 214, "quantoffset2": 214, "quantscal": 214, "quantscale1": 214, "quantscale2": 214, "quay": [14, 176], "queri": [19, 38, 49, 50, 52, 53, 57, 59, 60, 61, 62, 66, 67, 68, 80, 85, 87, 88, 90, 91, 92, 94, 99, 104, 110, 111, 113, 114, 117, 118, 120, 121, 122, 123, 127, 128, 129, 141, 146, 148, 149, 151, 152, 153, 155, 160, 165, 214, 246], "query0": [90, 91, 151, 152], "query1": [56, 60, 70, 117, 121, 131], "query2": [60, 121], "query_bia": 214, "query_box": 214, "query_lay": 214, "query_padding_s": 214, "query_r": 214, "query_transpos": 214, "query_weight": 214, "querypaddings": 214, "question": [37, 56, 57, 60, 66, 68, 83, 86, 87, 89, 91, 113, 117, 118, 121, 127, 135, 144, 147, 148, 150, 152, 197, 243, 246], "queue": [67, 99, 128, 160, 181, 231], "queue_schedul": 230, "quick": [36, 69, 119, 129, 130, 152, 155, 163, 165, 172, 228, 241], "quicker": [130, 219], "quickstart": [179, 180, 181, 250], "quilt": [57, 118], "quint4x2": 214, "quit": [88, 90, 149, 151, 231], "qvq": [96, 157], "qwen": [6, 22, 27, 28, 29, 30, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 63, 66, 67, 68, 79, 82, 86, 88, 89, 90, 91, 94, 96, 102, 103, 104, 105, 111, 112, 113, 114, 116, 117, 118, 119, 121, 122, 124, 127, 128, 129, 140, 143, 147, 149, 150, 151, 152, 155, 157, 163, 164, 165, 166, 170, 174, 178, 179, 181, 191, 200, 209, 210, 222, 231, 245], "qwen1": [96, 157], "qwen2": [11, 13, 38, 49, 50, 51, 52, 53, 54, 55, 58, 60, 63, 66, 67, 68, 79, 82, 88, 89, 90, 91, 94, 96, 98, 99, 102, 104, 105, 110, 111, 112, 113, 114, 115, 116, 119, 121, 124, 127, 128, 129, 140, 143, 149, 150, 151, 152, 155, 157, 159, 160, 163, 165, 166, 170, 174, 175, 181, 194, 197, 200, 210, 222, 231, 245], "qwen2_5": [43, 70, 131, 222], "qwen2_5_32b_grpo_npu": 174, "qwen2_5_7b_grpo_npu": 174, "qwen2_5_omni": [53, 114], "qwen2_5_vl": [38, 58, 119], "qwen2_5_vl_32b_npu": 174, "qwen2_5_vl_3b_npu": 174, "qwen2_5_vl_7b_model": [58, 119], "qwen2_5_vl_7b_npu": 174, "qwen2_5_vl_fsdp1": 38, "qwen2_5_vlforconditionalgener": [58, 119], "qwen2_5_vlmodel": [58, 119], "qwen2_5_vlpatchmerg": [58, 119], "qwen2_5omniconfig": [53, 114], "qwen2_5omniforconditionalgener": [53, 114], "qwen2_5omniload": [53, 114], "qwen2_5omnimodel": [53, 114], "qwen2_5omniprocessor": [53, 114], "qwen2_5omniprocessorkwarg": [53, 114], "qwen2_5omnitempl": [53, 114], "qwen2_7b_function_rm": 174, "qwen2_7b_sft_npu": 174, "qwen2_vl": 37, "qwen2vl": [42, 91, 152], "qwen3": [15, 34, 35, 40, 42, 44, 48, 49, 55, 58, 59, 60, 63, 66, 67, 86, 96, 99, 102, 103, 104, 105, 109, 110, 116, 119, 120, 121, 124, 127, 128, 147, 157, 160, 163, 164, 165, 166, 170, 174, 175, 180, 191], "qwen3_14b_npu": 174, "qwen3_30b_fsdp_npu": 174, "qwen3_30b_megatron_npu": 174, "qwen3_8b_fsdp2_npu": 174, "qwen3_8b_model": [58, 119], "qwen3_8b_npu": 174, "qwen3_8b_ppo_npu": 174, "qwen3_8b_sglang_npu": 174, "qwen3_8b_vllm_npu": 174, "qwen3_gpu_patch_gen_config": 39, "qwen3_mo": 35, "qwen3_nothink": [103, 164], "qwen3_omni": 29, "qwen3_sft": 27, "qwen3_vl": [30, 38], "qwen3_vl_dens": [30, 38], "qwen3_vl_mo": [30, 46], "qwen3attent": 39, "qwen3fortokenclassif": 39, "qwen3guard": [96, 157], "qwen3mlp": 39, "qwen3model": 39, "qwen3moeexpert": 28, "qwen3moemlp": 28, "qwen3moesparsefusedmoeblock": 28, "qwen3moesparsemoeblock": 28, "qwen3rmsnorm": 39, "qwen3vl": 38, "qwen3vlforconditionalgener": [57, 118], "qwen3vlmoeconfig": 46, "qwen3vlmoeforcausallm": 46, "qwen3vlmoeforsequenceclassif": 46, "qwen3vlmoefortokenclassif": 46, "qwen3vlmoemodel": 46, "qwen3vlmoeprocessor": 46, "qwen_en": 128, "qwen_omni_util": [53, 67, 114, 128], "qwen_vl_util": [57, 67, 79, 118, 128, 140], "qwenlm": 128, "qwenlong": [96, 157], "qwenvl": [67, 128], "qwenvl_bbox_format": [53, 60, 114, 121], "qwq": [96, 157], "r1": [50, 51, 56, 63, 87, 94, 95, 96, 105, 111, 112, 117, 124, 148, 155, 156, 157, 166, 177, 214], "r1_ascend": 179, "r1v": 52, "r2": 214, "r_t": [73, 134], "race": [68, 70, 129, 131], "racial": 241, "rais": [41, 62, 86, 88, 123, 128, 135, 147, 149, 158, 219, 221, 222], "ram": 44, "ramp": 133, "ran": 212, "rand": 214, "randint": [214, 219], "randn": [55, 116, 191, 214, 215, 218, 219, 230, 239], "randn_lik": 219, "random": [7, 18, 31, 42, 43, 67, 70, 71, 85, 99, 100, 110, 113, 120, 128, 132, 146, 160, 161, 166, 191, 213, 214, 219], "random_flip": [3, 219], "random_prompt_preprocessor": 37, "random_prompt_sourc": 37, "randomcrop": 219, "randomhorizontalflip": 219, "rang": [28, 43, 48, 52, 53, 56, 67, 93, 109, 113, 114, 117, 121, 124, 125, 128, 131, 132, 135, 148, 150, 153, 154, 160, 166, 172, 173, 188, 191, 214, 219, 222, 241], "rank": [7, 9, 18, 19, 35, 38, 45, 46, 48, 56, 58, 67, 93, 97, 99, 102, 105, 109, 110, 117, 119, 120, 128, 154, 158, 160, 163, 166, 172, 173, 177, 188, 214, 215, 219], "rank0": [45, 67, 70, 93, 99, 131, 154], "rank1": [45, 70, 131], "rank7": [70, 131], "rank_end": 46, "rank_image_mask": 46, "rank_start": 46, "rapid": 113, "rare": [155, 241], "rate": [34, 42, 50, 67, 82, 99, 111, 113, 123, 126, 128, 139, 143, 148, 152, 160, 219], "rather": [110, 117, 136, 141, 142, 160, 164], "ratio": [7, 18, 42, 43, 67, 70, 78, 82, 89, 92, 99, 128, 131, 134, 136, 139, 142, 143, 148, 150, 153, 160, 162, 177], "raw": [37, 46, 128, 129, 197, 243], "raw_dataset": 219, "raw_hf_path": [27, 28], "ray": [4, 170, 175, 179, 180, 181], "ray2333": [96, 157], "ray_api_server_address": 9, "ray_data_hom": [179, 180], "ray_dedup_log": [179, 181], "ray_experimental_noset_ascend_rt_visible_devic": [175, 179], "ray_init_kwarg": 7, "ray_memory_monitor_refresh_m": [70, 131], "ray_num_work": 7, "ray_status_output": [179, 180, 181], "rayhelp": [93, 154], "rc1": [2, 14, 33, 55, 116, 170, 174, 175, 176, 178, 180, 181, 183, 193, 199, 206, 209, 212, 221, 227, 230, 233, 239, 248, 252, 255], "rc1_a2": 176, "rc1_a3": 176, "rc1_linux": 14, "rc2": [14, 187, 197, 252], "rd": [70, 131], "rdma": [181, 230], "rdzv": [48, 109], "rdzv_backend": [9, 15, 48, 109], "rdzv_conf": [48, 109], "rdzv_endpoint": [48, 109], "rdzv_id": [48, 109], "re": [38, 50, 52, 57, 62, 111, 113, 118, 123, 128, 130, 147, 156, 184, 219], "reach": [3, 41, 50, 111, 113, 128, 147, 160, 172], "react": [57, 60, 66, 67, 118, 121, 127, 128], "react_en": [66, 127, 128], "read": [27, 57, 90, 114, 118, 122, 123, 124, 128, 147, 151, 152, 160, 163, 170, 184, 219, 237], "read_tabl": 27, "readabl": [39, 160], "reader": [57, 118], "readi": [37, 70, 91, 131, 152, 177, 179, 180, 181, 231], "readlin": 204, "readm": [184, 219], "readme_cn": 175, "readthedoc": [56, 117, 181], "real": [31, 45, 57, 60, 118, 121, 127, 132, 147, 204, 214], "realist": 3, "realiz": [111, 136], "realli": 121, "realtime_aqi": [60, 66, 121, 127], "realworldqa": [68, 70, 129, 131], "reason": [39, 50, 57, 67, 70, 83, 86, 87, 96, 111, 113, 117, 118, 127, 128, 134, 136, 140, 144, 147, 148, 156, 157], "reasoning_cont": [95, 156, 231], "reasoning_token": 231, "rebalanc": 219, "reboot": 14, "recalcul": 219, "receipt": 241, "receiv": [46, 135, 154, 159], "recent": [70, 99, 131, 160, 219], "recheck": [73, 134], "recip": [0, 99, 160, 178, 179, 180, 181], "recognit": [243, 253, 256], "recommend": [32, 33, 42, 43, 114, 117, 118, 121, 125, 126, 128, 131, 132, 139, 140, 152, 153, 154, 158, 160, 164, 172, 219, 249, 252], "recompil": 45, "recomput": [45, 99, 160, 166, 171], "recompute_granular": [56, 57, 70, 99, 102, 103, 104, 105, 117, 118, 131, 160, 163, 164, 165, 166, 222], "recompute_method": [56, 57, 70, 99, 102, 103, 104, 105, 117, 118, 131, 160, 163, 164, 165, 166], "recompute_modul": [99, 160], "recompute_num_lay": [56, 57, 70, 99, 102, 103, 104, 105, 117, 118, 131, 160, 163, 164, 165, 166], "record": [42, 45, 68, 70, 129, 141, 144, 147, 150, 160, 172], "record_shap": 43, "record_vram": 7, "recov": [126, 132], "recoveri": [113, 159], "recurs": [180, 181], "red": [52, 57, 118], "redefin": 113, "redirect": [48, 109, 214], "rednot": [96, 157], "redpajama": [96, 157], "reduc": [34, 38, 40, 42, 44, 46, 67, 99, 113, 124, 128, 132, 135, 143, 147, 150, 152, 158, 160, 164, 166, 172, 214], "reduce_bucket_s": [9, 48, 109, 188, 219], "reduce_op": 214, "reduce_scatt": [9, 48, 109, 188, 219], "reduce_scatter_embed": [98, 159], "reduce_sequence_parallel_loss": 38, "reduct": [160, 219], "redund": [9, 128], "reen": [96, 157], "reentrant": [42, 70, 131], "ref": [53, 57, 60, 67, 76, 77, 89, 92, 99, 114, 118, 121, 128, 137, 138, 150, 153, 160, 170, 174, 177, 178, 180, 181, 250], "ref_adapt": [67, 99, 128, 160], "ref_logp": [89, 150], "ref_model": [7, 99, 128, 160], "ref_model_adapt": 7, "ref_model_quantization_bit": 7, "refactor": [144, 147, 150, 160, 164], "refcoco": [96, 157], "refcocog": [96, 157], "refer": [32, 33, 34, 35, 36, 38, 40, 43, 47, 99, 109, 110, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 172, 177, 181, 219, 222, 241], "referenc": [28, 113, 121, 123, 128, 131, 152, 158], "reference_model": [89, 150], "refin": [96, 157], "refinedweb": [96, 157], "reflect": [96, 128, 150, 157], "refresh": 199, "reft": [63, 124], "reft_lay": 128, "reg": [67, 128], "regard": [128, 166], "regardless": [188, 219], "regener": 39, "regex": [39, 50, 67, 99, 111, 127, 128, 160], "region": [89, 132, 140, 150, 214], "regist": [35, 41, 60, 61, 112, 121, 122, 123, 128, 130, 140, 144, 147, 148, 149, 194, 241], "register_dataset": [50, 52, 60, 111, 113, 121], "register_load_state_pre_hook": 219, "register_model": [53, 61, 114, 122], "register_model_arch": [53, 114], "register_model_group": 11, "register_preprocessor": 37, "register_qwen3_vl_moe_config": 46, "register_qwen3_vl_moe_model": 46, "register_qwen3_vl_moe_processor": 46, "register_save_state_pre_hook": 219, "register_templ": [11, 53, 61, 114, 122], "register_to_config": 219, "registr": [36, 46, 128, 140], "registrar": 194, "registri": [64, 70, 105, 125, 131, 166], "reglu": 214, "regress": [67, 99, 121, 128, 160], "regular": [75, 123, 127, 128, 136, 153, 160], "reinforc": [17, 63, 124, 133, 134, 139, 144, 147, 152, 156, 248, 249], "reinforce_plus_plus": [67, 76, 99, 128, 137, 160], "reinstal": 222, "reject": [7, 19, 60, 92, 95, 96, 121, 128, 153, 155, 157, 249], "rejected_imag": [60, 121], "rejected_messag": [60, 121], "rejected_respons": [60, 121, 156], "relat": [39, 44, 45, 50, 73, 76, 77, 81, 89, 109, 111, 113, 114, 117, 118, 120, 121, 123, 128, 129, 132, 134, 137, 138, 142, 143, 144, 148, 149, 150, 155, 156, 160, 162, 163, 164, 188, 219, 246], "relationship": [55, 116, 120, 121], "relax": [135, 214], "releas": [22, 38, 64, 105, 125, 150, 160, 166, 176, 181, 185, 191, 193, 199, 203, 212, 219, 230, 249], "release_v2": [105, 166], "relev": [5, 59, 120, 128, 148, 149, 152], "relevant_doc1": [59, 120], "relevant_doc2": [59, 120], "reli": [35, 127, 131, 140], "reload": 123, "relu": [188, 214, 215, 219], "relwithdebinfo": 203, "remain": [41, 42, 46, 50, 70, 111, 113, 114, 128, 131, 135, 148, 158, 160, 241], "remaind": 219, "remaining_tim": [70, 131], "remap": 40, "remark": 125, "rememb": 110, "reminisc": [57, 118], "remod": 234, "remot": [123, 131, 154, 172, 219, 231], "remov": [43, 44, 45, 67, 70, 113, 114, 118, 128, 158, 160, 166, 219, 237, 249], "remove_column": 219, "remove_until": [68, 129, 131], "remove_unused_column": [70, 131], "removing_checkpoint": 219, "renam": [140, 158], "render": [3, 57, 118, 222], "render_save_dir": 222, "renown": 164, "repeat": [66, 98, 109, 127, 128, 148, 155, 158, 159, 160, 172, 173, 219], "repeat_interleav": 46, "repeat_last_n": 194, "repeat_penalti": 194, "repetit": [67, 99, 128, 131, 160, 172], "repetition_penalti": [7, 52, 113, 171], "rephrasedcoco": [96, 157], "rephrasediqavcrvisu": [96, 157], "rephrasedmochegmocheg": [96, 157], "rephrasedmulti30kimag": [96, 157], "rephrasednlvrcoco": [96, 157], "rephrasedokvqaa": [96, 157], "rephrasedsn": [96, 157], "rephrasedvsrvsr": [96, 157], "replac": [35, 37, 43, 53, 114, 121, 122, 124, 128, 139, 145, 150, 159, 163, 222], "replace_bbox": [53, 114], "replace_class": 39, "replace_funct": 39, "replace_ref": [53, 114], "replace_tag": [53, 114], "replacement_modul": 39, "replacement_nam": 39, "repli": 147, "replic": 43, "replica": [48, 109, 172, 173], "replicaspec": [48, 109], "repo": [11, 64, 67, 70, 79, 105, 125, 128, 131, 140, 166, 194, 224, 236, 256], "repo_dir": [91, 152], "repo_fold": 219, "repo_id": [27, 28, 29, 30, 31, 219, 239, 245], "repo_id_or_path": 219, "report": [67, 99, 128, 160, 187, 207, 219], "report_to": [8, 12, 50, 51, 52, 67, 89, 111, 112, 113, 128, 150, 219], "repositori": [128, 130, 131, 152, 166, 170, 219, 224, 230], "repository_own": 170, "repres": [38, 52, 111, 113, 121, 122, 123, 127, 128, 149, 150, 151, 153, 154, 156, 158, 160, 162, 172], "represent": 151, "reprob": 234, "reproduc": [128, 219], "req": 231, "request": [41, 53, 62, 86, 90, 114, 123, 147, 148, 151, 156, 185, 206, 209, 233, 243, 245, 246], "request_config": [53, 57, 70, 88, 90, 91, 114, 118, 131, 149, 151, 152], "request_r": 179, "requestconfig": [53, 57, 70, 90, 91, 114, 118, 131, 151, 152], "requestid": [70, 131], "requir": [5, 8, 13, 14, 19, 22, 26, 34, 39, 40, 41, 42, 43, 44, 46, 50, 53, 59, 60, 66, 70, 96, 109, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 124, 127, 128, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 147, 148, 149, 150, 152, 153, 154, 155, 157, 159, 160, 161, 162, 163, 166, 170, 172, 174, 175, 187, 188, 215, 219, 222, 224, 236, 239, 252], "require_contigu": 214, "require_vers": 219, "requirements_common": 221, "requirements_npu": 224, "requires_grad": [28, 67, 128, 188, 214, 219], "requires_grad_": 219, "rerank": [63, 67, 91, 96, 99, 105, 124, 128, 152, 157, 160, 166], "res": [53, 97, 98, 114, 158, 159, 214], "res1": [62, 123], "res2": [62, 123], "resacl": [70, 131], "resampl": [67, 99, 128, 135, 160], "reseach": 83, "research": [11, 95, 96, 123, 144, 156, 157], "reserv": [131, 149, 204, 219], "reset": [83, 90, 144, 151, 214], "resetdevic": 213, "reshap": [28, 38, 40, 46, 53, 114, 204, 214, 219], "reshard": [43, 99, 160], "reshard_after_forward": 180, "resid_pdrop": 219, "residu": [188, 219], "resiz": [60, 121, 128, 140, 204, 219, 243], "resize_token_embed": 219, "resize_vocab": 7, "resnet": 204, "resnet50": 204, "resnet50_opset16": 204, "resolut": [3, 128, 131, 166, 219], "resolv": [41, 151, 179, 184, 243], "resourc": [48, 83, 109, 117, 121, 124, 125, 128, 144, 149, 150, 152, 166, 179, 180, 181], "resp": [53, 87, 90, 91, 114, 148, 151, 152], "resp_list": [53, 57, 90, 91, 114, 118, 151, 152], "respect": [83, 86, 87, 110, 111, 113, 121, 128, 144, 147, 148, 150, 153, 156, 158, 160, 163, 214], "respond": 246, "respons": [19, 50, 53, 56, 57, 60, 61, 62, 66, 67, 68, 76, 83, 87, 88, 90, 91, 92, 95, 104, 111, 112, 114, 117, 118, 121, 122, 123, 127, 128, 129, 135, 136, 137, 138, 144, 148, 149, 150, 151, 152, 153, 156, 160, 161, 165, 177, 194, 197, 214, 222, 237, 246], "response0": [90, 91, 151, 152], "response1": [56, 60, 90, 91, 117, 121, 151, 152], "response2": [60, 90, 121, 151], "response_choic": [86, 147], "response_clip": [70, 131], "response_clip_ratio": [70, 131], "response_hf": [53, 114], "response_length": 171, "response_loss_mask": [86, 147], "response_prefix": [56, 70, 117, 131], "response_swift": [53, 114], "response_token_id": [86, 147], "responsepreprocessor": [50, 52, 60, 111, 113, 121], "respson": 67, "rest": [39, 94, 155, 237], "restart": [48, 109, 126], "restartpolici": [48, 109], "restaur": 241, "restor": [35, 46, 128, 172, 219], "restrict": [50, 111, 128, 135], "result": [14, 21, 37, 42, 46, 50, 66, 67, 70, 83, 86, 87, 88, 91, 93, 98, 111, 113, 117, 123, 127, 128, 129, 134, 139, 144, 147, 148, 149, 150, 151, 152, 154, 159, 160, 164, 165, 166, 191, 204, 207, 210, 214, 219, 234, 244, 249, 250], "result_fil": [70, 131], "result_path": [56, 67, 71, 90, 117, 128, 132, 151], "resulttensor": 214, "resum": [42, 67, 128, 160, 179, 184, 219], "resume_from_checkpoint": [8, 67, 70, 128, 131, 219, 222], "resume_only_model": [67, 128], "resumpt": [128, 160], "retain": [42, 111, 113, 121, 122, 128, 142, 148, 156], "retool": 174, "retool_sft_preprocess": 178, "retrain": 155, "retri": [179, 180, 181], "retriev": [59, 120, 148, 160], "return": [11, 28, 35, 37, 38, 41, 43, 46, 47, 50, 51, 52, 53, 60, 62, 66, 67, 83, 85, 86, 87, 88, 93, 98, 110, 111, 112, 113, 114, 121, 123, 127, 128, 144, 146, 148, 149, 150, 154, 158, 159, 172, 173, 188, 204, 213, 214, 215, 219, 221, 237, 241], "return_audio": [53, 114], "return_dict": 219, "return_raw_chat": 178, "return_template_input": [60, 121], "return_tensor": [53, 57, 114, 118, 191, 219, 246], "return_video_kwarg": [57, 118], "return_video_metadata": [57, 118], "reus": [39, 58, 67, 70, 119, 131, 143], "reusabl": 37, "reuse_dataset_if_exist": [7, 20, 67, 128], "reveal": 155, "revers": [51, 99, 100, 112, 160, 161, 214], "reverse_kl": [99, 160], "reverse_std": [7, 18], "review": [39, 70, 131, 241], "revis": [67, 97, 99, 128, 158, 160, 219], "rewa": [70, 131], "rewar": 52, "reward": [7, 24, 50, 52, 62, 69, 75, 81, 83, 85, 86, 87, 88, 89, 90, 92, 94, 96, 99, 101, 117, 124, 130, 135, 136, 138, 139, 140, 142, 143, 144, 146, 150, 151, 152, 153, 155, 157, 160, 162, 170, 177, 180, 222, 249], "reward_": [70, 131], "reward_func": [50, 51, 52, 56, 74, 111, 112, 113, 117, 135, 148, 149], "reward_funct": [89, 149, 150], "reward_manag": 180, "reward_model": [7, 17, 67, 88, 99, 128, 149, 160, 180], "reward_model_adapt": 7, "reward_model_plugin": 149, "reward_model_quantization_bit": 7, "reward_model_typ": 7, "reward_norm": 222, "reward_pretrain": 222, "reward_std": [70, 113, 131], "reward_weight": [51, 67, 99, 112, 128, 149, 160], "rewardfunct": [86, 147], "rewardmodel": [95, 96, 156, 157], "rewards_mean": [89, 150], "rewards_std": [89, 150], "rewrit": 143, "rewritten": 138, "rf": [179, 180, 181, 224, 230], "rft": [94, 95, 155, 156], "rgb": 219, "rho": [81, 84, 142, 145], "rice": 121, "rich": [124, 164], "right": [7, 18, 50, 53, 67, 71, 73, 75, 77, 78, 81, 84, 89, 92, 111, 114, 128, 131, 132, 134, 136, 138, 139, 141, 142, 145, 150, 153, 219], "rightdowncasu": 214, "rightdowncaus": 214, "ring": [42, 63, 96, 124, 157], "ring2": [96, 157], "rise": [111, 243], "risk": [40, 219, 249], "rl": [81, 87, 94, 96, 142, 148, 155, 157, 174, 177, 180, 181, 201], "rl_exampl": 222, "rlaif": [96, 157], "rlhf": [50, 51, 52, 55, 56, 64, 69, 70, 71, 78, 89, 91, 92, 96, 105, 111, 112, 113, 116, 117, 125, 130, 131, 132, 139, 150, 152, 157, 166, 180], "rlhf_ckpt": [67, 99, 128, 160], "rlhf_main": [70, 131], "rlhf_type": [50, 51, 52, 56, 67, 70, 71, 78, 89, 111, 112, 113, 117, 128, 131, 132, 139, 150], "rlhfargument": [70, 131], "rloo": [63, 67, 76, 99, 124, 128, 137, 160], "rlvr": [80, 96, 141, 157, 222], "rlvr_megatron": 222, "rm": [4, 7, 17, 22, 24, 55, 63, 67, 88, 95, 96, 104, 105, 116, 124, 128, 149, 156, 157, 165, 166, 179, 180, 181, 197, 224, 230, 236], "rm_group": [93, 154], "rm_prompt": [88, 149], "rmpad": [42, 43, 45], "rmpad_with_pos_id": 43, "rmplugin": [88, 149], "rmreward": [88, 149], "rms": 214, "rms_norm": [39, 214], "rmsnorm": [38, 39, 177, 191, 214], "rmtree": 219, "rng": [99, 160, 213], "ro": 14, "robot": [56, 63, 70, 91, 102, 103, 105, 117, 124, 131, 152, 163, 164, 166], "robust": [39, 132], "roi": 214, "roi_end_mod": 214, "rois_num": 214, "role": [11, 19, 21, 37, 48, 49, 52, 53, 56, 57, 59, 60, 66, 67, 70, 83, 86, 88, 90, 91, 96, 109, 110, 113, 114, 117, 118, 120, 121, 127, 128, 131, 141, 144, 147, 149, 151, 152, 154, 157, 173, 191, 231, 243, 246, 250], "role_map": 37, "role_tag": 19, "roll": [0, 93, 154, 222, 231], "roll_exp": 222, "rollback": 143, "rollout": [50, 51, 52, 55, 75, 81, 83, 86, 89, 92, 93, 99, 101, 111, 112, 113, 116, 136, 142, 144, 147, 150, 153, 154, 155, 160, 162, 174, 175, 177, 178, 180, 181, 222, 250], "rollout_batch": 222, "rollout_batch_s": 222, "rollout_correct": [81, 142], "rollout_funct": [89, 150], "rollout_importance_sampling_mod": [67, 81, 86, 89, 99, 128, 142, 147, 150, 160], "rollout_importance_sampling_threshold": [81, 142], "rollout_info": [86, 147], "rollout_log_ppl": [81, 142], "rollout_logprob": [86, 147], "rollout_per_token_logp": [81, 142], "rollout_ppl": [81, 89, 142, 150], "rolloutinferrequest": [83, 86, 144, 147], "rolloutresponsechoic": [83, 144], "rollouttrainermixin": [86, 147], "room": [57, 90, 111, 118], "root": [14, 29, 31, 47, 55, 67, 70, 83, 86, 99, 116, 128, 131, 144, 147, 158, 160, 170, 176, 185, 187, 188, 191, 219, 230], "root_image_dir": [67, 128], "rope": [7, 39, 67, 70, 99, 128, 160, 194], "rope_delta": 46, "rope_finetun": 194, "rope_sc": [7, 67, 128], "rope_typ": [70, 131], "rot_pos_emb": 46, "rotari": [39, 46], "rotary_emb": 46, "rotary_pos_emb": 46, "rotaryembed": 214, "rotat": 213, "roug": [20, 67, 68, 128, 129], "rough": 160, "round": [50, 57, 67, 70, 96, 99, 111, 118, 121, 123, 128, 131, 143, 144, 147, 157, 160, 172, 219, 243], "round_robin_gradi": 9, "rout": [41, 139, 160], "router": [40, 67, 70, 99, 128, 160], "router_indic": 46, "router_logit": 28, "routing_weight": [28, 40, 46], "routing_weights_topk": 46, "row": [27, 49, 50, 52, 53, 60, 110, 111, 113, 114, 121, 128, 131, 155, 213], "rpn": 214, "rpo": [67, 99, 128, 160], "rpo_alpha": [67, 92, 99, 128, 153, 160], "rs": [63, 67, 99, 124, 128, 160], "rsampl": [188, 219], "rslora": [67, 99, 128, 160], "rst": 177, "rstqueue": 181, "rt": [67, 128], "rte": [68, 70, 129, 131], "rtsqueue": 181, "rtx": [63, 124, 125], "rtx20": 64, "rubber": 52, "rude": 241, "rule": [51, 89, 110, 112, 128, 147, 148, 150], "rumin": [96, 157], "run": [14, 15, 22, 39, 40, 41, 42, 43, 48, 53, 57, 60, 61, 67, 70, 86, 88, 99, 109, 114, 116, 117, 118, 121, 122, 126, 128, 129, 147, 149, 150, 151, 152, 158, 160, 164, 166, 170, 172, 178, 180, 183, 188, 191, 193, 194, 197, 204, 215, 219, 222, 230, 231, 234, 237, 249, 256], "run_": [179, 180, 181], "run_agentic_pipeline_sokoban": 222, "run_agentic_rollout_sokoban": 222, "run_clm": 219, "run_codegen": 39, "run_dpo_pipelin": 222, "run_mm_all_reduce_bas": 214, "run_nam": 12, "run_npu": 253, "run_qwen2": 178, "run_qwen2_7b_sft_npu": 178, "run_qwen3mo": 179, "run_rlvr_pipelin": 222, "run_task": [58, 70, 119, 131], "run_test": 214, "run_train": [239, 240], "runner": 39, "running_loss": [188, 219], "runopt": 204, "runtim": [0, 34, 39, 40, 42, 116, 126, 172, 173, 178, 181, 187, 188, 191, 197, 204, 219, 230], "runtimeerror": [88, 91, 149, 152, 221], "runwayml": 2, "ruozhiba": [96, 157], "rust": [70, 131], "rwmote": 70, "rzf8xaiyf5": 245, "s0": 253, "s0002": 253, "s1": [45, 96, 157, 214], "s2": [45, 214], "s3": 45, "s34b": 207, "s4": 45, "sa1b": [96, 157], "safe": [67, 97, 128, 158, 234], "safe_decod": [53, 60, 66, 114, 121, 127], "safe_seri": [58, 62, 97, 119, 123, 158], "safe_snapshot_download": [91, 152], "safetensor": [7, 40, 44, 58, 67, 70, 92, 99, 103, 105, 119, 128, 131, 153, 160, 164, 166, 184, 225, 234], "safeti": 41, "safety_check": 219, "sahil2801": [96, 157], "sail": [96, 157], "salesforc": [96, 157, 224], "same": [35, 37, 38, 43, 46, 70, 110, 111, 117, 120, 121, 123, 128, 132, 133, 135, 138, 140, 142, 145, 147, 148, 150, 155, 160, 161, 164, 166, 172, 219, 222], "same_network": [9, 15], "sampl": [40, 42, 45, 46, 47, 49, 62, 67, 78, 82, 87, 89, 92, 93, 94, 95, 96, 97, 99, 110, 111, 113, 117, 120, 121, 123, 127, 129, 133, 136, 137, 138, 139, 140, 141, 143, 144, 145, 147, 148, 150, 152, 153, 154, 155, 157, 158, 160, 161, 164, 180, 194, 213, 219, 225, 250, 256], "sample_count": 128, "sample_group": [93, 154], "sample_num": 214, "sample_output": [67, 95, 128, 156], "sample_s": 128, "sampler": [67, 70, 93, 95, 128, 131, 154], "sampler_engin": [95, 128, 156], "sampler_typ": [95, 156], "sampling_param": [171, 231], "sampling_r": [53, 114, 243], "samplingparam": 171, "san": [66, 127], "sandbox": 178, "sandbox_fusion_tool_config": 178, "sandboxfus": 178, "saniti": 219, "sapo": [63, 67, 124, 128], "satisfi": [110, 162], "save": [3, 8, 9, 17, 20, 21, 23, 24, 35, 39, 42, 44, 46, 58, 61, 62, 67, 70, 82, 97, 99, 105, 114, 117, 119, 122, 123, 128, 143, 150, 151, 152, 153, 156, 158, 160, 161, 164, 166, 172, 207, 219], "save_at_breakpoint": [48, 109], "save_dir": [7, 20], "save_directori": [58, 62, 97, 119, 123, 158], "save_dtyp": 44, "save_freq": [174, 178, 179, 180], "save_metr": 219, "save_model": [58, 119, 219], "save_model_card": 219, "save_model_hook": 219, "save_model_weight": 44, "save_only_model": [8, 56, 117], "save_path": [172, 173, 219], "save_pretrain": [62, 97, 123, 158, 219], "save_safetensor": [56, 57, 99, 102, 103, 104, 105, 117, 118, 160, 163, 164, 165, 166], "save_st": 219, "save_step": [8, 9, 17, 24, 48, 50, 51, 52, 53, 55, 56, 57, 58, 63, 67, 68, 99, 102, 103, 104, 105, 109, 111, 112, 113, 114, 116, 117, 118, 119, 124, 128, 129, 160, 163, 164, 165, 166, 222], "save_strategi": [52, 67, 68, 113, 128, 129], "save_to_peft_format": [97, 158], "save_total_limit": [48, 50, 51, 52, 53, 56, 57, 58, 63, 68, 70, 109, 111, 112, 113, 114, 117, 118, 119, 124, 129, 131], "save_weight": [103, 164], "saw": 237, "saxophon": [57, 118], "say": [45, 121], "sbh": 214, "sbin": [14, 230], "scalar": [137, 149, 214], "scalartyp": 214, "scale": [0, 31, 38, 46, 56, 57, 60, 62, 66, 67, 70, 86, 99, 105, 117, 118, 120, 121, 127, 128, 142, 147, 153, 155, 160, 164, 166, 194, 214, 219], "scale_1": 214, "scale_attn_weight": 219, "scale_i": 214, "scale_lr": 219, "scale_reward": [76, 137], "scale_valu": 214, "scaled_dot_product_attent": 38, "scaler": [70, 131], "scalerl": [73, 134], "scaling_factor": 219, "scatter": [7, 18, 38, 46, 57, 118, 214], "scedit": [97, 158], "scenario": [34, 114, 121, 128, 129, 130, 131, 132, 142, 143, 147, 154, 160, 172], "scene": [57, 118, 219], "schduler": 86, "sched": 234, "schedul": [29, 34, 35, 42, 62, 67, 98, 123, 124, 128, 133, 144, 159, 160, 162, 172, 173, 181, 188, 219, 246], "schedule_typ": 29, "scheduler_output": [172, 173], "schema": 193, "scheme": [132, 160], "scholar": [57, 118], "school_math_0": [96, 157], "scidoc": [96, 157], "scienc": [96, 157], "scienceqa": [96, 157], "scienceqa_test": [68, 70, 129, 131], "scienceqa_v": [68, 70, 129, 131], "scikit": [184, 219, 241], "scipi": [185, 206, 209, 230, 233], "scope": [41, 67, 128, 160], "score": [38, 50, 52, 62, 67, 68, 87, 111, 113, 120, 123, 128, 129, 140, 148, 149, 153, 155, 156, 204, 214, 243, 244], "score_singl": [87, 148], "score_threshold": 214, "scores_threshold": 214, "scout": [11, 96, 157], "scp": 253, "scratch": [110, 119, 155, 219], "screen": [121, 127, 194], "screenshot": 117, "script": [20, 21, 27, 28, 29, 30, 31, 39, 40, 43, 44, 57, 109, 110, 113, 116, 117, 118, 119, 124, 126, 128, 130, 132, 133, 136, 137, 138, 139, 140, 143, 144, 147, 148, 150, 151, 152, 153, 155, 156, 157, 159, 160, 161, 162, 163, 165, 166, 175, 179, 180, 181, 184, 185, 219, 239, 249], "scriptstyl": [50, 89, 111, 150], "sd": [0, 3, 219], "sdk": [53, 57, 63, 69, 70, 114, 118, 124, 130, 131], "sdma": 181, "sdpa": [7, 67, 128], "sdxl": 3, "seamless": 172, "search": [50, 52, 59, 62, 67, 94, 111, 113, 120, 123, 128, 143, 155], "search_end": 214, "search_start": 214, "search_step": 214, "seat": [57, 118], "sec": [237, 256], "second": [51, 112, 114, 118, 121, 123, 128, 151, 160, 179, 180, 181, 194, 237], "seconds_per_chunk": [53, 114], "secret": [67, 128, 230], "section": [32, 35, 75, 113, 114, 117, 118, 121, 127, 128, 136, 151, 152, 160, 165, 166, 219], "secur": 219, "security_studi": 200, "see": [35, 36, 37, 39, 43, 50, 109, 111, 114, 116, 117, 118, 121, 127, 128, 130, 133, 140, 141, 144, 145, 147, 149, 150, 151, 152, 154, 160, 166, 191, 219, 249], "seed": [3, 7, 20, 32, 33, 35, 42, 43, 46, 67, 96, 99, 128, 157, 160, 171, 179, 194, 199, 207, 214, 219, 222, 225, 241], "seed2": 214, "seed_omni": 36, "seedbench2": [68, 70, 129, 131], "seedbench2_plus": [68, 70, 129, 131], "seedbench_img": [68, 70, 129, 131], "seek": [71, 132], "seem": [50, 57, 111, 118, 219, 237], "seen": [128, 129, 152, 237], "seggpt": [96, 157], "segment": [34, 52, 67, 113, 127, 128, 143, 172], "select": [40, 46, 99, 111, 113, 120, 121, 126, 127, 128, 131, 136, 137, 140, 142, 144, 151, 160, 185, 194, 219, 241], "selected_box": 214, "selected_expert": [28, 40, 46], "selected_idx": 214, "selected_index": 214, "selected_indic": 214, "selected_mask": 214, "selected_num": 214, "self": [11, 28, 36, 38, 39, 40, 43, 46, 50, 52, 53, 55, 56, 60, 62, 63, 67, 71, 83, 85, 86, 87, 88, 91, 93, 94, 95, 96, 97, 98, 102, 103, 105, 111, 113, 114, 115, 116, 121, 123, 124, 128, 132, 144, 146, 147, 148, 149, 152, 154, 155, 156, 157, 158, 159, 163, 164, 166, 172, 173, 188, 194, 214, 215, 219, 256], "self_attn": 18, "semant": [40, 41, 121], "send": [46, 148, 150], "sens": [57, 118], "sensenova": [96, 157], "sensit": 214, "sent": 110, "sentenc": [0, 49, 60, 96, 110, 121, 135, 136, 150, 157, 219, 228, 244], "sentence1": [49, 60, 110, 121], "sentence2": [49, 60, 110, 121], "sentence3": [49, 110], "sentence4": [49, 110], "sentencepiec": 219, "sentencetransform": 228, "sentiment": 244, "sentinel": 222, "sep": [61, 122], "separ": [32, 33, 35, 46, 53, 114, 121, 122, 123, 124, 128, 129, 138, 146, 147, 150, 160, 164, 166, 188, 219], "seq": [38, 45, 46, 62, 67, 70, 81, 99, 123, 128, 131, 142, 160, 181, 210, 214, 231], "seq2seqtrainingargu": [67, 128], "seq_cl": [67, 99, 128, 160], "seq_dim": [38, 46], "seq_dimens": 38, "seq_kd": [60, 67, 100, 121, 128, 161], "seq_len": [38, 46, 181, 214, 240], "seq_length": [46, 214], "seq_pad": 38, "seq_per_rank": 46, "seq_weight": [75, 136], "seqgpt": [96, 157], "seqlen": [42, 45, 46, 177, 214], "seqmask": 214, "sequenc": [7, 36, 39, 42, 43, 45, 50, 51, 67, 85, 89, 96, 99, 110, 111, 112, 120, 124, 127, 128, 132, 141, 143, 146, 147, 150, 152, 157, 160, 166, 172, 173, 181, 214, 219, 243], "sequence_length": [28, 222], "sequence_mask": [67, 81, 99, 128, 142, 160], "sequence_parallel": [38, 56, 57, 70, 102, 103, 104, 105, 117, 118, 131, 163, 164, 165, 166], "sequence_token": [75, 136], "sequence_trunc": [67, 81, 99, 128, 142, 160], "sequenti": [67, 99, 128, 148, 160], "seren": 151, "seresnet34": 234, "seri": [110, 124, 125, 128, 130, 140, 152, 156, 164, 166], "serial": [46, 47, 67, 97, 128, 152, 219], "serious": [45, 131], "serv": [38, 67, 88, 113, 119, 122, 128, 134, 135, 147, 149, 160, 197, 241], "served_model_nam": [58, 90, 91, 119, 151, 152], "server": [22, 26, 50, 51, 52, 67, 86, 88, 89, 99, 100, 101, 111, 112, 113, 127, 128, 147, 149, 150, 160, 161, 162, 172, 193, 230, 231, 237, 255], "server_ip": 150, "serverarg": 175, "servic": [88, 126, 128, 140, 148, 149, 150, 172, 179, 194, 241], "service_port": 150, "servicenow": [96, 157], "sess_opt": 204, "session": [67, 87, 128, 148, 204], "session_opt": 204, "sessionopt": 204, "sessionoptionsappendexecutionprovider_cann": 204, "set": [7, 33, 34, 35, 38, 42, 43, 44, 51, 53, 55, 57, 97, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 121, 122, 123, 124, 127, 128, 129, 133, 134, 136, 137, 138, 141, 142, 145, 146, 149, 150, 151, 152, 153, 155, 156, 158, 160, 164, 165, 166, 171, 172, 173, 174, 177, 178, 180, 184, 188, 191, 194, 219, 222, 239], "set_active_adapt": [97, 158], "set_default_tensor_typ": 214, "set_devic": [188, 214, 219], "set_env": [14, 15, 33, 55, 116, 174, 175, 185, 197, 203, 230], "set_mod": [53, 60, 66, 114, 121, 127], "set_postfix": 219, "set_progress_bar_config": 219, "set_se": 219, "set_verbos": 219, "set_verbosity_error": 219, "set_verbosity_info": 219, "set_verbosity_warn": 219, "setdevic": 213, "setlevel": [214, 219], "setup": [37, 116, 128, 134, 163, 165, 215, 219, 221, 236], "sever": [35, 45, 111, 121, 123, 126, 128, 135, 142, 147, 150, 154, 160, 172], "sft": [0, 4, 7, 8, 9, 17, 18, 20, 21, 23, 27, 42, 43, 48, 53, 57, 58, 62, 63, 65, 67, 68, 69, 71, 77, 79, 91, 92, 93, 94, 96, 98, 99, 100, 102, 103, 104, 105, 109, 114, 115, 118, 119, 123, 124, 126, 128, 129, 130, 132, 138, 140, 152, 153, 154, 155, 157, 159, 160, 161, 163, 164, 165, 166, 174, 178, 201], "sft_alpha": [67, 71, 99, 100, 128, 132, 160, 161], "sft_ckpt": [67, 99, 128, 160], "sft_loss": [67, 99, 128, 160], "sft_main": [53, 91, 114, 152], "sft_peft_sp2_npu": 174, "sftargument": [53, 62, 91, 114, 123, 152], "sg": [75, 136], "sgd": [99, 160, 215, 219], "sgl": [175, 176, 179, 231], "sgl_kernel_npu": 230, "sglang": [0, 36, 55, 63, 64, 68, 69, 89, 90, 91, 103, 116, 124, 125, 129, 130, 150, 151, 152, 164, 172, 173, 174, 176, 250], "sglang_8": 176, "sglang_client": 179, "sglang_deepep_bf16_dispatch": 175, "sglang_npu": 230, "sglang_profil": [172, 173], "sglang_serv": 179, "sglangengin": [90, 91, 151, 152], "sh": [9, 10, 14, 15, 22, 27, 28, 29, 30, 31, 33, 37, 38, 43, 48, 55, 109, 116, 133, 140, 170, 174, 175, 178, 179, 180, 181, 185, 197, 203, 222, 224, 230, 234, 236, 239, 240, 245, 253, 256], "shade": [52, 57, 113, 118], "shake": 241, "shall": 219, "shanghai": [96, 121, 127, 157, 179, 197], "shannon": [100, 161], "shape": [11, 38, 40, 42, 46, 53, 99, 114, 160, 172, 173, 180, 213, 214, 219, 234, 246], "shard": [9, 38, 42, 43, 46, 67, 70, 99, 128, 131, 152, 160, 219], "shard_grad_op": 9, "shard_siz": 44, "shardingstrategi": 9, "share": [46, 65, 67, 70, 99, 105, 118, 126, 128, 131, 150, 153, 160, 166, 172, 187, 197], "shareai": [96, 157], "sharegpt": [37, 60, 96, 121, 157], "sharegpt4v": [29, 30, 37, 96, 157], "sharegpt4v_captioner_sft": 29, "sharegpt4v_instruct_gpt4": [29, 30], "sharegpt4v_pretrain": 37, "sharegpt4v_pretrain_preprocess": 37, "sharegpt4v_sft": 30, "sharegpt4vsharegpt4v": [96, 157], "sharegpt_gpt4": [96, 157], "sharegptfireflycodefusemetamathqa": [96, 157], "sharp": [113, 128], "sharper": 128, "she": 241, "sheep": [118, 121, 151], "shell": [63, 65, 67, 90, 91, 124, 126, 128, 151, 152, 174], "shengbinyu": [96, 157], "shenweizhou": [96, 157], "shi": 46, "shibing624": [96, 157], "shift": [7, 142, 150, 219], "shift_attn": 7, "ship": [39, 188, 219], "shirt": [57, 118, 151], "shjwudp": [96, 157], "shm": [14, 15, 48, 109, 170, 183, 187, 230], "short": [7, 35, 128, 160], "shot": [7, 20, 129, 200], "should": [29, 35, 36, 38, 40, 46, 50, 51, 56, 66, 70, 109, 110, 111, 112, 113, 114, 117, 121, 124, 127, 128, 129, 135, 136, 142, 147, 151, 155, 156, 184, 219, 222, 241, 244, 246], "should_checkpoint": [98, 159], "should_exit": [98, 159], "should_log": 219, "show": [38, 39, 46, 50, 52, 57, 90, 111, 113, 118, 121, 126, 128, 140, 147, 151, 164, 199, 213, 219, 230, 237], "show_config": 199, "showcas": [57, 118], "shown": [36, 113, 117, 127, 131, 140, 153, 155, 172], "shrink_axis_mask": 214, "shuffl": [67, 99, 128, 160, 188, 219, 241], "shut": 126, "shutil": 219, "si": [96, 157], "sia": [178, 179, 181], "sibl": 39, "side": [35, 67, 97, 128, 135, 147, 158, 160, 166, 172, 237], "sigma": [78, 84, 92, 139, 145, 153], "sigmoid": [7, 17, 67, 78, 84, 92, 99, 128, 139, 145, 153, 160, 214], "sign_bits_pack": 214, "signal": [133, 139, 144], "signatur": [40, 66, 127, 159, 245], "signific": [38, 39, 46, 111, 113, 120, 123, 128, 132, 139, 142, 143, 148, 152, 155, 160, 172], "silent": 249, "silu": 214, "sim": [50, 71, 81, 89, 111, 132, 142, 150], "similar": [35, 40, 49, 96, 113, 117, 121, 126, 127, 128, 133, 137, 144, 145, 157, 158, 160, 162], "simpl": [2, 14, 37, 55, 58, 111, 113, 116, 118, 119, 120, 123, 124, 128, 148, 149, 151, 164, 172, 183, 184, 185, 193, 194, 206, 209, 219, 227, 230, 233, 244, 248], "simpleai": [96, 157], "simplenamespac": 46, "simpler": [35, 40], "simplesokoban": 222, "simplest": 131, "simpli": [35, 38, 116, 117, 122, 124, 126, 151, 152, 164, 166, 188, 219], "simplic": [41, 113, 154], "simplifi": [35, 83, 86, 119, 137, 144, 147, 152], "simpo": [7, 17, 63, 67, 91, 124, 128, 152], "simpo_gamma": 7, "simultan": [42, 44, 111, 113, 128, 148, 156, 160], "sin": [39, 46, 214], "sinc": [35, 38, 46, 50, 52, 60, 80, 110, 111, 113, 114, 121, 124, 132, 136, 141, 144, 150, 154, 155, 159, 160, 161, 209, 219], "singl": [28, 38, 39, 41, 44, 45, 46, 48, 55, 67, 90, 99, 109, 111, 113, 117, 118, 120, 121, 124, 127, 128, 132, 147, 151, 152, 160, 163, 166, 172, 201, 214, 219, 222, 243], "single_label_classif": 128, "single_op": 214, "sinkhorn": [99, 160], "sip": 14, "siqa": [68, 70, 129, 131], "sit": [57, 90, 118, 151, 237], "site": [48, 81, 109, 142, 187], "situat": [51, 112, 123, 204], "size": [9, 14, 15, 34, 35, 38, 42, 43, 45, 46, 48, 50, 52, 59, 67, 80, 82, 89, 92, 96, 99, 101, 109, 111, 116, 120, 123, 128, 129, 141, 143, 145, 148, 150, 153, 157, 160, 161, 162, 170, 172, 173, 177, 179, 181, 183, 187, 188, 194, 204, 207, 210, 214, 219, 230, 234, 243, 256], "size_t": 204, "sizelimit": [48, 109], "sizenot": 162, "skepsun": [96, 157], "skip": [35, 51, 67, 97, 112, 119, 128, 135, 148, 158, 160, 172, 224], "skip_first": [98, 159], "skip_special_token": [7, 8, 53, 57, 114, 118, 191, 246], "skipped_it": [98, 159], "sklearn": 241, "skv": 214, "sky": 151, "skypil": [96, 157], "skywork": [96, 157, 170], "slack": [67, 128], "sleep": [67, 70, 99, 128, 131, 151, 160, 179, 180, 181], "sleep_level": [56, 89, 117, 150], "slice": [27, 38, 67, 93, 128, 154, 177, 214], "slice_position_embed": 46, "slight": [57, 90, 118, 152, 156, 160, 219], "slimorca": [96, 157], "slimpajama": [96, 157], "slope": 139, "slot": [9, 11], "slow": [118, 125, 128, 132, 149, 152, 160], "slower": [110, 111, 128, 160, 166, 219], "slowli": 113, "sm": 194, "small": [43, 52, 57, 96, 118, 141, 142, 149, 157, 219, 243, 256], "small_eval_dataset": 241, "small_train_dataset": 241, "smaller": [44, 52, 128, 150, 155, 160, 219], "smallthink": [96, 157], "smax": 214, "smell": 234, "smi": [14, 55, 116, 170, 183, 185, 193], "smile": [57, 118], "smooth": [67, 99, 128, 132, 139, 141, 145, 148, 154, 160, 172], "smoother": 128, "smp": [55, 116], "snapshot_download": [53, 57, 114, 118, 245], "sniff": 237, "snr": 219, "snr_gamma": 219, "so": [31, 35, 45, 46, 50, 51, 56, 62, 110, 111, 112, 113, 116, 117, 118, 121, 123, 128, 129, 146, 147, 148, 152, 159, 160, 164, 166, 178, 180, 181, 188, 197, 219, 230, 241, 243, 256], "social_sci": 200, "sociolog": 200, "socket": [70, 131, 179, 180, 181], "socket_ifnam": [179, 180, 181], "soft": [57, 67, 118, 128, 145], "soft_cache_length": [74, 135], "soft_max_length": [74, 135], "soft_overlong": [67, 74, 87, 99, 128, 135, 148, 160], "softmax": [59, 80, 99, 120, 141, 160, 207, 214], "softmax_ls": 214, "softmax_lse_flag": 214, "softmax_r": 214, "softmax_use_float": 214, "softmax_v2": 214, "softmaxls": 214, "softmaxlseflag": 214, "softwar": [55, 116, 174, 175, 178, 180, 181, 219, 221], "sokoban": 222, "sokobandifferentgridvocab": 222, "sol": [52, 113], "sol_match": [52, 113], "sole": [38, 153], "solut": [37, 45, 50, 51, 52, 56, 60, 83, 85, 86, 87, 88, 89, 92, 96, 111, 112, 113, 117, 121, 128, 144, 146, 147, 148, 149, 153, 157, 250], "solv": [51, 83, 85, 86, 87, 111, 112, 114, 144, 146, 147, 148, 155, 172], "some": [39, 46, 49, 51, 53, 57, 59, 90, 110, 112, 113, 114, 118, 120, 121, 123, 125, 128, 147, 151, 155, 156, 160, 164, 180, 184, 219, 244, 249], "some_valu": 39, "someon": 241, "someth": [56, 57, 62, 117, 118, 123, 219, 241], "sometim": [57, 118, 152], "soon": 37, "sort": [42, 50, 85, 111, 146, 219], "sorted_x": 214, "sota": 94, "soundfil": [32, 33, 53, 96, 114, 157], "sourc": [14, 15, 16, 28, 29, 32, 33, 38, 39, 43, 55, 71, 110, 116, 120, 121, 123, 128, 129, 132, 156, 159, 161, 172, 174, 175, 185, 197, 203, 214, 221, 224, 230, 236], "source_config": 37, "source_modul": 39, "source_nam": [30, 37], "southeast": 170, "sox": [96, 157], "sp": [34, 38, 39, 41, 43, 63, 124], "sp_enabl": 46, "sp_group": [43, 46], "sp_pad_and_slic": 46, "sp_rank": [43, 46], "sp_size": [46, 181], "space": [65, 67, 96, 126, 128, 129, 131, 157, 219, 243], "sparkl": 246, "spars": [9, 214], "sparse_mod": 214, "sparsemod": 214, "spatial": [46, 67, 128], "spatial_merge_s": [58, 119], "spatial_scal": 214, "spawn": [48, 109, 214, 215], "speak": 129, "spearman": [49, 110], "spec": [48, 109], "special": [7, 39, 40, 67, 96, 99, 121, 123, 128, 144, 151, 152, 153, 155, 157, 160, 194, 219, 241], "special_npu": 170, "specif": [31, 34, 37, 39, 45, 46, 53, 85, 110, 114, 117, 118, 120, 121, 123, 126, 127, 129, 134, 135, 140, 142, 144, 146, 148, 149, 150, 151, 152, 155, 158, 159, 160, 162, 163, 172, 219, 237, 246], "specifi": [36, 37, 38, 42, 46, 47, 109, 110, 114, 117, 121, 122, 123, 124, 127, 128, 129, 130, 133, 144, 147, 148, 149, 151, 152, 153, 154, 156, 158, 160, 166, 219, 221], "spectacular": 241, "specul": [67, 128, 193], "speech": [243, 253, 256], "speech_asr": [53, 96, 114, 157], "speech_asr_aishell1_trainset": [53, 96, 114, 157], "speed": [9, 81, 110, 111, 116, 117, 118, 124, 128, 132, 142, 148, 149, 150, 152, 160, 164, 166, 219], "speedup": 166, "sphere": 52, "spk_dict": [53, 114], "split": [38, 40, 46, 50, 52, 60, 62, 67, 99, 111, 113, 121, 123, 128, 147, 148, 150, 154, 158, 160, 172, 177, 184, 194, 219, 234], "split_dataset_ratio": [53, 55, 56, 57, 58, 60, 67, 89, 103, 104, 114, 116, 117, 118, 119, 121, 128, 150, 164, 165], "split_gener": 219, "split_item": 214, "split_params_into_different_moe_groups_for_optim": [188, 219], "split_special_token": 7, "split_streaming_dataset": 219, "spread": 139, "spurious": 41, "sq": [99, 160, 214], "sql": [96, 157], "sqrt": [83, 86, 144, 147, 214], "squar": [83, 86, 99, 144, 147, 160], "squash": 234, "squeez": [28, 188, 219], "sr": [53, 114, 243], "src": [9, 11, 15, 40, 55, 116, 128, 207, 214, 219], "src_dtype": 214, "src_len": 214, "srt": [172, 173], "srt_npu": 230, "ssbuild": [96, 157], "sse3": [194, 256], "ssm_d_conv": 194, "ssm_d_inner": 194, "ssm_d_state": 194, "ssm_dt_rank": 194, "sss": 249, "ssse3": [194, 256], "stabil": [7, 18, 81, 111, 113, 128, 135, 139, 150, 153, 160, 224], "stabilityai": 3, "stabl": [0, 2, 3, 40, 41, 42, 67, 89, 113, 128, 142, 150, 160, 199, 219, 225], "stablediffus": 224, "stablediffusionpipelin": 219, "stack": [42, 96, 157, 159, 172, 173, 219], "stackoverflowdupquest": [96, 157], "stage": [7, 8, 9, 17, 18, 20, 24, 48, 57, 99, 109, 118, 135, 153, 156, 160, 172, 188, 219, 253], "stage1": [96, 157], "stage1_checkpoint": [58, 119], "stage2_checkpoint": [58, 119], "stage3_gather_16bit_weights_on_model_sav": 9, "stage3_max_live_paramet": 9, "stage3_max_reuse_dist": 9, "stage3_param_persistence_threshold": 9, "stage3_prefetch_bucket_s": 9, "stand": [57, 118, 123, 151, 243], "standalon": [9, 48, 67, 109, 128, 164], "standard": [9, 37, 46, 47, 89, 111, 113, 123, 127, 128, 129, 132, 135, 137, 138, 145, 150, 160, 188, 219], "star": [72, 94, 133, 155, 181, 234], "starcoderdata": [96, 157], "start": [5, 9, 36, 42, 43, 44, 48, 51, 56, 67, 88, 98, 99, 111, 112, 116, 117, 118, 121, 125, 126, 128, 147, 149, 152, 153, 159, 160, 163, 165, 172, 173, 179, 180, 181, 188, 194, 210, 214, 219, 230, 231, 237, 241, 243], "start_agentic_pipelin": 222, "start_box": [60, 121], "start_step": 43, "start_tim": 191, "startswith": [29, 30, 53, 114, 219], "startup": [43, 88, 109, 126, 131, 149, 150, 172, 231], "state": [35, 38, 40, 46, 52, 56, 58, 62, 66, 70, 96, 113, 117, 123, 127, 128, 148, 152, 155, 157, 160, 219, 231], "state_dict": [35, 58, 62, 119, 123, 219], "statement": [56, 117], "static": [9, 15, 67, 128], "static_cast": 204, "staticmethod": [62, 93, 123, 154], "statist": [96, 128, 157, 188, 219], "status": [49, 60, 66, 110, 121, 126, 127, 154, 179, 180, 181, 201, 221], "std": [7, 18, 50, 52, 67, 70, 74, 76, 77, 89, 96, 128, 131, 135, 137, 138, 150, 157, 160, 204, 213, 234], "stderr": 200, "stdin": [51, 112], "stdin_stdout": [51, 112], "stdout": [51, 112, 219], "stds": 214, "stds0": 214, "stds1": 214, "stds2": 214, "stds3": 214, "stdtemplateinput": [53, 114], "steadili": [111, 113], "steak": 241, "stem": 200, "step": [3, 8, 24, 35, 38, 40, 42, 43, 46, 48, 50, 52, 62, 67, 68, 82, 83, 86, 89, 96, 98, 99, 109, 113, 119, 123, 128, 129, 132, 133, 140, 143, 144, 147, 148, 150, 155, 157, 159, 160, 162, 166, 170, 172, 173, 179, 188, 193, 194, 215, 219, 225, 240], "step1": [38, 62, 123, 188, 219], "step2": [38, 62, 123], "step3": [38, 96, 157], "step_": 219, "step_loss": 219, "step_siz": 214, "stepfun": [96, 157], "steps_per_gener": [75, 89, 99, 101, 136, 150, 162], "steps_per_print": [48, 109, 188, 219], "still": [40, 41, 45, 50, 51, 111, 112, 118, 121, 128, 132, 142, 172, 241], "stinkhorn": 234, "stir": 121, "stop": [43, 61, 67, 83, 86, 98, 122, 128, 136, 144, 147, 152, 159, 170, 179, 180, 181, 210, 231], "stop_stag": 253, "stop_word": [11, 53, 114], "storag": [67, 128, 151, 152, 160, 166], "store": [40, 46, 47, 121, 122, 128, 150, 158, 160, 172, 219, 241], "store_tru": [188, 219], "stori": [56, 57, 117, 118, 237], "storycloz": [68, 70, 129, 131], "str": [7, 11, 18, 20, 38, 42, 43, 44, 46, 47, 50, 52, 53, 60, 62, 70, 71, 74, 78, 83, 86, 93, 95, 97, 100, 111, 113, 114, 121, 123, 131, 132, 135, 139, 144, 147, 154, 156, 158, 161, 188, 194, 214, 219, 243], "straggler": [48, 109], "straightforward": [46, 111, 123], "strategi": [38, 40, 43, 46, 55, 67, 68, 70, 99, 116, 118, 124, 128, 129, 131, 132, 135, 136, 142, 149, 160, 161, 162, 172, 174, 180, 199, 222], "strategy_arg": 222, "strategy_config": 222, "strategy_nam": 222, "strategyqa": [68, 70, 129, 131], "strato": [96, 157], "stream": [7, 53, 55, 56, 57, 63, 65, 67, 90, 91, 95, 99, 102, 103, 104, 105, 114, 116, 117, 118, 124, 126, 128, 150, 151, 152, 156, 160, 163, 164, 165, 166, 172, 179, 184, 219, 243, 244], "streamhandl": 219, "strength": 148, "strict": [37, 67, 70, 128, 131, 135, 139], "stride": 214, "strike": [57, 118], "string": [19, 41, 43, 47, 52, 60, 66, 67, 113, 121, 127, 128, 129, 131, 154, 158, 160, 213, 214, 219, 228, 243], "stringformatt": 11, "strip": [37, 44, 50, 52, 62, 88, 111, 113, 123, 149, 191, 204, 221], "stripe": [57, 118], "strong": [123, 154, 156], "stronger": [128, 153, 155], "structbert": [96, 157], "structur": [29, 44, 67, 119, 122, 128, 129, 143, 158, 160, 164, 194, 219], "struggl": [135, 139], "stsb": [96, 157], "stub": 230, "student": [71, 100, 128, 161], "student_answ": [52, 113], "studi": [96, 157], "studio": [67, 128], "studio_titl": [65, 126], "stumbl": 237, "style": [42, 45, 47, 57, 99, 118, 138, 151, 155, 160, 219], "sub": 46, "sub_group_s": 9, "subclass": 158, "subdataset": 121, "subfield": 121, "subfold": 219, "subject": [57, 118, 213], "submit": [9, 151], "submodul": [180, 181], "subprocess": [219, 221], "subsequ": [111, 113, 116, 121, 123, 126, 127, 163], "subset": [50, 52, 60, 67, 68, 70, 82, 96, 111, 113, 121, 128, 129, 131, 143, 151, 157], "subset1": [60, 67, 121, 128], "subset2": [60, 67, 121, 128], "subset_list": [68, 70, 129, 131], "subset_nam": [68, 70, 129, 131], "subsetdataset": [52, 60, 113, 121], "substanc": 129, "substitut": [83, 86, 144, 147], "subtl": 241, "subtract": [50, 52, 111, 113, 128, 137, 138, 160], "success": [14, 60, 66, 111, 113, 114, 116, 121, 127, 152, 179, 180, 181, 185], "such": [36, 38, 40, 41, 50, 51, 55, 56, 57, 70, 111, 112, 116, 117, 118, 121, 123, 124, 126, 127, 128, 129, 134, 140, 141, 142, 143, 144, 147, 148, 149, 150, 152, 153, 155, 158, 160, 163, 164, 165, 166, 172], "sudo": [22, 32, 33, 181, 185], "suffer": 131, "suffici": [35, 155], "suffix": [53, 61, 114, 122, 128, 160], "sugar": 241, "suggest": [57, 111, 118, 128, 219, 234], "suit": [57, 118], "suitabl": [44, 120, 121, 129, 149, 180, 219], "sum": [46, 50, 51, 53, 71, 75, 77, 81, 84, 89, 111, 112, 114, 128, 132, 136, 138, 141, 142, 145, 150, 188, 214, 219], "summari": [35, 37, 40, 135, 160, 210, 219], "summary_typ": 219, "summedit": [68, 70, 129, 131], "sunglass": 90, "sunni": 121, "suno": 243, "super": [28, 36, 39, 50, 52, 53, 60, 62, 88, 111, 113, 114, 121, 123, 149, 188, 214, 215, 219], "superpod": [180, 181], "supervis": [24, 119, 128, 133, 140, 152, 155, 156, 166], "supplementari": 155, "support": [5, 27, 28, 31, 32, 36, 40, 41, 42, 43, 44, 47, 55, 70, 96, 110, 111, 112, 113, 114, 117, 120, 121, 122, 123, 124, 126, 128, 129, 130, 132, 136, 145, 147, 148, 151, 152, 155, 156, 158, 159, 160, 162, 163, 164, 165, 166, 172, 174, 188, 201, 209, 219, 221, 230, 237], "support_padding_fre": [53, 114], "supported_op_exec": 214, "suppos": [38, 45, 146], "suppress": [134, 135, 214], "sure": [33, 37, 38, 56, 70, 117, 121, 128, 130, 172, 175, 219, 241, 245], "surfac": 41, "surpris": [39, 237], "sus": [96, 157], "sustc": [96, 157], "sustech": [96, 157], "sv2": 22, "svd": [7, 67, 128], "sve": 194, "swanlab": [8, 22, 89, 99, 101, 150, 160, 162], "swanlab_api_key": [7, 67, 99, 128, 160], "swanlab_mod": 7, "swanlab_notification_method": [67, 128], "swanlab_project": [7, 12], "swanlab_run_nam": [7, 12], "swanlab_workspac": 7, "sweet": [57, 118], "swift": [0, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 98, 99, 100, 101, 102, 103, 104, 109, 110, 111, 112, 113, 114, 116, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 154, 156, 157, 159, 160, 161, 162, 163, 164, 165], "swift3": [62, 64, 67, 89, 96, 99, 105, 125, 150, 166], "swift4": [62, 64, 70, 96], "swift_debug": [53, 57, 114, 118], "swift_patch_conv3d": [57, 67, 118, 128], "swift_timeout": [70, 131], "swiftconfig": [97, 158], "swiglu": [39, 214], "swin2sr": 243, "swish": 214, "switch": [55, 116, 121, 127, 128, 151, 152, 172, 219], "switchbox": [48, 109], "swr": 170, "sylveon": 3, "symbol": [52, 113], "symint": 214, "symlink": [67, 99, 128, 160], "symmetr": [132, 135, 160, 161], "sympi": [185, 206, 209, 233], "sync": [32, 33, 38, 41, 46, 67, 128, 214, 219], "sync_gradi": 219, "sync_ref_model": [101, 162], "synchron": [124, 128, 142, 147, 148, 150, 153, 160, 162, 164], "syntact": 160, "syntax": 128, "synthetic_text_to_sql": [96, 157], "sys": [14, 55, 116, 219], "sys_ptrac": 14, "system": [11, 19, 37, 38, 43, 48, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61, 63, 65, 66, 67, 83, 86, 87, 88, 90, 91, 92, 102, 105, 109, 110, 111, 112, 113, 114, 117, 118, 120, 121, 122, 124, 126, 127, 128, 144, 147, 148, 149, 151, 152, 153, 163, 166, 179, 180, 187, 194, 219, 246], "system_env": 222, "system_info": [194, 256], "system_instruct": 199, "system_messag": [7, 83, 144], "system_prefix": [53, 61, 114, 122], "system_prompt": [88, 149], "system_tag": 19, "t2i": [96, 157], "t4": [63, 64, 124, 125], "tab": [65, 70, 126, 131], "tabbi": [57, 118], "tabl": [27, 89, 150, 154, 157, 162, 201], "table_first_2000": 27, "tablet": 243, "tag": [14, 19, 50, 52, 53, 66, 83, 86, 87, 96, 105, 110, 111, 113, 114, 121, 127, 144, 147, 148, 151, 157, 166, 219, 222], "tagengo": [96, 157], "tail": [179, 180, 181], "tailor": [128, 146, 149], "take": [35, 41, 50, 60, 66, 83, 86, 111, 120, 121, 125, 127, 128, 130, 139, 144, 147, 148, 149, 150, 158, 160, 166, 219, 241], "taken": [129, 142], "talker": [53, 114], "talker_config": [53, 114], "tangent": [52, 113], "tanh": 214, "tanhct": 214, "tany0699": [96, 157], "tar": [29, 96, 157, 181, 234], "target": [39, 42, 45, 50, 60, 67, 99, 111, 121, 128, 142, 155, 158, 160, 188, 193, 194, 212, 214, 219, 255], "target_dir": 178, "target_dtyp": [188, 219], "target_fil": 39, "target_modul": [48, 53, 56, 57, 62, 63, 67, 68, 99, 102, 103, 104, 109, 114, 117, 118, 123, 124, 128, 129, 160, 163, 164, 165], "target_regex": [67, 70, 128, 131], "task": [7, 20, 27, 28, 29, 30, 31, 34, 37, 38, 43, 45, 50, 56, 57, 67, 85, 87, 91, 96, 99, 112, 114, 115, 117, 118, 120, 121, 123, 124, 126, 128, 134, 141, 148, 151, 152, 155, 157, 160, 165, 177, 181, 184, 199, 200, 219, 243, 244, 246, 256], "task1": 199, "task2": 199, "task_cfg": [58, 119], "task_cfg_dict": [58, 70, 119, 131], "task_dir": [7, 20], "task_queue_en": [15, 178, 179], "task_typ": [49, 67, 99, 110, 128, 160], "taskconfig": [58, 70, 119, 131], "tastelikefeet": [95, 96, 156, 157], "tau": [67, 78, 81, 84, 92, 128, 139, 142, 145, 153], "tau_neg": [67, 78, 128, 139], "tau_po": [67, 78, 128, 139], "taverski": 17, "tb": [172, 173], "tcp": 214, "tdrz": 256, "te": [99, 160], "teacher": [60, 71, 99, 100, 121, 160, 161], "teacher_generated_data": [71, 132], "teacher_model": [71, 100, 132, 161], "team": [35, 46, 219], "tech": [67, 96, 99, 128, 157, 160], "techniqu": [117, 118, 121, 124, 128, 130, 138, 142, 151, 152, 160, 164, 165, 166], "technolog": [124, 151, 152], "techxgenus": 16, "tedious": 166, "tee": [48, 109], "teknium": [96, 157], "tele": [96, 157], "teleai": [96, 157], "telechat": [96, 157], "telechat2": [96, 157], "tell": [35, 56, 117, 121, 144], "temp": [55, 116, 185, 194], "temperatur": [7, 42, 48, 49, 50, 51, 52, 53, 56, 57, 58, 63, 67, 68, 71, 80, 89, 90, 91, 95, 99, 100, 104, 105, 109, 110, 111, 112, 113, 114, 117, 118, 119, 120, 124, 128, 129, 132, 141, 145, 150, 151, 152, 153, 155, 156, 160, 161, 165, 166, 178, 179, 194, 222, 231, 246], "templat": [7, 8, 9, 20, 21, 23, 24, 42, 48, 49, 50, 53, 57, 60, 61, 63, 66, 67, 88, 91, 92, 96, 99, 103, 105, 109, 110, 111, 117, 118, 120, 121, 122, 124, 127, 149, 151, 152, 153, 157, 160, 164, 166, 222], "template_backend": [67, 128], "template_cl": [53, 114], "template_input": [60, 121], "template_map": [61, 122], "template_meta": [61, 122], "template_mod": [67, 128], "template_typ": [53, 91, 114, 152], "templatemeta": [53, 61, 114, 122], "tempor": 46, "temporarili": [35, 128, 219], "tencent": [96, 157], "tend": [132, 155], "tender": [57, 118], "tensor": [7, 11, 28, 31, 35, 38, 40, 42, 43, 45, 46, 49, 53, 62, 67, 89, 90, 97, 98, 99, 110, 114, 123, 128, 150, 151, 152, 158, 159, 160, 161, 162, 164, 166, 172, 173, 177, 188, 191, 194, 207, 214, 219], "tensor_info": 204, "tensor_model_parallel_s": [57, 70, 98, 99, 102, 103, 104, 105, 118, 131, 159, 160, 163, 164, 165, 166, 174, 178, 222], "tensor_parallel": 9, "tensor_parallel_degre": 240, "tensor_parallel_s": 43, "tensorboard": [8, 67, 99, 128, 160, 207, 219, 222], "tensorboard_trace_handl": [98, 159, 172, 173], "tensorfloat": 219, "tensorflow": [0, 12, 204, 219], "tensorlist": 214, "tensorwis": [99, 160], "term": [89, 128, 134, 137, 138, 145, 150, 153, 160, 213], "termin": [90, 126, 128, 143, 147, 151, 246], "terminolog": 37, "terminus": [96, 157], "test": [31, 39, 48, 51, 60, 67, 70, 90, 94, 95, 96, 99, 103, 109, 112, 114, 116, 117, 121, 127, 128, 151, 152, 155, 156, 157, 160, 163, 166, 170, 174, 180, 184, 188, 193, 197, 212, 214, 219, 224, 230, 234, 241, 244], "test_batch_s": [188, 219], "test_cas": [51, 112], "test_convers": 37, "test_convert_precis": [99, 102, 103, 105, 160, 163, 164, 166], "test_custom_source_preprocessor": 37, "test_data": [70, 131], "test_dataset": [60, 121], "test_fil": [178, 179, 180], "test_freq": [174, 178], "test_ground": [91, 152], "test_lora": [90, 91, 151, 152], "test_lora2": [91, 152], "test_my_qwen2_5_omni": [53, 114], "test_run": 12, "test_train": 241, "test_xxx": 170, "testcas": 214, "testing_util": 219, "testload": [188, 219], "testnpuflashattent": 214, "testset": [188, 219], "text": [3, 11, 19, 37, 42, 43, 46, 53, 56, 57, 60, 62, 71, 72, 73, 74, 76, 77, 78, 80, 81, 84, 87, 89, 90, 92, 96, 110, 111, 113, 114, 117, 118, 120, 123, 124, 127, 128, 129, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 145, 147, 148, 150, 151, 152, 153, 157, 160, 164, 172, 173, 180, 184, 191, 194, 207, 219, 231, 241, 243, 246, 253], "text1": [60, 67, 121, 128], "text2": [60, 67, 121, 128], "text2imag": 219, "text_column_nam": 219, "text_encod": 219, "text_featur": 207, "text_gflop": 207, "text_id": [53, 114], "text_key": 42, "text_label": 253, "text_mparam": 207, "text_position_id": [53, 114], "text_prob": 207, "text_to_imag": 3, "text_width": 207, "textcap": [96, 157], "textclassificationpipelin": 243, "textfm": [96, 157], "texttosqlv2_25000_v2": [96, 157], "textvqa_v": [68, 70, 129, 131], "tf32": 219, "tfinal": [67, 128], "tfs_z": 194, "tgt_len": 214, "th": [138, 145, 154, 160, 172], "than": [35, 37, 45, 89, 96, 110, 120, 121, 128, 136, 141, 142, 147, 150, 155, 157, 160, 164, 166, 184, 219, 237, 241], "thank": [34, 35, 46], "that": [35, 36, 37, 38, 39, 41, 43, 44, 45, 46, 50, 51, 52, 56, 57, 59, 70, 83, 86, 109, 110, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 125, 127, 128, 129, 130, 133, 135, 136, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 156, 158, 159, 160, 161, 162, 164, 166, 172, 184, 187, 188, 194, 214, 219, 234, 241, 243], "the": [9, 11, 16, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 66, 67, 81, 83, 85, 86, 87, 88, 89, 90, 96, 104, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 142, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 172, 176, 179, 180, 181, 184, 187, 188, 191, 199, 204, 206, 209, 213, 214, 215, 219, 222, 228, 230, 231, 233, 234, 237, 241, 243, 244, 249, 250], "their": [35, 36, 46, 50, 57, 110, 111, 113, 118, 121, 123, 127, 128, 131, 134, 137, 138, 142, 151, 153, 156, 158, 160, 161, 241, 245], "them": [34, 35, 39, 43, 46, 50, 51, 56, 57, 111, 112, 114, 117, 118, 119, 121, 123, 127, 128, 140, 147, 149, 152, 153, 154, 158, 163, 166, 172, 188, 219], "themselv": [50, 111, 134], "then": [28, 35, 46, 50, 51, 56, 83, 86, 87, 111, 112, 114, 117, 121, 123, 128, 132, 137, 140, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 158, 159, 160, 164, 166, 178, 179, 180, 181, 188, 219, 241], "theoret": 136, "there": [28, 45, 50, 51, 52, 56, 110, 111, 112, 113, 117, 118, 121, 124, 128, 130, 132, 140, 142, 148, 149, 150, 151, 152, 154, 160, 219, 237], "therebi": [119, 128, 133, 143, 148, 153, 160, 166], "therefor": [38, 41, 52, 111, 113, 114, 120, 132, 136, 139, 140, 142, 149, 154, 156, 160, 164], "these": [35, 39, 40, 41, 46, 50, 51, 52, 111, 112, 114, 118, 121, 122, 123, 124, 127, 128, 130, 134, 141, 142, 147, 148, 149, 150, 151, 152, 154, 158, 160, 164, 219], "theta": [50, 72, 73, 75, 76, 77, 78, 80, 81, 84, 89, 111, 133, 134, 136, 137, 138, 139, 141, 142, 145, 150], "they": [35, 36, 45, 51, 57, 90, 109, 112, 118, 121, 123, 130, 135, 143, 147, 154, 158, 162, 209, 219, 237, 241], "thick": 237, "thing": [188, 219], "think": [50, 52, 56, 59, 60, 62, 66, 67, 68, 71, 83, 86, 87, 95, 96, 103, 111, 113, 117, 120, 121, 123, 127, 128, 129, 132, 134, 144, 147, 148, 156, 157, 164], "thinker": [53, 67, 70, 114, 128, 131], "thinker_config": [53, 114], "thinker_do_sampl": [53, 114], "thinking_tips_schedul": [86, 147], "thinkingmodeltipsschedul": [86, 147], "thinklite_eureka": [79, 140], "third": [121, 152], "this": [28, 29, 31, 32, 34, 35, 36, 37, 38, 40, 43, 44, 45, 47, 50, 51, 52, 57, 66, 70, 83, 86, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 172, 180, 184, 188, 194, 197, 199, 213, 219, 228, 237, 241, 243, 244, 249], "thoma": [96, 157], "thorough": [128, 160], "those": [41, 53, 114, 123, 219, 241], "though": [41, 160, 164], "thought": [66, 87, 96, 117, 127, 128, 148, 155, 157], "thousand": 172, "thousandth": [121, 128], "thread": [34, 67, 128, 158, 256], "threaten": 237, "three": [11, 38, 43, 45, 46, 50, 52, 111, 121, 123, 128, 129, 135, 136, 140, 151, 152, 154], "threshold": [67, 89, 99, 110, 128, 141, 142, 150, 155, 160], "through": [36, 41, 46, 55, 89, 109, 111, 112, 113, 114, 116, 121, 123, 124, 126, 127, 128, 132, 140, 142, 143, 150, 151, 152, 159, 160, 172, 219], "throughout": 37, "throughput": [166, 237], "throw": [160, 219], "thus": [38, 111, 117, 140, 150, 155, 166], "thw": 46, "tianl": [35, 46], "tidi": 246, "tiger": [96, 157, 197], "tigerbot": [96, 157], "tigerresearch": [96, 157], "tiiuae": [96, 157], "tild": [76, 137], "tile": 214, "tile_height": 11, "tile_width": 11, "time": [11, 31, 35, 38, 39, 42, 44, 45, 50, 66, 67, 70, 83, 84, 86, 91, 95, 99, 111, 118, 121, 127, 128, 129, 133, 144, 145, 147, 150, 152, 155, 156, 160, 166, 172, 177, 184, 187, 188, 191, 194, 219, 234, 237, 256], "timelin": 177, "timeout": [42, 67, 99, 128, 150, 160, 170], "timestamp": [128, 156, 160, 172, 173, 178, 210, 256], "timestep": [141, 219], "timm": [0, 96, 157, 234, 252], "timmi": 237, "tini": [96, 157, 256], "tinit": [67, 128], "tiny_vit_21m_512": 234, "tip": [124, 128, 130, 151, 160, 164, 174, 246], "tir": [56, 82, 96, 117, 143, 157], "titl": [67, 128], "tl": [35, 81, 142], "tldr": 46, "tmp": [179, 180, 181, 219], "tnew": [68, 70, 129, 131], "tng": 214, "to": [2, 3, 27, 28, 29, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 56, 57, 58, 60, 63, 66, 67, 68, 79, 83, 85, 86, 88, 89, 90, 91, 95, 96, 99, 104, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 164, 165, 166, 170, 171, 175, 176, 179, 180, 181, 184, 187, 188, 191, 193, 194, 204, 207, 212, 213, 214, 215, 219, 222, 228, 230, 231, 234, 237, 241, 243, 244, 245, 246, 249, 250, 256], "to_cached_dataset": [67, 128], "to_float_dtyp": [53, 114], "to_hf": [99, 102, 103, 105, 160, 163, 164, 166], "to_mcor": [67, 102, 103, 105, 128, 163, 164, 166], "today": [35, 56, 117, 121, 127], "toddler": [57, 118], "todo": 222, "togeth": [41, 50, 111, 128, 160, 219], "togethercomput": [96, 157], "tok_logg": 219, "toke": 180, "token": [7, 11, 13, 37, 38, 40, 42, 43, 45, 46, 51, 52, 53, 56, 57, 59, 60, 61, 62, 63, 66, 67, 69, 71, 73, 75, 78, 79, 81, 84, 89, 91, 94, 96, 99, 100, 103, 105, 110, 112, 113, 114, 117, 118, 120, 121, 122, 123, 124, 127, 128, 130, 132, 134, 136, 139, 140, 142, 145, 150, 152, 153, 155, 157, 160, 161, 164, 166, 172, 173, 179, 180, 181, 184, 191, 194, 207, 210, 214, 219, 231, 237, 238, 241, 243, 244, 246, 249, 251, 256], "token2wav": [53, 114], "token_id": [53, 114, 147], "token_len": [53, 114], "token_mask": [67, 81, 99, 128, 142, 160], "token_trunc": [67, 81, 99, 128, 142, 160], "token_typ": 194, "tokenization_utils_bas": 219, "tokenize_capt": 219, "tokenize_funct": [219, 241], "tokenized_dataset": [219, 241], "tokenized_path": 7, "tokenizer_config": [11, 184], "tokenizer_kwarg": 219, "tokenizer_nam": 219, "tokenizer_path": [43, 239], "tokenizers_parallel": 184, "tokens_per_chunk": [53, 114], "tolist": [53, 114, 191], "tomato": 121, "tomg": [96, 157], "toml": [32, 33, 239, 240], "tomorrow": [56, 117, 121, 144], "tone": [56, 57, 117, 118], "tongyi": [57, 96, 117, 118, 157], "tongyifin": [96, 157], "too": [50, 111, 118, 128, 138, 139, 219], "took": 241, "tool": [11, 19, 60, 67, 79, 83, 86, 121, 128, 140, 144, 147, 159, 172, 173, 178, 185, 253], "tool_cal": [60, 66, 67, 79, 83, 86, 121, 127, 128, 140, 144, 147, 231], "tool_config": [172, 173], "tool_config_path": 178, "tool_format": [7, 11], "tool_respons": [60, 66, 67, 121, 127, 128], "tool_reward": [79, 140], "toolbench": [67, 96, 128, 157], "toolcal": 67, "toolcallschedul": [86, 147], "toolformatt": 11, "toolkit": [15, 33, 55, 116, 170, 174, 175, 185, 193, 197, 199, 203, 212, 218, 230], "toolkit_": 14, "top": [40, 42, 67, 70, 120, 121, 128, 141, 152, 154, 160, 177, 188, 213, 219], "top1": 234, "top1_err": 234, "top5": 234, "top5_err": 234, "top_entropy_quantil": [80, 89, 150, 162], "top_k": [7, 40, 67, 128, 188, 194, 210, 219, 222], "top_logprob": [70, 131], "top_p": [7, 56, 95, 117, 128, 156, 178, 194, 210, 222, 231, 246], "top_x": 28, "topic": [56, 117], "topk": [67, 128, 234], "topk_method": [70, 131], "topo": [55, 116], "torch": [2, 3, 4, 7, 9, 11, 22, 28, 35, 38, 39, 40, 42, 43, 46, 47, 53, 55, 58, 61, 62, 64, 67, 69, 73, 75, 96, 97, 98, 99, 103, 105, 114, 116, 119, 122, 123, 125, 128, 130, 134, 136, 157, 158, 159, 160, 164, 166, 172, 173, 174, 175, 176, 178, 180, 181, 183, 187, 188, 189, 191, 204, 205, 207, 208, 210, 214, 215, 218, 219, 220, 224, 227, 231, 232, 236, 238, 241, 244, 246, 248, 252], "torch1": 214, "torch2": [57, 64, 70, 105, 125, 131, 166, 214], "torch_dist": [99, 103, 160, 164], "torch_dtyp": [2, 3, 48, 50, 51, 52, 53, 55, 56, 57, 58, 61, 63, 67, 68, 91, 102, 103, 105, 109, 111, 112, 113, 114, 116, 117, 118, 119, 122, 124, 128, 129, 152, 160, 163, 164, 166, 191, 219, 241, 246], "torch_log": 214, "torch_memori": [172, 173], "torch_npu": [14, 55, 98, 116, 159, 172, 173, 174, 175, 176, 178, 180, 181, 183, 187, 189, 206, 207, 214, 215, 217, 218, 219, 221, 224, 227, 230, 233, 239, 241, 244, 246, 248, 249, 252], "torch_npu_vers": 236, "torch_parallel": 43, "torch_util": 219, "torch_vers": 236, "torchair": 214, "torchao": 236, "torchaudio": [96, 157, 221, 224, 252], "torchchat": [0, 237], "torchcodec": [32, 33, 57, 118], "torchdata": 236, "torchdynamo_dis": 178, "torchdynamo_verbos": 214, "torchrun": [7, 15, 37, 48, 67, 91, 102, 103, 109, 128, 152, 163, 164, 207], "torchtitan": [0, 35], "torchtun": 236, "torchvis": [2, 174, 176, 188, 219, 221, 224, 230, 236], "torchvision_vers": 230, "tornado": [48, 109], "total": [35, 42, 44, 45, 52, 67, 70, 82, 89, 99, 110, 111, 113, 128, 137, 143, 145, 148, 150, 154, 156, 160, 188, 194, 212, 219, 237, 256], "total_batch_s": [128, 219], "total_epoch": [174, 178], "total_flo": 241, "total_length": 219, "total_loss": [89, 150], "total_pr": 219, "total_sampl": 128, "total_seq_len": 46, "total_token": 231, "totensor": [188, 219], "touch": [41, 57, 118, 178], "toward": [40, 50, 111, 133], "tower": [67, 99, 129], "toymodel": 215, "tp": [9, 35, 43, 63, 67, 89, 90, 99, 100, 101, 103, 105, 124, 128, 150, 151, 160, 161, 162, 164, 166, 177, 179, 197, 214, 240], "tp_group": 43, "tp_mesh": 43, "tp_size": [43, 89, 150], "tpu_env": 9, "tpu_use_clust": 9, "tpu_use_sudo": 9, "tpus": 219, "tqdm": [70, 131, 219], "trace": [42, 43], "trace_dir": 43, "traceback": [70, 131], "track_with": 222, "tracker": [99, 160, 219], "tracker_config": 219, "tracker_kwarg": 222, "tracker_project_nam": 219, "trade": 132, "tradeoff": 40, "train": [0, 8, 9, 14, 15, 16, 20, 23, 24, 34, 36, 39, 40, 44, 45, 46, 48, 50, 51, 52, 53, 56, 57, 60, 62, 66, 67, 82, 87, 89, 93, 94, 96, 97, 98, 99, 105, 122, 123, 124, 125, 126, 130, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 145, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 162, 165, 172, 173, 174, 178, 180, 184, 188, 201, 207, 210, 214, 219, 222, 234, 240, 241, 244, 249, 253], "train2017": 29, "train_0": [96, 157], "train_1m_cn": [96, 157], "train_2m_cn": [96, 157], "train_3": [96, 157], "train_batch_s": [3, 9, 48, 109, 174, 178, 188, 219], "train_config": [239, 240], "train_data_dir": 219, "train_data_iter": [98, 159], "train_data_ratio": 179, "train_dataload": [43, 219], "train_dataloader_shuffl": [67, 99, 128, 160], "train_dataset": [43, 60, 121, 219, 241], "train_dir": 3, "train_env_manag": 222, "train_fil": [174, 178, 179, 180, 219], "train_from_scratch": 7, "train_ful": [9, 15, 18], "train_it": [56, 98, 99, 117, 159, 160], "train_lora": [8, 9, 15, 20, 24], "train_loss": [219, 241], "train_micro_batch_size_per_gpu": [9, 48, 109], "train_mm_proj_on": 7, "train_on_prompt": 7, "train_path": [27, 30, 38, 42, 43], "train_qwen2_5_vl": 38, "train_qwen2_vl": [37, 43], "train_qwen3_omni": 29, "train_qwen_vl": [30, 38], "train_result": 219, "train_runtim": 241, "train_sampl": 219, "train_samples_per_second": 241, "train_siz": [42, 43], "train_sp": 178, "train_spe": [70, 82, 131, 143], "train_step": [43, 98, 159], "train_steps_per_second": 241, "train_stream": 219, "train_text_to_imag": 219, "train_text_to_image_lora_sdxl": 3, "train_torch": [27, 28, 43], "train_transform": 219, "train_typ": [48, 67, 99, 109, 128, 160], "train_wan": 31, "trainabl": [67, 97, 99, 123, 128, 158, 160, 219], "trainable_paramet": [67, 99, 128, 160], "trainable_parameters_regex": [67, 128], "traincoco": 207, "trainer": [9, 62, 67, 70, 81, 86, 88, 89, 93, 98, 99, 123, 128, 131, 142, 147, 148, 149, 150, 154, 159, 160, 172, 173, 174, 178, 179, 180, 181, 219, 249], "trainer_pt_util": [67, 99, 128, 160], "trainer_st": [87, 148], "trainercallback": [62, 123], "trainercontrol": [62, 123], "trainerst": [62, 123], "training_arg": [219, 222, 241], "training_config": 9, "training_data": [188, 219], "training_log_ppl": [81, 142], "training_loss": 241, "training_port": [48, 109], "training_ppl": [81, 89, 142, 150], "training_script": [48, 109], "training_util": 219, "trainingargu": [43, 62, 123, 219, 241], "trainingmigrguid": 181, "trainload": [188, 219], "trainoutput": 241, "trainset": [188, 219], "trainvalid": [96, 157], "trainvalidationtest": [96, 157], "traj_env": 222, "traj_group_id": 222, "trajectori": [86, 140, 147], "trajectory_id": [83, 144], "trajectory_info": [83, 144], "trajectory_input": 147, "tran": 214, "trans_bnsd2bsh": 214, "trans_weight": 214, "transcrib": [243, 256], "transfer": [38, 97, 128, 132, 158, 161, 230], "transfom": 244, "transform": [0, 9, 11, 16, 28, 31, 35, 36, 37, 38, 39, 45, 53, 56, 57, 58, 62, 63, 64, 67, 68, 71, 87, 90, 91, 93, 95, 96, 99, 103, 105, 114, 117, 118, 119, 120, 121, 123, 124, 125, 128, 129, 132, 148, 151, 152, 154, 156, 157, 160, 164, 166, 174, 178, 180, 181, 184, 188, 189, 199, 200, 201, 214, 217, 221, 228, 241, 243, 246, 248, 249], "transformer_based_wrap": [9, 15], "transformer_engin": [105, 166], "transformer_infer": 187, "transformerengin": [99, 105, 160, 166], "transformers4": 70, "transformers5": 41, "transformers_modul": [70, 131], "transformers_vers": [96, 157], "transformersengin": [53, 57, 67, 70, 88, 90, 91, 114, 118, 128, 149, 151, 152], "transit": [133, 147], "translat": 155, "transmit": 38, "transpar": [35, 111], "transpos": [28, 40, 46, 177, 204, 214], "transpose_box": 214, "transpose_first": 214, "travers": [55, 116], "treat": [35, 144, 147, 160], "tree": [63, 93, 94, 105, 124, 133, 140, 154, 155, 166, 243, 256], "trend": [113, 144], "tri": [35, 41, 50, 52, 70, 88, 98, 111, 113, 118, 128, 149, 150, 159, 160, 184, 188, 219, 221], "trick": [74, 135], "trigger": [37, 45, 128, 134, 160, 161, 172, 249], "tril": [70, 131], "triton": [97, 158, 174, 176], "triu": [70, 131], "trivia_qa": [68, 129], "triviaqa": [68, 70, 129, 131], "trl": [0, 64, 93, 99, 105, 125, 154, 160, 166, 247, 249], "trn": [96, 157], "truck": [188, 219], "true": [6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 24, 28, 33, 34, 38, 42, 43, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 62, 63, 65, 67, 68, 69, 72, 74, 76, 77, 79, 81, 83, 86, 89, 90, 91, 95, 98, 99, 100, 102, 103, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 124, 126, 128, 129, 130, 133, 135, 137, 138, 140, 142, 144, 147, 150, 151, 152, 156, 159, 160, 161, 163, 164, 165, 166, 170, 171, 172, 173, 174, 175, 178, 179, 180, 181, 184, 188, 191, 197, 199, 204, 207, 210, 214, 215, 219, 222, 228, 241, 243, 246, 253], "truncat": [67, 99, 110, 114, 128, 135, 147, 150, 160, 174, 178, 210, 219, 241], "truncation_strategi": [53, 67, 114, 128], "trust": [70, 131, 219, 231], "trust_remote_cod": [7, 8, 53, 114, 179, 199, 210, 219], "truth": [50, 52, 111, 113, 140, 214, 219], "truthful_qa": [68, 129], "ts": [181, 228, 249], "tsinghua": [2, 183, 184, 185, 206, 209, 227, 233, 244, 248], "tts": [67, 128], "tulu": [27, 96, 157], "tulu_sharegpt4v_llavavideo": 29, "tuna": [2, 183, 184, 185, 206, 209, 227, 233, 244, 248], "tune": [0, 16, 19, 24, 67, 97, 99, 111, 118, 119, 124, 128, 133, 140, 151, 156, 158, 160, 161, 162, 165, 166, 181, 201, 219], "tuner": [70, 99, 131, 160], "tuner_backend": [67, 128], "tuner_nam": [97, 158], "tuner_typ": [50, 51, 52, 53, 55, 56, 57, 58, 63, 67, 68, 91, 92, 102, 103, 104, 111, 112, 113, 114, 116, 117, 118, 119, 124, 128, 129, 152, 153, 163, 164, 165], "tupl": [38, 53, 62, 83, 93, 114, 123, 144, 154, 219], "turbomind": [70, 131, 196], "turn": [57, 67, 70, 86, 118, 122, 123, 124, 128, 140, 144, 151, 160, 162, 172, 222], "tutori": [35, 36, 38, 46, 172, 177, 219], "tweak": 219, "two": [38, 41, 42, 43, 45, 46, 50, 110, 111, 112, 113, 117, 118, 119, 120, 121, 123, 127, 128, 129, 130, 132, 147, 148, 149, 150, 151, 152, 156, 160, 164, 165, 166, 172, 219, 241, 243], "txt": [8, 13, 14, 22, 26, 51, 52, 60, 67, 99, 105, 112, 113, 121, 128, 160, 166, 170, 174, 175, 184, 204, 210, 219, 221, 224, 236, 239, 252, 253], "type": [19, 38, 42, 43, 46, 48, 51, 52, 53, 57, 58, 60, 61, 66, 67, 74, 79, 90, 92, 96, 99, 109, 110, 112, 114, 116, 118, 119, 121, 122, 124, 127, 128, 129, 132, 135, 139, 140, 146, 147, 148, 151, 153, 154, 157, 158, 160, 161, 179, 188, 194, 210, 213, 214, 219, 222, 231, 234, 256], "type_info": 204, "typeerror": 37, "typic": [38, 89, 114, 121, 122, 123, 128, 131, 136, 138, 141, 147, 150, 152, 155, 160, 164, 166, 172], "typical_p": 194, "typing_extens": [206, 209, 233], "u32": 194, "ubuntu": [22, 32, 33, 176, 185, 194], "ubuntu22": [14, 64, 70, 105, 125, 131, 166, 170, 183], "ucp_device_typ": [48, 109], "ui": [7, 8, 63, 64, 70, 96, 124, 125, 131, 157], "uint16": 214, "uint32": 214, "uint64": 214, "uint8": [53, 114, 214], "ukplab": 228, "ulimit": [179, 180, 181], "ultra": 164, "ultrachat_200k": [96, 157], "ultrafeedback": [96, 157], "ulyss": [39, 42, 43, 46, 63, 124], "ulysses_attention_forward": 39, "ulysses_parallel_s": [38, 43], "ulysses_s": 43, "ulysses_sequence_parallel_s": 178, "umd": [96, 157], "umi": [67, 96, 128, 157], "un": 92, "unam": [22, 170, 185, 236], "unavail": 142, "unbias": 138, "unbiased": 138, "unbind": [97, 158], "uncas": 244, "uncensor": [96, 157], "uncensoredflan5m": [96, 157], "uncertain": 133, "uncertainti": [133, 141, 142], "unchang": [39, 41, 128, 135, 214], "unclip": [89, 150], "unconstrain": 135, "under": [37, 39, 46, 57, 109, 118, 121, 128, 132, 135, 141, 148, 150, 155, 160, 166, 172, 199, 219, 222, 249], "underlin": [106, 107, 108, 167, 168, 169], "understand": [35, 39, 44, 52, 113, 119, 129, 152, 219, 237], "understood": [155, 156], "underw": [111, 150], "undesir": [67, 92, 99, 128, 153, 160], "unet": 219, "unet2dconditionmodel": 219, "unet_ema": 219, "uneven": 45, "unfold": [57, 118], "unfreez": [119, 160], "unfus": [99, 160], "unhandl": [70, 131], "unidirect": 214, "unifi": [0, 39, 43, 47], "uniform": [34, 56, 57, 67, 70, 99, 102, 103, 104, 105, 117, 118, 123, 128, 131, 142, 160, 163, 164, 165, 166, 214], "uniform_": 214, "uniniti": 128, "uninstal": [22, 128, 131, 174, 185, 199, 236, 244], "union": [7, 38, 62, 93, 95, 123, 154, 156], "uniqu": [37, 51, 112, 122, 123, 148, 149], "unit": [37, 60, 66, 67, 121, 127, 128, 136, 160, 231], "unittest": 214, "universal": [48, 109], "unknown": [37, 55, 70, 116, 131, 187, 194, 219], "unless": [128, 160, 219, 241], "unlik": [121, 123, 237], "unlimit": 128, "unload": 158, "unlucki": 121, "unmerg": [97, 158], "unnecessari": [45, 46, 128], "unpad": [38, 46], "unpadded_dim_s": 38, "unpars": 39, "unreal": 3, "unrecogn": [70, 131], "unsampl": 139, "unsign": 204, "unslic": 46, "unsloth": [7, 11, 63, 96, 97, 124, 157, 158], "unslothai": [97, 158], "unsqueez": [53, 73, 75, 114, 134, 136, 207], "unsqueeze_dim": 39, "unstabl": [113, 131, 136], "unsupport": [125, 219], "until": [70, 135], "unus": [67, 70, 128, 131], "unwrap": 219, "unwrap_model": 219, "unzip": [70, 131, 179], "up": [14, 37, 40, 46, 50, 57, 83, 99, 110, 111, 116, 118, 123, 124, 127, 129, 133, 144, 146, 148, 152, 160, 166, 172, 194, 219, 231, 243], "up_proj": [28, 40, 46, 67, 99, 128, 160], "up_proj_out": 28, "up_proj_t": 46, "upcast_layernorm": 7, "upcast_lmhead_output": 7, "updat": [5, 39, 46, 50, 52, 53, 67, 75, 89, 98, 99, 111, 113, 114, 123, 128, 134, 135, 136, 138, 139, 150, 153, 159, 160, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 204, 214, 215, 219], "update_from_str": 219, "update_polici": 250, "updatecannprovideropt": 204, "upgrad": [35, 39, 150, 199, 230, 249], "upi": [55, 116], "upload": [43, 128, 172, 219], "upload_fold": 219, "upload_trac": 43, "upon": [119, 126, 128, 237], "upper": [53, 67, 99, 114, 128, 135, 150, 160, 219], "upscal": 243, "upscaled_img": 243, "upvot": [96, 157], "urea": 129, "urgent": 243, "uric": 129, "url": [49, 53, 55, 57, 60, 62, 67, 68, 90, 95, 99, 110, 114, 116, 118, 121, 123, 128, 129, 151, 160, 174, 219, 221, 224, 230, 243, 245], "us": [50, 64, 105, 111, 125, 146, 166, 188, 219, 243], "us_foreign_polici": 200, "usa": [52, 113], "usabl": 41, "usag": [38, 42, 48, 55, 109, 113, 116, 117, 118, 125, 128, 129, 150, 152, 160, 164, 166, 172, 185, 199, 219, 231, 237], "use": [28, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 57, 66, 67, 68, 70, 83, 86, 88, 89, 99, 104, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 157, 159, 160, 161, 162, 163, 165, 166, 170, 172, 179, 180, 181, 184, 188, 194, 199, 209, 214, 219, 228, 230, 234, 237, 240, 244, 249, 256], "use_8bit_adam": 219, "use_adam_mini": 7, "use_apollo": 7, "use_async_engin": [86, 147, 150], "use_audio_in_video": [53, 114], "use_badam": [7, 18], "use_cach": [7, 199], "use_cann": 203, "use_chat_templ": [91, 152], "use_cpu": [9, 15], "use_cpu_initi": 179, "use_dist_checkpoint": 179, "use_distributed_optim": 222, "use_dora": [7, 18], "use_dynamic_bsz": [178, 180], "use_ema": 219, "use_experts_implement": 40, "use_fast": 219, "use_fast_token": [7, 219], "use_flash_attn": 174, "use_flash_ckpt": [48, 109], "use_galor": [7, 18], "use_gym_env": [83, 144], "use_hf": [56, 63, 69, 70, 117, 124, 130, 131], "use_kernel": 191, "use_kernel_forward_from_hub": 39, "use_kl_in_reward": [178, 181], "use_kl_loss": [174, 178, 181], "use_liger_kernel": [56, 117], "use_llama_pro": [7, 10], "use_local_kernel": 191, "use_lock": 214, "use_mbridg": 179, "use_megatron": 175, "use_model": [53, 114], "use_modelscop": 222, "use_modelscope_hub": 7, "use_nesterov": 214, "use_openmind_hub": 7, "use_optimized_model": 180, "use_precision_aware_optim": [99, 160], "use_ray": [7, 9], "use_reentr": [67, 70, 91, 99, 128, 131, 152, 160], "use_reentrant_gc": 7, "use_remove_pad": [174, 178], "use_residu": [188, 219], "use_rslora": [7, 18], "use_submodel_func": [53, 114], "use_swanlab": [7, 12], "use_torch_compil": 178, "use_tqdm": [88, 149], "use_unique_thread": [97, 158], "use_unsloth": [6, 7], "use_unsloth_gc": 7, "use_v1_kernel": 15, "use_vllm": [50, 51, 52, 56, 89, 99, 100, 101, 111, 112, 113, 117, 128, 150, 160, 161, 162], "used_numb": [50, 111], "user": [11, 19, 21, 35, 36, 37, 38, 40, 43, 49, 50, 52, 53, 56, 57, 59, 60, 61, 66, 67, 70, 83, 86, 87, 88, 90, 91, 109, 110, 111, 113, 114, 117, 118, 120, 121, 122, 123, 124, 125, 127, 128, 129, 131, 142, 144, 147, 148, 149, 151, 152, 156, 158, 160, 164, 172, 181, 185, 191, 204, 231, 243, 246, 249], "user_tag": 19, "useradd": 185, "usergroup": 14, "usermod": 185, "usernam": [14, 67, 128], "userwarn": [37, 67, 128, 249], "usr": [14, 15, 22, 33, 55, 116, 170, 174, 175, 178, 180, 181, 183, 185, 193, 197, 203, 219, 230], "usual": [45, 53, 114, 121, 122, 128, 149, 155, 160, 209], "utf": [29, 30, 90, 151, 215, 219], "util": [37, 38, 43, 53, 55, 57, 67, 70, 91, 96, 99, 105, 112, 114, 116, 117, 118, 125, 128, 129, 131, 142, 150, 152, 157, 160, 166, 179, 188, 207, 214, 219], "utilspi": 70, "uv": [5, 41], "uvicorn": [88, 149, 231], "v0": [0, 35, 55, 67, 96, 116, 128, 157, 170, 172, 173, 174, 175, 176, 178, 180, 181, 188, 190, 219, 221, 230], "v01": [96, 157], "v0v1": [96, 157], "v1": [0, 2, 21, 22, 58, 60, 67, 70, 88, 90, 91, 95, 96, 119, 121, 128, 131, 149, 151, 152, 156, 157, 180, 214, 219, 225, 231, 256], "v10": [96, 157], "v100": [63, 64, 124, 125], "v14": [96, 157], "v15": [96, 157], "v17": [96, 157], "v18": [96, 157], "v1_7": [96, 157], "v1alpha1": [48, 109], "v2": [55, 67, 69, 96, 105, 116, 128, 130, 157, 166, 170, 190, 214, 219, 228, 256], "v21": [96, 157], "v22": [96, 157], "v23": [96, 157], "v24": [96, 157], "v2shapesshap": [96, 157], "v3": [67, 81, 94, 96, 99, 128, 142, 155, 157, 160, 194, 256], "v4": [41, 170, 191, 221], "v5": 41, "v7": 230, "v8": [96, 157], "v_bia": 38, "v_in": 214, "v_out": 214, "v_predict": 219, "v_proj": [67, 99, 128, 160], "v_threshold": 214, "v_weight": 38, "vae": [3, 219], "vae_nam": 3, "val": [57, 67, 70, 89, 96, 99, 118, 128, 131, 157, 160, 207, 222, 234], "val2017": 243, "val_batch_s": 222, "val_before_train": 178, "val_dataset": [56, 57, 60, 67, 70, 71, 89, 90, 91, 117, 118, 121, 128, 131, 132, 150, 151, 152], "val_env_manag": 222, "val_fil": [174, 178], "val_imgs_grid": 219, "val_kwarg": 178, "val_siz": [7, 8, 24], "valid": [37, 38, 41, 44, 46, 53, 60, 71, 112, 114, 118, 121, 128, 129, 132, 135, 150, 152, 156, 160, 164, 165, 184, 188, 219, 222, 234, 241], "valid_output": 214, "validation_epoch": 219, "validation_fil": 219, "validation_percentag": 219, "validation_prompt": [3, 219], "validation_split_percentag": 219, "validation_stream": 219, "vall": [55, 116], "valley": [72, 96, 133, 157], "valu": [19, 34, 35, 37, 38, 42, 44, 46, 49, 50, 62, 67, 70, 83, 86, 87, 92, 97, 99, 109, 110, 111, 112, 114, 118, 120, 121, 123, 127, 128, 133, 134, 135, 139, 142, 143, 144, 147, 148, 149, 150, 153, 154, 158, 160, 180, 188, 194, 200, 204, 214, 219], "value_antiquant_mod": 214, "value_antiquant_offset": 214, "value_antiquant_scal": 214, "value_bia": 214, "value_head": [92, 153], "value_lay": 214, "value_r": 214, "value_shared_prefix": 214, "value_transpos": 214, "value_weight": 214, "valueerror": [37, 41, 219, 222], "vanish": 135, "var": [214, 219, 230], "var_in": 214, "var_out": 214, "varepsilon": [50, 89, 111, 150, 180], "vari": [45, 110, 121, 157], "variabl": [5, 39, 40, 53, 56, 70, 91, 110, 112, 114, 116, 117, 118, 120, 121, 131, 140, 152, 158, 160, 166, 184, 222, 230], "varianc": [128, 136, 138, 139, 142], "variance_epsilon": 39, "variant": [128, 153, 219], "variat": 131, "various": [36, 39, 50, 52, 111, 113, 124, 129, 150, 153, 155, 163, 164, 166, 172, 234, 241], "vb": 3, "vcr_en_easy_100": [68, 70, 129, 131], "vcr_en_easy_500": [68, 70, 129, 131], "vcr_en_easy_al": [68, 70, 129, 131], "vcr_en_hard_100": [68, 70, 129, 131], "vcr_en_hard_500": [68, 70, 129, 131], "vcr_en_hard_al": [68, 70, 129, 131], "vcr_zh_easy_100": [68, 70, 129, 131], "vcr_zh_easy_500": [68, 70, 129, 131], "vcr_zh_easy_al": [68, 70, 129, 131], "vcr_zh_hard_100": [68, 70, 129, 131], "vcr_zh_hard_500": [68, 70, 129, 131], "vcr_zh_hard_al": [68, 70, 129, 131], "ve": [37, 96, 110, 157, 241], "ve_exc": 222, "vec": 177, "vector": [177, 181, 204, 214], "venv": [32, 33, 224, 236], "veomni": [0, 29, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44], "veomni_enable_chunk_loss": 33, "veomni_flash_attention_2_with_sp": 41, "veomni_flash_attention_3_with_sp": 41, "veomni_flash_attention_4_with_sp": 41, "verbos": [39, 67, 128, 199], "veri": [28, 44, 45, 50, 111, 121, 155, 163, 164, 219], "verif": [52, 113], "verifi": [37, 38, 39, 43, 44, 51, 52, 96, 109, 112, 113, 131, 157, 164, 170, 201], "verification_info": [51, 112], "verify_model_nam": [88, 149], "verl": [0, 39, 75, 81, 93, 136, 142, 154, 170, 172, 173, 175, 176, 177, 178, 179, 180], "verl_grpo_example_gsm8k": 174, "version": [14, 22, 39, 46, 48, 55, 67, 70, 99, 105, 109, 114, 116, 123, 125, 128, 130, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 147, 148, 150, 152, 157, 158, 160, 161, 162, 166, 172, 174, 175, 176, 178, 179, 180, 181, 185, 187, 193, 194, 197, 200, 206, 209, 210, 219, 233, 236, 249, 252], "vert": 138, "vertic": [121, 127], "vesn": [96, 157], "vf": [67, 92, 128, 153], "via": [37, 40, 53, 87, 97, 110, 114, 116, 117, 121, 122, 126, 127, 128, 136, 137, 138, 142, 144, 147, 148, 149, 153, 158, 160, 166, 172, 219, 221, 237], "viabl": [50, 111], "vicgall": [96, 157], "vicuna": [21, 96, 157], "video": [11, 19, 31, 32, 33, 37, 46, 49, 53, 57, 58, 60, 66, 67, 68, 83, 86, 90, 96, 110, 114, 118, 119, 121, 124, 127, 128, 129, 144, 147, 151, 152, 157], "video_audios_mask": [53, 114], "video_chunk_index": [53, 114], "video_fp": 7, "video_grid_thw": [53, 114], "video_input": [57, 118], "video_kwarg": [57, 118], "video_llm": [58, 70, 119, 131], "video_max_pixel": [7, 53, 58, 67, 90, 114, 119, 128, 151], "video_max_token_num": [57, 103, 118, 164], "video_maxlen": 7, "video_metadata": [57, 118], "video_min_pixel": 7, "video_second_per_grid": [53, 114], "video_seq_length": [53, 114], "video_token_id": [53, 114], "video_token_indic": [53, 114], "videochatgpt": [53, 57, 96, 114, 118, 157], "videoinput": 11, "videos_kwarg": [53, 114], "view": [35, 49, 110, 117, 128, 151, 157, 158, 188, 201, 219], "viewer": [57, 118], "vikhyatk": [96, 157], "villag": 237, "vim": 222, "violat": 142, "virolog": 200, "virtual": [99, 116, 160, 162, 209, 230], "visibl": [39, 57, 67, 70, 90, 118, 128, 131, 152], "vision": [29, 30, 53, 58, 67, 70, 96, 97, 99, 114, 128, 131, 150, 157, 158, 160], "vision_bo": [53, 114], "vision_cap100k": [29, 30], "vision_cap100k_coco": [29, 30], "vision_config": [58, 119], "vision_end": [66, 127], "vision_eo": [53, 114], "vision_process": [53, 114], "vision_start": [66, 127], "vision_tow": [53, 114, 128, 160], "vision_util": [53, 114], "visionconfig": [67, 128], "visit": 125, "visual": [11, 53, 57, 58, 97, 114, 118, 119, 129, 140, 158, 250], "vit": [53, 58, 61, 62, 63, 67, 89, 91, 99, 114, 119, 122, 123, 124, 128, 150, 152, 160, 207, 243], "vit_gradient_checkpoint": [57, 67, 99, 118, 128, 160], "vivo": [96, 157], "vl": [11, 15, 34, 38, 40, 42, 49, 52, 54, 55, 59, 60, 63, 66, 67, 79, 89, 90, 91, 96, 99, 103, 104, 110, 113, 115, 116, 120, 121, 124, 127, 128, 140, 150, 151, 152, 157, 160, 164, 165, 170, 174, 180, 197], "vl2": [63, 67, 70, 96, 124, 128, 131, 157], "vl_agent": [79, 140], "vllm": [20, 21, 22, 36, 39, 50, 51, 52, 53, 56, 57, 58, 63, 64, 68, 69, 71, 79, 86, 88, 89, 90, 91, 99, 100, 101, 103, 111, 112, 113, 114, 117, 118, 119, 124, 125, 129, 130, 132, 140, 147, 149, 150, 151, 152, 160, 161, 162, 164, 170, 172, 173, 175, 176, 178, 179, 180, 201, 209, 220, 222, 250], "vllm0": [64, 70, 105, 125, 131, 166], "vllm_api": 179, "vllm_api_stream_chat": 179, "vllm_ascend": [172, 173], "vllm_ascend_enable_mlp_optim": 178, "vllm_ascend_enable_nz": [178, 180], "vllm_attention_backend": [174, 181], "vllm_config": 7, "vllm_data_parallel_s": [52, 89, 113, 150], "vllm_enable_graph_mod": 178, "vllm_enable_lora": [51, 89, 112, 150], "vllm_enable_v1_multiprocess": 171, "vllm_enforce_eag": [7, 90, 151], "vllm_gpu_memory_util": [56, 58, 70, 71, 86, 89, 90, 117, 119, 131, 132, 147, 151], "vllm_gpu_util": 7, "vllm_infer": [20, 21], "vllm_limit_mm_per_prompt": [58, 67, 70, 90, 119, 128, 131, 151], "vllm_max_lora_rank": [7, 51, 89, 112, 150], "vllm_max_model_len": [56, 58, 63, 70, 71, 86, 90, 117, 119, 124, 131, 132, 147, 151], "vllm_max_num_seq": [90, 151], "vllm_maxlen": 7, "vllm_mode": [50, 51, 52, 89, 99, 100, 111, 112, 113, 150, 160, 161], "vllm_profil": [172, 173], "vllm_server_host": [50, 51, 52, 89, 111, 112, 113, 128, 150], "vllm_server_pass_dataset": [86, 147], "vllm_server_port": [50, 51, 52, 89, 111, 112, 113, 128, 150], "vllm_server_timeout": [89, 150], "vllm_strategi": 222, "vllm_tag": 230, "vllm_target_devic": [174, 221, 230], "vllm_tensor_parallel_s": [56, 70, 79, 88, 89, 90, 117, 131, 140, 149, 150, 151], "vllm_use_v1": [70, 131, 178, 180, 181], "vllmcustomapichatstream": 179, "vllmengin": [90, 91, 151, 152], "vlm": [0, 39, 45, 46, 231], "vlmeval": [70, 131], "vlmevalkit": [58, 67, 68, 119, 128, 129], "vlms": [0, 196], "vocab": [181, 184, 194, 219], "vocab_on": 194, "vocab_s": [58, 119, 194], "vocabparallelembed": [98, 159], "vocabulari": [80, 141], "void": 204, "volcengin": [75, 81, 136, 142, 174, 175], "volum": [38, 48, 109, 172, 230], "volumemount": [48, 109], "vp": [99, 160], "vpp": [63, 99, 101, 103, 124, 160, 162, 164], "vqa": [91, 96, 152, 157, 180, 243], "vqa_train": [96, 157], "vqaflickr8k": [96, 157], "vqaocr": [96, 157], "vqast": [96, 157], "vqav2": [96, 157], "vram": [7, 67, 117, 128], "vs": [9, 40, 59, 120], "vsft": [96, 157], "vstar": [79, 140], "vsx": [194, 256], "vx": [53, 56, 57, 63, 69, 91, 102, 103, 104, 105, 114, 117, 118, 124, 130, 152, 163, 164, 165, 166], "w1": 214, "w2": 214, "w4a16": 197, "wait": [45, 73, 80, 88, 98, 128, 134, 141, 149, 152, 159, 160, 172, 173, 177, 179, 180, 181, 231, 241], "wait_for_everyon": 219, "wake_up": [70, 131], "wall_clock_breakdown": [48, 109, 188, 219], "wan": 31, "wan2": 34, "wan_sft": 31, "wandb": [7, 8, 42, 50, 51, 52, 67, 89, 99, 111, 112, 113, 128, 150, 160, 178, 219, 222], "wandb_api_key": [7, 50, 51, 52, 67, 99, 111, 112, 113, 128, 160], "wandb_arg": 199, "wandb_dis": 7, "wandb_info": 219, "wandb_nam": 43, "wandb_project": [7, 43, 67, 128], "wandb_run_url": 219, "wander": 237, "wangrui6": [96, 157], "want": [35, 43, 46, 51, 56, 112, 114, 116, 117, 121, 124, 128, 132, 142, 147, 150, 151, 152, 153, 160, 163, 164, 172, 219, 245], "wari": 237, "warm": [43, 57, 118, 160], "warm_up": 191, "warmth": [57, 118], "warmup": [42, 43, 50, 67, 98, 99, 111, 128, 159, 160, 172, 173, 207, 219, 234], "warmup_max_lr": [188, 219], "warmup_min_lr": [188, 219], "warmup_num_step": [188, 219], "warmup_ratio": [8, 17, 24, 48, 50, 51, 52, 53, 56, 57, 58, 63, 70, 109, 111, 112, 113, 114, 117, 118, 119, 124, 131], "warmup_step": [24, 222], "warmuplr": [188, 219], "warn": [7, 44, 62, 67, 96, 123, 128, 157, 184, 199, 219, 228, 237], "warranti": 219, "was": [44, 46, 70, 111, 128, 144, 147, 164, 219, 237, 241], "wasm_simd": [194, 256], "wasn": [50, 111], "wast": 128, "watch": 241, "wav": [60, 121, 253, 256], "wav_id": 253, "wav_path": 253, "way": [35, 50, 51, 57, 111, 112, 118, 138, 147, 148, 149, 150, 219], "wb": [53, 114], "wd": [99, 160, 207], "wds_voc2007_multilabel": [96, 157], "we": [31, 32, 35, 36, 38, 39, 40, 45, 46, 47, 50, 52, 53, 60, 83, 86, 111, 113, 114, 116, 117, 118, 119, 121, 122, 123, 128, 129, 130, 132, 133, 134, 137, 138, 140, 142, 144, 146, 147, 149, 150, 151, 152, 154, 155, 157, 159, 160, 163, 164, 165, 166, 172, 188, 219], "wear": [57, 90, 118, 151, 225], "weather": [56, 66, 117, 121, 127, 144], "web": [7, 8, 59, 63, 64, 120, 124, 125, 194], "webchat": 21, "webhook": [67, 128], "webinstructsub": [96, 157], "webnovel_cn": [96, 157], "websit": [125, 193, 194], "webui": [0, 7, 12, 13, 22, 225], "wechat": 201, "weight": [7, 12, 18, 29, 35, 36, 37, 38, 39, 42, 43, 46, 67, 73, 88, 89, 92, 97, 99, 111, 114, 117, 118, 123, 124, 127, 128, 134, 136, 137, 145, 152, 153, 158, 160, 163, 164, 165, 166, 179, 180, 184, 214, 219, 234, 244], "weight1": 214, "weight2": 214, "weight3": 214, "weight_col": 214, "weight_decay": [43, 97, 158, 188, 214, 219, 222], "weight_dtyp": 219, "weight_hidden": 214, "weight_i": 214, "weight_input": 214, "weight_int4": 214, "weight_vers": 231, "weights_path": [36, 43], "welcom": [56, 117], "well": [50, 57, 110, 111, 112, 118, 121, 124, 128, 129, 131, 148, 150, 219], "wenet": 0, "wer": 253, "were": [39, 111, 113, 128, 142, 150, 184, 237, 244], "west": [64, 105, 125, 166], "wget": [22, 179, 224, 230, 236], "wh_ratio_clip": 214, "what": [37, 39, 52, 56, 57, 66, 83, 85, 86, 110, 113, 117, 118, 121, 127, 129, 144, 146, 147, 151, 152, 191, 219, 231, 243, 246, 256], "wheel": [22, 187, 206, 209, 230, 233, 236], "when": [35, 37, 38, 39, 41, 42, 43, 45, 46, 62, 81, 110, 113, 114, 116, 117, 118, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 145, 147, 148, 149, 150, 151, 152, 153, 158, 159, 160, 161, 164, 166, 172, 188, 214, 219, 241], "where": [11, 28, 34, 35, 38, 43, 45, 56, 80, 110, 113, 114, 116, 117, 118, 121, 122, 123, 127, 128, 129, 132, 133, 134, 136, 137, 138, 139, 141, 142, 145, 147, 150, 151, 152, 153, 154, 160, 219, 237, 241], "wherea": [121, 127], "whether": [42, 59, 114, 116, 120, 121, 122, 123, 128, 129, 132, 141, 144, 147, 148, 153, 157, 158, 160, 163, 172, 219], "whi": [111, 124, 129, 138, 150], "which": [28, 35, 37, 38, 39, 42, 43, 46, 50, 51, 52, 56, 57, 89, 110, 111, 112, 113, 114, 117, 118, 120, 121, 122, 123, 126, 127, 128, 129, 130, 135, 136, 139, 140, 141, 143, 144, 146, 148, 149, 150, 152, 153, 154, 155, 156, 157, 158, 160, 164, 166, 172, 191, 204, 219, 249], "whichev": 114, "while": [35, 38, 40, 46, 57, 98, 111, 113, 114, 117, 118, 119, 121, 123, 128, 129, 134, 135, 139, 142, 143, 151, 152, 159, 160, 166, 179, 180, 181, 184, 237], "whisker": [57, 118], "whisper": [0, 96, 157], "whisper_backend_init_gpu": 256, "whisper_init_from_file_with_params_no_st": 256, "whisper_init_st": 256, "whisper_init_with_params_no_st": 256, "whisper_model_load": 256, "whisper_print_tim": 256, "white": [52, 57, 113, 118, 151], "whiten": [67, 92, 128, 153], "whiten_advantag": 222, "whitespac": [50, 111], "whl": [14, 22, 70, 131, 174, 221, 224, 230], "who": [21, 39, 56, 57, 90, 91, 105, 117, 118, 121, 151, 152, 166, 237, 241, 246], "whole": [38, 50, 111, 147, 219], "whom": 237, "whose": [38, 40, 128, 234], "wic": [68, 70, 129, 131], "wide": [56, 57, 117, 118, 124, 128, 160], "width": [11, 46, 53, 114, 121, 225], "wikipedia": [96, 157], "wildcard": 128, "will": [36, 38, 39, 42, 43, 44, 45, 46, 47, 50, 51, 67, 83, 86, 109, 110, 111, 112, 113, 114, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 130, 134, 140, 142, 144, 146, 147, 148, 149, 150, 151, 152, 153, 156, 158, 160, 161, 162, 163, 164, 166, 172, 187, 188, 219, 237, 241, 243, 249], "win": 120, "win_amd64": 22, "window": [67, 128, 177, 188, 219], "winogrand": [68, 70, 129, 131], "winterschool": [96, 157], "wip": 237, "wise": [7, 16, 18, 72, 133], "wish": [121, 148], "with": [0, 3, 5, 11, 29, 30, 36, 37, 38, 39, 41, 42, 43, 45, 46, 50, 51, 52, 53, 56, 57, 66, 67, 70, 83, 86, 87, 90, 97, 98, 103, 110, 111, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 132, 134, 135, 136, 138, 139, 141, 142, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 170, 172, 173, 179, 180, 181, 184, 188, 194, 201, 204, 207, 209, 213, 214, 219, 230, 237, 243, 246, 250], "with_caroten": 212, "with_debug": 212, "with_ipp": 212, "with_modul": [172, 173], "with_offset": 214, "with_stack": [43, 98, 159], "with_transform": 219, "within": [38, 39, 45, 66, 83, 86, 87, 110, 117, 121, 127, 128, 135, 136, 137, 140, 141, 144, 146, 147, 148, 149, 150, 160, 165, 166, 172], "without": [35, 39, 41, 42, 43, 44, 46, 110, 114, 117, 122, 123, 128, 140, 142, 152, 155, 156, 158, 160, 163, 164, 166, 172, 219, 245], "wizard": [96, 157, 241], "wizardlm": [96, 157], "wizardlm2": [96, 157], "wizardlm_evol_instruct_v2_196k": [96, 157], "woman": 121, "won": 131, "wood": 237, "wool": 151, "word": [35, 51, 61, 67, 112, 122, 123, 126, 128, 141, 148, 160, 210, 243], "word_embed": [98, 99, 159, 160], "wordschartqacoinstructcontrastive_captiondocvqadreamsimdvqaiconqaimagecodellava_665k_multilrv_multimulti_vqanextqanlvr2spot": [96, 157], "work": [31, 37, 38, 43, 46, 50, 111, 117, 118, 128, 155, 160, 179, 197, 219, 241], "work_dir": [58, 70, 119, 131, 197], "workaround": [70, 118, 131, 219], "worker": [9, 42, 43, 48, 67, 93, 99, 109, 128, 154, 160, 172, 173, 174, 207], "worker_v1": [172, 173], "workerbas": [172, 173], "workflow": [119, 124, 147, 155, 170], "workload": 249, "worksiz": 214, "workspac": [67, 128], "world": [31, 35, 37, 48, 67, 99, 109, 129, 131, 160, 188, 219], "world_religion": 200, "world_siz": [56, 58, 67, 101, 117, 119, 128, 162, 214, 215], "wors": 160, "worth": 44, "wosyn": [96, 157], "would": [35, 39, 50, 70, 111, 128, 154, 219, 237], "wouldn": [50, 111], "wrap": [46, 70, 123, 131], "wrapper": [41, 126], "write": [37, 39, 53, 56, 62, 67, 85, 114, 117, 122, 123, 128, 146, 160, 219, 237], "write_batch_s": [56, 71, 117, 132], "write_out": 199, "write_t": 27, "writer": 219, "written": [121, 127, 128, 132, 160, 219], "wrong": [67, 87, 128, 148, 249], "wsc": [68, 70, 129, 131], "wsd": [99, 160], "www": [9, 14, 49, 70, 110, 131, 175, 181, 219], "wxwork": [67, 128], "wyj123456": [96, 157], "x0": 214, "x1": 214, "x1_shape": 214, "x2": [214, 243], "x2_notranspose_29": 214, "x2_shape": 214, "x3": 214, "x6agfqsjhkhrulu8efso5qde8kriptk5rgh9olrtmeas3sid": 245, "x86": [14, 174, 185, 218], "x86_64": [22, 181], "x_0": 219, "x_i": 214, "x_new": 214, "x_npu": 214, "x_tensor": 214, "xavier": 67, "xavier_norm": 128, "xavier_uniform": 128, "xcomposer2": [67, 96, 128, 157], "xcomposer2d5": [96, 157], "xdist": 230, "xformer": [174, 181, 219, 224], "xformers_vers": 219, "xi": 214, "xiao": [35, 46, 67, 91, 128, 152], "xiaomimimo": [96, 157], "xj": 214, "xl": 3, "xla_spawn": 219, "xlam": [96, 157], "xml": [66, 127], "xsum": [68, 70, 129, 131], "xtensor": 214, "xtuner": [96, 157], "xvers": [96, 157], "xvf": 181, "xw1": 214, "xx": [55, 116], "xxx": [48, 51, 53, 55, 56, 57, 58, 60, 61, 62, 63, 65, 67, 69, 83, 85, 89, 91, 93, 102, 103, 104, 105, 109, 112, 114, 116, 117, 118, 119, 121, 122, 123, 124, 126, 128, 130, 144, 146, 150, 152, 154, 163, 164, 165, 166, 170, 177, 185, 212, 219], "xxxx": [83, 144], "xxxxx": [70, 131], "xxxxxx": [88, 149], "xywh": 214, "xywht": 214, "xyxi": 214, "xyxyt": 214, "y0": 214, "y1": 214, "y2": 214, "y_gelu_npu": 214, "y_ground_truth": [71, 132], "y_i": 214, "y_npu": 214, "yahma": [96, 157], "yali": 222, "yaml": [8, 9, 15, 18, 20, 21, 23, 24, 27, 28, 30, 31, 37, 38, 43, 47, 93, 154, 172, 173, 178, 222], "yarn": [7, 67, 128], "ydshieh": 243, "yeah": [56, 117], "year": 241, "yell": 241, "yellow": [52, 237], "yelp": 241, "yelp_review_ful": 241, "yentinglin": 178, "yes": [44, 59, 120, 131], "yet": [31, 70, 114, 131, 140, 155, 160, 201, 241], "yeungnlp": [96, 157], "yi": [6, 96, 157], "yi1": [96, 157], "yield": [98, 130, 159, 219], "yifan": [35, 46], "yingru": [81, 142], "yml": [14, 47, 170], "yorickh": [96, 157], "you": [7, 21, 31, 32, 33, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 48, 50, 51, 53, 56, 57, 60, 61, 63, 66, 70, 88, 90, 91, 102, 105, 109, 110, 111, 112, 113, 114, 116, 117, 118, 121, 122, 123, 124, 125, 126, 127, 128, 130, 132, 136, 138, 140, 141, 142, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 166, 172, 175, 184, 188, 197, 214, 219, 222, 228, 230, 244, 245, 246, 249, 256], "youcook2": 29, "young": [57, 118, 237], "your": [33, 35, 38, 39, 42, 45, 47, 48, 50, 51, 53, 56, 57, 62, 63, 70, 91, 109, 111, 112, 114, 117, 118, 120, 121, 123, 124, 128, 130, 131, 143, 147, 149, 151, 152, 153, 154, 160, 175, 179, 180, 181, 187, 194, 207, 219, 239, 245, 246, 249, 256], "your_api_key": [95, 156], "your_custom_model": 36, "your_data_path": 38, "your_dataset": 170, "your_env_nam": [233, 244], "your_experiment_nam": 43, "your_job_nam": 170, "your_local_megatron_lm_path": [55, 116], "your_model_path": 38, "your_path": [70, 131], "your_path_to_dataset": 43, "your_path_to_model": 43, "your_path_to_save_checkpoint": 43, "your_program": 9, "your_project_nam": 43, "your_script": 170, "your_task": 43, "your_test_script": 170, "your_transform_funct": 43, "your_wandb_api_key": [52, 113], "your_wandb_key": [50, 111], "your_yml_ascend": 170, "yourcustomconfig": 36, "yourcustommodel": 36, "yourself": [110, 121, 131], "youtu": [96, 157], "youtub": [96, 157], "yu": [35, 46], "yuan": [96, 157], "yuan2": [96, 157], "yukang": [96, 157], "yum": [33, 181, 185], "yys": [96, 157], "yyyi": 19, "z1": [96, 157], "zai": [96, 157], "zephyr": [96, 157, 243], "zero": [28, 38, 46, 66, 67, 75, 89, 96, 101, 127, 128, 135, 136, 147, 150, 153, 157, 160, 162, 166, 188, 214, 219, 221], "zero0": [67, 128], "zero1": [9, 48, 67, 99, 105, 109, 128], "zero2": [9, 51, 53, 55, 56, 57, 58, 63, 67, 70, 91, 105, 112, 114, 116, 117, 118, 119, 124, 128, 131, 152, 166], "zero2_offload": 128, "zero3": [9, 18, 42, 43, 50, 52, 53, 55, 56, 63, 67, 87, 89, 91, 105, 111, 113, 114, 116, 117, 124, 128, 148, 150, 152, 166], "zero3_init_context_manag": 219, "zero3_init_flag": 9, "zero3_offload": 128, "zero_allow_untested_optim": 9, "zero_grad": [43, 89, 150, 219], "zero_optim": [9, 48, 109, 188, 219], "zero_stag": 9, "zeros_lik": [46, 214], "zeroshot": 207, "zh": [7, 20, 53, 56, 57, 63, 65, 67, 68, 90, 91, 95, 96, 98, 102, 105, 114, 117, 118, 124, 126, 128, 129, 151, 152, 156, 157, 159, 163, 166, 175, 177, 181, 250], "zh_cls_fudan": [96, 157], "zh_ner": [96, 157], "zhcommon": [96, 157], "zhejiang": [56, 117, 118, 121, 151, 152], "zhelun": 46, "zhihu": [96, 157], "zhihu_rlhf_3k": [96, 157], "zhipuai": [66, 96, 127, 157], "zhiwen": [96, 157], "zhong": [35, 46], "zhunknow": [96, 157], "zip": [50, 52, 57, 62, 70, 85, 88, 111, 113, 118, 123, 131, 146, 149, 179, 219, 224, 231], "ziya": [96, 157], "ziya2": [96, 157], "zoo": [0, 204], "zoom": [79, 140], "zouxuhong": [50, 96, 111, 157], "zsh": 224, "zxbsmk": [96, 157], "zyang39": [96, 157], "zzliang": [96, 157]}, "titles": ["\u6607\u817e\u5f00\u6e90\u6587\u6863\u4e2d\u5fc3", "Diffusers", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "LLaMA-Factory", "VeOmni", "\u52a0\u901f", "\u53c2\u6570\u4ecb\u7ecd", "GPT-OSS", "\u5206\u5e03\u8bad\u7ec3", "\u989d\u5916\u9009\u9879", "\u6a21\u578b\u652f\u6301", "\u5b9e\u9a8c\u76d1\u63a7", "NPU\u63a8\u7406", "NPU\u5b89\u88c5\u53ca\u914d\u7f6e", "NPU\u8bad\u7ec3", "\u91cf\u5316", "\u8bad\u7ec3\u65b9\u6cd5", "\u8c03\u4f18\u7b97\u6cd5", "\u6570\u636e\u5904\u7406", "\u8bc4\u4f30", "\u63a8\u7406", "\u5b89\u88c5", "LoRA \u5408\u5e76", "SFT \u8bad\u7ec3", "WebUI", "VeOmni documents", "Qwen3 training guide", "Qwen3 MoE training guide", "Qwen3 Omni MoE training guide", "Qwen3 VL training guide", "Wan2.1-I2V training guide", "Installation with Nvidia GPU", "Installation with Ascend NPU", "Get Started with Ascend NPU", "EP+FSDP2 for Large-scale MoE Model Training", "Adding a New Model to VeOmni", "Custom Preprocessor Registry", "Long-Sequence Training Using Ulysses", "Modeling Code Generation", "Transformers v5 MoE Weight Loading", "VeOmni Flash Attention Custom Name Adapter (Transformers 5.x)", "Arguments API Reference", "Basic Modules", "Checkpoint Conversion", "Usage of rmpad_with_pos_ids and dyn_bsz", "Support New Models", "maintain docs", "Elastic", "Embedding\u8bad\u7ec3", "GRPO\u5b8c\u6574\u5b9e\u9a8c\u6d41\u7a0b", "GRPO\u4ee3\u7801\u8bad\u7ec3", "\u591a\u6a21\u6001GRPO\u5b8c\u6574\u5b9e\u9a8c\u6d41\u7a0b", "\u6ce8\u518c\u591a\u6a21\u6001\u6a21\u578b\u6700\u4f73\u5b9e\u8df5", "\u66f4\u591a\u6700\u4f73\u5b9e\u8df5", "NPU\u652f\u6301", "Qwen3\u6700\u4f73\u5b9e\u8df5", "Qwen3-VL\u6700\u4f73\u5b9e\u8df5", "\u5feb\u901f\u8bad\u7ec3VL\u6a21\u578b", "Reranker\u8bad\u7ec3", "\u81ea\u5b9a\u4e49\u6570\u636e\u96c6", "\u81ea\u5b9a\u4e49\u6a21\u578b", "\u63d2\u4ef6\u5316", "\u5feb\u901f\u5f00\u59cb", "SWIFT\u5b89\u88c5", "Web-UI", "Agent\u652f\u6301", "\u547d\u4ee4\u884c\u53c2\u6570", "\u8bc4\u6d4b", "\u5bfc\u51fa\u4e0e\u63a8\u9001", "\u5e38\u89c1\u95ee\u9898\u6574\u7406", "GKD", "On-Policy RL Meets Off-Policy Experts: Harmonizing SFT and RL via Dynamic Weighting (CHORD)", "Clipped Importance Sampling Policy Optimization (CISPO)", "DAPO: An Open-Source LLM Reinforcement Learning System at Scale", "Group Sequence Policy Optimization", "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models", "REINFORCE Leave-One-Out (RLOO)", "Soft Adaptive Policy Optimization (SAPO)", "DeepEyes: Incentivizing &quot;Thinking with Images&quot; via Reinforcement Learning", "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning", "Training-Inference-Mismatch", "TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling", "GYM\u73af\u5883\u8bad\u7ec3", "Loss Types", "\u591a\u4efb\u52a1\u8bad\u7ec3", "\u591a\u8f6e\u8bad\u7ec3", "\u5956\u52b1\u51fd\u6570", "\u5956\u52b1\u6a21\u578b", "GRPO", "\u63a8\u7406\u548c\u90e8\u7f72", "\u9884\u8bad\u7ec3\u4e0e\u5fae\u8c03", "\u4eba\u7c7b\u5bf9\u9f50", "ray\u7684\u652f\u6301", "\u5f3a\u5316\u5fae\u8c03", "\u91c7\u6837", "\u652f\u6301\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6", "\u4f7f\u7528Tuners", "Ascend NPU", "\u547d\u4ee4\u884c\u53c2\u6570", "GKD", "GRPO", "LoRA\u8bad\u7ec3", "Mcore Bridge", "\u591a\u6a21\u6001\u6a21\u578b", "\u5feb\u901f\u5f00\u59cb", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Elastic", "Embedding Training", "Complete GRPO Experiment Process", "Code Training with GRPO", "Complete Multimodal GRPO Experiment Workflow", "Best Practices for Registering Multimodal Models", "More Best Practices", "NPU Support", "Qwen3 Best Practices", "Qwen3-VL Best Practices", "Best Practices for Rapidly Training Vision-Language (VL) Models", "Reranker Training", "Custom Dataset", "Custom Model", "Pluginization", "Quick Start", "SWIFT Installation", "Web-UI", "Agent Support", "Command Line Parameters", "Evaluation", "Export and Push", "Frequently-asked-questions", "GKD", "On-Policy RL Meets Off-Policy Experts: Harmonizing SFT and RL via Dynamic Weighting (CHORD)", "Clipped Importance Sampling Policy Optimization (CISPO)", "DAPO: An Open-Source LLM Reinforcement Learning System at Scale", "Group Sequence Policy Optimization (GSPO)", "REINFORCE++: An Efficient RLHF Algorithm with Robustness to Both Prompt and Reward Models", "REINFORCE Leave-One-Out (RLOO)", "Soft Adaptive Policy Optimization (SAPO)", "DeepEyes: Incentivizing &quot;Thinking with Images&quot; via Reinforcement Learning", "Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning", "Training-Inference-Mismatch", "TreePO: Bridging the Gap of Policy Optimization and Efficacy and Inference Efficiency with Heuristic Tree-based Modeling", "GYM Environment Training", "Loss Types", "Multi-Task Training", "Multi-turn Training", "Reward Function", "Reward Model", "GRPO", "Inference and Deployment", "Pre-training and Fine-tuning", "RLHF", "Ray Support", "Reinforced Fine-Tuning", "Sampling", "Supported Models and Datasets", "Using Tuners", "Ascend NPU", "Command Line Arguments", "GKD", "Megatron GRPO", "LoRA Training", "Mcore Bridge", "Multimodal Models", "Quick Start", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "NPU-CI \u6dfb\u52a0\u6307\u5bfc", "Align the Inference results of the verl and vLLM frameworks on Ascend devices(zh)", "Performance data collection based on FSDP or MindSpeed(Megatron) on Ascend devices(en)", "Performance data collection based on FSDP or MindSpeed(Megatron) on Ascend devices(zh)", "Ascend Quickstart", "Ascend Quickstart with SGLang Backend", "Ascend Dockerfile Build Guidance", "\u80cc\u666f\u4ecb\u7ecd", "Ascend Retool Best Practice", "Ascend SGLang Best Practice", "DAPO multi model optimization practice", "NPU Qwen3-32B GSPO Optimization Practice", "Accelerate", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "\u5feb\u901f\u5b89\u88c5\u6607\u817e\u73af\u5883", "DeepSpeed", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "kernels", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u4f7f\u7528", "Llama.cpp", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "LMDeploy", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "LM-Evalution-Harness", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "ms-swift", "ONNX Runtime", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "open_clip", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "OpenCompass", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "OpenCV", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "API \u6587\u6863", "\u529f\u80fd\u6837\u4f8b", "FAQ", "PyTorch", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "ROLL", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb\uff0c\u5355\u8282\u70b9\u90e8\u7f72\u6307\u5f15", "Stable-Diffusion-WebUI", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "Sentence Transformers", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "SGLang", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "timm", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "Torchchat", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "TorchTitan", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b", "Transformers", "\u63a8\u7406", "\u5b89\u88c5\u6307\u5357", "\u6a21\u578b\u83b7\u53d6", "\u5feb\u901f\u5f00\u59cb", "Transformer Reinforcement Learning", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "verl", "WeNet", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb", "Whisper.cpp", "\u5b89\u88c5\u6307\u5357", "\u5feb\u901f\u5f00\u59cb"], "titleterms": {"00000": [70, 131], "10": [70, 131], "100": 131, "100step": 70, "1024": 131, "1024token": 70, "11": [70, 131], "11111": [70, 131], "12": [70, 131], "12000": [70, 131], "128": [70, 131], "14b": [70, 131], "16b": [70, 131], "178k": 29, "18": [70, 131], "18145": [70, 131], "1b": [70, 131], "20": [70, 80, 131, 141], "22222": [70, 131], "260": [70, 131], "2b": [70, 131], "30": [56, 70, 117, 131], "30b": [27, 30, 70, 131, 179], "32768": [70, 131], "32b": [179, 181], "35": [70, 131], "42": [70, 131], "44": 8, "50": 131, "500": [70, 131], "5000": [70, 131], "50step": 70, "5b": [70, 131], "5vl": [70, 131], "628": [70, 131], "671b": [70, 131], "6b": [70, 131], "72b": [70, 131], "7b": [70, 131, 178], "80": [70, 80, 131, 141], "8b": [27, 30, 70, 131], "9000": [70, 131], "9b": [70, 131], "9c": [70, 131], "9e": [70, 131], "__init__": 46, "a10": [70, 131], "a100": [70, 131], "a3b": [70, 131], "about": 131, "acc": [70, 131], "acceler": [9, 131, 132, 150, 182, 183], "access": [131, 147], "accord": 131, "accumul": 131, "accuraci": [87, 131, 148, 159, 164], "accuracy_orm": [70, 131], "acknowledg": [35, 46], "aclgraph": 181, "across": 131, "action_preprocessor": [70, 131], "activ": [70, 131], "actor": [172, 173], "adalora": [67, 128], "adap": 70, "adapt": [41, 70, 78, 131, 139], "adaptor": 230, "add": [36, 39, 46, 131], "addit": [46, 147], "adjust": 131, "advanc": [37, 39, 44, 110, 120, 147, 172], "advantag": 138, "ae": [70, 131], "after": [110, 131, 142], "agent": [60, 62, 66, 121, 123, 127, 222], "aicpu": 181, "aim": [70, 131], "aiv": 181, "algorithm": [76, 116, 133, 134, 137, 138, 150], "align": [40, 58, 70, 114, 119, 131, 171], "all": [70, 131], "all_to_al": 38, "alloc": [70, 131], "alpaca": 19, "alreadi": 131, "also": [44, 131], "alway": 131, "am": 131, "amp": [70, 131], "an": [70, 74, 76, 131, 135, 137], "analysi": 38, "and": [39, 43, 45, 46, 72, 76, 82, 111, 113, 119, 129, 130, 131, 132, 133, 137, 139, 143, 151, 152, 156, 157, 164, 171, 172], "ani": 131, "anoth": 131, "answer": [70, 129, 131], "anyon": 131, "apex": [70, 131], "api": [21, 37, 38, 42, 70, 131, 214], "apollo": 7, "apolloargu": 7, "app": [67, 70, 128, 131], "appear": 131, "append": 131, "appli": [131, 138], "approach": [39, 46], "aqlm": 16, "arc": [70, 131], "architectur": 37, "are": [70, 131], "argument": [42, 43, 44, 70, 128, 131, 160], "around": 131, "as": 131, "ascend": [13, 33, 34, 55, 98, 116, 159, 171, 172, 173, 174, 175, 176, 178, 179, 221, 230], "ask": 131, "assert": [70, 131], "asset": 44, "assist": [70, 131], "assumpt": 142, "async": [38, 89, 148, 150], "asynchron": 38, "at": [74, 111, 131, 135], "atom": 128, "attempt": [70, 131], "attent": [41, 46, 70, 131], "attention_mask": [70, 131], "attribut": [70, 131], "attributeerror": [70, 131], "audio": [70, 131], "augment": 131, "automat": 131, "automodelforcausallm": 246, "autotp": 9, "aux": 70, "aux_loss": 131, "aux_loss_coef": 131, "avail": [70, 131], "avoid": 131, "awar": 117, "awq": [16, 70, 131], "b3": [70, 131], "b5": [70, 131], "b7": [70, 131], "backend": [131, 175], "background": [39, 40, 41, 45, 81, 139, 142, 172], "backpropag": 131, "badam": [7, 18], "badamargu": [7, 18], "bare": 131, "base": [70, 82, 128, 131, 143, 172, 173], "base64": [70, 131], "baselin": [131, 138], "basic": [43, 44, 142], "batch": [70, 84, 131, 133, 145, 161], "batch_siz": 70, "bd": [70, 131], "be": [70, 131], "becaus": [70, 131], "becom": 131, "befor": [110, 131], "behavior": 41, "being": 131, "below": 131, "benchmark": [70, 105, 131, 166], "benefit": 38, "besid": 131, "best": [37, 114, 115, 117, 118, 119, 131, 140, 144, 178, 179], "better": 46, "between": 131, "beyond": [80, 141], "bf16": [70, 131], "bfloat16": [70, 131], "big": 131, "bitsandbyt": 16, "block": 131, "bnpo": [84, 145], "bodi": 70, "boft": [67, 128], "both": [76, 131, 137], "bottom": 35, "bound": [131, 177], "box": 131, "bridg": [82, 102, 103, 105, 143, 163, 164, 166], "browser": 26, "bs": 70, "bsz": 181, "bug": [70, 131], "build": [14, 26, 176], "buildingconfig": [70, 131], "built": [131, 148], "but": [70, 131], "by": 131, "cach": [70, 131], "calcul": 131, "calibr": 131, "call": 131, "callback": [62, 123], "can": 131, "cann": [14, 33, 197], "cannot": [70, 131], "capabl": [129, 156], "card": [116, 131], "case": [46, 132], "categori": 131, "caus": 131, "certain": 131, "chain": 131, "challeng": [46, 172], "chang": 131, "channel": [60, 121], "channel_loss": [70, 131], "chaotic": 131, "charact": 131, "chat": [43, 70, 131], "chat_templ": [70, 131], "check": 131, "check_dataset_strategi": [70, 131], "checkpoint": [35, 44, 70, 131], "chi": [81, 142], "choic": 129, "choos": 131, "chord": [72, 133], "ci": 170, "cispo": [73, 84, 134, 145], "ckpt": 70, "ckpt_dir": [70, 131], "class": [39, 131, 158], "classif": [120, 121, 131], "clevrcount": [52, 113], "cli": [9, 39, 90, 91, 151, 152], "client": [70, 131, 151, 152], "clip": [70, 73, 74, 131, 134, 135], "clone": [70, 131], "cluster": 150, "cmvn": 253, "cn": [70, 131], "coco2017": 29, "code": [39, 112, 125, 131, 159, 164], "coef": 70, "collat": 43, "collect": [159, 172, 173], "coloc": [70, 89, 131, 150], "column": [70, 131], "command": [44, 128, 131, 160], "common": 39, "communic": 38, "compar": [39, 131], "comparison": [131, 162], "compat": 131, "complet": [70, 111, 113, 131], "compon": 131, "compos": 14, "comput": 131, "compute_log_prob": [172, 173], "concept": 155, "concern": 131, "conda": 224, "condit": 37, "conduct": 131, "config": [37, 44, 58, 119], "configur": [35, 36, 39, 42, 109, 131, 133, 134, 137, 138, 172], "conflict": 131, "connect": 46, "consequ": 35, "consist": 131, "construct": [131, 138], "contain": [70, 131], "content": [36, 38, 70, 131], "continu": 131, "contrast": [49, 110, 131], "contribut": [39, 131], "control": [131, 142, 156, 172], "conv_preprocess": 37, "conveni": 37, "convers": [37, 44, 164], "convert": [44, 131, 163], "coordin": 131, "core": [38, 39], "correct": [35, 131, 142], "correspond": 131, "cosin": [87, 110, 148], "cosine_similar": 49, "cot": [70, 131], "could": [70, 131], "cp": 38, "cpo": [60, 92, 121, 153], "cpp": [192, 193, 254, 255], "cpu": [46, 70, 131], "cpu_affinity_conf": 34, "crash": 131, "creat": [36, 39, 70, 131], "critic": [172, 173], "ctrl": [70, 131], "cuda": 22, "cuda_visible_devic": [70, 131], "curl": [70, 131], "current": [116, 131, 161], "curv": 131, "custom": [37, 41, 43, 44, 121, 122, 123, 129, 131, 148, 149, 156], "customis": 147, "custompreprocessor": [70, 131], "dapo": [70, 74, 84, 131, 135, 145, 180], "data": [42, 43, 44, 116, 117, 128, 131, 133, 143, 147, 159, 172, 173], "dataargu": 7, "dataload": 43, "dataset": [27, 29, 30, 31, 43, 70, 110, 111, 113, 120, 121, 127, 129, 131, 147, 153, 157], "dataset_info": [60, 70, 121, 131], "dcp": [35, 44], "ddp": [70, 131, 215], "debug": [70, 131], "declar": 34, "decreas": 131, "deep": [131, 230], "deepey": [79, 140], "deepseek": [70, 131], "deepseek_vl2": [70, 131], "deepspe": [9, 38, 55, 70, 116, 131, 186, 187, 188, 219], "deepstack": 46, "default": [70, 131], "defin": [37, 39, 46, 131], "definit": [70, 111, 113, 131], "delet": 131, "dens": [57, 70, 103, 104, 118, 131, 164, 165], "deoloy": 119, "depend": [22, 109], "deploy": [70, 116, 119, 127, 128, 131, 149, 151, 152], "descript": 137, "deseri": [70, 131], "design": [35, 39, 41], "detail": [35, 44, 134, 140, 143, 154], "detect": 131, "deviat": 142, "devic": [131, 171, 172, 173], "diagnost": 142, "did": [70, 131], "didn": 131, "differ": [111, 131, 137, 138], "diffus": [1, 2, 219, 223, 224], "dimens": 35, "direct": 131, "directori": [44, 131], "disabl": [131, 172], "disappear": 131, "discard": [70, 131], "disconnect": 131, "discrep": 131, "discret": 172, "display": 131, "dist": [70, 131], "distil": [71, 131, 132], "distinguish": 131, "distribut": [35, 131], "dive": 38, "diverg": [71, 81, 132, 137, 142], "do": 131, "do_sampl": [70, 131], "doc": [26, 47, 131], "docker": [14, 175, 230], "dockerfil": [174, 176], "document": [26, 131], "doe": 131, "doesn": 131, "doing": 131, "don": 131, "done": 131, "dora": 18, "down": 131, "download": [27, 29, 30, 31, 131], "dpo": [15, 17, 60, 70, 92, 99, 121, 131, 153, 160], "dr": [84, 145], "drive": [80, 141], "driver": 197, "drop": 131, "dummi": 46, "duplic": 37, "dure": [129, 131], "dyn_bsz": 45, "dynam": [72, 74, 131, 133, 135], "e2b": 51, "e4": [70, 131], "e5": [70, 131], "e6": [70, 131], "e8": [70, 131], "each": 131, "eetq": 16, "effect": [80, 81, 131, 141, 142], "efficaci": [82, 143], "effici": [44, 76, 82, 137, 143], "either": [70, 131], "elast": [48, 109], "element": [70, 131], "embed": [46, 49, 60, 70, 110, 121, 131], "embed_token": [70, 131], "empti": 131, "en": 172, "enabl": [38, 46, 131, 142, 159], "encod": [70, 131], "encount": 131, "end": [37, 131, 172], "engin": [70, 131], "english": 131, "ensur": 131, "entri": 131, "entropi": [80, 131, 141], "environ": [7, 32, 33, 34, 114, 116, 117, 118, 125, 128, 129, 131, 144, 152, 156, 166], "ep": [35, 46, 230], "epoch": [70, 131], "error": [37, 70, 131], "ess": [81, 142], "etc": 131, "eval": [70, 131], "eval_backend": [70, 131], "evalargu": [7, 20], "evalscop": [70, 131], "evalscpo": 70, "evalu": [119, 128, 129, 131, 199], "evalut": 198, "even": 131, "everyth": 131, "exampl": [37, 39, 44, 110, 111, 124, 131, 156, 159, 166, 172], "excus": 131, "exist": 39, "exit": 131, "expand": 131, "expect": 41, "experi": [111, 113], "experiment": [111, 113, 155], "expert": [35, 46, 72, 131, 133], "explain": 131, "export": [70, 103, 128, 130, 131, 160, 164], "exportargu": 7, "extern": [39, 89, 149, 150], "extra": [22, 70, 131], "extra_bodi": 131, "face": 131, "factor": [70, 131], "factori": [4, 8, 13, 22], "fail": 131, "fals": [70, 131], "faq": [89, 150, 216], "featur": [37, 161], "feel": 131, "field": 131, "file": [37, 46, 119, 131], "filter": [74, 135, 156], "final": 131, "find": 131, "fine": [17, 18, 116, 117, 121, 131, 152, 155, 172], "finetun": 70, "finetuningargu": 7, "firmwar": 197, "first": 131, "fix": 131, "flash": [41, 70, 131], "flash_attn": [70, 131], "flashattent": [6, 22], "float16": [70, 131], "flow": 37, "flush": [70, 131], "focal": [70, 131], "folder": 131, "follow": [70, 131], "for": [35, 38, 45, 46, 70, 80, 110, 114, 119, 131, 137, 141, 156], "format": [37, 39, 40, 44, 87, 110, 120, 121, 127, 129, 131, 148], "forward": [46, 71, 132], "found": [37, 44, 70, 131], "four": 142, "fourierft": [67, 128], "fp16": [70, 131], "fp8": [70, 131], "frame": 131, "frame_r": [70, 131], "framework": [131, 171], "free": [70, 131], "freez": [7, 18, 70, 131], "freeze_paramet": 131, "freeze_parameters_ratio": [70, 131], "freeze_vit": [70, 131], "freezeargu": [7, 18], "frequent": 131, "from": [35, 70, 131, 156], "fsdp": [9, 46, 172, 173, 215], "fsdp2": [9, 35], "full": [15, 18, 70, 104, 119, 128, 131, 165], "full_decode_on": 181, "fulli": [116, 131], "function": [37, 39, 43, 46, 111, 112, 113, 120, 128, 131, 132, 139, 145, 147, 148], "fuse": [40, 46], "futur": 40, "ga": [67, 70, 128, 131], "galor": [7, 18, 67, 128], "galoreargu": [7, 18], "gap": [82, 143], "garbl": 131, "gate": 139, "gb": 8, "general": [71, 132], "generat": [37, 39, 70, 120, 128, 131], "generatingargu": 7, "geometr": [52, 113], "get": [34, 131], "get_default_template_typ": [70, 131], "gguf": [70, 131], "git": [70, 131, 236, 245], "give": 131, "gkd": [60, 67, 70, 71, 99, 100, 121, 128, 131, 132, 160, 161], "glm4": [70, 131], "glm4v": [70, 131], "global": [70, 131, 172], "goal": 41, "got": [70, 131], "gpqa": [70, 131], "gpqa_extend": [70, 131], "gpt": 8, "gptq": [16, 70, 131], "gpu": [8, 27, 29, 30, 31, 32, 39, 46, 131], "gpus": 131, "grad_norm": [70, 131], "grad_scal": [70, 131], "gradient": [70, 131], "grain": 172, "greedi": 131, "grid": 46, "ground": [60, 70, 121, 131], "group": [75, 116, 136, 150, 166], "grpo": [50, 51, 52, 60, 67, 70, 81, 84, 89, 92, 99, 101, 111, 112, 113, 121, 128, 131, 142, 145, 150, 153, 160, 162], "gspo": [70, 131, 136, 181], "guid": [27, 28, 29, 30, 31, 172], "guidanc": [131, 176], "gym": [83, 144], "handl": [37, 40, 46, 131], "happen": [41, 131], "har": [198, 199], "hardwar": 125, "harmon": [72, 133], "has": [70, 131], "have": [70, 131], "head": [70, 131], "header": [70, 131], "headertoolarg": [70, 131], "help": 131, "helper": 46, "heurist": [82, 143], "hf": [102, 163, 245], "high": [80, 141], "higher": [70, 74, 131, 135], "host": [177, 181], "hour": 131, "how": [39, 109, 131, 138], "howev": 131, "hqq": 16, "html": [70, 131], "https": [70, 131], "hug": 131, "huggingfac": [44, 70, 245], "i2v": 31, "ids": [86, 147], "if": 131, "ifev": [70, 131], "ignor": 131, "imag": [37, 46, 70, 79, 121, 131, 140], "implem": 70, "implement": [36, 41, 46, 70, 120, 131, 134, 140, 143, 155], "import": [39, 70, 73, 131, 134, 138, 142], "importance_sampling_level": [70, 131], "importerror": [70, 131], "in": [37, 40, 46, 70, 131, 147, 148, 150, 172], "incentiv": [79, 140], "includ": [44, 131], "increas": 131, "increment": 131, "index": [70, 131], "individu": 131, "ineffect": 131, "inf": [70, 131], "infer": [42, 70, 81, 82, 110, 114, 116, 117, 118, 119, 127, 128, 131, 142, 143, 147, 151, 152, 163, 171], "infer_backend": [70, 131], "inferenti": 131, "infonc": [49, 110], "inform": 147, "inherit": 131, "init": [39, 70, 131], "init_weight": [70, 131], "initi": [43, 119], "input": [45, 70, 131], "input_id": [70, 131], "inspect": 131, "instal": [32, 33, 34, 109, 116, 124, 125, 131, 159], "instanc": 131, "instead": 131, "instruct": [70, 131], "insuffici": 131, "int4": [70, 131], "integr": [46, 128], "interact": [131, 147], "interfac": [40, 131, 144, 158], "intern": [89, 131, 149, 150], "internet": 131, "internvl": [67, 70, 128, 131], "internvl2": [67, 128], "internvl2_5": [67, 70, 128, 131], "internvl2_phi3": [67, 128], "internvl3": [67, 128], "internvl3_5": [67, 128], "internvl_phi3": [67, 128], "into": [38, 46, 131], "introduc": [131, 142], "introduct": [129, 140, 143, 156], "invalid": 131, "io": [70, 131], "is": [38, 70, 81, 131, 138, 142], "isn": 131, "issu": 131, "it": [70, 131], "item": 131, "itself": 131, "jemalloc": 181, "jensen": [71, 132], "jsd": [71, 132], "json": [58, 60, 70, 119, 121, 131], "jsonl": [70, 131], "judg": [70, 131], "judge0": [51, 112], "just": 131, "kd": [71, 100, 132, 161], "keep": 131, "kernel": [6, 14, 70, 131, 189, 190, 191, 230], "key": [34, 44, 46, 70, 131, 137], "keye_vl": [67, 128], "keye_vl_1_5": [67, 128], "keyword": [70, 131], "kimi": [70, 131], "kl": [70, 71, 76, 77, 81, 131, 132, 137, 138, 142], "know": 131, "kto": [17, 19, 60, 92, 99, 121, 153, 160], "kullback": [71, 132], "kwarg": [37, 70, 131], "label": [70, 131], "languag": [46, 70, 119, 131, 157], "language_model": [70, 131], "larg": [35, 131, 156, 157], "larger": 131, "last": [70, 131], "last_hidden_st": [70, 131], "last_model_checkpoint": [70, 131], "latenc": 131, "latest": [70, 131], "launch": 131, "layer": [119, 131], "lazi": [70, 131], "lead": [70, 131], "learn": [70, 74, 79, 80, 117, 124, 131, 132, 135, 140, 141, 161, 247], "leav": [77, 138], "left": [70, 131], "leibler": [71, 132], "length": [70, 131], "level": [74, 133, 135], "lfs": 245, "lib": [70, 131], "librari": 131, "liger": [6, 70, 131], "like": 131, "limit": [39, 161], "line": [44, 70, 128, 131, 160], "linear": [70, 131], "linux": 22, "lisa": [67, 128], "list": [70, 131, 158], "listwis": [59, 120], "llama": [4, 8, 10, 13, 22, 70, 131, 192, 193], "llama3": [70, 131], "llama3_1_omni": [67, 128], "llamaboard": 12, "llamafactori": 9, "llamapro": [67, 70, 128, 131], "llava": 29, "llm": [70, 74, 80, 131, 135, 141, 197], "llm_emb": [70, 131], "lm": [46, 198, 199], "lm_deploy": 196, "lmdeploy": [67, 70, 128, 131, 195], "lmdeployengin": [70, 131], "load": [36, 40, 131], "load_data_arg": [70, 131], "load_weight": [70, 131], "local": [70, 131, 191], "locat": 131, "log": [89, 113, 131, 142, 150], "log_entropi": [70, 131], "logic": [131, 132, 147], "logit": [70, 131], "logprob": [70, 131], "long": [38, 131], "longlora": [70, 131], "look": 131, "loop": [43, 131], "lora": [3, 7, 8, 18, 23, 67, 69, 70, 91, 102, 103, 104, 128, 130, 131, 152, 163, 164, 165], "loraargu": [7, 18], "loss": [43, 49, 60, 62, 70, 74, 84, 110, 120, 121, 123, 131, 132, 135, 139, 145, 147], "loss_scal": [62, 66, 127], "lot": 131, "lower": 131, "lr": 43, "machin": 131, "magic": 131, "main": [46, 131], "maintain": 47, "make": 131, "mani": 131, "manual": 131, "map": [44, 70, 131], "mappi": 70, "mask": [81, 131, 142, 147], "match": 131, "math": [70, 131], "max": [70, 131], "max_batch_s": [70, 131], "max_length": [70, 131], "max_new_token": [70, 131], "max_pixel": [70, 131], "max_step": [70, 131], "mcore": [102, 103, 105, 163, 164, 166], "mcq": [68, 129], "me": 131, "mean": 131, "mechan": [123, 131], "media_typ": [70, 131], "meet": [72, 133], "megatron": [56, 70, 99, 103, 105, 117, 131, 160, 162, 164, 166, 172, 173], "memfabr": 230, "memori": [44, 131, 150, 156], "mention": 131, "merg": [69, 70, 91, 102, 128, 130, 131, 152, 163], "merge_lora": [70, 131], "messag": [70, 131], "meta": 245, "method": [39, 120, 131, 139, 163, 166], "metric": [62, 81, 89, 123, 131, 132, 142, 150], "micro": [70, 131], "might": 131, "million": 131, "mimo_vl": [67, 128], "mindspe": [172, 173, 174], "mini": [70, 131], "miniconda": 224, "minicpmo": [67, 70, 128, 131], "minicpmv": [70, 131], "minicpmv2_6": [67, 128], "minicpmv4": [67, 128], "minimum": 131, "minor": [70, 80, 131, 141], "minut": [117, 131], "mirror": [125, 131, 245], "mismatch": [81, 142, 147], "miss": [44, 131], "mix": [35, 131], "mixtur": 29, "mlflow": 12, "mllm": [70, 131], "mlp1": [70, 131], "mmengin": [70, 131], "mmlu": [70, 131], "mmvet": [70, 131], "mnt": [70, 131], "modal": [37, 70, 131], "mode": [71, 89, 100, 131, 132, 142, 150, 161, 172], "model": [17, 27, 29, 30, 31, 34, 35, 36, 38, 39, 42, 43, 44, 46, 70, 76, 82, 114, 118, 119, 122, 123, 128, 130, 131, 132, 137, 143, 149, 152, 156, 157, 164, 165, 180], "model_typ": [70, 131], "modelargu": 7, "modeling_util": [70, 131], "modeling_utilspi": 70, "modelscop": [70, 131], "modif": [39, 119, 131, 159], "modifi": [29, 131], "modul": [35, 43, 70, 116, 131], "moe": [28, 29, 35, 40, 46, 57, 70, 103, 104, 118, 131, 164, 165], "monitor": 131, "monkey": 39, "moonlight": [70, 131], "more": [115, 124], "motiv": [35, 139], "mplug_owl3": [67, 128], "mplug_owl3_241101": [67, 128], "ms": [70, 131, 201], "msleak": 177, "msprobe": [98, 159], "much": 131, "multi": [37, 70, 131, 146, 147, 180], "multimod": [52, 113, 114, 121, 131, 147, 157, 165], "multipl": [37, 129, 131], "multisourc": 29, "multiturnschedul": [86, 147], "must": 131, "my": 131, "name": [37, 41, 44, 70, 131], "name_or_path": [70, 131], "nan": [70, 131], "nativ": [46, 116, 131], "nativeddp": 9, "near": 131, "need": 131, "neftun": [70, 131], "new": [36, 38, 46], "next": 131, "nlg": 20, "nnal": 14, "no": [44, 70, 131], "node": 131, "nois": 131, "non": 131, "none": [70, 131], "normal": [84, 131, 137, 145], "not": [37, 39, 70, 116, 131, 132, 161], "notat": 131, "note": [41, 144, 148], "notebook": [64, 125], "noth": 131, "notic": 131, "now": 131, "npu": [13, 14, 15, 27, 30, 31, 33, 34, 55, 98, 116, 159, 170, 181, 206, 207, 209, 230, 233, 234, 239], "npus": 116, "null": [70, 131], "num_iter": [70, 131], "num_train_epoch": [70, 131], "number": [70, 131], "numpi": [70, 131], "nvidia": 32, "object": [70, 131], "observ": [111, 113], "occupi": 131, "occur": 131, "of": [35, 36, 38, 44, 45, 70, 82, 127, 131, 142, 143, 155, 171], "off": [39, 45, 72, 81, 100, 133, 142, 161], "offici": 131, "offlin": [131, 132], "offload": 9, "oftq": 16, "ollama": [70, 131], "omni": [29, 70, 131], "on": [27, 29, 30, 31, 45, 71, 72, 100, 116, 131, 132, 133, 161, 171, 172, 173], "onc": 131, "one": [77, 131, 138], "onli": [70, 131, 142], "onlin": 110, "online_contrast": 49, "onnx": [202, 203], "oom": [70, 131], "op": 40, "open": [26, 52, 74, 113, 135], "open_clip": [205, 206], "openai": [19, 70, 131], "opencompass": [70, 131, 208, 209, 210], "opencv": [211, 212], "openeul": 181, "optim": [43, 46, 62, 73, 75, 78, 82, 84, 123, 131, 134, 136, 139, 143, 145, 150, 180, 181], "option": 131, "or": [32, 33, 70, 131, 156, 172, 173], "order": [70, 131], "origin": [39, 131], "orm": [62, 70, 95, 123, 131, 156], "orpo": [60, 92, 121, 153], "oss": 8, "other": [128, 131, 132], "out": [44, 77, 131, 138], "outcom": 123, "output": [37, 39, 44, 70, 131], "over": 131, "overlong": [74, 87, 135, 148], "overrid": [39, 131, 147], "overview": [35, 36, 37, 38, 44, 46, 133, 134, 137, 138, 150], "ovis1_6": [67, 128], "ovis2": [67, 70, 128, 131], "ovis2_5": [67, 128], "own": 36, "pack": [45, 70, 131], "packag": [70, 125, 131], "packing_cach": [70, 131], "pad": [45, 46, 70, 131], "pad_packed_input": 45, "pad_scal": 46, "para": 70, "parallel": [35, 38, 43, 46, 70, 116, 131], "paramet": [18, 70, 111, 113, 128, 131, 132, 134, 135, 137, 138, 139, 147, 154, 160, 161, 162], "part": [46, 131], "particip": 131, "pass": [46, 131], "patch": 39, "path": [131, 172], "peft": [70, 131], "per": 131, "percentag": 131, "perf": [70, 131], "perform": [38, 46, 131, 159, 172, 173], "perman": 131, "perplex": [81, 142], "phase": [131, 172], "phenomenon": 131, "phi3_vis": [67, 128], "pil": [70, 131], "pip": [2, 32, 33, 196, 203], "pipelin": [37, 70, 222, 243, 246], "pipeline_parallel_s": 131, "pisit": 70, "pissa": 18, "place": 131, "plain": 131, "plan": 46, "plot": 131, "plugin": [123, 149], "point": 131, "pointwis": [59, 120], "polici": [70, 71, 72, 73, 75, 78, 81, 82, 84, 100, 131, 132, 133, 134, 136, 139, 142, 143, 145, 161], "posit": [46, 70, 131], "possibl": 131, "post": 17, "potenti": 131, "ppl": [81, 142], "ppo": [17, 60, 67, 70, 92, 121, 128, 131, 153], "practic": [37, 114, 115, 117, 118, 119, 131, 140, 144, 156, 178, 179, 180, 181], "pre": [17, 121, 131, 132, 152], "predict": 131, "prefetch": 35, "prefix": [70, 131], "prepar": [31, 33, 116, 117, 129, 152], "prepend": 131, "preprocess": [37, 43, 70, 131], "preprocessor": 37, "preprocessor_registri": 37, "pretrain": [45, 70, 131], "previous": 131, "principl": [39, 140, 142, 143], "print": 131, "prm": [62, 95, 123, 156], "pro": 10, "probabl": [70, 131], "problem": [39, 41, 131], "process": [46, 111, 123, 131], "processorargu": 7, "produc": 131, "profil": [43, 173, 177], "programmat": 39, "project": 39, "prompt": [70, 76, 131, 137], "proper": 35, "proport": 131, "provid": 131, "pt": [15, 70, 131], "ptq": 16, "punish": [74, 87, 135, 148], "pure": 131, "push": 130, "py": [46, 70, 131, 210], "python": [2, 70, 90, 91, 131, 151, 152, 204, 206, 209, 212, 213, 221, 230, 233, 239, 252], "python3": [70, 131], "pytorch": [35, 70, 131, 217, 218], "pytorch_npu_alloc_conf": 34, "q1": [70, 131], "q10": [70, 131], "q100": [70, 131], "q101": [70, 131], "q102": [70, 131], "q103": [70, 131], "q104": [70, 131], "q105": [70, 131], "q106": [70, 131], "q107": [70, 131], "q108": [70, 131], "q109": [70, 131], "q11": [70, 131], "q110": [70, 131], "q111": [70, 131], "q112": [70, 131], "q113": [70, 131], "q114": [70, 131], "q115": [70, 131], "q116": [70, 131], "q117": [70, 131], "q118": [70, 131], "q119": [70, 131], "q12": [70, 131], "q120": [70, 131], "q121": [70, 131], "q122": [70, 131], "q123": [70, 131], "q124": [70, 131], "q125": [70, 131], "q126": [70, 131], "q127": [70, 131], "q128": [70, 131], "q129": [70, 131], "q13": [70, 131], "q130": [70, 131], "q131": [70, 131], "q132": [70, 131], "q133": [70, 131], "q134": [70, 131], "q135": [70, 131], "q136": [70, 131], "q137": [70, 131], "q138": [70, 131], "q139": [70, 131], "q14": [70, 131], "q140": [70, 131], "q141": [70, 131], "q142": [70, 131], "q143": [70, 131], "q144": [70, 131], "q145": [70, 131], "q146": [70, 131], "q147": [70, 131], "q148": [70, 131], "q149": [70, 131], "q15": [70, 131], "q150": [70, 131], "q151": [70, 131], "q152": [70, 131], "q153": [70, 131], "q154": [70, 131], "q155": [70, 131], "q156": [70, 131], "q157": [70, 131], "q158": [70, 131], "q159": [70, 131], "q16": [70, 131], "q160": [70, 131], "q161": [70, 131], "q162": [70, 131], "q163": [70, 131], "q164": [70, 131], "q165": [70, 131], "q17": [70, 131], "q18": [70, 131], "q19": [70, 131], "q2": [70, 131], "q20": [70, 131], "q21": [70, 131], "q22": [70, 131], "q23": [70, 131], "q24": [70, 131], "q25": [70, 131], "q26": [70, 131], "q27": [70, 131], "q28": [70, 131], "q29": [70, 131], "q3": [70, 131], "q30": [70, 131], "q31": [70, 131], "q32": [70, 131], "q33": [70, 131], "q34": [70, 131], "q35": [70, 131], "q36": [70, 131], "q37": [70, 131], "q38": [70, 131], "q39": [70, 131], "q4": [70, 131], "q40": [70, 131], "q41": [70, 131], "q42": [70, 131], "q43": [70, 131], "q44": [70, 131], "q45": [70, 131], "q46": [70, 131], "q47": [70, 131], "q48": [70, 131], "q49": [70, 131], "q5": [70, 131], "q50": [70, 131], "q51": [70, 131], "q52": [70, 131], "q53": [70, 131], "q54": [70, 131], "q55": [70, 131], "q56": [70, 131], "q57": [70, 131], "q58": [70, 131], "q59": [70, 131], "q5_k_m": [70, 131], "q6": [70, 131], "q60": [70, 131], "q61": [70, 131], "q62": [70, 131], "q63": [70, 131], "q64": [70, 131], "q65": [70, 131], "q66": [70, 131], "q67": [70, 131], "q68": [70, 131], "q69": [70, 131], "q7": [70, 131], "q70": [70, 131], "q71": [70, 131], "q72": [70, 131], "q73": [70, 131], "q74": [70, 131], "q75": [70, 131], "q76": [70, 131], "q77": [70, 131], "q78": [70, 131], "q79": [70, 131], "q8": [70, 131], "q80": [70, 131], "q81": [70, 131], "q82": [70, 131], "q83": [70, 131], "q84": [70, 131], "q85": [70, 131], "q86": [70, 131], "q87": [70, 131], "q88": [70, 131], "q89": [70, 131], "q9": [70, 131], "q90": [70, 131], "q91": [70, 131], "q92": [70, 131], "q93": [70, 131], "q94": [70, 131], "q95": [70, 131], "q96": [70, 131], "q97": [70, 131], "q98": [70, 131], "q99": [70, 131], "qa": [52, 68, 113, 129], "qat": 16, "qianwen": 131, "qlora": [22, 70, 131], "qps": [70, 131], "qqq": [70, 131], "qualiti": 131, "quantiz": [128, 130, 131], "quantizationargu": 7, "queri": [70, 131], "question": [70, 129, 131], "quick": [37, 38, 39, 124, 166], "quickstart": [174, 175], "qvq": [67, 128], "qwem3": [70, 131], "qwen": [40, 70, 131], "qwen2": [37, 70, 131, 178, 179], "qwen2_5_omni": [67, 128], "qwen2_5_vl": [67, 128], "qwen2_audio": [67, 128], "qwen2_vl": [67, 128], "qwen2audio": [70, 131], "qwen2vl": [70, 131], "qwen2vlforconditionalgener": [70, 131], "qwen3": [27, 28, 29, 30, 39, 46, 56, 57, 70, 117, 118, 131, 179, 181], "qwen3_5_mo": 40, "qwen3_mo": 40, "qwen3_omni": [67, 128], "qwen3_vl": [67, 128], "qwen3_vl_emb": [67, 128], "qwen3_vl_mo": 40, "qwen3_vl_rerank": [67, 128], "qwen3mo": 40, "qwenvl2": [70, 131], "r1": [52, 70, 113, 131], "rag": [70, 131], "raga": [70, 131], "rais": [70, 131], "random": [37, 131], "rapid": 119, "rate": [70, 131], "rather": 131, "ray": [7, 9, 67, 93, 128, 154], "rayargu": 7, "re": 131, "read": 131, "readthedoc": [70, 131], "real": 131, "reason": [80, 131, 141], "receiv": [70, 131], "recommend": [45, 163, 166], "record": [111, 131], "redownload": 131, "reduc": 131, "ref": [172, 173], "refer": [37, 39, 42, 46, 70, 131, 142, 161], "reft": [67, 128], "regard": 131, "regist": [36, 37, 46, 114], "registr": [37, 114, 121, 122, 131], "registri": [36, 37], "regular": [137, 138], "reinforc": [74, 76, 77, 79, 80, 117, 131, 135, 137, 138, 140, 141, 155, 247], "relat": [147, 161], "releas": 131, "relev": 33, "remot": 191, "remov": [46, 131], "repeat": 131, "repetit": [87, 148], "replac": [39, 119, 131], "report": 131, "repres": 131, "reproduc": 131, "request": 131, "requir": [32, 33, 131], "requires_grad": [70, 131], "rerank": [59, 60, 120, 121], "resacle_imag": [70, 131], "resolv": 131, "resourc": 131, "respect": 131, "respons": [70, 86, 131, 147], "result": [131, 155, 156, 171], "result_path": [70, 131], "resum": 131, "retool": 178, "retriev": 131, "return": [70, 131, 147], "revers": [71, 132], "reward": [17, 67, 70, 76, 111, 112, 113, 123, 128, 131, 137, 147, 148, 149], "reward_func": [70, 131], "reward_model": [70, 131], "rl": [55, 56, 72, 89, 116, 117, 133, 150], "rlhf": [7, 17, 60, 67, 76, 99, 121, 128, 137, 153, 160], "rloo": [77, 138], "rm": [15, 60, 70, 92, 99, 121, 131, 153, 160], "rmpad_with_pos_id": 45, "robust": [76, 137], "role": 172, "roll": [220, 221], "rollout": [67, 70, 128, 131, 172, 173], "rope_sc": [70, 131], "roug": [70, 131], "rout": 131, "router": 131, "rslora": 18, "rule": [80, 131, 141], "run": [125, 131, 210], "runtim": [41, 202, 203], "runtimeerror": [70, 131], "safetensorerror": [70, 131], "safetensors_rust": [70, 131], "same": 131, "sampl": [37, 70, 73, 74, 81, 128, 131, 132, 134, 135, 142, 156, 172], "sapo": [78, 84, 139, 145], "save": 131, "save_step": [70, 131], "say": 131, "scale": [35, 74, 123, 135], "scenario": 39, "schedul": [43, 86, 147], "score": [70, 131], "script": [37, 112, 120, 131], "sdpa": [70, 131], "seamless": 164, "search": 131, "see": [44, 131], "seem": 131, "select": 132, "self": [70, 117, 131], "sent": 131, "sentenc": [226, 227], "separ": 131, "seq2seqtrain": [67, 128], "seq_kd": [71, 132], "sequenc": [38, 46, 70, 75, 81, 121, 131, 136, 142], "sequence_parallel_s": [70, 131], "sequenti": [71, 100, 132, 161], "seri": 131, "serv": [70, 131], "server": [131, 151, 152], "servic": 131, "set": [70, 131, 132, 135, 139, 147, 154], "setup": [35, 114, 117, 118, 131, 156, 166], "sever": 131, "sft": [15, 24, 29, 45, 55, 56, 70, 72, 116, 117, 131, 133], "sgl": 230, "sglang": [67, 128, 175, 179, 229, 230, 231], "shannon": [71, 132], "shape": 177, "shard": [35, 44], "shard_checkpoint": [70, 131], "sharegpt": 19, "sharegpt4v_cap_100k": 29, "should": 131, "show": 131, "shuffl": [70, 131], "side": [131, 151, 152], "signific": 131, "similar": [110, 131], "simpl": [46, 131], "simpli": 131, "simpo": [60, 92, 121, 153], "simultan": 131, "sinc": [70, 131], "singl": [116, 131], "site": [70, 131], "size": [44, 70, 81, 131, 133, 142], "slice": 46, "slight": 131, "slow": 131, "slower": 131, "small": 131, "smaller": 131, "so": 131, "soft": [74, 78, 87, 135, 139, 148], "solut": [39, 70, 81, 131, 132, 134, 142, 150, 172], "solv": 131, "some": 131, "sometim": 131, "somewhat": 131, "sooner": 131, "sourc": [37, 70, 74, 125, 131, 135], "sp": 46, "special": [46, 70, 131], "special_token": [70, 131], "specif": [128, 131, 161], "specifi": 131, "speed": 131, "split": [70, 131], "split_dataset_ratio": [70, 131], "squar": [81, 142], "stabil": 142, "stabl": [223, 224], "stage": [119, 131], "stage1": 58, "stage2": 58, "standard": [121, 131], "start": [27, 29, 30, 31, 34, 37, 38, 39, 109, 114, 124, 131, 166], "state": [43, 131], "statement": 131, "static": 158, "statist": [137, 142], "status": [116, 131], "step": [70, 111, 131], "still": 131, "stop": 131, "store": 131, "str": 37, "strategi": [35, 41], "stream": [70, 131], "stress": 131, "structur": [37, 39, 131], "student": [70, 131, 132], "subsequ": 131, "such": 131, "suffici": 131, "sum": 131, "summari": 46, "supervis": [17, 117, 121], "support": [34, 35, 37, 38, 39, 46, 116, 125, 127, 131, 150, 154, 157, 161], "suppos": 131, "sure": 131, "survey": 40, "swanlab": [7, 12, 67, 128], "swanlabargu": 7, "swift": [56, 64, 70, 94, 97, 105, 117, 125, 131, 155, 158, 166, 201], "swift2x": [70, 131], "swift3": [70, 131], "swiftmodel": [97, 158], "sync": 150, "synchron": 46, "system": [36, 70, 74, 131, 135], "system_prompt": [70, 131], "tabl": [36, 38, 116, 131], "take": 131, "talker": [70, 131], "target": [70, 131], "target_modul": [70, 131], "task": [70, 111, 113, 131, 146], "task_id": [70, 131], "task_queue_en": 181, "teacher": [67, 70, 128, 131, 132], "technic": 154, "temperatur": [70, 131, 139], "templat": [11, 43, 62, 70, 114, 123, 128, 131], "template_typ": [70, 131], "tempratur": 70, "tensor": [70, 131], "tensorboard": 12, "term": 131, "test": [37, 131, 143, 164], "text": [121, 131], "than": 131, "that": 131, "the": [26, 35, 39, 46, 70, 80, 82, 131, 138, 141, 143, 147, 171], "their": 39, "them": 131, "then": 131, "there": 131, "these": 131, "they": 131, "thing": 131, "think": [70, 79, 131, 140], "this": [39, 41, 46, 131], "those": 131, "though": 131, "thought": 131, "three": [131, 132, 161], "through": 131, "throw": 131, "time": 131, "timeout": 131, "timm": [232, 233], "tip": [147, 152, 166], "to": [36, 37, 39, 44, 70, 76, 109, 121, 131, 137, 155, 163, 172], "togeth": 131, "token": [44, 70, 72, 74, 80, 86, 131, 133, 135, 141, 147, 239, 253], "token_acc": [70, 131], "tongyi": 131, "too": 131, "tool": [39, 66, 70, 127, 131], "toolkit": 14, "top": 131, "top_entropy_quantil": [70, 131], "top_k": 131, "top_p": 131, "topic": 147, "topk": 70, "topp": 70, "torch": [14, 70, 131, 190, 206, 209, 221, 230, 233, 234, 239], "torch_dtyp": [70, 131], "torch_npu": [190, 236], "torchchat": [235, 236], "torchrun": [9, 70, 131], "torchtitan": [238, 239, 240], "total": 131, "trade": 39, "tradit": [163, 166], "train": [17, 27, 28, 29, 30, 31, 35, 37, 38, 42, 43, 70, 81, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 121, 127, 128, 129, 131, 132, 142, 144, 146, 147, 152, 160, 161, 163, 164, 166], "trainabl": [70, 131], "trainable_paramet": [70, 131], "trainer": 241, "trainer_sampler_random": [70, 131], "trainerst": [70, 131], "transform": [8, 40, 41, 43, 46, 55, 70, 116, 131, 191, 219, 226, 227, 242, 244, 247], "treat": 131, "tree": [82, 143], "treepo": [82, 143], "tri": 131, "trick": [70, 131], "trigger": 132, "triton": 230, "triu_tril_cuda_templ": [70, 131], "trl": [70, 131, 248], "troubleshoot": [37, 44, 131], "true": [45, 70, 71, 131, 132], "truncat": [81, 142], "trust_remote_cod": 131, "trust_rwmote_cod": 70, "tulu": 29, "tune": [17, 18, 70, 116, 117, 121, 131, 152, 155], "tuner": [62, 67, 97, 123, 128, 158], "tuner_typ": [70, 131], "tupl": [70, 131], "turn": [37, 131, 147], "tutori": 131, "two": [131, 133], "txt": [70, 131], "type": [39, 44, 70, 84, 120, 131, 145], "typeerror": [70, 131], "ubuntu": 181, "ui": [65, 67, 90, 91, 126, 128, 151, 152], "ulyss": [38, 70, 131], "unchang": 131, "unclear": 131, "under": 131, "uneven": 131, "unexpect": [70, 131], "universal": 131, "unscal": [70, 131], "unscale_grad": [70, 131], "unsloth": [6, 67, 70, 128, 131], "unstabl": 111, "up": [35, 131], "updat": [34, 119, 131], "update_polici": [172, 173], "upgrad": 131, "url": [70, 131], "usag": [37, 39, 43, 44, 45, 124, 127, 131, 142], "use": [37, 38, 39, 131, 137, 151, 152, 155, 156, 158, 164], "use_async_engin": [70, 131], "use_cach": [70, 131], "use_liger_kernel": [70, 131], "use_logits_to_keep": [70, 131], "useless": 131, "usr": [70, 131], "uv": [32, 33], "v1": 181, "v100": [70, 131], "v5": 40, "valid": 131, "valu": 131, "valueerror": [70, 131], "variabl": [7, 33, 34, 128], "variant": 133, "ve": 131, "veomni": [5, 26, 36, 40, 41, 46], "vera": [67, 128], "veri": 131, "verifi": 116, "verl": [70, 131, 171, 174, 181, 250], "version": 131, "via": [72, 79, 131, 133, 140], "video": [29, 70, 131], "video_cogvlm2": [67, 128], "video_llava": [67, 128], "view": 116, "virtual": 131, "vision": [46, 119], "vision_model": [70, 131], "visual": [46, 70, 131, 172], "vit": [46, 70, 131], "vl": [30, 37, 46, 57, 58, 70, 118, 119, 131], "vllm": [7, 13, 55, 67, 70, 81, 116, 128, 131, 142, 171, 174, 181, 221, 230], "vllm_ascend_enable_dense_optim": 181, "vllm_ascend_enable_flashcomm": 181, "vllm_ascend_enable_prefetch_mlp": 181, "vllmargument": 7, "vllmengin": [70, 131], "vlm": [70, 131, 197], "vlmevalkit": [70, 131], "vlms": 46, "vocabulari": 131, "vqa": [37, 70, 131], "vs": [39, 81, 142], "vx": [70, 131], "wan2": 31, "wandb": [12, 70, 131], "want": 131, "warn": [37, 70, 131], "was": 131, "wasn": 131, "way": 131, "we": 131, "web": [65, 67, 70, 90, 91, 126, 128, 131, 151, 152], "webui": [25, 223, 224], "wechat": [116, 150, 166], "weight": [40, 44, 70, 72, 119, 131, 133, 142, 150], "wenet": [251, 252, 253], "were": 131, "what": [38, 131], "wheel": [64, 125], "when": [131, 155], "where": 131, "whether": 131, "whi": [39, 41, 46, 131], "which": 131, "while": [70, 131], "whisper": [254, 255, 256], "will": 131, "window": 22, "with": [26, 32, 33, 34, 35, 40, 44, 76, 79, 82, 112, 116, 131, 137, 140, 143, 175], "within": 131, "without": 131, "word": 70, "work": [40, 131], "workflow": 113, "workspac": [70, 131], "world_siz": 131, "wors": 131, "would": 131, "write": 131, "written": 131, "wrong": 37, "xcomposer2_4khd": [67, 128], "xcomposer2_5": [67, 128], "xxx": [70, 131], "yaml": [29, 67, 70, 128, 131, 170], "yet": [116, 161], "yi": [70, 131], "you": 131, "your": [26, 36, 37, 43, 46], "zero": 9, "zero3": [70, 131], "zh": [70, 131, 171, 173]}})