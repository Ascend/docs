

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>æ¨¡å‹æ”¯æŒ &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">æ¨¡å‹æ”¯æŒ</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../_sources/sources/_generated/sources/LLaMA-Factory/source/advanced/model_support.rst.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="id1">
<h1>æ¨¡å‹æ”¯æŒ<a class="headerlink" href="#id1" title="Link to this heading">ïƒ</a></h1>
<p>LLaMA-Factory å…è®¸ç”¨æˆ·æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹æ”¯æŒã€‚æˆ‘ä»¬å°†ä»¥ LLaMA-4 å¤šæ¨¡æ€æ¨¡å‹ä¸ºä¾‹ï¼Œè¯¦ç»†ä»‹ç»å¦‚ä½•ä¸ºæ–°æ¨¡å‹æ·»åŠ æ”¯æŒã€‚å¯¹äºå¤šæ¨¡æ€æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦å®Œæˆä¸¤ä¸ªä¸»è¦ä»»åŠ¡ï¼š</p>
<ol class="arabic simple">
<li><p>æ³¨å†Œæ¨¡å‹çš„template</p></li>
<li><p>è§£æå¤šæ¨¡æ€æ•°æ®å¹¶æ„å»º messages</p></li>
</ol>
<section id="template">
<h2>æ³¨å†Œ template<a class="headerlink" href="#template" title="Link to this heading">ïƒ</a></h2>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹æ³•è·å– LLaMA-4 æ¨¡å‹çš„ templateï¼š</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoProcessor</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;unsloth/Llama-4-Scout-17B-16E-Instruct&quot;</span><span class="p">)</span>
<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;{{content}}&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;{{content}}&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;{{content}}&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;tool&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="sa">r</span><span class="s2">&quot;{{content}}&quot;</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;========== Template ==========&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p>è¾“å‡ºå¦‚ä¸‹ã€‚é€šè¿‡è§‚å¯Ÿè¾“å‡ºæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¨¡å‹çš„ chat_templateã€‚é™¤æ­¤ä»¥å¤–ä¹Ÿå¯ä»¥é€šè¿‡ <a class="reference external" href="https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct/blob/main/tokenizer_config.json#L9077">huggingface repo</a>  æ¥è·å–æ¨¡å‹çš„ template.</p>
<pre><code class="python" style="font-family: monospace; font-size: 14px; background-color: #fefefe; color: #000000; padding: 5px; border-radius: 0px;">========== Template ==========
&lt;|begin_of_text|&gt;<span style='background-color: #fff9b1;'>&lt;|header_start|&gt;user&lt;|header_end|&gt;

{{content}}&lt;|eot|&gt;</span><span style='background-color: #ffff66;'>&lt;|header_start|&gt;assistant&lt;|header_end|&gt;

</span><span style='background-color: #ffff66;'>{{content}}&lt;|eot|&gt;</span><span style="background-color: #d6f0ff;">&lt;|header_start|&gt;system&lt;|header_end|&gt;

{{content}}&lt;|eot|&gt;</span><span style="background-color: #f1e6ff;">&lt;|header_start|&gt;ipython&lt;|header_end|&gt;

"{{content}}"&lt;|eot|&gt;</span><span style='background-color: #ffff66;'>&lt;|header_start|&gt;assistant&lt;|header_end|&gt;</span>
</code></pre><p>é€šè¿‡è§‚å¯Ÿè¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥å¾—çŸ¥ LLaMA-4 çš„ chat_template ä¸»è¦ç”±ä»¥ä¸‹å‡ éƒ¨åˆ†ç»„æˆï¼š</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 30.0%" />
<col style="width: 70.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>æ¶ˆæ¯ç±»å‹</p></th>
<th class="head"><p>æ¨¡æ¿æ ¼å¼</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ç”¨æˆ·æ¶ˆæ¯</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;|header_start|&gt;user&lt;|header_end|&gt;\n\n{{content}}&lt;|eot|&gt;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>åŠ©æ‰‹æ¶ˆæ¯</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;|header_start|&gt;assistant&lt;|header_end|&gt;\n\n{{content}}&lt;|eot|&gt;</span></code></p></td>
</tr>
<tr class="row-even"><td><p>ç³»ç»Ÿæ¶ˆæ¯</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;|header_start|&gt;system&lt;|header_end|&gt;\n\n{{content}}&lt;|eot|&gt;</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>å·¥å…·æ¶ˆæ¯</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">&lt;|header_start|&gt;ipython&lt;|header_end|&gt;\n\n&quot;{{content}}&quot;&lt;|eot|&gt;</span></code></p></td>
</tr>
</tbody>
</table>
<p>æˆ‘ä»¬å¯ä»¥åœ¨ <code class="docutils literal notranslate"><span class="pre">src/llamafactory/data/template.py</span></code> ä¸­ä½¿ç”¨ <code class="docutils literal notranslate"><span class="pre">register_template</span></code> æ–¹æ³•ä¸ºè‡ªå®šä¹‰æ¨¡å‹æ³¨å†Œ chat_templateã€‚</p>
<p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¾€å¾€ä¼šåœ¨ç”¨æˆ·è¾“å…¥çš„ä¿¡æ¯åæ·»åŠ åŠ©æ‰‹å›å¤æ¨¡æ¿çš„å¤´éƒ¨ <code class="docutils literal notranslate"><span class="pre">&lt;|header_start|&gt;assistant&lt;|header_end|&gt;</span></code> æ¥å¼•å¯¼æ¨¡å‹è¿›è¡Œå›å¤ã€‚</p>
<p>å› æ­¤æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œç”¨æˆ·æ¶ˆæ¯å’Œå·¥å…·è¾“å‡ºçš„æ¨¡æ¿ä¸­éƒ½é™„æœ‰äº†åŠ©æ‰‹å›å¤çš„å¤´éƒ¨ï¼Œè€ŒåŠ©æ‰‹æ¶ˆæ¯æ ¼å¼ <code class="docutils literal notranslate"><span class="pre">format_assitant</span></code> ä¹Ÿå› æ­¤çœç•¥äº†åŠ©æ‰‹å›å¤çš„å¤´éƒ¨ï¼Œåªä¿ç•™å…¶å†…å®¹éƒ¨åˆ† <code class="docutils literal notranslate"><span class="pre">{{content}}&lt;|eot|ã€‚&gt;</span></code>ã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥æ ¹æ®ä¸Šé¢çš„è¾“å‡ºå®Œæˆ <code class="docutils literal notranslate"><span class="pre">name</span></code>, <code class="docutils literal notranslate"><span class="pre">format_user</span></code>, <code class="docutils literal notranslate"><span class="pre">format_assistant</span></code>, <code class="docutils literal notranslate"><span class="pre">format_system</span></code> ä¸ <code class="docutils literal notranslate"><span class="pre">format_observation</span></code> å­—æ®µçš„å¡«å†™ã€‚</p>
<p><code class="docutils literal notranslate"><span class="pre">format_prefix</span></code> å­—æ®µç”¨äºæŒ‡å®šæ¨¡å‹çš„å¼€å¤´éƒ¨åˆ†ï¼Œé€šå¸¸å¯ä»¥åœ¨ <a class="reference external" href="https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct/blob/main/tokenizer_config.json#L9076">tokenizer_config.json</a> ä¸­æ‰¾åˆ°ã€‚</p>
<p><code class="docutils literal notranslate"><span class="pre">stop_words</span></code> å­—æ®µç”¨äºæŒ‡å®šæ¨¡å‹çš„åœæ­¢è¯ï¼Œå¯ä»¥åœ¨ <a class="reference external" href="https://huggingface.co/unsloth/Llama-4-Scout-17B-16E-Instruct/blob/main/generation_config.json">generation_config.json</a> ä¸­æ‰¾åˆ° eos_token_idï¼Œå†æŠŠ eos_token_id å¯¹åº”çš„ token å¡«å…¥ã€‚</p>
<p>å¯¹äºå¤šæ¨¡æ€æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åœ¨ <code class="docutils literal notranslate"><span class="pre">mm_plugin</span></code> å­—æ®µä¸­æŒ‡å®šå¤šæ¨¡æ€æ’ä»¶ã€‚</p>
<pre><code class="python" style="font-family: monospace; font-size: 14px; background-color: #fefefe; color: #000000; padding: 5px; border-radius: 0px;">register_template(
    # Template
    name="llama4",
    # User Message Format, with a generation prompt template at the end
    format_user=StringFormatter(
        slots=["<span style='background-color: #fff9b1;'>&lt;|header_start|&gt;user&lt;|header_end|&gt;\n\n{{content}}&lt;|eot|&gt;</span><span style='background-color: #ffff66;'>&lt;|header_start|&gt;assistant&lt;|header_end|&gt;\n\n</span>"]
    ),
    # Assistant Message format
    <span style='background-color: #ffff66;'>format_assistant</span>=StringFormatter(slots=["<span style='background-color: #ffff66;'>{{content}}&lt;|eot|&gt;</span>"]),
    # System Message Format
    format_system=StringFormatter(slots=["<span style="background-color: #d6f0ff;">&lt;|header_start|&gt;system&lt;|header_end|&gt;\n\n{{content}}&lt;|eot|&gt;</span>"]),
    # Function Call Format
    format_function=FunctionFormatter(slots=["{{content}}&lt;|eot|&gt;"], tool_format="llama3"),
    # Tool Output Format, with a generation prompt template at the end
    format_observation=StringFormatter(
        slots=[
            "<span style='background-color: #f1e6ff;'>&lt;|header_start|&gt;ipython&lt;|header_end|&gt;\n\n{{content}}&lt;|eot|&gt;</span><span style='background-color: #ffff66;'>&lt;|header_start|&gt;assistant&lt;|header_end|&gt;</span>\n\n"
        ]
    ),
    # Tool Call Format
    format_tools=ToolFormatter(tool_format="llama3"),
    format_prefix=EmptyFormatter(slots=[{"bos_token"}]),
    stop_words=["&lt;|eot|&gt;", "&lt;|eom|&gt;"],
    mm_plugin=get_mm_plugin(name="llama4", image_token="&lt;|image|&gt;"),
)
</code></pre></section>
<section id="id2">
<h2>å¤šæ¨¡æ€æ•°æ®æ„å»º<a class="headerlink" href="#id2" title="Link to this heading">ïƒ</a></h2>
<p>å¯¹äºå¤šæ¨¡æ€æ¨¡å‹ï¼Œæˆ‘ä»¬å‚ç…§åŸå§‹æ¨¡å‹åœ¨ LLaMA-Factory ä¸­å®ç°å¤šæ¨¡æ€æ•°æ®çš„è§£æã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥åœ¨ <code class="docutils literal notranslate"><span class="pre">src/llamafactory/data/mm_plugin.py</span></code> ä¸­å®ç° <code class="docutils literal notranslate"><span class="pre">Llama4Plugin</span></code> ç±»æ¥è§£æå¤šæ¨¡æ€æ•°æ®ã€‚</p>
<p><code class="docutils literal notranslate"><span class="pre">Llama4Plugin</span></code> ç±»ç»§æ‰¿è‡ª <code class="docutils literal notranslate"><span class="pre">BasePlugin</span></code> ç±»ï¼Œå¹¶å®ç°äº† <code class="docutils literal notranslate"><span class="pre">get_mm_inputs</span></code> å’Œ <code class="docutils literal notranslate"><span class="pre">process_messages</span></code> æ–¹æ³•æ¥è§£æå¤šæ¨¡æ€æ•°æ®ã€‚</p>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Llama4Plugin</span><span class="p">(</span><span class="n">BasePlugin</span><span class="p">):</span>
    <span class="nd">@override</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">process_messages</span><span class="p">(</span>
        <span class="o">...</span>
    <span class="nd">@override</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_mm_inputs</span><span class="p">(</span>
        <span class="o">...</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">get_mm_inputs</span></code> çš„ä½œç”¨æ˜¯å°†å›¾åƒã€è§†é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®è½¬åŒ–ä¸ºæ¨¡å‹å¯ä»¥æ¥æ”¶çš„è¾“å…¥ï¼Œå¦‚ <code class="docutils literal notranslate"><span class="pre">pixel_values</span></code>ã€‚ä¸ºå®ç° <code class="docutils literal notranslate"><span class="pre">get_mm_inputs</span></code>ï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦æ£€æŸ¥ llama4 çš„ processor æ˜¯å¦å¯ä»¥ä¸ <a class="reference external" href="https://github.com/hiyouga/LLaMA-Factory/blob/da971c37640de20f97b4d774e77e6f8d5c00b40a/src/llamafactory/data/mm_plugin.py#L264">å·²æœ‰å®ç°</a> å…¼å®¹ã€‚æ¨¡å‹å®˜æ–¹ä»“åº“ä¸­çš„ <a class="reference external" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama4/processing_llama4.py#L157">processing_llama4.py</a> è¡¨æ˜ llama4 çš„ processor è¿”å›æ•°æ®åŒ…å«å­—æ®µ <code class="docutils literal notranslate"><span class="pre">pixel_values</span></code>ï¼Œè¿™ä¸ LLaMA-Factory ä¸­çš„å·²æœ‰å®ç°å…¼å®¹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦å‚ç…§å·²æœ‰çš„ <code class="docutils literal notranslate"><span class="pre">get_mm_inputs</span></code> æ–¹æ³•å®ç°å³å¯ã€‚</p>
<div class="admonition note">
<p class="admonition-title">å¤‡æ³¨</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># https://github.com/hiyouga/LLaMA-Factory/blob/da971c37640de20f97b4d774e77e6f8d5c00b40a/src/llamafactory/data/mm_plugin.py#L264</span>
<span class="k">def</span><span class="w"> </span><span class="nf">_get_mm_inputs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">images</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;ImageInput&quot;</span><span class="p">],</span>
    <span class="n">videos</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;VideoInput&quot;</span><span class="p">],</span>
    <span class="n">audios</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="s2">&quot;AudioInput&quot;</span><span class="p">],</span>
    <span class="n">processor</span><span class="p">:</span> <span class="s2">&quot;MMProcessor&quot;</span><span class="p">,</span>
    <span class="n">imglens</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="s2">&quot;torch.Tensor&quot;</span><span class="p">]:</span>
    <span class="sa">r</span><span class="s2">&quot;&quot;&quot;Process visual inputs.</span>

<span class="s2">    Returns: (llava and paligemma)</span>
<span class="s2">        pixel_values: tensor with shape (B, C, H, W)</span>

<span class="s2">    Returns: (qwen2-vl)</span>
<span class="s2">        pixel_values: tensor with shape (num_patches, patch_dim)</span>
<span class="s2">        image_grid_thw: tensor with shape (num_images, 3), where the three numbers are time, width, height</span>
<span class="s2">        where num_patches == torch.prod(image_grid_thw)</span>

<span class="s2">    Returns: (mllama)</span>
<span class="s2">        pixel_values: tensor with shape</span>
<span class="s2">                    (batch_size, max_num_images, max_image_tiles, channels, tile_height, tile_width)</span>
<span class="s2">                    For example, (2, 1, 4, 3, 560, 560).</span>
<span class="s2">        aspect_ratio_ids: tensor with shape (batch_size, max_num_images). For example, (2, 1).</span>
<span class="s2">        aspect_ratio_mask: tensor with shape (batch_size, max_num_images, max_image_tiles). For example, (2, 1, 4).</span>
<span class="s2">        num_tiles: List[List[int]] with shape (batch_size, num_images_in_batch). For example, (2, 1).</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">process_messages</span></code> çš„ä½œç”¨æ˜¯æ ¹æ®è¾“å…¥å›¾ç‰‡/è§†é¢‘çš„å¤§å°ï¼Œæ•°é‡ç­‰ä¿¡æ¯åœ¨ messages ä¸­æ’å…¥ç›¸åº”æ•°é‡çš„å ä½ç¬¦ï¼Œä»¥ä¾¿æ¨¡å‹å¯ä»¥æ­£ç¡®è§£æå¤šæ¨¡æ€æ•°æ®ã€‚ æˆ‘ä»¬éœ€è¦å‚è€ƒ <a class="reference external" href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama4/processing_llama4.py#L157">åŸä»“åº“å®ç°</a> ä»¥åŠ LLaMA-Factory ä¸­çš„è§„èŒƒè¿”å› <code class="docutils literal notranslate"><span class="pre">list[dict[str,</span> <span class="pre">str]]</span></code> ç±»å‹çš„ messagesã€‚</p>
</section>
<section id="id5">
<h2>æä¾›æ¨¡å‹è·¯å¾„<a class="headerlink" href="#id5" title="Link to this heading">ïƒ</a></h2>
<p>æœ€å, åœ¨ <a class="reference external" href="https://github.com/hiyouga/LLaMA-Factory/blob/main/src/llamafactory/extras/constants.py">src/llamafactory/extras/constants.py</a> ä¸­æä¾›æ¨¡å‹çš„ä¸‹è½½è·¯å¾„ã€‚ä¾‹å¦‚ï¼š</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">register_model_group</span><span class="p">(</span>
<span class="n">models</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">&quot;Llama-4-Scout-17B-16E&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">:</span> <span class="s2">&quot;meta-llama/Llama-4-Scout-17B-16E&quot;</span><span class="p">,</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">MODELSCOPE</span><span class="p">:</span> <span class="s2">&quot;LLM-Research/Llama-4-Scout-17B-16E&quot;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;Llama-4-Scout-17B-16E-Instruct&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">:</span> <span class="s2">&quot;meta-llama/Llama-4-Scout-17B-16E-Instruct&quot;</span><span class="p">,</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">MODELSCOPE</span><span class="p">:</span> <span class="s2">&quot;LLM-Research/Llama-4-Scout-17B-16E-Instruct&quot;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;Llama-4-Maverick-17B-128E&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">:</span> <span class="s2">&quot;meta-llama/Llama-4-Maverick-17B-128E&quot;</span><span class="p">,</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">MODELSCOPE</span><span class="p">:</span> <span class="s2">&quot;LLM-Research/Llama-4-Maverick-17B-128E&quot;</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="s2">&quot;Llama-4-Maverick-17B-128E-Instruct&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">:</span> <span class="s2">&quot;meta-llama/Llama-4-Maverick-17B-128E-Instruct&quot;</span><span class="p">,</span>
        <span class="n">DownloadSource</span><span class="o">.</span><span class="n">MODELSCOPE</span><span class="p">:</span> <span class="s2">&quot;LLM-Research/Llama-4-Maverick-17B-128E-Instruct&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">},</span>
<span class="n">template</span><span class="o">=</span><span class="s2">&quot;llama4&quot;</span><span class="p">,</span>
<span class="n">multimodal</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>