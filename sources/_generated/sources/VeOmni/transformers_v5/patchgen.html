

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Modeling Code Generation &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Modeling Code Generation</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/sources/_generated/sources/VeOmni/transformers_v5/patchgen.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="modeling-code-generation">
<h1>Modeling Code Generation<a class="headerlink" href="#modeling-code-generation" title="Link to this heading">ïƒ</a></h1>
<p>A code generation framework for creating patched HuggingFace modeling files. Instead of runtime monkey patches that are hard to debug, this tool generates self-contained, readable modeling code with all patches applied at code-generation time.</p>
<section id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate patched Qwen3 GPU modeling code (writes to veomni/models/transformers/qwen3/generated/)</span>
python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config

<span class="c1"># With verbose output</span>
python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config<span class="w"> </span>-v

<span class="c1"># Dry run (preview without writing)</span>
python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config<span class="w"> </span>--dry-run

<span class="c1"># Custom output directory</span>
python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config<span class="w"> </span>-o<span class="w"> </span>/path/to/output

<span class="c1"># List available patch configurations</span>
python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>--list

<span class="c1"># Save unified diff alongside generated modeling code</span>
python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config<span class="w"> </span>--diff
</pre></div>
</div>
</section>
<section id="project-structure">
<h2>Project Structure<a class="headerlink" href="#project-structure" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>veomni/
â”œâ”€â”€ patchgen/
â”‚   â”œâ”€â”€ patch_spec.py              # Patch specification DSL
â”‚   â”œâ”€â”€ codegen.py                 # AST-based code generator
â”‚   â””â”€â”€ run_codegen.py             # CLI runner script
â””â”€â”€ models/
    â””â”€â”€ transformers/
        â””â”€â”€ qwen3/
            â”œâ”€â”€ patches/
            â”‚   â””â”€â”€ qwen3_gpu_patch_gen_config.py       # Qwen3 GPU patches
            â””â”€â”€ generated/
                â””â”€â”€ patched_modeling_qwen3_gpu.py  # Generated output
</pre></div>
</div>
</section>
<section id="core-design">
<h2>Core Design<a class="headerlink" href="#core-design" title="Link to this heading">ïƒ</a></h2>
<section id="the-problem">
<h3>The Problem<a class="headerlink" href="#the-problem" title="Link to this heading">ïƒ</a></h3>
<p>When adapting HuggingFace models for training frameworks (VeOmni, veRL, etc.), we need to apply various modifications:</p>
<ul class="simple">
<li><p><strong>Attention replacement</strong>: Custom flash attention, Ulysses sequence parallelism</p></li>
<li><p><strong>Kernel fusion</strong>: LigerKernel RMSNorm, fused rotary embeddings</p></li>
<li><p><strong>MoE optimizations</strong>: Fused MoE with expert parallelism</p></li>
<li><p><strong>Framework-specific code</strong>: Gradient checkpointing, loss computation</p></li>
</ul>
<p>Current approaches have significant drawbacks:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># BAD: Runtime monkey patching - hard to debug, order-dependent</span>
<span class="n">apply_ops_patch</span><span class="p">()</span>
<span class="n">apply_logprobs_patch</span><span class="p">()</span>
<span class="n">apply_xpu_patch</span><span class="p">()</span>

<span class="n">ALL_ATTENTION_FUNCTIONS</span><span class="p">[</span><span class="s2">&quot;flash_attention_2&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">my_impl</span>

<span class="k">class</span><span class="w"> </span><span class="nc">OptimizedQwen3Model</span><span class="p">(</span><span class="n">Qwen3Model</span><span class="p">):</span>
    <span class="o">...</span>
<span class="n">Qwen3Model</span> <span class="o">=</span> <span class="n">OptimizedQwen3Model</span>  <span class="c1"># Who knows what this is now?</span>
</pre></div>
</div>
<p><strong>Problems with monkey patching:</strong></p>
<ul class="simple">
<li><p>Cannot see the final patched code</p></li>
<li><p>Import order affects behavior</p></li>
<li><p>Difficult to debug</p></li>
<li><p>Multiple patches can conflict</p></li>
<li><p>Hard to maintain across HF version upgrades</p></li>
</ul>
</section>
<section id="the-solution">
<h3>The Solution<a class="headerlink" href="#the-solution" title="Link to this heading">ïƒ</a></h3>
<p>Generate a single, self-contained modeling file with all patches applied:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># GOOD: Generated file - everything is visible</span>
<span class="c1"># ======================================================================</span>
<span class="c1"># [PATCHED CLASS] Qwen3RMSNorm</span>
<span class="c1"># Reason: Use fused RMSNorm kernel for better performance</span>
<span class="c1"># ======================================================================</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Qwen3RMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">):</span>
        <span class="c1"># Patched implementation - fully visible</span>
        <span class="o">...</span>
</pre></div>
</div>
<p><strong>Benefits:</strong></p>
<ul class="simple">
<li><p>Complete visibility of final code</p></li>
<li><p>Easy to debug and understand</p></li>
<li><p>Clear documentation of what changed and why</p></li>
<li><p>No runtime surprises</p></li>
<li><p>Can diff against original HF code</p></li>
<li><p>Comments in patch code are preserved in output</p></li>
</ul>
</section>
<section id="design-principles">
<h3>Design Principles<a class="headerlink" href="#design-principles" title="Link to this heading">ïƒ</a></h3>
<ol class="simple">
<li><p><strong>AST-based transformation</strong>: Uses Python AST for robust code manipulation, not fragile regex</p></li>
<li><p><strong>Declarative patches</strong>: Define what to patch using decorators, not imperative monkey patches</p></li>
<li><p><strong>Source preservation</strong>: Extracts source from installed transformers at generation time</p></li>
<li><p><strong>Comment preservation</strong>: Comments in replacement code are preserved in the generated output</p></li>
<li><p><strong>Self-contained output</strong>: Generated file has no hidden dependencies on patch code</p></li>
</ol>
</section>
</section>
<section id="how-to-use">
<h2>How to Use<a class="headerlink" href="#how-to-use" title="Link to this heading">ïƒ</a></h2>
<section id="create-a-patch-configuration">
<h3>1. Create a Patch Configuration<a class="headerlink" href="#create-a-patch-configuration" title="Link to this heading">ïƒ</a></h3>
<p>Create a new file under <code class="docutils literal notranslate"><span class="pre">veomni/models/transformers/qwen3/</span></code> (for now we only ship Qwen3):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.patchgen.patch_spec</span><span class="w"> </span><span class="kn">import</span> <span class="n">PatchConfig</span>

<span class="c1"># Define the configuration</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">PatchConfig</span><span class="p">(</span>
    <span class="n">source_module</span><span class="o">=</span><span class="s2">&quot;transformers.models.qwen3.modeling_qwen3&quot;</span><span class="p">,</span>
    <span class="n">target_file</span><span class="o">=</span><span class="s2">&quot;patched_modeling_qwen3_gpu.py&quot;</span><span class="p">,</span>
    <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Qwen3 GPU patches&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="define-patches">
<h3>2. Define Patches<a class="headerlink" href="#define-patches" title="Link to this heading">ïƒ</a></h3>
<section id="class-replacement">
<h4>Class Replacement<a class="headerlink" href="#class-replacement" title="Link to this heading">ïƒ</a></h4>
<p>Replace an entire class with a custom implementation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@config</span><span class="o">.</span><span class="n">replace_class</span><span class="p">(</span><span class="s2">&quot;Qwen3RMSNorm&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Use fused kernel&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">OptimizedRMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">variance_epsilon</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">):</span>
        <span class="c1"># Your optimized implementation</span>
        <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="function-replacement">
<h4>Function Replacement<a class="headerlink" href="#function-replacement" title="Link to this heading">ïƒ</a></h4>
<p>Replace a module-level function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@config</span><span class="o">.</span><span class="n">replace_function</span><span class="p">(</span><span class="s2">&quot;apply_rotary_pos_emb&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Use fused RoPE&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">optimized_rotary_pos_emb</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">cos</span><span class="p">,</span> <span class="n">sin</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">unsqueeze_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># Your optimized implementation</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="method-override">
<h4>Method Override<a class="headerlink" href="#method-override" title="Link to this heading">ïƒ</a></h4>
<p>Replace a specific method within a class (keeps the rest of the class unchanged):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@config</span><span class="o">.</span><span class="n">override_method</span><span class="p">(</span><span class="s2">&quot;Qwen3Attention.forward&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Add Ulysses SP&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">ulysses_attention_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="n">position_embeddings</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
    <span class="c1"># Your modified forward pass</span>
    <span class="c1"># Comments here will be preserved in the generated output!</span>

    <span class="c1"># ==========================================================================</span>
    <span class="c1"># BEGIN ULYSSES SEQUENCE PARALLEL MODIFICATIONS</span>
    <span class="c1"># ==========================================================================</span>
    <span class="c1"># These comments will appear in the generated file</span>
    <span class="o">...</span>
</pre></div>
</div>
</section>
</section>
<section id="add-supporting-imports">
<h3>3. Add Supporting Imports<a class="headerlink" href="#add-supporting-imports" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add imports needed by your patches</span>
<span class="n">config</span><span class="o">.</span><span class="n">add_import</span><span class="p">(</span><span class="s2">&quot;torch.distributed&quot;</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">,</span> <span class="s2">&quot;all_reduce&quot;</span><span class="p">])</span>

<span class="c1"># Exclude classes you don&#39;t need</span>
<span class="n">config</span><span class="o">.</span><span class="n">exclude_from_output</span><span class="p">(</span><span class="s2">&quot;Qwen3ForTokenClassification&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="generate-code">
<h3>4. Generate Code<a class="headerlink" href="#generate-code" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config<span class="w"> </span>-v
</pre></div>
</div>
</section>
</section>
<section id="patch-types-reference">
<h2>Patch Types Reference<a class="headerlink" href="#patch-types-reference" title="Link to this heading">ïƒ</a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>Type</th>
<th>Decorator</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>Class Replacement</td>
<td><code>@config.replace_class("ClassName")</code></td>
<td>Replace entire class (e.g., RMSNorm -&gt; LigerRMSNorm)</td>
</tr>
<tr>
<td>Function Replacement</td>
<td><code>@config.replace_function("func_name")</code></td>
<td>Replace module-level function</td>
</tr>
<tr>
<td>Method Override</td>
<td><code>@config.override_method("Class.method")</code></td>
<td>Replace single method, keep rest of class</td>
</tr>
</tbody>
</table></section>
<section id="generated-output-format">
<h2>Generated Output Format<a class="headerlink" href="#generated-output-format" title="Link to this heading">ïƒ</a></h2>
<p>The generated file includes:</p>
<ol>
<li><p><strong>Header</strong> with metadata:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ==============================================================================</span>
<span class="c1">#  AUTO-GENERATED FILE - DO NOT EDIT DIRECTLY</span>
<span class="c1"># ==============================================================================</span>
<span class="c1">#  Source: transformers.models.qwen3.modeling_qwen3</span>
<span class="c1">#  Based on: transformers==4.57.3</span>
<span class="c1">#  Generated: 2026-01-25T10:30:00</span>
<span class="c1">#</span>
<span class="c1">#  Patches applied:</span>
<span class="c1">#    - class_replacement: Qwen3RMSNorm</span>
<span class="c1">#    - function_replacement: apply_rotary_pos_emb</span>
<span class="c1">#    - method_override: Qwen3Attention.forward</span>
<span class="c1"># ==============================================================================</span>
</pre></div>
</div>
</li>
<li><p><strong>Converted imports</strong> (relative -&gt; absolute):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Original relative import: from ...activations import ACT2FN</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers.activations</span><span class="w"> </span><span class="kn">import</span> <span class="n">ACT2FN</span>
</pre></div>
</div>
</li>
<li><p><strong>Patch markers</strong> for modified code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ======================================================================</span>
<span class="c1"># [PATCHED CLASS] Qwen3RMSNorm</span>
<span class="c1"># Reason: Use fused RMSNorm kernel for better performance</span>
<span class="c1"># ======================================================================</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Qwen3RMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
</li>
<li><p><strong>Preserved comments</strong> in patched methods:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ======================================================================</span>
<span class="c1"># [MODIFIED CLASS] Qwen3Attention</span>
<span class="c1"># Methods patched: forward</span>
<span class="c1"># ======================================================================</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Qwen3Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="o">...</span><span class="p">):</span>
        <span class="c1"># ==========================================================================</span>
        <span class="c1"># BEGIN ULYSSES SEQUENCE PARALLEL MODIFICATIONS</span>
        <span class="c1"># ==========================================================================</span>
        <span class="c1"># All your inline comments are preserved!</span>
        <span class="o">...</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="example-qwen3-gpu-patches">
<h2>Example: Qwen3 GPU Patches<a class="headerlink" href="#example-qwen3-gpu-patches" title="Link to this heading">ïƒ</a></h2>
<p>See <code class="docutils literal notranslate"><span class="pre">veomni/models/transformers/qwen3/qwen3_gpu_patch_gen_config.py</span></code> for a complete example that includes:</p>
<ul class="simple">
<li><p><strong>LigerRMSNorm</strong>: Fused kernel replacement for <code class="docutils literal notranslate"><span class="pre">Qwen3RMSNorm</span></code></p></li>
<li><p><strong>LigerSwiGLUMLP</strong>: Fused SwiGLU MLP replacement for <code class="docutils literal notranslate"><span class="pre">Qwen3MLP</span></code></p></li>
<li><p><strong>apply_rotary_pos_emb</strong>: LigerKernel rotary position embedding</p></li>
</ul>
<p>Run it:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config<span class="w"> </span>-v
</pre></div>
</div>
<p>Output: <code class="docutils literal notranslate"><span class="pre">veomni/models/transformers/qwen3/generated/patched_modeling_qwen3_gpu.py</span></code> (~600 lines of self-contained code)</p>
</section>
<section id="comparing-generated-vs-original-code">
<h2>Comparing Generated vs Original Code<a class="headerlink" href="#comparing-generated-vs-original-code" title="Link to this heading">ïƒ</a></h2>
<p>Use the <code class="docutils literal notranslate"><span class="pre">--diff</span></code> flag to save a unified diff file next to the generated modeling file:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate patched modeling code and save a .diff file in output directory</span>
python<span class="w"> </span>-m<span class="w"> </span>veomni.patchgen.run_codegen<span class="w"> </span>veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config<span class="w"> </span>--diff
</pre></div>
</div>
<p>With <code class="docutils literal notranslate"><span class="pre">--diff</span></code>, <code class="docutils literal notranslate"><span class="pre">run_codegen</span></code> writes:</p>
<ul class="simple">
<li><p>Compares the generated file against the original HuggingFace source</p></li>
<li><p>Saves unified diff as <code class="docutils literal notranslate"><span class="pre">&lt;generated_modeling_name&gt;.diff</span></code> in the output directory</p></li>
<li><p>Shows exactly which classes, methods, and functions were modified</p></li>
</ul>
<p>Example output:</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="gd">-class Qwen3RMSNorm(nn.Module):</span>
<span class="gd">-    def forward(self, hidden_states):</span>
<span class="gd">-        input_dtype = hidden_states.dtype</span>
<span class="gd">-        hidden_states = hidden_states.to(torch.float32)</span>
<span class="gd">-        ...</span>
<span class="gi">+# ======================================================================</span>
<span class="gi">+# [PATCHED CLASS] Qwen3RMSNorm</span>
<span class="gi">+# Reason: Use fused RMSNorm kernel for better performance</span>
<span class="gi">+# ======================================================================</span>
<span class="gi">+class Qwen3RMSNorm(nn.Module):</span>
<span class="gi">+    def forward(self, hidden_states):</span>
<span class="gi">+        # Optimized implementation with comments preserved</span>
<span class="gi">+        ...</span>
</pre></div>
</div>
</section>
<section id="advanced-usage">
<h2>Advanced Usage<a class="headerlink" href="#advanced-usage" title="Link to this heading">ïƒ</a></h2>
<section id="external-class-references">
<h3>External Class References<a class="headerlink" href="#external-class-references" title="Link to this heading">ïƒ</a></h3>
<p>For large classes from external libraries, reference them without copying source:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.patchgen.patch_spec</span><span class="w"> </span><span class="kn">import</span> <span class="n">create_patch_from_external</span>

<span class="n">patch</span> <span class="o">=</span> <span class="n">create_patch_from_external</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;Qwen3RMSNorm&quot;</span><span class="p">,</span>
    <span class="n">replacement_module</span><span class="o">=</span><span class="s2">&quot;liger_kernel.transformers.rms_norm&quot;</span><span class="p">,</span>
    <span class="n">replacement_name</span><span class="o">=</span><span class="s2">&quot;LigerRMSNorm&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">patches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">patch</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="programmatic-generation">
<h3>Programmatic Generation<a class="headerlink" href="#programmatic-generation" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">codegen</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelingCodeGenerator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config</span><span class="w"> </span><span class="kn">import</span> <span class="n">config</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">ModelingCodeGenerator</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">generator</span><span class="o">.</span><span class="n">load_source</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">generator</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;veomni/models/transformers/qwen3/generated/patched_modeling_qwen3_gpu.py&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="init-modification">
<h3>Init Modification<a class="headerlink" href="#init-modification" title="Link to this heading">ïƒ</a></h3>
<p>Modify <code class="docutils literal notranslate"><span class="pre">__init__</span></code> methods without replacing the entire class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@config</span><span class="o">.</span><span class="n">modify_init</span><span class="p">(</span><span class="s2">&quot;Qwen3Attention&quot;</span><span class="p">)</span>
<span class="k">def</span><span class="w"> </span><span class="nf">modified_init</span><span class="p">(</span><span class="n">original_init</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">):</span>
    <span class="n">original_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">custom_attr</span> <span class="o">=</span> <span class="n">some_value</span>
</pre></div>
</div>
</section>
</section>
<section id="cli-reference">
<h2>CLI Reference<a class="headerlink" href="#cli-reference" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">veomni</span><span class="o">.</span><span class="n">patchgen</span><span class="o">.</span><span class="n">run_codegen</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">o</span> <span class="n">OUTPUT_DIR</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">c</span> <span class="n">CONFIG_NAME</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="nb">list</span><span class="p">]</span>
                      <span class="p">[</span><span class="o">--</span><span class="n">dry</span><span class="o">-</span><span class="n">run</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">diff</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">v</span><span class="p">]</span>
                      <span class="p">[</span><span class="n">patch_module</span><span class="p">]</span>

<span class="n">positional</span> <span class="n">arguments</span><span class="p">:</span>
  <span class="n">patch_module</span>          <span class="n">Patch</span> <span class="n">module</span> <span class="n">to</span> <span class="n">use</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="p">,</span> <span class="s1">&#39;veomni.models.transformers.qwen3.qwen3_gpu_patch_gen_config&#39;</span><span class="p">)</span>

<span class="n">options</span><span class="p">:</span>
  <span class="o">-</span><span class="n">h</span><span class="p">,</span> <span class="o">--</span><span class="n">help</span>            <span class="n">Show</span> <span class="n">help</span> <span class="n">message</span>
  <span class="o">-</span><span class="n">o</span><span class="p">,</span> <span class="o">--</span><span class="n">output</span><span class="o">-</span><span class="nb">dir</span>      <span class="n">Output</span> <span class="n">directory</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="n">sibling</span> <span class="n">generated</span><span class="o">/</span> <span class="nb">next</span> <span class="n">to</span> <span class="n">patch</span> <span class="n">module</span><span class="p">)</span>
  <span class="o">-</span><span class="n">c</span><span class="p">,</span> <span class="o">--</span><span class="n">config</span><span class="o">-</span><span class="n">name</span>     <span class="n">Config</span> <span class="n">variable</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">patch</span> <span class="n">module</span> <span class="p">(</span><span class="n">default</span><span class="p">:</span> <span class="n">config</span><span class="p">)</span>
  <span class="o">--</span><span class="nb">list</span>                <span class="n">List</span> <span class="n">available</span> <span class="n">patch</span> <span class="n">configurations</span>
  <span class="o">--</span><span class="n">dry</span><span class="o">-</span><span class="n">run</span>             <span class="n">Show</span> <span class="n">what</span> <span class="n">would</span> <span class="n">be</span> <span class="n">generated</span> <span class="n">without</span> <span class="n">writing</span> <span class="n">files</span>
  <span class="o">--</span><span class="n">diff</span>                <span class="n">Save</span> <span class="n">a</span> <span class="n">unified</span> <span class="o">.</span><span class="n">diff</span> <span class="n">file</span> <span class="n">alongside</span> <span class="n">generated</span> <span class="n">modeling</span> <span class="n">code</span>
  <span class="o">-</span><span class="n">v</span><span class="p">,</span> <span class="o">--</span><span class="n">verbose</span>         <span class="n">Print</span> <span class="n">detailed</span> <span class="n">progress</span>
</pre></div>
</div>
</section>
<section id="background-why-not-monkey-patching">
<h2>Background: Why Not Monkey Patching?<a class="headerlink" href="#background-why-not-monkey-patching" title="Link to this heading">ïƒ</a></h2>
<section id="existing-approaches-and-their-trade-offs">
<h3>Existing Approaches and Their Trade-offs<a class="headerlink" href="#existing-approaches-and-their-trade-offs" title="Link to this heading">ïƒ</a></h3>
<table border="1" class="docutils">
<thead>
<tr>
<th>Approach</th>
<th>Example</th>
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Monkey Patching</strong></td>
<td>veRL</td>
<td>Reuses HF code</td>
<td>Hard to debug, order-dependent</td>
</tr>
<tr>
<td><strong>Copy + Modify</strong></td>
<td>VeOmni</td>
<td>Fully visible code</td>
<td>Manual maintenance, drift from HF</td>
</tr>
<tr>
<td><strong>Inheritance</strong></td>
<td>Various</td>
<td>Code reuse</td>
<td>Deep inheritance chains</td>
</tr>
<tr>
<td><strong>Custom Backend</strong></td>
<td>vLLM</td>
<td>Maximum optimization</td>
<td>Accuracy black hole</td>
</tr>
</tbody>
</table></section>
<section id="this-tool-s-approach">
<h3>This Tool's Approach<a class="headerlink" href="#this-tool-s-approach" title="Link to this heading">ïƒ</a></h3>
<p>Inspired by HuggingFace's own <code class="docutils literal notranslate"><span class="pre">modular_model_converter.py</span></code>, we:</p>
<ol class="simple">
<li><p><strong>Define patches declaratively</strong> in Python files</p></li>
<li><p><strong>Generate code at build time</strong>, not runtime</p></li>
<li><p><strong>Produce readable output</strong> with clear patch markers</p></li>
<li><p><strong>Preserve comments</strong> from patch definitions</p></li>
<li><p><strong>Support easy regeneration</strong> when HF updates</p></li>
</ol>
</section>
</section>
<section id="common-patch-scenarios">
<h2>Common Patch Scenarios<a class="headerlink" href="#common-patch-scenarios" title="Link to this heading">ïƒ</a></h2>
<table border="1" class="docutils">
<thead>
<tr>
<th>Scenario</th>
<th>Patch Type</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fused kernels (LigerKernel)</td>
<td>Class replacement</td>
<td>RMSNorm, SwiGLU</td>
</tr>
<tr>
<td>Optimized RoPE</td>
<td>Function replacement</td>
<td>apply_rotary_pos_emb</td>
</tr>
<tr>
<td>Sequence parallelism</td>
<td>Method override</td>
<td>Attention.forward</td>
</tr>
<tr>
<td>Expert parallelism</td>
<td>Method override</td>
<td>MoE.forward</td>
</tr>
<tr>
<td>Custom loss</td>
<td>Function replacement</td>
<td>cross_entropy</td>
</tr>
<tr>
<td>VLM modifications</td>
<td>Method override</td>
<td>Model.forward</td>
</tr>
</tbody>
</table></section>
<section id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Link to this heading">ïƒ</a></h2>
<ul class="simple">
<li><p><strong>Python 3.9+</strong> required (uses <code class="docutils literal notranslate"><span class="pre">ast.unparse</span></code>)</p></li>
<li><p>Generated code may need manual adjustment for complex patches</p></li>
<li><p>Some HF decorators (e.g., <code class="docutils literal notranslate"><span class="pre">&#64;use_kernel_forward_from_hub</span></code>) may need special handling</p></li>
<li><p>Does not handle dynamic/conditional patches (use config flags in patches instead)</p></li>
</ul>
</section>
<section id="contributing">
<h2>Contributing<a class="headerlink" href="#contributing" title="Link to this heading">ïƒ</a></h2>
<p>To add support for a new model:</p>
<ol class="simple">
<li><p>Create <code class="docutils literal notranslate"><span class="pre">veomni/models/transformers/&lt;model&gt;/patches/&lt;model&gt;_patches.py</span></code></p></li>
<li><p>Define your <code class="docutils literal notranslate"><span class="pre">PatchConfig</span></code> and patches</p></li>
<li><p>Test with <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">veomni.patchgen.run_codegen</span> <span class="pre">veomni.models.transformers.&lt;model&gt;.patches.&lt;model&gt;_patches</span> <span class="pre">--dry-run</span></code></p></li>
<li><p>Generate and verify the output in <code class="docutils literal notranslate"><span class="pre">veomni/models/transformers/&lt;model&gt;/generated/</span></code></p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">--diff</span></code> to review changes against original HF code</p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>