

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Transformers v5 MoE Weight Loading &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Transformers v5 MoE Weight Loading</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/sources/_generated/sources/VeOmni/transformers_v5/transformers_v5_moe_weight_loading.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="transformers-v5-moe-weight-loading">
<h1>Transformers v5 MoE Weight Loading<a class="headerlink" href="#transformers-v5-moe-weight-loading" title="Link to this heading">ïƒ</a></h1>
<p>This note documents VeOmni MoE weight-loading expectations for <code class="docutils literal notranslate"><span class="pre">transformers&gt;=5.0.0</span></code>.</p>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Link to this heading">ïƒ</a></h2>
<p>Transformers v5 introduced expert-dispatch integration points (<code class="docutils literal notranslate"><span class="pre">use_experts_implementation</span></code> and <code class="docutils literal notranslate"><span class="pre">ALL_EXPERTS_FUNCTIONS</span></code>).</p>
<p>For VeOmni qwen3_moe transformers v5 path, we use a simpler path:</p>
<ul class="simple">
<li><p>patch experts behavior in generated modeling;</p></li>
<li><p>call <code class="docutils literal notranslate"><span class="pre">veomni.ops.fused_moe_forward(...)</span></code> explicitly in the patched forward;</p></li>
<li><p>keep <code class="docutils literal notranslate"><span class="pre">_moe_implementation</span></code> (<code class="docutils literal notranslate"><span class="pre">eager</span></code> or <code class="docutils literal notranslate"><span class="pre">fused</span></code>) as runtime selection.</p></li>
</ul>
</section>
<section id="survey-qwen-moe-weight-formats">
<h2>Survey: Qwen MoE Weight Formats<a class="headerlink" href="#survey-qwen-moe-weight-formats" title="Link to this heading">ïƒ</a></h2>
<p>Reference mapping from HF:</p>
<ul class="simple">
<li><p>https://github.com/huggingface/transformers/blob/v5.2.0/src/transformers/conversion_mapping.py</p></li>
</ul>
<section id="qwen3-moe">
<h3>qwen3_moe<a class="headerlink" href="#qwen3-moe" title="Link to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p>Sample checkpoint: https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507</p></li>
<li><p>HF safetensor expert layout (per-expert split keys):</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>model.layers.0.mlp.experts.0.gate_proj.weight  [I, H]
model.layers.0.mlp.experts.0.up_proj.weight    [I, H]
model.layers.0.mlp.experts.0.down_proj.weight  [H, I]
</pre></div>
</div>
<ul class="simple">
<li><p>Transformers v5 modeling layout:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">gate_up_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>
<span class="bp">self</span><span class="o">.</span><span class="n">down_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_dim</span><span class="p">))</span>
</pre></div>
</div>
<p>Handling summary:</p>
<ul class="simple">
<li><p>safetensor keys are per expert, while v5 expects merged expert tensors;</p></li>
<li><p>for VeOmni qwen3_moe training, run offline merge first via <code class="docutils literal notranslate"><span class="pre">scripts/moe_ckpt_merge/moe_merge.py</span></code>.</p></li>
</ul>
<p>Other Qwen3 family models with similar layout like qwen3_moe (i.e., per-expert split keys in safetensors):</p>
<ul class="simple">
<li><p>Qwen3 Next: https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct</p></li>
<li><p>Qwen3 Omni: https://huggingface.co/Qwen/Qwen3-Omni-30B-A3B-Instruct</p></li>
</ul>
</section>
<section id="qwen3-vl-moe">
<h3>qwen3_vl_moe<a class="headerlink" href="#qwen3-vl-moe" title="Link to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p>Sample checkpoint: https://huggingface.co/Qwen/Qwen3-VL-30B-A3B-Instruct</p></li>
<li><p>HF safetensor layout:</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>model.language_model.layers.0.mlp.experts.gate_up_proj  [num_experts, H, 2 * I]
model.language_model.layers.0.mlp.experts.down_proj     [num_experts, I, H]
</pre></div>
</div>
<ul class="simple">
<li><p>Transformers v5 modeling layout:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">gate_up_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>
<span class="bp">self</span><span class="o">.</span><span class="n">down_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_dim</span><span class="p">))</span>
</pre></div>
</div>
<p>Handling summary:</p>
<ul class="simple">
<li><p>v5 layout is transposed vs the safetensor dimension order for these tensors;</p></li>
<li><p>tensor transpose/conversion is required before direct v5 loading.</p></li>
</ul>
</section>
<section id="qwen3-5-moe">
<h3>qwen3_5_moe<a class="headerlink" href="#qwen3-5-moe" title="Link to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p>Sample checkpoint: https://huggingface.co/Qwen/Qwen3.5-397B-A17B</p></li>
<li><p>HF safetensor layout:</p></li>
</ul>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>model.language_model.layers.0.mlp.experts.gate_up_proj  [num_experts, 2 * I, H]
model.language_model.layers.0.mlp.experts.down_proj     [num_experts, H, I]
</pre></div>
</div>
<ul class="simple">
<li><p>Transformers v5 modeling layout:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="bp">self</span><span class="o">.</span><span class="n">gate_up_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>
<span class="bp">self</span><span class="o">.</span><span class="n">down_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_experts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">intermediate_dim</span><span class="p">))</span>
</pre></div>
</div>
<p>Handling summary:</p>
<ul class="simple">
<li><p>no special remap/transpose needed for shape semantics.</p></li>
</ul>
</section>
</section>
<section id="qwen3moe-handling-in-veomni">
<h2>Qwen3Moe Handling in VeOmni<a class="headerlink" href="#qwen3moe-handling-in-veomni" title="Link to this heading">ïƒ</a></h2>
<p>For qwen3_moe, VeOmni keeps split expert tensors in patched modeling:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">gate_proj</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">up_proj</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">down_proj</span></code></p></li>
</ul>
<p>This differs from native Transformers v5 <code class="docutils literal notranslate"><span class="pre">gate_up_proj</span></code> layout.</p>
<p>Checkpoint loading behavior:</p>
<ul class="simple">
<li><p>VeOmni does not do runtime remapping from legacy per-expert keys;</p></li>
<li><p>HuggingFace safetensor checkpoints commonly store expert weights in per-expert form.</p></li>
</ul>
<p>To avoid loading/mapping issues, merge weights offline before training:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scripts/moe_ckpt_merge/moe_merge.py</span></code></p></li>
</ul>
</section>
<section id="veomni-fused-moe-op-interface">
<h2>VeOmni Fused MoE Op Interface<a class="headerlink" href="#veomni-fused-moe-op-interface" title="Link to this heading">ïƒ</a></h2>
<p>VeOmni fused MoE entrypoint:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">veomni.ops.fused_moe.fused_moe_forward(...)</span></code></p></li>
</ul>
<p>Current signature:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fused_moe_forward</span><span class="p">(</span>
    <span class="n">module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">num_experts</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">routing_weights</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">selected_experts</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fc1_1_weight</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fc1_2_weight</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fc2_weight</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Expected tensor interface:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hidden_states</span></code>: token-major hidden states used by experts, shape <code class="docutils literal notranslate"><span class="pre">[num_tokens,</span> <span class="pre">hidden_dim]</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">routing_weights</span></code>: router top-k probabilities, shape <code class="docutils literal notranslate"><span class="pre">[num_tokens,</span> <span class="pre">top_k]</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">selected_experts</span></code>: router top-k expert indices, shape <code class="docutils literal notranslate"><span class="pre">[num_tokens,</span> <span class="pre">top_k]</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fc1_1_weight</span></code> (gate): shape <code class="docutils literal notranslate"><span class="pre">[num_experts,</span> <span class="pre">intermediate_dim,</span> <span class="pre">hidden_dim]</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fc1_2_weight</span></code> (up): shape <code class="docutils literal notranslate"><span class="pre">[num_experts,</span> <span class="pre">intermediate_dim,</span> <span class="pre">hidden_dim]</span></code>;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fc2_weight</span></code> (down): shape <code class="docutils literal notranslate"><span class="pre">[num_experts,</span> <span class="pre">hidden_dim,</span> <span class="pre">intermediate_dim]</span></code>.</p></li>
</ul>
<p>Important constraints:</p>
<ul class="simple">
<li><p>op expects split gate/up tensors (<code class="docutils literal notranslate"><span class="pre">fc1_1_weight</span></code> and <code class="docutils literal notranslate"><span class="pre">fc1_2_weight</span></code>), not a merged <code class="docutils literal notranslate"><span class="pre">gate_up_proj</span></code> tensor;</p></li>
<li><p>needs to be <code class="docutils literal notranslate"><span class="pre">.contiguous()</span></code>.</p></li>
</ul>
</section>
<section id="future-work-align-with-transformers-v5-weight-formatting">
<h2>Future Work: Align with Transformers v5 Weight Formatting<a class="headerlink" href="#future-work-align-with-transformers-v5-weight-formatting" title="Link to this heading">ïƒ</a></h2>
<p>To reduce integration friction and runtime overhead, we should converge toward v5-native MoE weight handling.</p>
<ul>
<li><p>For models whose safetensor layout is already close to Transformers v5 (for example, <code class="docutils literal notranslate"><span class="pre">qwen3_5_moe</span></code>), add fused-op support for v5-native MoE tensors directly.
This avoids extra offline remapping and avoids runtime reshape/copy steps such as <code class="docutils literal notranslate"><span class="pre">.contiguous()</span></code> in expert forward paths.</p></li>
<li><p>For models with layout mismatch (for example, <code class="docutils literal notranslate"><span class="pre">qwen3_moe</span></code>), we still need to choose one stable strategy:</p>
<ol class="simple">
<li><p>Offline remap to v5 format before training.</p></li>
<li><p>Runtime remap during model loading.</p></li>
</ol>
<ul class="simple">
<li><p>Tradeoffs:</p>
<ol class="simple">
<li><p>Offline remap: lower runtime complexity and more predictable execution, but adds preprocessing burden and user error risk.</p></li>
<li><p>Runtime remap: less user preprocessing and easier onboarding, but adds loader complexity and may introduce runtime variability.</p></li>
</ol>
</li>
</ul>
</li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>