

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Basic Modules &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Basic Modules</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../_sources/sources/_generated/sources/VeOmni/usage/basic_modules.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="basic-modules">
<h1>Basic Modules<a class="headerlink" href="#basic-modules" title="Link to this heading">ïƒ</a></h1>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Link to this heading">ïƒ</a></h2>
<ol>
<li><p><strong>Install VeOmni</strong><br />Please refer to <a class="reference internal" href="../get_started/installation/install.html"><span class="doc">Install</span></a> for detailed instructions.</p></li>
<li><p><strong>Run Example Script</strong><br />Verify training startup: (need download the dataset first)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>train.sh<span class="w"> </span>tasks/train_torch.py<span class="w"> </span>configs/pretrain/qwen2_5.yaml
</pre></div>
</div>
</li>
<li><p><strong>Create Custom Task Directory</strong><br /><a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/tasks/train_torch.py"><code class="docutils literal notranslate"><span class="pre">train_torch.py</span></code></a> can be used for most of task pre-training and post-training tasks, you can just modify the train config to complete your task. However, if you want to create a new task, you can copy the <code class="docutils literal notranslate"><span class="pre">train_torch.py</span></code> file from the <code class="docutils literal notranslate"><span class="pre">tasks</span></code> directory and modify it. like <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/tasks/omni/train_qwen2_vl.py"><code class="docutils literal notranslate"><span class="pre">tasks/omni/train_qwen2_vl.py</span></code></a></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>tasks/your_task
cp<span class="w"> </span>tasks/train_torch.py<span class="w"> </span>tasks/your_task/train.py
</pre></div>
</div>
</li>
<li><p><strong>Launch Custom Training</strong><br />You can overwrite the default arguments in train yaml by passing them to the script.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bash<span class="w"> </span>train.sh<span class="w"> </span>tasks/your_task/train.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="nv">$CONFIG</span>.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model.model_path<span class="w"> </span>your_path_to_model<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--data.train_path<span class="w"> </span>your_path_to_dataset<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--train.output_dir<span class="w"> </span>your_path_to_save_checkpoints<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--train.wandb_project<span class="w"> </span>your_project_name<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--train.wandb_name<span class="w"> </span>your_experiment_name
</pre></div>
</div>
</li>
</ol>
</section>
<section id="arguments">
<h2>Arguments<a class="headerlink" href="#arguments" title="Link to this heading">ïƒ</a></h2>
<p><strong>Default Parameter Access</strong>:<br />veomni offers a unified argument management system, which can be easily extended to support custom arguments. About the default arguments explanation, you can refer to the <a class="reference internal" href="arguments.html"><span class="doc">Config arguments Explanation</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">veomni.arguments</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataArguments</span><span class="p">,</span> <span class="n">ModelArguments</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">parse_args</span>

<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Arguments</span><span class="p">:</span>
    <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;ModelArguments&quot;</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">ModelArguments</span><span class="p">)</span>
    <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;DataArguments&quot;</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">DataArguments</span><span class="p">)</span>
    <span class="n">train</span><span class="p">:</span> <span class="s2">&quot;TrainingArguments&quot;</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">TrainingArguments</span><span class="p">)</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parse_args</span><span class="p">(</span><span class="n">Arguments</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>  <span class="c1"># Access default arguments</span>
</pre></div>
</div>
<p><strong>Custom Parameter Extension</strong>:<br />you can extend the default arguments by creating a new class that inherits from the existing class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">CustomTrainingArguments</span><span class="p">(</span><span class="n">TrainingArguments</span><span class="p">):</span>
    <span class="n">enable_xxx</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Enable me if necessary.&quot;</span><span class="p">},</span>
    <span class="p">)</span>

<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">Arguments</span><span class="p">:</span>
    <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;ModelArguments&quot;</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">ModelArguments</span><span class="p">)</span>
    <span class="n">data</span><span class="p">:</span> <span class="s2">&quot;DataArguments&quot;</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">DataArguments</span><span class="p">)</span>
    <span class="n">train</span><span class="p">:</span> <span class="s2">&quot;CustomTrainingArguments&quot;</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="n">CustomTrainingArguments</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="parallel-state">
<h2>Parallel State<a class="headerlink" href="#parallel-state" title="Link to this heading">ïƒ</a></h2>
<p>VeOmni use torch device mesh to manage all the parallel state, which is useful and concise when working with multi-dimensional parallelism (i.e. 3-D parallel) where parallelism composability is required. You can create the parallel state by calling the <code class="docutils literal notranslate"><span class="pre">init_parallel_state</span></code> function. and get the parallel state by calling the <code class="docutils literal notranslate"><span class="pre">get_parallel_state</span></code> function.</p>
<p>More details about torch device mesh, you can refer to the <a class="reference external" href="https://pytorch.org/tutorials/recipes/distributed_device_mesh.html">Getting Started with DeviceMesh</a>.</p>
<ul class="simple">
<li><p>source code <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/distributed/parallel_state.py">veomni/distributed/parallel_state.py</a>.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.distributed.parallel_state</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_parallel_state</span><span class="p">,</span> <span class="n">init_parallel_state</span>

<span class="n">init_parallel_state</span><span class="p">(</span>
    <span class="n">dp_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">data_parallel_size</span><span class="p">,</span> <span class="c1"># data parallel size</span>
    <span class="n">dp_replicate_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">data_parallel_replicate_size</span><span class="p">,</span> <span class="c1"># data parallel replicate size</span>
    <span class="n">dp_shard_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">data_parallel_shard_size</span><span class="p">,</span> <span class="c1"># data parallel shard degree</span>
    <span class="n">tp_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">tensor_parallel_size</span><span class="p">,</span> <span class="c1"># tensor parallel size</span>
    <span class="n">ep_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">expert_parallel_size</span><span class="p">,</span> <span class="c1"># expert parallel size</span>
    <span class="n">pp_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">pipeline_parallel_size</span><span class="p">,</span> <span class="c1"># pipeline parallel size, not support now</span>
    <span class="n">cp_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">context_parallel_size</span><span class="p">,</span> <span class="c1"># context parallel size, not support now</span>
    <span class="n">ulysses_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ulysses_parallel_size</span><span class="p">,</span> <span class="c1"># ulysses parallel size</span>
    <span class="n">dp_mode</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">data_parallel_mode</span><span class="p">,</span> <span class="c1"># data parallel mode, can be &quot;ddp&quot;, &quot;fsdp1&quot;, &quot;fsdp2&quot;</span>
<span class="p">)</span>

<span class="n">parallel_state</span> <span class="o">=</span> <span class="n">get_parallel_state</span><span class="p">()</span>

<span class="c1"># Access dp state</span>
<span class="n">dp_mesh</span> <span class="o">=</span> <span class="n">parallel_state</span><span class="o">.</span><span class="n">dp_mesh</span>
<span class="n">dp_group</span> <span class="o">=</span> <span class="n">parallel_state</span><span class="o">.</span><span class="n">dp_group</span>

<span class="c1"># Access sp state</span>
<span class="n">sp_group</span> <span class="o">=</span> <span class="n">parallel_state</span><span class="o">.</span><span class="n">sp_group</span>
<span class="n">sp_rank</span> <span class="o">=</span> <span class="n">parallel_state</span><span class="o">.</span><span class="n">sp_rank</span>

<span class="c1"># Access tp state</span>
<span class="n">tp_group</span> <span class="o">=</span> <span class="n">parallel_state</span><span class="o">.</span><span class="n">tp_group</span>
<span class="n">tp_mesh</span> <span class="o">=</span> <span class="n">parallel_state</span><span class="o">.</span><span class="n">tp_mesh</span>
</pre></div>
</div>
</section>
<section id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Link to this heading">ïƒ</a></h2>
<p>VeOmni default supports two types of datasets(source code: <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/data/dataset.py">veomni/data/dataset.py</a>):</p>
<ol class="simple">
<li><p><strong>IterativeDataset</strong> (recommended for large datasets)</p></li>
<li><p><strong>MappingDataset</strong> (default for small datasets)</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_dataset</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">build_dataset</span><span class="p">(</span>
    <span class="n">dataset_name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
    <span class="n">dataloader_batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">dataloader_batch_size</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
    <span class="o">**</span><span class="n">asdict</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p><strong>Note</strong>:</p>
<p>args.train.compute_train_steps is used to compute the number of training steps. without this, the train steps will be computed incorrectly.</p>
<p>If your dataset is iterable, you are recommended to add data.train_size (the token you want to consume) to the config file, the <code class="docutils literal notranslate"><span class="pre">train_steps</span></code> will approximate to <code class="docutils literal notranslate"><span class="pre">train_size</span> <span class="pre">/</span> <span class="pre">(global_batch_size</span> <span class="pre">*</span> <span class="pre">max_seq_len)</span></code> (without any warm strategy).</p>
<p>If your dataset is mapping, you are recommended to pass len(train_dataset) to the <code class="docutils literal notranslate"><span class="pre">train_steps</span></code> to compute the correct train steps.</p>
</div></blockquote>
<section id="custom-datasets">
<h3>Custom Datasets<a class="headerlink" href="#custom-datasets" title="Link to this heading">ïƒ</a></h3>
<p>VeOmni is a flexible framework that supports custom datasets. You can implement your own dataset function and use it with VeOmni.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">build_custom_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">transform</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="c1"># Implement your custom dataset logic</span>
    <span class="k">pass</span>

<span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">datasets_type</span> <span class="o">==</span> <span class="s2">&quot;custom&quot;</span><span class="p">:</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info_rank0</span><span class="p">(</span><span class="s2">&quot;Start building custom dataset&quot;</span><span class="p">)</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">build_custom_dataset</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_path</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
    <span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">compute_train_steps</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span> <span class="c1"># compute train steps, remove the len(train_dataset) if your dataset is iterable</span>
</pre></div>
</div>
</section>
<section id="data-transform-preprocess">
<h3>Data Transform (Preprocess)<a class="headerlink" href="#data-transform-preprocess" title="Link to this heading">ïƒ</a></h3>
<p>VeOmni default supports two types of transform(source code: <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/data/data_transform.py">veomni/data/data_transform.py</a>):</p>
<ol class="simple">
<li><p><strong>process_pretrain_example</strong> (recommended for pretrain task)</p></li>
<li><p><strong>process_sft_example</strong> (recommended for sft task)</p></li>
</ol>
<p><strong>Pretrain Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">veomni.data.data_transform</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_pretrain_example</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">veomni.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_tokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">build_tokenizer</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">tokenizer_path</span><span class="p">)</span>
<span class="c1"># Can replace with the following code if you want to use the AutoTokenizer from transformers.</span>
<span class="c1"># tokenizer = AutoTokenizer.from_pretrained(args.model.tokenizer_path)</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">process_pretrain_example</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">max_seq_len</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>SFT Example</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.data.chat_template</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_chat_template</span>

<span class="n">chat_template</span> <span class="o">=</span> <span class="n">build_chat_template</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">chat_template</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">process_sft_example</span><span class="p">,</span>
    <span class="n">chat_template</span><span class="o">=</span><span class="n">chat_template</span><span class="p">,</span>
    <span class="n">max_seq_len</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="chat-template">
<h3>Chat Template<a class="headerlink" href="#chat-template" title="Link to this heading">ïƒ</a></h3>
<p>VeOmni default supports few chat template(source code: <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/data/chat_template.py">veomni/data/chat_template.py</a>):
you can add your custom chat template by implementing the <code class="docutils literal notranslate"><span class="pre">ChatTemplate</span></code> class.
<strong>Custom Template Implementation</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.data.chat_template</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatTemplate</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CustomTemplate</span><span class="p">(</span><span class="n">ChatTemplate</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">encode_messages</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8192</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]:</span>
        <span class="c1"># Implement encoding logic</span>
        <span class="k">pass</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_jinja_template</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>  <span class="c1"># Jinja template string</span>
</pre></div>
</div>
</section>
</section>
<section id="dataloader">
<h2>DataLoader<a class="headerlink" href="#dataloader" title="Link to this heading">ïƒ</a></h2>
<p>VeOmni offered a flexible and powerful dataloader implementation, which supports</p>
<ul class="simple">
<li><p>both padding and remove padding (packing) strategy</p></li>
<li><p>dynamic batching strategy</p></li>
</ul>
<p>(source code: <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/data/data_loader.py">veomni/data/data_loader.py</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_dataloader</span><span class="p">,</span> <span class="n">build_mapping_dataset</span>

<span class="n">transform</span> <span class="o">=</span> <span class="n">YOUR_TRANSFORM_FUNCTION</span>

<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">build_mapping_dataset</span><span class="p">(</span>
    <span class="n">data_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_path</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">compute_train_steps</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">))</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">build_dataloader</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">micro_batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">micro_batch_size</span><span class="p">,</span> <span class="c1"># micro batch size</span>
    <span class="n">global_batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">global_batch_size</span><span class="p">,</span> <span class="c1"># global batch size</span>
    <span class="n">dataloader_batch_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">dataloader_batch_size</span><span class="p">,</span> <span class="c1"># dataloader batch size, how many micro batches to get with next(train_dataloader), automatically calculate</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span> <span class="c1"># random seed</span>
    <span class="n">max_seq_len</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="c1"># max sequence length</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="c1"># you can pass your custom collate_fn</span>
    <span class="n">train_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train_steps</span><span class="p">,</span> <span class="c1"># train steps, calculate by args.train.compute_train_steps</span>
    <span class="n">rmpad</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">rmpad</span><span class="p">,</span> <span class="c1"># remove padding</span>
    <span class="n">rmpad_with_pos_ids</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">rmpad_with_pos_ids</span><span class="p">,</span> <span class="c1"># remove padding with position ids</span>
    <span class="n">dyn_bsz</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">dyn_bsz</span><span class="p">,</span> <span class="c1"># enable dynamic batching</span>
    <span class="n">bsz_warmup_ratio</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">bsz_warmup_ratio</span><span class="p">,</span> <span class="c1"># bsz warmup ratio</span>
    <span class="n">bsz_warmup_init_mbtoken</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">bsz_warmup_init_mbtoken</span><span class="p">,</span> <span class="c1"># bsz warmup init micro batch token</span>
    <span class="n">dyn_bsz_margin</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">dyn_bsz_margin</span><span class="p">,</span> <span class="c1"># dynamic batching margin</span>
    <span class="n">dyn_bsz_buffer_size</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">dyn_bsz_buffer_size</span><span class="p">,</span> <span class="c1"># dynamic batching buffer size</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span> <span class="c1"># dataloader num workers</span>
    <span class="n">drop_last</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">drop_last</span><span class="p">,</span>  <span class="c1"># dataloader drop last</span>
    <span class="n">pin_memory</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span>  <span class="c1"># dataloader pin memory</span>
    <span class="n">prefetch_factor</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">prefetch_factor</span><span class="p">,</span> <span class="c1"># dataloader prefetch factor</span>
<span class="p">)</span>
</pre></div>
</div>
<section id="collate-function">
<h3>Collate Function<a class="headerlink" href="#collate-function" title="Link to this heading">ïƒ</a></h3>
<p>VeOmni default supports three types of collate function for text task(source code: <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/data/data_collator.py">veomni/data/data_collator.py</a>):</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DataCollatorWithPadding</span></code> (enable when <code class="docutils literal notranslate"><span class="pre">rmpad</span></code> is False and <code class="docutils literal notranslate"><span class="pre">rmpad_with_pos_ids</span></code> is False)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DataCollatorWithPacking</span></code> (enable when <code class="docutils literal notranslate"><span class="pre">rmpad</span></code> is True and <code class="docutils literal notranslate"><span class="pre">rmpad_with_pos_ids</span></code> is False)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DataCollatorWithPositionIDs</span></code> (enable when <code class="docutils literal notranslate"><span class="pre">rmpad</span></code> is False and <code class="docutils literal notranslate"><span class="pre">rmpad_with_pos_ids</span></code> is True)</p></li>
</ol>
<p>For Omni model task:</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">OmniDataCollatorWithPacking</span></code> (for when <code class="docutils literal notranslate"><span class="pre">rmpad_with_pos_ids</span></code> is True)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OmniDataCollatorWithPadding</span></code> (for <code class="docutils literal notranslate"><span class="pre">rmpad</span></code> is False and <code class="docutils literal notranslate"><span class="pre">rmpad_with_pos_ids</span></code> is False)</p></li>
</ol>
<p>See detail in source code: <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/data/multimodal/data_collator.py">veomni/data/multimodal/data_collator.py</a> and how to use it in the <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/tasks/omni/train_omni_model.py">train_omni_model.py</a></p>
</section>
</section>
<section id="model-and-optimizer">
<h2>Model and Optimizer<a class="headerlink" href="#model-and-optimizer" title="Link to this heading">ïƒ</a></h2>
<section id="model-initialization">
<h3>Model Initialization<a class="headerlink" href="#model-initialization" title="Link to this heading">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">build_foundation_model</span></code> implement the model initialization with the config and weights path.</p>
<ul class="simple">
<li><p>meta device init</p></li>
<li><p>init model from model config or weights path</p></li>
<li><p>source code <a class="reference external" href="https://github.com/ByteDance-Seed/VeOmni/blob/main/veomni/models/auto.py">veomni/models/auto.py</a></p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_foundation_model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_foundation_model</span><span class="p">(</span>
    <span class="n">config_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config_path</span><span class="p">,</span> <span class="c1"># model config path, can be None if weights_path is not None</span>
    <span class="n">weights_path</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model_path</span><span class="p">,</span> <span class="c1"># model weights path, can be None if config_path is not None</span>
    <span class="n">init_device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">init_device</span><span class="p">,</span> <span class="c1"># model init device</span>
<span class="p">)</span>

<span class="c1"># You can replace the following code if you want to use the AutoModelForCausalLM from transformers.</span>
<span class="c1"># model = AutoModelForCausalLM.from_pretrained(args.model.model_path)</span>
</pre></div>
</div>
</section>
<section id="parallelization-your-model">
<h3>Parallelization your model<a class="headerlink" href="#parallelization-your-model" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.distributed.torch_parallelize</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_parallelize_model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_foundation_model</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_parallelize_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">enable_full_shard</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">enable_full_shard</span><span class="p">,</span> <span class="c1"># enable full shard, same to Zero3</span>
    <span class="n">enable_reshard_after_forward</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">enable_reshard_after_forward</span><span class="p">,</span> <span class="c1"># enable reshard after forward for FSDP2</span>
    <span class="n">enable_mixed_precision</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">enable_mixed_precision</span><span class="p">,</span> <span class="c1"># enable mixed precision</span>
    <span class="n">enable_gradient_checkpointing</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">enable_gradient_checkpointing</span><span class="p">,</span> <span class="c1"># enable gradient checkpointing</span>
    <span class="n">init_device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">init_device</span><span class="p">,</span> <span class="c1"># model init device</span>
    <span class="n">enable_fsdp_offload</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">enable_fsdp_offload</span><span class="p">,</span> <span class="c1"># enable fsdp offload</span>
    <span class="n">basic_modules</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;_no_split_modules&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">[])</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">basic_modules</span><span class="p">)),</span> <span class="c1"># FSDP basic modules</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="optimizer-and-lr-scheduler">
<h3>Optimizer and LR Scheduler<a class="headerlink" href="#optimizer-and-lr-scheduler" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_lr_scheduler</span><span class="p">,</span> <span class="n">build_optimizer</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">build_optimizer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">,</span>
    <span class="c1"># ... other parameters</span>
<span class="p">)</span>

<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">build_lr_scheduler</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">train_steps</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train_steps</span> <span class="o">*</span> <span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_train_epochs</span><span class="p">,</span>
    <span class="c1"># ... other parameters</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="train-loop">
<h2>Train Loop<a class="headerlink" href="#train-loop" title="Link to this heading">ïƒ</a></h2>
<p>After the parallel_state, model, optimizer, and dataloader are initialized, you can start the training loop.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_train_epochs</span><span class="p">):</span>
    <span class="n">data_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train_steps</span><span class="p">):</span>
        <span class="n">micro_batches</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">data_iterator</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">micro_batch</span> <span class="ow">in</span> <span class="n">micro_batches</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">micro_batch</span><span class="p">)</span><span class="o">.</span><span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">micro_batches</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>
</div>
<section id="custom-loss-function">
<h3>Custom Loss Function<a class="headerlink" href="#custom-loss-function" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="n">loss_fct</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">loss_func</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># In train loop:</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">micro_batch</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">micro_batches</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="profiler">
<h2>Profiler<a class="headerlink" href="#profiler" title="Link to this heading">ïƒ</a></h2>
<p>VeOmni offers a profiler function for users to trace training, use like that.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">veomni.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">helper</span>

<span class="c1"># before train loop, create your profiler</span>
<span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">global_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">enable_profiling</span><span class="p">:</span>
        <span class="n">profiler</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">create_profiler</span><span class="p">(</span>
            <span class="n">start_step</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_start_step</span><span class="p">,</span>
            <span class="n">end_step</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_end_step</span><span class="p">,</span>
            <span class="n">trace_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_trace_dir</span><span class="p">,</span>
            <span class="n">record_shapes</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_record_shapes</span><span class="p">,</span>
            <span class="n">profile_memory</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_profile_memory</span><span class="p">,</span>
            <span class="n">with_stack</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_with_stack</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">profiler</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_train_epochs</span><span class="p">):</span>
    <span class="n">data_iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">train_steps</span><span class="p">):</span>

        <span class="c1">## train code</span>

        <span class="n">profiler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">global_step</span> <span class="o">==</span> <span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_end_step</span><span class="p">:</span>
            <span class="n">profiler</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
            <span class="c1"># upload file to merlin</span>
            <span class="n">helper</span><span class="o">.</span><span class="n">upload_trace</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">wandb_project</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">wandb_name</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">profile_trace_dir</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>