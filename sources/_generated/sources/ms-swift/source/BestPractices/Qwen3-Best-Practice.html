

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Qwen3æœ€ä½³å®è·µ &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Qwen3æœ€ä½³å®è·µ</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../_sources/sources/_generated/sources/ms-swift/source/BestPractices/Qwen3-Best-Practice.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="qwen3">
<h1>Qwen3æœ€ä½³å®è·µ<a class="headerlink" href="#qwen3" title="Link to this heading">ïƒ</a></h1>
<p>è®¨è®ºåŒºï¼š<a class="reference external" href="https://github.com/modelscope/ms-swift/issues/4030">issue 4030</a></p>
<p>Qwenæ–‡æ¡£: <a class="reference external" href="https://qwen.readthedocs.io/en/latest/training/ms_swift.html">https://qwen.readthedocs.io/en/latest/training/ms_swift.html</a></p>
<section id="id1">
<h2>æ¨ç†<a class="headerlink" href="#id1" title="Link to this heading">ïƒ</a></h2>
<p>æ€è€ƒæ¨¡å¼ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--infer_backend<span class="w"> </span>vllm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&lt;&lt;&lt; who are you?
&lt;think&gt;
Okay, the user is asking &quot;who are you?&quot; Let me start by introducing myself as Qwen, the large language model developed by Alibaba Cloud. I should mention my capabilities, like answering questions, creating content, and engaging in conversations. But I need to keep it concise. Also, the user might want to know how I can assist them. Maybe I should ask how I can help them today. Let me check if there&#39;s anything else important to include. Oh, I should make sure the tone is friendly and approachable. Alright, that should cover it.
&lt;/think&gt;

Hello! I am Qwen, a large language model developed by Alibaba Cloud. I can assist with a wide range of tasks, such as answering questions, creating content, writing stories, coding, and more. How can I help you today? ğŸ˜Š
&lt;&lt;&lt; clear
&lt;&lt;&lt; who are you? /no_think
&lt;think&gt;

&lt;/think&gt;

I am Qwen, a large language model developed by Alibaba Cloud. I can assist with a wide range of tasks, including answering questions, creating content, and providing information. How can I help you today?
</pre></div>
</div>
<p>éæ€è€ƒæ¨¡å¼ï¼š</p>
<ul class="simple">
<li><p>å…¶ä¸­<code class="docutils literal notranslate"><span class="pre">--response_prefix</span></code>ä»£è¡¨æ¨¡å‹çš„è¾“å‡ºä¼šåœ¨å…¶å‰ç¼€åç»§ç»­ç”Ÿæˆã€‚ç­‰ä»·äºenable_thinkingè®¾ç½®ä¸ºFalseã€‚</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--infer_backend<span class="w"> </span>vllm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--response_prefix<span class="w"> </span><span class="s1">&#39;&lt;think&gt;\n\n&lt;/think&gt;\n\n&#39;</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&lt;&lt;&lt; who are you?
&lt;think&gt;

&lt;/think&gt;

I am Qwen, a large-scale language model developed by Alibaba Cloud. I am designed to assist with a wide range of tasks, including answering questions, creating content, and providing information. How can I assist you today?
</pre></div>
</div>
</section>
<section id="id2">
<h2>è®­ç»ƒ<a class="headerlink" href="#id2" title="Link to this heading">ïƒ</a></h2>
<p>åœ¨å¼€å§‹è®­ç»ƒä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒå·²æ­£ç¡®é…ç½®ã€‚</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>ms-swift<span class="w"> </span>-U
pip<span class="w"> </span>install<span class="w"> </span>transformers

pip<span class="w"> </span>install<span class="w"> </span>deepspeed<span class="w"> </span><span class="c1"># å¤šGPUè®­ç»ƒ</span>
pip<span class="w"> </span>install<span class="w"> </span>liger-kernel<span class="w"> </span><span class="c1"># èŠ‚çº¦æ˜¾å­˜èµ„æº</span>
pip<span class="w"> </span>install<span class="w"> </span>flash-attn<span class="w"> </span>--no-build-isolation<span class="w">  </span><span class="c1"># packingéœ€è¦</span>
</pre></div>
</div>
</section>
<section id="sft">
<h2>ç›‘ç£å¾®è°ƒ (SFT)<a class="headerlink" href="#sft" title="Link to this heading">ïƒ</a></h2>
<section id="id3">
<h3>æ•°æ®å‡†å¤‡<a class="headerlink" href="#id3" title="Link to this heading">ïƒ</a></h3>
<p>ä½¿ç”¨ ms-swift è¿›è¡Œ SFT çš„è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼å¦‚ä¸‹ï¼ˆsystem å­—æ®µæ˜¯å¯é€‰çš„ï¼‰ã€‚æ‚¨å¯ä»¥å°†å…¶ç»„ç»‡ä¸º JSONã€JSONL æˆ– CSV æ ¼å¼ã€‚åœ¨è®­ç»ƒè„šæœ¬ä¸­æŒ‡å®š <code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">&lt;dataset_path&gt;</span></code>ã€‚æœ‰å…³å®Œæ•´çš„æ•°æ®é›†æ ¼å¼æŒ‡å—ï¼Œè¯·å‚è€ƒ<a class="reference internal" href="../Customization/Custom-dataset.html"><span class="doc">è‡ªå®šä¹‰æ•°æ®é›†æ–‡æ¡£</span></a>ã€‚</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># é€šç”¨æ ¼å¼
{&quot;messages&quot;: [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&lt;system-prompt&gt;&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&lt;query1&gt;&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;&lt;response1&gt;&quot;}
]}
# å¸¦thinkçš„æ ¼å¼
{&quot;messages&quot;: [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Where is the capital of Zhejiang?&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;&lt;think&gt;\n...\n&lt;/think&gt;\n\nThe capital of Zhejiang is Hangzhou.&quot;}
]}
</pre></div>
</div>
<p>å¦‚æœæ‚¨æƒ³ä½¿ç”¨ä¸å«æ€ç»´é“¾çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶ä¿ç•™æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ç§æ–¹æ³•å°½é‡å‡å°‘å¾®è°ƒçš„å½±å“ï¼š</p>
<p><strong>é€‰é¡¹ 1</strong>ï¼šã€æ¨èã€‘åœ¨è®­ç»ƒæœŸé—´ï¼ŒæŒ‡å®š <code class="docutils literal notranslate"><span class="pre">--loss_scale</span> <span class="pre">ignore_empty_think</span></code>ï¼Œä»¥å¿½ç•¥å¯¹ <code class="docutils literal notranslate"><span class="pre">'&lt;think&gt;\n\n&lt;/think&gt;\n\n'</span></code> çš„æŸå¤±è®¡ç®—ï¼Œä»è€Œé¿å…æ¨ç†èƒ½åŠ›çš„ä¸§å¤±ã€‚è®­ç»ƒè„šæœ¬å‚è€ƒ<a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo1.sh">è¿™é‡Œ</a>ã€‚è¯¥æ–¹å¼åŒæ ·é€‚ç”¨äºdeepseek-r1ç­‰æ¨¡å‹ã€‚è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼å¦‚ä¸‹ï¼š</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Where is the capital of Zhejiang?&quot;</span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;think&gt;\n\n&lt;/think&gt;\n\nThe capital of Zhejiang is Hangzhou.&quot;</span><span class="p">}</span>
<span class="p">]}</span>
</pre></div>
</div>
<p><strong>é€‰é¡¹ 2</strong>ï¼šåœ¨æ•°æ®é›†çš„æŸ¥è¯¢ä¸­æ·»åŠ  <code class="docutils literal notranslate"><span class="pre">/no_think</span></code>ï¼Œä»¥é¿å…æ¨ç†èƒ½åŠ›çš„ä¸§å¤±ã€‚è®­ç»ƒè„šæœ¬è¯·å‚è€ƒ<a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo2.sh">è¿™é‡Œ</a>ã€‚è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼å¦‚ä¸‹ï¼š</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Where is the capital of Zhejiang? /no_think&quot;</span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;think&gt;\n\n&lt;/think&gt;\n\nThe capital of Zhejiang is Hangzhou.&quot;</span><span class="p">}</span>
<span class="p">]}</span>
</pre></div>
</div>
<p>ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è·å–è’¸é¦çš„æ¨ç†æ•°æ®é›†ï¼Œåœ¨è®­ç»ƒæ—¶ï¼Œä¸ä¸å«æ€ç»´é“¾æ•°æ®é›†è¿›è¡Œæ··åˆï¼Œè¿›ä¸€æ­¥ç¼“è§£æ¨ç†èƒ½åŠ›çš„ä¸§å¤±ï¼š</p>
<ul class="simple">
<li><p>å…¶ä¸­<code class="docutils literal notranslate"><span class="pre">--val_dataset</span></code>çš„é€‰æ‹©ä»»æ„ã€‚æ¨ç†äº§ç”Ÿçš„<code class="docutils literal notranslate"><span class="pre">result_path</span></code>ï¼Œå¯ä»¥ç›´æ¥åœ¨è®­ç»ƒæ—¶æŒ‡å®š<code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">distill_dataset.jsonl</span></code>ä½¿ç”¨ã€‚</p></li>
<li><p>è¯¥æ€è·¯åŒæ ·é€‚ç”¨äºå…¶ä»–æ¨ç†æ¨¡å‹ï¼Œä¾‹å¦‚deepseek-r1ã€‚</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4 * 80GiB</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-32B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--infer_backend<span class="w"> </span>vllm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--val_dataset<span class="w"> </span><span class="s1">&#39;AI-ModelScope/alpaca-gpt4-data-en#5000&#39;</span><span class="w"> </span><span class="s1">&#39;AI-ModelScope/alpaca-gpt4-data-zh#5000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_gpu_memory_utilization<span class="w"> </span><span class="m">0</span>.9<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_tensor_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--write_batch_size<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--result_path<span class="w"> </span>distill_dataset.jsonl
</pre></div>
</div>
</section>
<section id="id4">
<h3>30åˆ†é’Ÿè‡ªæˆ‘è®¤çŸ¥å¾®è°ƒ<a class="headerlink" href="#id4" title="Link to this heading">ïƒ</a></h3>
<p>æœ¬èŠ‚å°†ä»‹ç»30åˆ†é’Ÿå¯¹ Qwen3-8B è¿›è¡Œè‡ªæˆ‘è®¤çŸ¥å¾®è°ƒã€‚æ‰€éœ€GPUæ˜¾å­˜ä¸º 22GBï¼Œå¯ä»¥åœ¨ ModelScope æä¾›çš„<a class="reference external" href="https://modelscope.cn/my/mynotebook">å…è´¹ç®—åŠ›</a> A10 ä¸­è¿è¡Œã€‚</p>
<p>è®­ç»ƒåï¼Œæ¨¡å‹å°†ä¸å†è®¤ä¸ºè‡ªå·±æ˜¯ç”±â€œé˜¿é‡Œäº‘â€è®­ç»ƒçš„â€œQwenâ€ï¼Œè€Œæ˜¯ç”±â€œswiftâ€è®­ç»ƒçš„â€œswift-robotâ€ã€‚</p>
<p>å¦‚æœéœ€è¦åœ¨ç¦»çº¿ç¯å¢ƒä¸‹è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†ï¼Œå¹¶æŒ‡å®š <code class="docutils literal notranslate"><span class="pre">--model</span> <span class="pre">&lt;model-path&gt;</span></code> å’Œ <code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">&lt;dataset-dir&gt;</span></code>ã€‚æ•°æ®é›†å¯ä»¥åœ¨ <a class="reference external" href="https://modelscope.cn/datasets/swift/self-cognition">Modelscope Hub</a>ä¸Šæ‰¾åˆ°ã€‚å¯¹<code class="docutils literal notranslate"><span class="pre">swift/self-cognition</span></code>æ•°æ®é›†çš„é¢„å¤„ç†å‡½æ•°å¯ä»¥æŸ¥çœ‹<a class="reference external" href="https://github.com/modelscope/ms-swift/blob/36fdf381e5e88cb8a71c9d69c1d8936a989318cc/swift/llm/dataset/dataset/llm.py#L882">è¿™é‡Œ</a>ã€‚</p>
<p>å…³äºè®­ç»ƒè„šæœ¬ä¸­å„å‚æ•°çš„å«ä¹‰ï¼Œè¯·å‚è€ƒ<a class="reference internal" href="../Instruction/Command-line-parameters.html"><span class="doc">å‘½ä»¤è¡Œå‚æ•°æ–‡æ¡£</span></a>ã€‚</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># æ˜¾å­˜å ç”¨ï¼š22GB</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>lora<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;swift/Qwen3-SFT-Mixin#2000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">              </span><span class="s1">&#39;swift/self-cognition:qwen3#600&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_rank<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_alpha<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--target_modules<span class="w"> </span>all-linear<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_author<span class="w"> </span>swift<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_name<span class="w"> </span>swift-robot
</pre></div>
</div>
<p>å¾®è°ƒå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹è„šæœ¬æ¥æµ‹è¯•å¾®è°ƒç»“æœã€‚æ³¨æ„ï¼Œ<code class="docutils literal notranslate"><span class="pre">--adapters</span></code> éƒ¨åˆ†éœ€è¦ä¿®æ”¹ä¸ºæœ€åä¿å­˜æ£€æŸ¥ç‚¹çš„ç›®å½•è·¯å¾„ï¼š</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--temperature<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&lt;&lt;&lt; who are you?
&lt;think&gt;
Okay, the user asked, &quot;who are you?&quot; I need to introduce myself. Let me start by stating my name, swift-robot. Then, I should mention that I&#39;m an AI assistant developed by swift. I should explain my purpose, which is to provide information and assistance. I should also highlight my capabilities, like answering questions, generating text, and engaging in conversation. It&#39;s important to keep the tone friendly and approachable. Maybe add something about being here to help and encourage the user to ask anything. Let me check if I covered all the key points: name, developer, purpose, capabilities, and a welcoming statement. Yeah, that should do it. Now, let me put that into a concise and friendly response.
&lt;/think&gt;

Hello! I am swift-robot, an artificial intelligence assistant developed by swift. My purpose is to provide information and assistance to users like you. I can answer questions, generate text, and engage in conversations on a wide range of topics. I am here to help, so feel free to ask me anything you need!
</pre></div>
</div>
<p>é»˜è®¤æƒ…å†µä¸‹ï¼Œms-swift ä¼šä½¿ç”¨ ModelScope ç¤¾åŒºä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†ã€‚å¦‚æœæƒ³ä½¿ç”¨ HuggingFace ç¤¾åŒºï¼Œåˆ™éœ€è¦é¢å¤–æŒ‡å®š <code class="docutils literal notranslate"><span class="pre">--use_hf</span> <span class="pre">true</span></code>ã€‚</p>
<p>åˆå¹¶ LoRA æƒé‡ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>swift<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--merge_lora<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>æ¨é€æ¨¡å‹åˆ° ModelScope/HuggingFaceï¼š</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># å¦‚æœæ˜¯æ¨é€å®Œæ•´çš„æƒé‡ï¼Œéœ€è¦ä¿®æ”¹`--adapters`ä¸º`--model`.</span>
<span class="c1"># Modelscopeçš„hub_tokenå¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°: https://modelscope.cn/my/myaccesstoken</span>
swift<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--push_to_hub<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--hub_model_id<span class="w"> </span><span class="s1">&#39;&lt;hub-model-id&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--hub_token<span class="w"> </span><span class="s1">&#39;&lt;hub-token&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_hf<span class="w"> </span><span class="nb">false</span>
</pre></div>
</div>
<p>å¦‚æœè¦ä½¿ç”¨å¤š GPU è¿›è¡Œè®­ç»ƒï¼Œä»¥ä¸‹æä¾›äº†å¤š GPU è®­ç»ƒçš„ç¤ºä¾‹ï¼š</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4 * 60GB</span>
<span class="c1"># ä½ å¯ä»¥é€šè¿‡è®¾ç½®`--dataset AI-ModelScope/alpaca-gpt4-data-en`è·‘é€šå®éªŒ</span>
<span class="c1"># æ³¨æ„ï¼šå¦‚æœä½ æŒ‡å®šäº†`--packing true`, ä½ å¿…é¡»é¢å¤–è®¾ç½®`--attn_impl flash_attn`</span>

<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;&lt;your-dataset&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_only_model<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deepspeed<span class="w"> </span>zero3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_liger_kernel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attn_impl<span class="w"> </span>flash_attn
</pre></div>
</div>
</section>
</section>
<section id="rl">
<h2>å¼ºåŒ–å­¦ä¹  (RL)<a class="headerlink" href="#rl" title="Link to this heading">ïƒ</a></h2>
<p>ms-swift æ”¯æŒ DPOã€GRPOã€DAPOã€PPOã€KTOã€GKD ç­‰ RLHF æ–¹æ³•ã€‚æœ¬ç« å°†ç€é‡ä»‹ç»ä½¿ç”¨ ms-swift å¯¹ Qwen3-8B è¿›è¡Œ GRPO è®­ç»ƒã€‚æ›´å¤šå…³äºGRPOçš„å†…å®¹ï¼Œå¯ä»¥å‚è€ƒ<a class="reference internal" href="../Instruction/GRPO/GetStarted/GRPO.html"><span class="doc">GRPOæ–‡æ¡£</span></a>ã€‚æ›´å¤šRLHFè®­ç»ƒè„šæœ¬ï¼Œå‚è€ƒ<a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/rlhf">examples/train/rlhf</a>ã€‚</p>
<section id="id5">
<h3>ç¯å¢ƒè®¾ç½®<a class="headerlink" href="#id5" title="Link to this heading">ïƒ</a></h3>
<p>é™¤äº†å®‰è£…ä¸Šè¿°ä»‹ç»çš„ ms-swift ç›¸å…³ä¾èµ–é¡¹å¤–ï¼Œè¿˜éœ€è¦å®‰è£…ä»¥ä¸‹ä¾èµ–é¡¹ï¼š</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="s2">&quot;math_verify&quot;</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">vllm</span><span class="o">==</span><span class="mf">0.8.5</span><span class="o">.</span><span class="n">post1</span>
</pre></div>
</div>
</section>
<section id="id6">
<h3>æ•°æ®å‡†å¤‡<a class="headerlink" href="#id6" title="Link to this heading">ïƒ</a></h3>
<p>ä½¿ç”¨ ms-swift è¿›è¡Œ GRPO è®­ç»ƒçš„æ•°æ®é›†æ ¼å¼ä¸ SFT ç±»ä¼¼ï¼Œä½†ä¸éœ€è¦æœ€åä¸€è½®çš„ assistant éƒ¨åˆ†ã€‚å¦‚æœä½¿ç”¨ accuracy ä½œä¸ºå¥–åŠ±ï¼Œåˆ™éœ€è¦é¢å¤–çš„ <code class="docutils literal notranslate"><span class="pre">solution</span></code> åˆ—æ¥è®¡ç®—å‡†ç¡®ç‡ã€‚</p>
<p>ç¤ºä¾‹æ•°æ®é›†æ ¼å¼ï¼š</p>
<div class="highlight-jsonl notranslate"><div class="highlight"><pre><span></span>{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me tomorrow&#39;s weather&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is 1 + 1?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;It equals 2&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What about adding 1?&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is your name?&quot;}]}
</pre></div>
</div>
<p>å…³äºå…¶ä»– RLHF ç®—æ³•çš„æ•°æ®é›†å‡†å¤‡ï¼Œè¯·å‚è€ƒ<a class="reference external" href="../Customization/Custom-dataset.md#rlhf">è‡ªå®šä¹‰æ•°æ®é›†æ–‡æ¡£</a>ã€‚</p>
<p>æ•°æ®é›†è¦æ±‚çš„æ³¨æ„äº‹é¡¹ï¼š</p>
<ul class="simple">
<li><p><strong>å¥–åŠ±å‡½æ•°è®¡ç®—</strong>ï¼šæ•°æ®é›†æ ¼å¼å–å†³äºæ‰€ä½¿ç”¨çš„å¥–åŠ±å‡½æ•°ã€‚å¯èƒ½éœ€è¦é¢å¤–çš„åˆ—æ¥æ”¯æŒç‰¹å®šçš„å¥–åŠ±è®¡ç®—ã€‚ä¾‹å¦‚ï¼š</p>
<ul>
<li><p>å½“ä½¿ç”¨å†…ç½®çš„ accuracy æˆ– cosine å¥–åŠ±æ—¶ï¼Œæ•°æ®é›†å¿…é¡»åŒ…å«ä¸€ä¸ª <code class="docutils literal notranslate"><span class="pre">solution</span></code> åˆ—ä»¥è®¡ç®—å›å¤çš„å‡†ç¡®æ€§ã€‚</p></li>
<li><p>æ•°æ®é›†ä¸­çš„å…¶ä»–åˆ—å°†ä½œä¸º <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code> ä¼ é€’ç»™å¥–åŠ±å‡½æ•°ä»¥å®ç°è¿›ä¸€æ­¥çš„è‡ªå®šä¹‰ã€‚</p></li>
</ul>
</li>
<li><p><strong>è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°</strong>ï¼šä¸ºäº†æ ¹æ®æ‚¨çš„å…·ä½“éœ€æ±‚è°ƒæ•´å¥–åŠ±å‡½æ•°ï¼Œå¯ä»¥å‚è€ƒé“¾æ¥ï¼š<a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/grpo/plugin">å¤–éƒ¨å¥–åŠ±æ’ä»¶</a>ã€‚è¯¥æ’ä»¶æä¾›äº†å®ç°è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°çš„ç¤ºä¾‹å’Œæ¨¡æ¿ã€‚</p></li>
</ul>
<p>æˆ‘ä»¬ä½¿ç”¨ä½¿ AI-MO/NuminaMath-TIR ä½œä¸ºæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨accuracyå‡½æ•°è®¡ç®—æ¨¡å‹å›ç­”çš„å‡†ç¡®ç‡å¥–åŠ±ã€‚</p>
<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ vLLM åŠ é€Ÿé‡‡æ ·è¿‡ç¨‹ã€‚</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 70G*8</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>rlhf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--rlhf_type<span class="w"> </span>grpo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;AI-MO/NuminaMath-TIR#5000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_completion_length<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--reward_funcs<span class="w"> </span>accuracy<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_generations<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_vllm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_gpu_memory_utilization<span class="w"> </span><span class="m">0</span>.4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sleep_level<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--offload_model<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--offload_optimizer<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deepspeed<span class="w"> </span>zero3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_tensor_parallel_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--temperature<span class="w"> </span><span class="m">1</span>.0<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--top_p<span class="w"> </span><span class="m">0</span>.85<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--log_completions<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--overlong_filter<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
</section>
</section>
<section id="megatron-swift">
<h2>Megatron-SWIFT<a class="headerlink" href="#megatron-swift" title="Link to this heading">ïƒ</a></h2>
<p>Qwen3-235B-A22B-Instruct-250718 å•æœº8å¡H20 LoRAè®­ç»ƒçš„æœ€ä½³å®è·µå‚è€ƒï¼š<a class="reference external" href="https://github.com/modelscope/ms-swift/pull/5033">https://github.com/modelscope/ms-swift/pull/5033</a>ã€‚</p>
<p>ms-swift å¼•å…¥äº† Megatron å¹¶è¡ŒæŠ€æœ¯ä»¥åŠ é€Ÿå¤§æ¨¡å‹çš„CPT/SFT/DPO/GRPOã€‚æ”¯æŒçš„æ¨¡å‹å¯ä»¥åœ¨<a class="reference internal" href="../Instruction/Supported-models-and-datasets.html"><span class="doc">æ”¯æŒçš„æ¨¡å‹æ–‡æ¡£</span></a>ä¸­æ‰¾åˆ°ã€‚</p>
<p>å…³äºç¯å¢ƒå‡†å¤‡ï¼Œå¯ä»¥å‚è€ƒ<a class="reference internal" href="../Megatron-SWIFT/Quick-start.html"><span class="doc">Megatron-SWIFTè®­ç»ƒæ–‡æ¡£</span></a>ã€‚</p>
<p>æˆ‘ä»¬å°†ä½¿ç”¨é˜¿é‡Œäº‘ DLC å¯åŠ¨è®­ç»ƒã€‚è®­ç»ƒç¯å¢ƒç”±2å°é…å¤‡8å¡ 80GiB A800 GPU ç»„æˆã€‚å…³äºå¤šèŠ‚ç‚¹å¯åŠ¨æ–¹æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒ<a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/multi-node">è¿™é‡Œ</a>ã€‚</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># https://help.aliyun.com/zh/pai/user-guide/general-environment-variables</span>
<span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NNODES</span><span class="o">=</span><span class="nv">$WORLD_SIZE</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NODE_RANK</span><span class="o">=</span><span class="nv">$RANK</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Base<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_safetensors<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;liucong/Chinese-DeepSeek-R1-Distill-data-110k-SFT&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_grouped_gemm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_shared_expert_overlap<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_permute_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_aux_loss_coeff<span class="w"> </span>1e-3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--micro_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--global_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_granularity<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_method<span class="w"> </span>uniform<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_num_layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--train_iters<span class="w"> </span><span class="m">2000</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_iters<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--finetune<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cross_entropy_loss_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_warmup_fraction<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--min_lr<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Base<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_optim<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_rng<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sequence_parallel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attention_backend<span class="w"> </span>flash
</pre></div>
</div>
<p>è®­ç»ƒlosså›¾ï¼ˆéƒ¨åˆ†ï¼‰ï¼š</p>
<img width="910" alt="Image" src="https://github.com/user-attachments/assets/9fe393aa-8299-4659-aa2f-be5d44f0730b" /><p>æ•ˆæœæˆªå›¾ï¼š</p>
<img width="1066" alt="Image" src="https://github.com/user-attachments/assets/1a924130-1954-43e9-9093-b019aeef5949" /><p>è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼ä¸<code class="docutils literal notranslate"><span class="pre">swift</span> <span class="pre">sft</span></code>ç›¸åŒï¼Œè¯¦è§ä¹‹å‰ç« èŠ‚ã€‚åªéœ€æŒ‡å®š <code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">&lt;dataset_path&gt;</span></code> å³å¯ã€‚</p>
<p>ä½¿ç”¨ <code class="docutils literal notranslate"><span class="pre">megatron</span> <span class="pre">sft</span></code> å’Œ <code class="docutils literal notranslate"><span class="pre">swift</span> <span class="pre">sft</span></code> åœ¨å¯¹ Qwen3-30B-A3B æ¨¡å‹è¿›è¡Œå…¨å‚æ•°å¾®è°ƒçš„è®­ç»ƒé€Ÿåº¦å’Œ GPU æ˜¾å­˜ä½¿ç”¨å¯¹æ¯”æƒ…å†µå¦‚ä¸‹ï¼š</p>
<table border="1" class="docutils">
<thead>
<tr>
<th></th>
<th>Megatron-LM</th>
<th>DeepSpeed-ZeRO2</th>
<th>DeepSpeed-ZeRO3</th>
</tr>
</thead>
<tbody>
<tr>
<td>è®­ç»ƒé€Ÿåº¦</td>
<td>9.6s/it</td>
<td>-</td>
<td>91.2s/it</td>
</tr>
<tr>
<td>æ˜¾å­˜ä½¿ç”¨</td>
<td>16 * 60GiB</td>
<td>OOM</td>
<td>16 * 80GiB</td>
</tr>
</tbody>
</table></section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>