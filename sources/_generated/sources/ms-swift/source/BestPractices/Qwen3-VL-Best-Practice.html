

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Qwen3-VLæœ€ä½³å®è·µ &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Qwen3-VLæœ€ä½³å®è·µ</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../_sources/sources/_generated/sources/ms-swift/source/BestPractices/Qwen3-VL-Best-Practice.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="qwen3-vl">
<h1>Qwen3-VLæœ€ä½³å®è·µ<a class="headerlink" href="#qwen3-vl" title="Link to this heading">ïƒ</a></h1>
<section id="id1">
<h2>ç¯å¢ƒå‡†å¤‡<a class="headerlink" href="#id1" title="Link to this heading">ïƒ</a></h2>
<p>åœ¨å¼€å§‹æ¨ç†å’Œè®­ç»ƒä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒå·²å‡†å¤‡å°±ç»ªã€‚</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;transformers&gt;=4.57&quot;</span><span class="w"> </span><span class="s2">&quot;qwen_vl_utils&gt;=0.0.14&quot;</span>

pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;ms-swift&gt;=4.0&quot;</span>
<span class="c1"># pip install &quot;vllm&gt;=0.11.0&quot;  # è‹¥ä½¿ç”¨vllmæ¨ç†åç«¯è¿›è¡Œæ¨ç†</span>
</pre></div>
</div>
<ul class="simple">
<li><p>å…³äºè®­ç»ƒç¼“æ…¢ï¼šä½¿ç”¨torch2.9ä¼šé‡åˆ°è®­ç»ƒï¼ˆconv3dç®—å­ï¼‰ç¼“æ…¢çš„é—®é¢˜ï¼Œè¯·ä½¿ç”¨torch2.8å°è¯•ï¼Œå‚è€ƒ<a class="reference external" href="https://github.com/pytorch/pytorch/issues/166122">è¿™ä¸ªissue</a>ã€‚åœ¨ ms-swift&gt;=3.11.2ï¼Œä½ å¯ä»¥é€šè¿‡è®¾ç½®<code class="docutils literal notranslate"><span class="pre">SWIFT_PATCH_CONV3D=1</span></code>è§„é¿è¯¥é—®é¢˜ï¼Œå…·ä½“æŸ¥çœ‹<a class="reference external" href="https://github.com/modelscope/ms-swift/issues/7108">è¿™ä¸ªissue</a>ã€‚</p></li>
<li><p>å…³äºè§†é¢‘æ•°æ®è®­ç»ƒå¡ä½ï¼šä½¿ç”¨decordåç«¯è¯»å–è§†é¢‘å¯èƒ½å¯¼è‡´å¡ä½é—®é¢˜ï¼Œå‚è€ƒ<a class="reference external" href="https://github.com/dmlc/decord/issues/269">è¿™ä¸ªissue</a>ã€‚ä½ å¯ä»¥ä½¿ç”¨torchcodecåç«¯ï¼Œå…·ä½“å‚è€ƒ<a class="reference external" href="https://github.com/QwenLM/Qwen3-VL/blob/50068df2334f309979ff05d75f1078c8309c63ed/qwen-vl-utils/src/qwen_vl_utils/vision_process.py#L390-L400">qwen_vl_utils</a>åº“ã€‚</p></li>
</ul>
</section>
<section id="id2">
<h2>æ¨ç†<a class="headerlink" href="#id2" title="Link to this heading">ïƒ</a></h2>
<p>ä½¿ç”¨ transformers æ¨ç†ï¼š</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">modelscope</span><span class="w"> </span><span class="kn">import</span> <span class="n">snapshot_download</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">qwen_vl_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">process_vision_info</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Qwen3VLForConditionalGeneration</span><span class="p">,</span> <span class="n">AutoProcessor</span>

<span class="n">model_dir</span> <span class="o">=</span> <span class="n">snapshot_download</span><span class="p">(</span><span class="s1">&#39;Qwen/Qwen3-VL-4B-Instruct&#39;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Qwen3VLForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">model_dir</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="c1"># attn_implementation=&#39;flash_attention_2&#39;,</span>
<span class="p">)</span>

<span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_dir</span><span class="p">)</span>

<span class="n">messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
        <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;video&quot;</span><span class="p">,</span>
                <span class="s2">&quot;video&quot;</span><span class="p">:</span> <span class="s2">&quot;https://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/baby.mp4&quot;</span><span class="p">,</span>
                <span class="s2">&quot;max_pixels&quot;</span><span class="p">:</span> <span class="mi">128</span><span class="o">*</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span>
                <span class="s2">&quot;max_frames&quot;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="s2">&quot;Describe this video.&quot;</span><span class="p">},</span>
        <span class="p">],</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span><span class="n">messages</span><span class="p">,</span> <span class="n">tokenize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">image_inputs</span><span class="p">,</span> <span class="n">video_inputs</span><span class="p">,</span> <span class="n">video_kwargs</span> <span class="o">=</span> <span class="n">process_vision_info</span><span class="p">([</span><span class="n">messages</span><span class="p">],</span> <span class="n">return_video_kwargs</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                                <span class="n">image_patch_size</span><span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
                                                                <span class="n">return_video_metadata</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">if</span> <span class="n">video_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">video_inputs</span><span class="p">,</span> <span class="n">video_metadatas</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">video_inputs</span><span class="p">)</span>
    <span class="n">video_inputs</span><span class="p">,</span> <span class="n">video_metadatas</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">video_inputs</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="n">video_metadatas</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">video_metadatas</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="p">[</span><span class="n">text</span><span class="p">],</span> <span class="n">images</span><span class="o">=</span><span class="n">image_inputs</span><span class="p">,</span> <span class="n">videos</span><span class="o">=</span><span class="n">video_inputs</span><span class="p">,</span> <span class="n">video_metadata</span><span class="o">=</span><span class="n">video_metadatas</span><span class="p">,</span> <span class="o">**</span><span class="n">video_kwargs</span><span class="p">,</span> <span class="n">do_resize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

<span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">generated_ids_trimmed</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">out_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">in_ids</span><span class="p">)</span> <span class="p">:]</span> <span class="k">for</span> <span class="n">in_ids</span><span class="p">,</span> <span class="n">out_ids</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">generated_ids</span><span class="p">)</span>
<span class="p">]</span>
<span class="n">output_text</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span>
    <span class="n">generated_ids_trimmed</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">clean_up_tokenization_spaces</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output_text</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="c1"># &#39;A baby wearing glasses sits on a bed, engrossed in reading a book. The baby turns the pages with both hands, occasionally looking up and smiling. The room is cozy, with a crib in the background and clothes scattered around. The babyâ€™s focus and curiosity are evident as they explore the book, creating a heartwarming scene of early learning and discovery.&#39;</span>
</pre></div>
</div>
<p>ä½¿ç”¨ ms-swift çš„ <code class="docutils literal notranslate"><span class="pre">TransformersEngine</span></code> è¿›è¡Œæ¨ç†ï¼š</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="c1"># os.environ[&#39;SWIFT_DEBUG&#39;] = &#39;1&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;VIDEO_MAX_TOKEN_NUM&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;128&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;FPS_MAX_FRAMES&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;16&#39;</span>


<span class="kn">from</span><span class="w"> </span><span class="nn">swift.infer_engine</span><span class="w"> </span><span class="kn">import</span> <span class="n">TransformersEngine</span><span class="p">,</span> <span class="n">InferRequest</span><span class="p">,</span> <span class="n">RequestConfig</span>
<span class="n">engine</span> <span class="o">=</span> <span class="n">TransformersEngine</span><span class="p">(</span><span class="s1">&#39;Qwen/Qwen3-VL-4B-Instruct&#39;</span><span class="p">)</span>  <span class="c1"># attn_impl=&#39;flash_attention_2&#39;</span>
<span class="n">infer_request</span> <span class="o">=</span> <span class="n">InferRequest</span><span class="p">(</span><span class="n">messages</span><span class="o">=</span><span class="p">[{</span>
    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s1">&#39;&lt;video&gt;Describe this video.&#39;</span><span class="p">,</span>
<span class="p">}],</span> <span class="n">videos</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;https://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/baby.mp4&#39;</span><span class="p">])</span>
<span class="n">request_config</span> <span class="o">=</span> <span class="n">RequestConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">resp_list</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">infer</span><span class="p">([</span><span class="n">infer_request</span><span class="p">],</span> <span class="n">request_config</span><span class="o">=</span><span class="n">request_config</span><span class="p">)</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">resp_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
<span class="c1"># &#39;A baby wearing glasses sits on a bed, engrossed in reading a book. The baby turns the pages with both hands, occasionally looking up and smiling. The room is cozy, with a crib in the background and clothes scattered around. The babyâ€™s focus and curiosity are evident as they explore the book, creating a heartwarming scene of early learning and discovery.&#39;</span>

<span class="c1"># use stream</span>
<span class="n">request_config</span> <span class="o">=</span> <span class="n">RequestConfig</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">gen_list</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">infer</span><span class="p">([</span><span class="n">infer_request</span><span class="p">],</span> <span class="n">request_config</span><span class="o">=</span><span class="n">request_config</span><span class="p">)</span>
<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">gen_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">chunk</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">delta</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
<p>ä½¿ç”¨å‘½ä»¤è¡Œæ¨ç†ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="nv">IMAGE_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="nv">VIDEO_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="nv">FPS_MAX_FRAMES</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-VL-4B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;&lt;&lt; who are you?
Hello! I&#39;m Qwen, a large-scale language model independently developed by the Tongyi Lab under Alibaba Group. My main functions include answering questions, creating text such as stories, official documents, emails, scripts, and more, as well as performing logical reasoning, programming, and other tasks. If you have any questions or need assistance, feel free to let me know anytime, and I&#39;ll do my best to help!
--------------------------------------------------
&lt;&lt;&lt; &lt;image&gt;describe the image.
Input an image path or URL &lt;&lt;&lt; http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/cat.png
This is a beautifully detailed, close-up portrait of an adorable tabby kitten, rendered with a soft, painterly effect that gives it a gentle, dreamy quality.

Hereâ€™s a breakdown of the image:

- **The Kitten:** The subject is a young, fluffy kitten with a classic tabby pattern. Its fur is a mix of white and soft grayish-brown stripes, with a prominent dark stripe running down the center of its forehead and over its nose. The kittenâ€™s face is predominantly white, with delicate markings around its eyes and cheeks.

- **The Eyes:** Its most captivating feature is its large, round, and expressive eyes. They are a striking shade of bright blue-gray, with dark pupils that give it an intense, curious, and slightly innocent gaze. The eyes are wide open, suggesting the kitten is alert and attentive.

- **The Expression:** The kittenâ€™s expression is sweet and innocent. Its small pink nose and slightly parted mouth give it a gentle, almost pleading look. Its whiskers are long and white, standing out against its fur.

- **The Style:** The image has a soft-focus, artistic quality, reminiscent of impressionist painting. The edges of the kittenâ€™s fur are slightly blurred, creating a halo effect that draws attention to its face. The background is softly blurred with muted tones of green and gray, which helps the kitten stand out as the clear focal point.

- **Overall Impression:** The image evokes feelings of warmth, cuteness, and tenderness. The kitten appears to be looking directly at the viewer, creating a sense of connection and affection.

This is a lovely and charming depiction of a young kitten, capturing its innocence and charm in a visually appealing and emotionally engaging way.
--------------------------------------------------
&lt;&lt;&lt; &lt;video&gt;describe the video.
Input a video path or URL &lt;&lt;&lt; https://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/baby.mp4
This video captures a charming and adorable moment of a young child, likely a toddler, sitting on a bed and pretending to read a book. The child is wearing glasses, which adds a humorous and endearing touch to the scene â€” as if theyâ€™re a little scholar or librarian.

Hereâ€™s a breakdown of what unfolds:

- The child is seated cross-legged on a bed with a patterned quilt. Behind them, a crib and some household items are visible, suggesting a cozy bedroom setting.

- The child holds an open book and appears to be turning the pages with focused attention, mimicking the behavior of a real reader.

- At one point, the child looks up, smiles, or seems to react with delight â€” perhaps amused by something in the book or just enjoying the activity.

- The childâ€™s movements are gentle and deliberate, showing a sense of concentration and curiosity. They turn pages, sometimes with one hand, and occasionally lift the book slightly as if to examine it more closely.

- The video has a warm, candid feel â€” itâ€™s not staged, and the childâ€™s natural behavior makes it feel authentic and heartwarming.

Overall, this is a sweet, lighthearted video that showcases the innocence and imagination of early childhood. The childâ€™s engagement with the book, combined with their glasses and playful demeanor, creates a delightful and memorable scene.
</pre></div>
</div>
<ul class="simple">
<li><p>å…¶ä¸­ç‰¹å®šæ¨¡å‹å‚æ•°ï¼Œä¾‹å¦‚ <code class="docutils literal notranslate"><span class="pre">VIDEO_MAX_TOKEN_NUM</span></code> ç­‰ç¯å¢ƒå˜é‡çš„å«ä¹‰å‚è€ƒ<a class="reference external" href="../Instruction/Command-line-parameters.md#qwen3_vl">å‘½ä»¤è¡Œå‚æ•°æ–‡æ¡£</a>ã€‚</p></li>
</ul>
</section>
<section id="id3">
<h2>è®­ç»ƒ<a class="headerlink" href="#id3" title="Link to this heading">ïƒ</a></h2>
<p>æœ¬æ–‡æ¡£å°†ä»‹ç»å¦‚ä½•ä½¿ç”¨ ms-swift ä¸ Megatron-SWIFT è®­ç»ƒ Qwen3-VLã€‚æ¨è Dense æ¨¡å‹ä½¿ç”¨ ms-swiftï¼ˆå³ transformers åç«¯ï¼Œæ›´åŠ æ–¹ä¾¿ç®€å•ï¼‰ï¼Œè€Œ Moe æ¨¡å‹ä½¿ç”¨ Megatron-SWIFTï¼ˆå³ megatron åç«¯ï¼Œæ›´å¿«çš„è®­ç»ƒé€Ÿåº¦ï¼ŒbenchmarkæŸ¥çœ‹<a class="reference external" href="../Megatron-SWIFT/Quick-start.md#benchmark">è¿™é‡Œ</a>ï¼‰ã€‚</p>
<p>å¦‚æœæ‚¨éœ€è¦è‡ªå®šä¹‰æ•°æ®é›†å¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥å°†æ•°æ®å‡†å¤‡æˆä»¥ä¸‹æ ¼å¼ï¼Œå¹¶åœ¨å‘½ä»¤è¡Œä¸­è®¾ç½®<code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">train.jsonl</span> <span class="pre">--val_dataset</span> <span class="pre">val.jsonl</span></code>ï¼Œå…¶ä¸­éªŒè¯é›†ä¸ºå¯é€‰ã€‚æ›´å¤šä»‹ç»è¯·å‚è€ƒ<a class="reference external" href="../Customization/Custom-dataset.md#%E5%A4%9A%E6%A8%A1%E6%80%81">å¤šæ¨¡æ€æ•°æ®é›†æ–‡æ¡£</a>ã€‚</p>
<div class="highlight-jsonl notranslate"><div class="highlight"><pre><span></span>{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;æµ™æ±Ÿçš„çœä¼šåœ¨å“ªï¼Ÿ&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;æµ™æ±Ÿçš„çœä¼šåœ¨æ­å·ã€‚&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&lt;image&gt;&lt;image&gt;ä¸¤å¼ å›¾ç‰‡æœ‰ä»€ä¹ˆåŒºåˆ«&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;å‰ä¸€å¼ æ˜¯å°çŒ«ï¼Œåä¸€å¼ æ˜¯å°ç‹—&quot;}], &quot;images&quot;: [&quot;/xxx/x.jpg&quot;, &quot;/xxx/x.png&quot;]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;ä½ æ˜¯ä¸ªæœ‰ç”¨æ— å®³çš„åŠ©æ‰‹&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&lt;image&gt;å›¾ç‰‡ä¸­æ˜¯ä»€ä¹ˆï¼Œ&lt;video&gt;è§†é¢‘ä¸­æ˜¯ä»€ä¹ˆ&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;å›¾ç‰‡ä¸­æ˜¯ä¸€ä¸ªå¤§è±¡ï¼Œè§†é¢‘ä¸­æ˜¯ä¸€åªå°ç‹—åœ¨è‰åœ°ä¸Šå¥”è·‘&quot;}], &quot;images&quot;: [&quot;/xxx/x.jpg&quot;], &quot;videos&quot;: [&quot;/xxx/x.mp4&quot;]}
</pre></div>
</div>
<p>Qwen3-VLçš„bboxè¾“å‡ºé‡‡ç”¨å½’ä¸€åŒ–1000çš„ç›¸å¯¹åæ ‡ã€‚ä½ å¯ä»¥ä½¿ç”¨ ms-swift æä¾›çš„ grounding æ•°æ®é›†æ ¼å¼ï¼Œå…¶ä¸­&quot;bbox&quot;ä¸­çš„åæ ‡ä¸ºç»å¯¹åæ ‡ï¼Œms-swift ä¼šè‡ªåŠ¨å°†ç»å¯¹åæ ‡è½¬ä¸ºå½’ä¸€åŒ–1000çš„ç›¸å¯¹åæ ‡ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ<a class="reference external" href="../Customization/Custom-dataset.md#grounding">groundingæ•°æ®é›†æ ¼å¼æ–‡æ¡£</a>ã€‚</p>
<div class="highlight-jsonl notranslate"><div class="highlight"><pre><span></span>{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&lt;image&gt;æ‰¾åˆ°å›¾åƒä¸­çš„&lt;ref-object&gt;&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;[\n\t{\&quot;bbox_2d\&quot;: &lt;bbox&gt;, \&quot;label\&quot;: \&quot;&lt;ref-object&gt;\&quot;},\n\t{\&quot;bbox_2d\&quot;: &lt;bbox&gt;, \&quot;label\&quot;: \&quot;&lt;ref-object&gt;\&quot;}\n]&quot;}], &quot;images&quot;: [&quot;cat.png&quot;], &quot;objects&quot;: {&quot;ref&quot;: [&quot;ç¾Š&quot;, &quot;ç¾Š&quot;, &quot;ç¾Š&quot;], &quot;bbox&quot;: [[90.9, 160.8, 135, 212.8], [360.9, 480.8, 495, 532.8]]}}
</pre></div>
</div>
<section id="dense">
<h3>Denseæ¨¡å‹<a class="headerlink" href="#dense" title="Link to this heading">ïƒ</a></h3>
<p>ä»¥ä¸‹æä¾›å¯¹<code class="docutils literal notranslate"><span class="pre">Qwen3-VL-4B-Instruct</span></code>æ¨¡å‹çš„å¾®è°ƒè„šæœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨æ··åˆæ¨¡æ€æ•°æ®ä½œä¸ºDemoæ•°æ®é›†ï¼Œè¯¥ç¤ºä¾‹è„šæœ¬ä»…ä½œä¸ºæ¼”ç¤ºç”¨é€”ã€‚è®­ç»ƒæ˜¾å­˜ä¸º2 * 21GiBï¼Œè®­ç»ƒæ—¶é—´ä¸º12åˆ†é’Ÿã€‚</p>
<ul class="simple">
<li><p>è‹¥è§‰å¾—é¢„å¤„ç†æ—¶é—´å¤ªé•¿ï¼Œä½ å¯ä»¥å°†<code class="docutils literal notranslate"><span class="pre">--packing</span></code>å»é™¤ï¼Œæˆ–è€…ä½¿ç”¨<a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/cached_dataset">cached dataset</a>ã€‚</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2 * 21GiB</span>
<span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">IMAGE_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="nv">VIDEO_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="nv">FPS_MAX_FRAMES</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1<span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-VL-4B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;AI-ModelScope/alpaca-gpt4-data-zh#10000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">              </span><span class="s1">&#39;AI-ModelScope/LaTeX_OCR:human_handwrite#5000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">              </span><span class="s1">&#39;swift/VideoChatGPT:Generic#2000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>lora<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attn_impl<span class="w"> </span>flash_attn<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--padding_free<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_rank<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_alpha<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--target_modules<span class="w"> </span>all-linear<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--freeze_vit<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--freeze_aligner<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_checkpointing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vit_gradient_checkpointing<span class="w"> </span><span class="nb">false</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deepspeed<span class="w"> </span>zero2<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">4</span>
</pre></div>
</div>
<p>è®­ç»ƒç»“æŸåï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹è„šæœ¬å¯¹éªŒè¯é›†è¿›è¡Œæ¨ç†ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="nv">IMAGE_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="nv">VIDEO_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="nv">FPS_MAX_FRAMES</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_data_args<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>--------------------------------------------------
[QUERY] Using LaTeX to perform OCR on the image.
[LABELS] 1 + \frac { 1 } { 1 ! } + \frac { 1 } { 2 ! } + \frac { 1 } { 3 ! } + \frac { 1 } { 4 ! }
[RESPONSE] 1 + \frac { 1 } { 1 ! } + \frac { 1 } { 2 ! } + \frac { 1 } { 3 ! } + \frac { 1 } { 4 ! }
--------------------------------------------------
[QUERY] What color suit is the man wearing while playing the saxophone on stage?
[LABELS] The man is wearing a black suit and white shirt while playing the saxophone on the red-floored stage.
[RESPONSE] The man is wearing a black suit while playing the saxophone on stage.
--------------------------------------------------
...
</pre></div>
</div>
</section>
<section id="moe">
<h3>Moeæ¨¡å‹<a class="headerlink" href="#moe" title="Link to this heading">ïƒ</a></h3>
<p>ä»¥ä¸‹æä¾›å¯¹<code class="docutils literal notranslate"><span class="pre">Qwen3-VL-30B-A3B-Instruct</span></code>æ¨¡å‹çš„å¾®è°ƒè„šæœ¬ï¼Œæˆ‘ä»¬ä½¿ç”¨ Megatron-SWIFT è¿›è¡Œå•æœºå…¨å‚æ•°è®­ç»ƒã€‚æˆ‘ä»¬åŒæ ·é‡‡ç”¨æ··åˆæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¯¥ç¤ºä¾‹è„šæœ¬ä»…ä½œä¸ºæ¼”ç¤ºç”¨é€”ã€‚è®­ç»ƒæ‰€éœ€æ˜¾å­˜èµ„æºä¸º8 * 80GiBï¼Œè®­ç»ƒæ—¶é—´ä¸º20åˆ†é’Ÿã€‚</p>
<p>å…³äº Megatron-SWIFT çš„ç¯å¢ƒå®‰è£…ï¼Œè¯·å‚è€ƒ<a class="reference internal" href="../Megatron-SWIFT/Quick-start.html"><span class="doc">Megatron-SWIFTæ–‡æ¡£</span></a>ã€‚Megatron-SWIFT ä¸ ms-swift å…±ç”¨ template å’Œ dataset æ¨¡å—ï¼Œå› æ­¤å‰é¢ä»‹ç»çš„è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼å’Œæ¨¡å‹ç‰¹æœ‰ç¯å¢ƒå˜é‡ä¾æ—§ç”Ÿæ•ˆã€‚</p>
<p>å¾®è°ƒè„šæœ¬å¦‚ä¸‹ï¼Œè®­ç»ƒæŠ€å·§ä¸å¹¶è¡ŒæŠ€æœ¯çš„è°ƒæ•´å‚è€ƒ<a class="reference external" href="../Megatron-SWIFT/Quick-start.md#%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7">Megatron-SWIFTæ–‡æ¡£</a>ã€‚</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 8 * 80GiB</span>
<span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">OMP_NUM_THREADS</span><span class="o">=</span><span class="m">14</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span><span class="se">\</span>
<span class="nv">IMAGE_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="nv">VIDEO_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="nv">FPS_MAX_FRAMES</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-VL-30B-A3B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_safetensors<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;AI-ModelScope/alpaca-gpt4-data-zh#10000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">              </span><span class="s1">&#39;AI-ModelScope/LaTeX_OCR:human_handwrite#5000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">              </span><span class="s1">&#39;swift/VideoChatGPT:Generic#2000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_permute_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_grouped_gemm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_shared_expert_overlap<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_aux_loss_coeff<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--micro_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--global_batch_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_granularity<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_method<span class="w"> </span>uniform<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_num_layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--finetune<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cross_entropy_loss_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_warmup_fraction<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--min_lr<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-VL-30B-A3B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_optim<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_rng<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sequence_parallel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_expert_capacity_factor<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attention_backend<span class="w"> </span>flash
</pre></div>
</div>
<p>è®­ç»ƒç»“æŸåï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹è„šæœ¬å¯¹éªŒè¯é›†è¿›è¡Œæ¨ç†ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="nv">IMAGE_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="nv">VIDEO_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="nv">FPS_MAX_FRAMES</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>megatron_output/Qwen3-VL-30B-A3B-Instruct/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_data_args<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å°†è®­ç»ƒæƒé‡æ¨é€åˆ° Modelscopeï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>swift<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>output/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--push_to_hub<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--hub_model_id<span class="w"> </span><span class="s1">&#39;&lt;your-model-id&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--hub_token<span class="w"> </span><span class="s1">&#39;&lt;your-sdk-token&gt;&#39;</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>