

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mcore Bridge &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Mcore Bridge</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../_sources/sources/_generated/sources/ms-swift/source/Megatron-SWIFT/Mcore-Bridge.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mcore-bridge">
<h1>Mcore Bridge<a class="headerlink" href="#mcore-bridge" title="Link to this heading">ïƒ</a></h1>
<p>Megatron ä»¥å…¶å“è¶Šçš„è®­ç»ƒé€Ÿåº¦å’Œä¸°å¯Œçš„å¹¶è¡ŒæŠ€æœ¯è€Œè‘—ç§°ï¼Œä½†ä¹Ÿå› æ­¤å¸¦æ¥äº†è¾ƒé«˜çš„ä½¿ç”¨é—¨æ§›ã€‚å› æ­¤mcore-bridge åº”è¿è€Œç”Ÿï¼Œæ—¨åœ¨è®© Megatron è®­ç»ƒåƒ transformers ä¸€æ ·ç®€å•æ˜“ç”¨ã€‚é€šè¿‡ Mcore-Bridgeï¼Œç”¨æˆ·å¯ä»¥ï¼š</p>
<ol class="simple">
<li><p>ç›´æ¥åŠ è½½ safetensors æ ¼å¼çš„æ¨¡å‹æƒé‡ï¼Œæ— ç¼ä½¿ç”¨ Megatron è¿›è¡Œé«˜æ•ˆè®­ç»ƒã€‚ç›´æ¥ä¿å­˜ è®­ç»ƒæƒé‡ä¸º safetensors æ ¼å¼ï¼Œæ— éœ€é¢å¤–è½¬æ¢ã€‚</p></li>
<li><p>å…¼å®¹ LoRA å¢é‡æƒé‡çš„åŒå‘è½¬æ¢ã€‚</p></li>
<li><p>å…¼å®¹GRPO/GKDç­‰ç®—æ³•çš„<code class="docutils literal notranslate"><span class="pre">Megatron-&gt;vLLM</span></code>æƒé‡åŒæ­¥ã€‚</p></li>
<li><p>æ”¯æŒå¤šæœºè½¬æ¢è¶…å¤§è§„æ¨¡æ¨¡å‹ã€‚</p></li>
</ol>
<p>Mcore-Bridge å…¼å®¹ Dense/MoE/å¤šæ¨¡æ€ç­‰å¤šç§æ¨¡å‹æ¶æ„ã€‚è®­ç»ƒå®Œæˆåï¼Œè½¬æ¢åçš„æ¨¡å‹å¯ç›´æ¥ä½¿ç”¨ transformersã€vLLMã€SGLang ç­‰ä¸»æµæ¨ç†æ¡†æ¶éƒ¨ç½²ã€‚</p>
<section id="id1">
<h2>æ— ç¼è®­ç»ƒ<a class="headerlink" href="#id1" title="Link to this heading">ïƒ</a></h2>
<p>ç›®å‰Mcore-Bridgeå·²æ”¯æŒTP/PP/EP/ETP/VPPç­‰å¹¶è¡ŒæŠ€æœ¯ï¼Œæ”¯æŒæ‰€æœ‰Megatron-SWIFTæ”¯æŒçš„æ¨¡å‹æ¶æ„ï¼Œå‚è€ƒ<a class="reference internal" href="../Instruction/Supported-models-and-datasets.html"><span class="doc">æ”¯æŒçš„æ¨¡å‹æ–‡æ¡£</span></a>ã€‚ä»¥ä¸‹ä»‹ç»Mcore-Bridgeçš„æ— ç¼è®­ç»ƒèƒ½åŠ›ï¼Œåˆ†åˆ«ä»‹ç»Denseæ¨¡å‹å’ŒMoeæ¨¡å‹ã€‚</p>
<section id="dense">
<h3>Denseæ¨¡å‹<a class="headerlink" href="#dense" title="Link to this heading">ïƒ</a></h3>
<p>ä»¥ä¸‹ä¸ºå¤šæ¨¡æ€æ¨¡å‹Qwen3-VLæ¨¡å‹è®­ç»ƒçš„ä¾‹å­:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 2 * 76GiB</span>
<span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="nv">IMAGE_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="nv">VIDEO_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="nv">FPS_MAX_FRAMES</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1<span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-VL-8B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_safetensors<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;AI-ModelScope/LaTeX_OCR:human_handwrite#5000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sequence_parallel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--freeze_llm<span class="w"> </span><span class="nb">false</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--freeze_vit<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--freeze_aligner<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--micro_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--global_batch_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_granularity<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_method<span class="w"> </span>uniform<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_num_layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--finetune<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cross_entropy_loss_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_warmup_fraction<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--min_lr<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-VL-8B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_optim<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_rng<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span>
</pre></div>
</div>
<p>ç„¶åæˆ‘ä»¬å¯¹éªŒè¯é›†éƒ¨åˆ†è¿›è¡Œæ¨ç†ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">IMAGE_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="nv">VIDEO_MAX_TOKEN_NUM</span><span class="o">=</span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="nv">FPS_MAX_FRAMES</span><span class="o">=</span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>megatron_output/Qwen3-VL-8B-Instruct/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_data_args<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
</section>
<section id="moe">
<h3>Moeæ¨¡å‹<a class="headerlink" href="#moe" title="Link to this heading">ïƒ</a></h3>
<p>ä»¥ä¸‹ä¸ºçº¯æ–‡æœ¬æ¨¡å‹Qwen3-Moeæ¨¡å‹CoTè®­ç»ƒçš„ä¾‹å­:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 8 * 76GiB, 3s/it</span>
<span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_safetensors<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;swift/Chinese-Qwen3-235B-Thinking-2507-Distill-data-110k-SFT#20000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_permute_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--decoder_first_pipeline_num_layers<span class="w"> </span><span class="m">25</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_grouped_gemm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_shared_expert_overlap<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_aux_loss_coeff<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--micro_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--global_batch_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_granularity<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_method<span class="w"> </span>uniform<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_num_layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--finetune<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cross_entropy_loss_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_warmup_fraction<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--min_lr<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_optim<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_rng<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sequence_parallel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_expert_capacity_factor<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attention_backend<span class="w"> </span>flash
</pre></div>
</div>
<p>å¯¹è®­ç»ƒåçš„æƒé‡è¿›è¡Œæ¨ç†ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">1024</span>
</pre></div>
</div>
</section>
</section>
<section id="lora">
<h2>LoRAå¯¼å‡º<a class="headerlink" href="#lora" title="Link to this heading">ïƒ</a></h2>
<p>Mcore-Bridgeé™¤äº†æ”¯æŒå…¨å‚æ•°çš„å¯¼å…¥å¯¼å‡ºï¼Œè¿˜æ”¯æŒå•ç‹¬å¯¹LoRAå¢é‡æ¨¡å‹è¿›è¡Œå¯¼å…¥å¯¼å‡ºã€‚</p>
<p>ä»¥ä¸‹ä¸ºçº¯æ–‡æœ¬æ¨¡å‹Qwen3-Moeæ¨¡å‹ä½¿ç”¨LoRAè‡ªæˆ‘è®¤çŸ¥è®­ç»ƒçš„ä¾‹å­ï¼š</p>
<ul class="simple">
<li><p>è‹¥ä½ å¸Œæœ›å¯¼å‡ºmergeåçš„æƒé‡ï¼Œè€Œä¸æ˜¯LoRAå¢é‡æƒé‡ï¼Œè¯·è®¾ç½®<code class="docutils literal notranslate"><span class="pre">--merge_lora</span> <span class="pre">true</span></code>ã€‚è®¾ç½®<code class="docutils literal notranslate"><span class="pre">--merge_lora</span> <span class="pre">true</span></code>çš„å…¼å®¹æ€§æ›´å¥½ï¼Œæ”¯æŒæ‰€æœ‰ç³»åˆ—æ¨¡å‹ã€‚</p></li>
<li><p>æ³¨æ„ï¼štransformers 5.0å¯¹Moeçš„æ¨¡å‹ç»„ç»‡ç»“æ„è¿›è¡Œäº†é‡æ„ï¼Œè¯¥ç»“æ„ä¸æ”¯æŒMoe LoRAçš„æ¨ç†ï¼Œå¯èƒ½é€ æˆæ¨ç†å¼‚å¸¸ã€‚å»ºè®®å¯¹Moeæ¨¡å‹è¿›è¡ŒMerge LoRAï¼ˆvLLMä¸å—å½±å“ï¼‰ã€‚</p></li>
<li><p>æ³¨æ„ï¼šç”±äºtransformerså’ŒMegatronæ¨¡å‹ä¸“å®¶ç»“æ„å¹¶ä¸ä¸€å®šä¸€è‡´ï¼ˆä¾‹å¦‚transformersçš„Qwen3-VL-Moeçš„ä¸“å®¶éƒ¨åˆ†å¹¶ä¸æ˜¯Linearå®ç°ï¼Œè€Œæ˜¯Parametersï¼‰ï¼Œå› æ­¤éƒ¨åˆ†æ¨¡å‹æ— æ³•è½¬æ¢LoRAå¢é‡æƒé‡ï¼ˆè‹¥Qwen3-VL-Moeåªè®¾ç½®linear_projå’Œlinear_qkvè®­ç»ƒLoRAä¹Ÿæ”¯æŒè½¬æ¢ï¼‰ã€‚ä½†å¤§å¤šæ•°çš„æ¨¡å‹æ”¯æŒLoRAè½¬æ¢ï¼Œä¾‹å¦‚ï¼šQwen3-Moeï¼ŒQwen3-Omni-Moeï¼ŒGLM4.5-Vç­‰ã€‚</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 50GiB</span>
<span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1<span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_safetensors<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--merge_lora<span class="w"> </span><span class="nb">false</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;swift/Chinese-Qwen3-235B-2507-Distill-data-110k-SFT#2000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">              </span><span class="s1">&#39;swift/self-cognition#1000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>lora<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_rank<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_alpha<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--target_modules<span class="w"> </span>all-linear<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_permute_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_grouped_gemm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_shared_expert_overlap<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_aux_loss_coeff<span class="w"> </span>1e-3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--micro_batch_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--global_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_granularity<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_method<span class="w"> </span>uniform<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_num_layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--finetune<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cross_entropy_loss_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr<span class="w"> </span>1e-4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_warmup_fraction<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--min_lr<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_optim<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_rng<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sequence_parallel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_expert_capacity_factor<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attention_backend<span class="w"> </span>flash<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_author<span class="w"> </span>swift<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_name<span class="w"> </span>swift-robot
</pre></div>
</div>
<p>å¯¹å¯¼å‡ºçš„LoRAæƒé‡è¿›è¡Œæ¨ç†ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>æç¤ºï¼šå¦‚æœåœ¨vLLMæƒé‡æ›´æ–°æœŸé—´é‡åˆ° GPU OOM é—®é¢˜ï¼Œæ‚¨å¯ä»¥è®¾ç½® <code class="docutils literal notranslate"><span class="pre">--offload_bridge</span> <span class="pre">true</span></code> å°†å¼ é‡å¸è½½åˆ° CPU å¹¶å‡å°‘ GPU å†…å­˜ä½¿ç”¨é‡ã€‚</p>
</section>
<section id="megatron-export">
<h2><code class="docutils literal notranslate"><span class="pre">megatron</span> <span class="pre">export</span></code> ä¸ è½¬æ¢ç²¾åº¦æµ‹è¯•<a class="headerlink" href="#megatron-export" title="Link to this heading">ïƒ</a></h2>
<p>Mcore-Bridgeé™¤äº†æ”¯æŒåœ¨è®­ç»ƒä¸­è¿›è¡Œsafetensorsçš„è½¬æ¢å’Œä¿å­˜ï¼Œä¹Ÿæ”¯æŒäº†<code class="docutils literal notranslate"><span class="pre">megatron</span> <span class="pre">export</span></code>å‘½ä»¤ç”¨äºå•ç‹¬çš„æƒé‡å¯¼å‡ºã€‚<code class="docutils literal notranslate"><span class="pre">megatron</span> <span class="pre">export</span></code>æ”¯æŒåœ¨æƒé‡è½¬æ¢æ—¶ï¼Œå¯¹è½¬æ¢ç²¾åº¦è¿›è¡Œæµ‹è¯•ï¼Œè¿™åœ¨æ¥å…¥æ–°æ¨¡å‹æ—¶éªŒè¯æ¥å…¥å‡†ç¡®æ€§å¾ˆæœ‰å¸®åŠ©ã€‚é€šå¸¸ï¼ŒMegatron-SWIFTå·²ç»æ¥å…¥çš„æ¨¡å‹ä¸ä¼šå‡ºç°ç²¾åº¦ä¸å¯¹é½çš„æƒ…å†µï¼Œä½ å¯ä»¥æ”¾å¿ƒè®¾ç½®<code class="docutils literal notranslate"><span class="pre">--test_convert_precision</span> <span class="pre">false</span></code>ã€‚</p>
<ul class="simple">
<li><p>æç¤ºï¼šå¤šæ¨¡æ€æ¨¡å‹è¯·å…³æ³¨<code class="docutils literal notranslate"><span class="pre">mean_diff</span> <span class="pre">(with</span> <span class="pre">loss)</span></code>å­—æ®µï¼Œ<code class="docutils literal notranslate"><span class="pre">mean_diff</span></code>å› åŒ…å«å›¾åƒtokensä¸”è¯¥éƒ¨åˆ†ä¸è®¡ç®—æŸå¤±ï¼Œæœ‰è¾ƒå¤§çš„diffã€‚</p></li>
</ul>
<p>å…¨å‚æ•°æƒé‡ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># safetensors -&gt; torch_dist</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>Qwen3-30B-A3B-Instruct-2507-mcore<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--to_mcore<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--test_convert_precision<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># torch_dist -&gt; safetensors</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--mcore_model<span class="w"> </span>Qwen3-30B-A3B-Instruct-2507-mcore<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>Qwen3-30B-A3B-Instruct-2507-hf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--to_hf<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--test_convert_precision<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>LoRAæƒé‡ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># torch_dist -&gt; safetensors</span>
<span class="c1"># è‹¥ä½ éœ€è¦è¿›è¡Œmerge-loraï¼Œå¹¶æµ‹è¯•merge-loraåçš„ç²¾åº¦å¯¹é½ï¼Œä½ åªéœ€è¦è®¾ç½®`--merge_lora true`å³å¯</span>
<span class="c1"># ä½ ä¹Ÿå¯ä»¥å°†`--model safetensors-path`ä¿®æ”¹ä¸º`--mcore_model torch-dist-path`ã€‚è¿™ä¸¤ç§æ–¹å¼æ˜¯ç­‰ä»·çš„ï¼Œmcore-bridgeä¼šè‡ªåŠ¨å¤„ç†ã€‚</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--mcore_adapter<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx-lora<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--merge_lora<span class="w"> </span><span class="nb">false</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--to_hf<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--test_convert_precision<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># safetensors -&gt; torch_dist</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx-lora<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx-mcore<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--merge_lora<span class="w"> </span><span class="nb">false</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--to_mcore<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--test_convert_precision<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>Merge-LoRA:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># torch_dist -&gt; torch_dist</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--mcore_adapter<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Instruct-2507/vx-xxx/checkpoint-xxx-merged<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--merge_lora<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--to_mcore<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tensor_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span>
</pre></div>
</div>
</section>
<section id="id2">
<h2>ä½¿ç”¨ä»£ç <a class="headerlink" href="#id2" title="Link to this heading">ïƒ</a></h2>
<p>ä½ éœ€è¦åˆ›å»ºä»¥ä¸‹æ–‡ä»¶ï¼ˆtest.pyï¼‰ï¼Œç„¶åè¿è¡Œ<code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=0,1</span> <span class="pre">torchrun</span> <span class="pre">--nproc_per_node=2</span> <span class="pre">test.py</span></code>ã€‚ä»¥ä¸‹ä¸ºä½¿ç”¨Mcore-Bridgeè¿›è¡Œæƒé‡åŠ è½½ã€å¯¼å‡ºã€ä¿å­˜çš„ç¤ºä¾‹ä»£ç ã€‚</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">swift.megatron</span><span class="w"> </span><span class="kn">import</span> <span class="n">MegatronArguments</span><span class="p">,</span> <span class="n">get_mcore_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">swift.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_processor</span>

<span class="n">model_id</span> <span class="o">=</span> <span class="s1">&#39;Qwen/Qwen3-4B-Instruct-2507&#39;</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">get_processor</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">download_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">hf_config</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">model_info</span><span class="o">.</span><span class="n">config</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">MegatronArguments</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
    <span class="n">tensor_model_parallel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">mg_models</span> <span class="o">=</span> <span class="n">get_mcore_model</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">)</span>
<span class="n">bridge</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">megatron_model_meta</span><span class="o">.</span><span class="n">bridge_cls</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="c1"># åŠ è½½æƒé‡</span>
<span class="n">bridge</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">mg_models</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
<span class="c1"># å¯¼å‡ºæƒé‡</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">bridge</span><span class="o">.</span><span class="n">export_weights</span><span class="p">(</span><span class="n">mg_models</span><span class="p">):</span>
    <span class="k">pass</span>
<span class="c1"># ä¿å­˜æƒé‡</span>
<span class="n">bridge</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">mg_models</span><span class="p">,</span> <span class="s1">&#39;output/Qwen3-4B-Instruct-2507-new&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>æ¨ç†æ–°äº§ç”Ÿçš„æƒé‡ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>output/Qwen3-4B-Instruct-2507-new<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_type<span class="w"> </span>qwen3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--template<span class="w"> </span>qwen3_nothinking<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>LoRAæƒé‡çš„åŠ è½½ã€å¯¼å‡ºå’Œå­˜å‚¨åŒç†ï¼Œè¿è¡Œ<code class="docutils literal notranslate"><span class="pre">CUDA_VISIBLE_DEVICES=0,1,2,3</span> <span class="pre">torchrun</span> <span class="pre">--nproc_per_node=4</span> <span class="pre">test.py</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">swift.megatron</span><span class="w"> </span><span class="kn">import</span> <span class="n">MegatronArguments</span><span class="p">,</span> <span class="n">get_mcore_model</span><span class="p">,</span> <span class="n">prepare_mcore_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">swift.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_processor</span>

<span class="n">model_id</span> <span class="o">=</span> <span class="s1">&#39;Qwen/Qwen3-30B-A3B-Instruct-2507&#39;</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">get_processor</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">download_model</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">hf_config</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">model_info</span><span class="o">.</span><span class="n">config</span>
<span class="n">args</span> <span class="o">=</span> <span class="n">MegatronArguments</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span>
    <span class="n">tensor_model_parallel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">pipeline_model_parallel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">expert_model_parallel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">sequence_parallel</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
    <span class="n">tuner_type</span><span class="o">=</span><span class="s1">&#39;lora&#39;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">mg_models</span> <span class="o">=</span> <span class="n">get_mcore_model</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">)</span>
<span class="n">bridge</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">megatron_model_meta</span><span class="o">.</span><span class="n">bridge_cls</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="c1"># åŠ è½½æƒé‡</span>
<span class="n">bridge</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">mg_models</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">model_dir</span><span class="p">)</span>
<span class="c1"># å‡†å¤‡LoRAå¹¶åŠ è½½</span>
<span class="n">peft_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">prepare_mcore_model</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">mg_model</span><span class="p">)</span> <span class="k">for</span> <span class="n">mg_model</span> <span class="ow">in</span> <span class="n">mg_models</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;peft_model: </span><span class="si">{</span><span class="n">peft_models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># bridge.load_weights(mg_models, &#39;adapter-path&#39;, is_peft_format=True)</span>
<span class="c1"># å¯¼å‡ºæƒé‡</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">bridge</span><span class="o">.</span><span class="n">export_weights</span><span class="p">(</span><span class="n">mg_models</span><span class="p">,</span> <span class="n">is_peft_format</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">pass</span>
<span class="c1"># ä¿å­˜æƒé‡</span>
<span class="n">bridge</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">mg_models</span><span class="p">,</span> <span class="s1">&#39;output/Qwen3-30B-A3B-Instruct-2507-lora&#39;</span><span class="p">,</span> <span class="n">is_peft_format</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>æ¨ç†æ–°äº§ç”Ÿçš„æƒé‡ï¼š</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Instruct-2507<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/Qwen3-30B-A3B-Instruct-2507-lora<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>