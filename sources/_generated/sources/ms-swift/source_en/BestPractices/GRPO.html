

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Complete GRPO Experiment Process &mdash; ÊòáËÖæÂºÄÊ∫ê  ÊñáÊ°£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Á¥¢Âºï" href="../../../../../../genindex.html" />
    <link rel="search" title="ÊêúÁ¥¢" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../index.html" class="icon icon-home">
            ÊòáËÖæÂºÄÊ∫ê
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="ÊêúÁ¥¢ÊñáÊ°£" aria-label="ÊêúÁ¥¢ÊñáÊ°£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="ÂØºËà™ËèúÂçï">
              <p class="caption" role="heading"><span class="caption-text">üèÅ ÂºÄÂßã‰ΩøÁî®</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ascend/quick_install.html">Âø´ÈÄüÂÆâË£ÖÊòáËÖæÁéØÂ¢É</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üèóÔ∏è  Âü∫Á°ÄËÆæÊñΩ‰∏éÊ°ÜÊû∂</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üß† ËÆ≠ÁªÉ‰∏éÂæÆË∞ÉÊ°ÜÊû∂</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üöÄ Êé®ÁêÜ‰∏éÊúçÂä°</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üé® Â§öÊ®°ÊÄÅ„ÄÅÂ∫îÁî®‰∏éËØÑÊµã</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ÁßªÂä®ÁâàÂØºËà™ËèúÂçï" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">ÊòáËÖæÂºÄÊ∫ê</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="È°µÈù¢ÂØºËà™">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Complete GRPO Experiment Process</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../_sources/sources/_generated/sources/ms-swift/source_en/BestPractices/GRPO.md.txt" rel="nofollow"> Êü•ÁúãÈ°µÈù¢Ê∫êÁ†Å</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="complete-grpo-experiment-process">
<h1>Complete GRPO Experiment Process<a class="headerlink" href="#complete-grpo-experiment-process" title="Link to this heading">ÔÉÅ</a></h1>
<p>This article starts with the relatively simple mathematical task &quot;Countdown Game&quot; and introduces the complete GRPO training process through several steps: dataset definition, reward function definition, and GRPO training. The task definition and training parameters are based on <a class="reference external" href="https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/mini-deepseek-r1-aha-grpo.ipynb">mini-deepseek-r1</a>.</p>
<section id="task-and-dataset-definition">
<h2>Task and Dataset Definition<a class="headerlink" href="#task-and-dataset-definition" title="Link to this heading">ÔÉÅ</a></h2>
<p>The goal of the Countdown Game task is to reach a target number using the given numbers and the four basic arithmetic operations. Therefore, we define the dataset as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CoundownTaskPreprocessor</span><span class="p">(</span><span class="n">ResponsePreprocessor</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">row</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">numbers</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;nums&#39;</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;response&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">query</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        Using the numbers </span><span class="si">{</span><span class="n">numbers</span><span class="si">}</span><span class="s2">, create an equation that equals </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">.</span>
<span class="s2">        You can use basic arithmetic operations (+, -, *, /) and each number can only be used once.</span>
<span class="s2">        Show your work in &lt;think&gt; &lt;/think&gt; tags. And return the final equation and answer in &lt;answer&gt; &lt;/answer&gt; tags,</span>
<span class="s2">        for example &lt;answer&gt; (1 + 2) / 3 * 4 = 4 &lt;/answer&gt;.</span>
<span class="s2">        &quot;&quot;&quot;</span>
        <span class="n">row</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span> <span class="s1">&#39;query&#39;</span><span class="p">:</span> <span class="n">query</span><span class="p">})</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="n">register_dataset</span><span class="p">(</span>
    <span class="n">DatasetMeta</span><span class="p">(</span>
        <span class="n">ms_dataset_id</span><span class="o">=</span><span class="s1">&#39;zouxuhong/Countdown-Tasks-3to4&#39;</span><span class="p">,</span>
        <span class="n">subsets</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;default&#39;</span><span class="p">],</span>
        <span class="n">preprocess_func</span><span class="o">=</span><span class="n">CoundownTaskPreprocessor</span><span class="p">(),</span>
        <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;math&#39;</span><span class="p">]))</span>
</pre></div>
</div>
<p>Through a template, numbers and the target are used to define the task, and a <code class="docutils literal notranslate"><span class="pre">query</span></code> field is provided for model sampling. At the same time, we need to retain the <code class="docutils literal notranslate"><span class="pre">nums</span></code> and <code class="docutils literal notranslate"><span class="pre">target</span></code> fields for subsequent reward function calculation.</p>
</section>
<section id="reward-function-definition">
<h2>Reward Function Definition<a class="headerlink" href="#reward-function-definition" title="Link to this heading">ÔÉÅ</a></h2>
<p>Two reward functions are used for this task: one is the format reward function mentioned in Deepseek-R1, and the other is the accuracy reward function for the Countdown Game. The former is already built into Swift and can be used directly with <code class="docutils literal notranslate"><span class="pre">--reward_funcs</span> <span class="pre">format</span></code>, while the latter requires custom definition. Here, we use the <code class="docutils literal notranslate"><span class="pre">external_plugin</span></code> method to define the accuracy reward function, placing the code in <code class="docutils literal notranslate"><span class="pre">swift/examples/train/grpo/plugin/plugin.py</span></code>.</p>
<p>The input to the reward function includes three fields: <code class="docutils literal notranslate"><span class="pre">completions</span></code>, <code class="docutils literal notranslate"><span class="pre">target</span></code>, and <code class="docutils literal notranslate"><span class="pre">nums</span></code>, representing the model-generated text, the target answer, and the available numbers, respectively. Each is a list, supporting simultaneous computation of multiple completions. Note that, except for <code class="docutils literal notranslate"><span class="pre">completions</span></code>, the other parameters are transparently passed from the fields defined in the dataset. If there are changes to the task, adjustments can be made to both the dataset and the reward function as needed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">CountdownORM</span><span class="p">(</span><span class="n">ORM</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">completions</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">nums</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates completions based on Mathematical correctness of the answer</span>
<span class="sd">        Args:</span>
<span class="sd">            completions (list[str]): Generated outputs</span>
<span class="sd">            target (list[str]): Expected answers</span>
<span class="sd">            nums (list[str]): Available numbers</span>
<span class="sd">        Returns:</span>
<span class="sd">            list[float]: Reward scores</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rewards</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">completion</span><span class="p">,</span> <span class="n">gt</span><span class="p">,</span> <span class="n">numbers</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">completions</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">nums</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Check if the format is correct</span>
                <span class="n">match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&lt;answer&gt;(.*?)&lt;\/answer&gt;&quot;</span><span class="p">,</span> <span class="n">completion</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">match</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="c1"># Extract the &quot;answer&quot; part from the completion</span>
                <span class="n">equation</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="k">if</span> <span class="s1">&#39;=&#39;</span> <span class="ow">in</span> <span class="n">equation</span><span class="p">:</span>
                    <span class="n">equation</span> <span class="o">=</span> <span class="n">equation</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;=&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="c1"># Extract all numbers from the equation</span>
                <span class="n">used_numbers</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\d+&#39;</span><span class="p">,</span> <span class="n">equation</span><span class="p">)]</span>
                <span class="c1"># Check if all numbers are used exactly once</span>
                <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">used_numbers</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">numbers</span><span class="p">):</span>
                    <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="c1"># Define a regex pattern that only allows numbers, operators, parentheses, and whitespace</span>
                <span class="n">allowed_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;^[\d+\-*/().\s]+$&#39;</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">allowed_pattern</span><span class="p">,</span> <span class="n">equation</span><span class="p">):</span>
                    <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="c1"># Evaluate the equation with restricted globals and locals</span>
                <span class="n">result</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;__builtins__&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span> <span class="p">{})</span>
                <span class="c1"># Check if the equation is correct and matches the ground truth</span>
                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">gt</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">1e-5</span><span class="p">:</span>
                    <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># If evaluation fails, reward is 0</span>
                <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">rewards</span>
<span class="n">orms</span><span class="p">[</span><span class="s1">&#39;external_countdown&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">CountdownORM</span>
</pre></div>
</div>
</section>
<section id="grpo-training-experiment-record">
<h2>GRPO Training Experiment Record<a class="headerlink" href="#grpo-training-experiment-record" title="Link to this heading">ÔÉÅ</a></h2>
<p>We first present the GRPO formula:</p>
<p>$$
{\scriptstyle
\begin{aligned}
\mathcal{J}<em>{G R P O}(\theta) &amp; =\mathbb{E}\left[q \sim P(Q),\left{o_i\right}</em>{i=1}^G \sim \pi_{\theta_{o l d}}(O \mid q)\right] \
&amp; \frac{1}{G} \sum_{i=1}^G \frac{1}{\left|o_i\right|} \sum_{t=1}^{\left|o_i\right|}\left{\min \left[\frac{\pi_\theta\left(o_{i, t} \mid q, o_{i,&lt;t}\right)}{\pi_{\theta_{o l d}}\left(o_{i, t} \mid q, o_{i,&lt;t}\right)} \hat{A}<em>{i, t}, \operatorname{clip}\left(\frac{\pi</em>\theta\left(o_{i, t} \mid q, o_{i,&lt;t}\right)}{\pi_{\theta_{o l d}}\left(o_{i, t} \mid q, o_{i,&lt;t}\right)}, 1-\varepsilon, 1+\varepsilon\right) \hat{A}<em>{i, t}\right]-\beta \mathbb{D}</em>{K L}\left[\pi_\theta| | \pi_{r e f}\right]\right}
\end{aligned}
}
$$</p>
<section id="training-parameters">
<h3>Training Parameters<a class="headerlink" href="#training-parameters" title="Link to this heading">ÔÉÅ</a></h3>
<p>We selected Qwen2.5-3B-Instruct as the base model for training, as using an instruct-tuned model allows for faster acquisition of format rewards. The experiment was conducted on three GPUs, with vLLM inference deployed on the last GPU and two processes set on the remaining GPUs for gradient updates.</p>
<p>Since the task is relatively simple, we set both <code class="docutils literal notranslate"><span class="pre">max_completion_length</span></code> to 1024. For more complex tasks, the model output length can be increased appropriately, but note that <strong>the larger these parameters, the more GPU memory is required, and the slower the training speed</strong>. The training time per step is linearly related to <code class="docutils literal notranslate"><span class="pre">max_completion_length</span></code>.</p>
<p>In our experiment, the total batch size is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">num_processes</span> <span class="o">*</span> <span class="n">per_device_train_batch_size</span> <span class="o">*</span> <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">=</span> <span class="mi">128</span>
</pre></div>
</div>
<p>Note that the single-GPU batch size is also closely related to GPU memory capacity, so set an appropriate value based on memory limits. Additionally, the total number of steps can be calculated as:</p>
<p>$$
\text{num_steps} = \text{epochs} \times \text{len(datasets)} \times \text{num_generations} \div \text{batch_size}
$$</p>
<p>This formula should guide the planning of learning rate and warmup settings.</p>
<p>Finally, two important parameters are learning rate and $\beta$. The learning rate is straightforward, while $\beta$ is the weight of the KL divergence gradient in the formula. Increasing these parameters accelerates convergence but may lead to instability. After experimentation, we set them to <code class="docutils literal notranslate"><span class="pre">5e-7</span></code> and <code class="docutils literal notranslate"><span class="pre">0.001</span></code>, respectively. During training, adjust these parameters appropriately if instability or oscillations occur.</p>
<p>For KL divergence, the community has extensive discussions, such as <a class="reference external" href="https://zhuanlan.zhihu.com/p/25862547100">Why GRPO Adheres to KL Divergence</a>.</p>
<p>Other parameter settings were not explored in detail and will not be discussed here.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>rollout<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen2.5-3B-Instruct
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1<span class="w"> </span><span class="se">\</span>
<span class="nv">WANDB_API_KEY</span><span class="o">=</span>your_wandb_key<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>rlhf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--rlhf_type<span class="w"> </span>grpo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen2.5-3B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--external_plugins<span class="w"> </span>examples/train/grpo/plugin/plugin.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--reward_funcs<span class="w"> </span>external_countdown<span class="w"> </span>format<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_vllm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_mode<span class="w"> </span>server<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_server_host<span class="w"> </span><span class="m">127</span>.0.0.1<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_server_port<span class="w"> </span><span class="m">8000</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;zouxuhong/Countdown-Tasks-3to4#50000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_completion_length<span class="w"> </span><span class="m">1024</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>5e-7<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">500</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output/GRPO_COUNTDOWN<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_generations<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--temperature<span class="w"> </span><span class="m">1</span>.0<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--system<span class="w"> </span><span class="s1">&#39;You are a helpful assistant. You first thinks about the reasoning process in the mind and then provides the user with the answer.&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deepspeed<span class="w"> </span>zero3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--log_completions<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--report_to<span class="w"> </span>wandb<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--beta<span class="w"> </span><span class="m">0</span>.001<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_iterations<span class="w"> </span><span class="m">1</span>
</pre></div>
</div>
</section>
<section id="experimental-observations">
<h3>Experimental Observations<a class="headerlink" href="#experimental-observations" title="Link to this heading">ÔÉÅ</a></h3>
<p>After training for 2000 steps, the following observations were made:</p>
<ol class="simple">
<li><p><strong>Custom CountdownORM Rewards</strong>: The custom <code class="docutils literal notranslate"><span class="pre">CountdownORM</span></code> reward is steadily increasing, which proves that the model is learning to accomplish the task. The final task success rate is around 50%.</p></li>
<li><p><strong>Format Reward</strong>: The format reward remains at a relatively high level, fluctuating between 0.9 and 1.</p></li>
<li><p><strong>Reward Standard Deviation</strong>: The reward standard deviation stabilizes around 0.2-0.3 but has not fully converged, indicating that the model still has room to improve its reward.</p></li>
<li><p><strong>Failure Cases</strong>: By examining the model's output, many failure cases are due to the model making simple arithmetic errors. Therefore, the model's final convergence direction involves solving the problem step by step. Using a larger model may lead to different convergence directions.</p></li>
<li><p><strong>Completion Length</strong>: The completion length initially decreases and then increases, reaching its lowest point around 200 steps and later rising to approximately 350. This suggests the model underwent a change in reasoning approach.</p></li>
<li><p><strong>Reasoning Patterns</strong>: The model's reasoning pattern evolves over time. Eventually, the model realizes that performing permutations and step-by-step calculations is more effective for completing this task. The final sampled outputs mostly follow this format. Below are examples of how completions change across different steps:</p></li>
</ol>
<section id="completion-examples-at-different-steps">
<h4>Completion Examples at Different Steps<a class="headerlink" href="#completion-examples-at-different-steps" title="Link to this heading">ÔÉÅ</a></h4>
<p><strong>Step 1:</strong></p>
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>&lt;think&gt;
We need to create an equation using the given numbers [70, 5, 42, 30] exactly once and make it equal to 77.

First, let&#39;s consider the possibility of multiplication or division to get closer to 77. Notice that 77 is close to 70 and 42. If we can use these numbers together, it might work.

Multiplying 70 by 1.1 would give us approximately 77, which is very close. So, let&#39;s try to make 1.1 using the remaining numbers 5 and 30.
If we take 30/5 = 6, and then 5/6 = 0.8333..., this isn&#39;t useful here, so let&#39;s look at other possibilities.

Next, let&#39;s consider if there&#39;s another way to achieve 77 using addition, subtraction, or another combination of our numbers. Given the numbers provided, it seems that multiplication or division will be key.

We can try subtracting 5 from 30 to get 25. Then, if we divide 42 by 25, we don&#39;t get a whole number, but we can round it to the nearest whole number, 1. Now, we need to make the equation fit 77. Let&#39;s multiply 25 by 3 and add 7 (since 77 = 25*3 + 7). However, we only have one 7 available and we need to find a way to use the remaining numbers to get 7.

Let&#39;s try:
70 - 42 = 28
Then, 28 + 5 = 33
Next, 33 + 30 = 63
Finally, 77 - 63 = 14, which doesn&#39;t help.

Considering different combinations, one viable way is:
(70 - 42) * (30 / 5) = 28 * 6 = 168 / 2 = 84 / 2 = 42 / 2 = 21 / 3 = 7

So, (70 - 42) * (30 / 5) = 77.
&lt;/think&gt;
&lt;answer&gt;(70 - 42) * (30 / 5) = 77&lt;/answer&gt;
</pre></div>
</div>
<p><strong>Step 200:</strong></p>
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>&lt;think&gt;
We need to use all the given numbers in a way that the resultant value of the calculation is 99. Given these restrictions, it&#39;s clear we should look into how the numbers relate and the mathematical operations that will bring them together to meet our condition.

Firstly, let&#39;s evaluate the sums, differences, and multiplication/division among the numbers and their relations to see how this could lead us towards an outcome of 99.
- Summing the three numbers: 96 + 70 + 73 = 239, which is far from 99. This shows addition isn&#39;t practical.
- Subtracting numbers: For instance, subtracting the lowest two (i.e., 73 - 70 = 3) and combining with the highest one (96) does not work. Also, there is no other combination of subtraction that would result in the number needing to add up to 99.
- Multiplying or dividing the numbers alone wouldn‚Äôt reach any near solution since none of the products or division results of the numbers themselves is very close to 99. We might think more carefully about the arrangement of them using a combination of the operations provided.
Therefore, considering the possible arrangement, a combination like taking (73 - 70 + 96) may produce an effective solution as this will sum the values in such a manner that it aligns with the goal of 99.

So we conclude that the operation: 73 - 70 + 96 gives the right sequence to equal 99.
&lt;/think&gt;
&lt;answer&gt;73 - 70 + 96 = 99&lt;/answer&gt;
</pre></div>
</div>
<p><strong>Step 500:</strong></p>
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>&lt;think&gt;
Let&#39;s begin by exploring various possible combinations of the given numbers using the arithmetic operators we have access to.

- If I add the numbers, I get: 56 + 73 + 51 = 180 which is not equal to our target number (68)
- If I subtract one number from another I will still exceed our target value as well since the maximum difference is: |(difference between max-min):| | (73 - 51) or | (73 - 56), etc.|
- Let&#39;s multiply the numbers individually and see if the division operation can bring us closer to the goal:
    - (73 * 51) - 56 = 3723 - 56 = 3667 which isn&#39;t the goal either.
    - The only operator left is addition and subtraction; I&#39;ll try the combination:
    ((73 - 56) + 51) gives me (17 + 51) = 68.

Thus, our solution fits the provided problem constraints and meets the required outcome.
&lt;/think&gt;
&lt;answer&gt;(73 - 56) + 51 = 68&lt;/answer&gt;
</pre></div>
</div>
<p><strong>Step 1000:</strong></p>
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>&lt;think&gt;
We need to form an expression using the given numbers (50, 86, and 49) such that it equals 85. Let&#39;s try different combinations:

(86 - 50) + 49 = 76 + 49 = 125 (too big)
(86 - 49) + 50 = 37 + 50 = 87 (too big)
(86 - 50) + 49 = 37 + 49 = 86 (too big)
(86 + 50) - 49 = 136 - 49 = 87 (too big)
(86 - 50) + (49 - x)? Not working!
(50 + 86) - 49: this is 136 which isn&#39;t our aim.
50 + (86 - 49) = 50 + 37 = 87 which wasn&#39;t correct.
50 - 86 + 49 = -16 + 49: This doesn&#39;t match up as well.
86 - (50 + 49) = 86 - 99 which doesn&#39;t work too.

We try one more:
(86 + 49) - 50 = 135 - 50 = 85!

That&#39;s it!
&lt;/think&gt;
&lt;answer&gt;(86 + 49) - 50 = 85&lt;/answer&gt;
</pre></div>
</div>
<p><strong>Step 2000:</strong></p>
<div class="highlight-plaintext notranslate"><div class="highlight"><pre><span></span>&lt;think&gt;
We need to form an expression using the numbers 58, 9, 78, and 44 which evaluates to 73. Let&#39;s try different combinations:
(78 - 58) + (9 + 44) = 10 + 53 = 63 (too low)
(78 - 58) + (9 - 44) = 20 - 35 = -15 (too low)
(78 - 58) + (44 - 9) = 20 + 35 = 55 (too low)
(78 + 58) - (9 + 44) = 136 - 53 = 83 (too high)
(78 + 58) - (9 - 44) = 136 + 35 = 171 (too high)
(78 + 58) - (44 + 9) = 136 + 53 = 189 (too high)
(78 + 9) - (58 + 44) = 87 - 102 = -15 (too low)
(78 + 9) - (58 - 44) = 87 - 14 = 73

So our solution is: (78 + 9) - (58 - 44) = 73
&lt;/think&gt;
&lt;answer&gt;(78 + 9) - (58 - 44) = 73&lt;/answer&gt;
</pre></div>
</div>
</section>
</section>
<hr class="docutils" />
<section id="unstable-experiment-records">
<h3>Unstable Experiment Records<a class="headerlink" href="#unstable-experiment-records" title="Link to this heading">ÔÉÅ</a></h3>
<p>For learning rate set to <code class="docutils literal notranslate"><span class="pre">1e-6</span></code> and $\beta$ set to <code class="docutils literal notranslate"><span class="pre">0.04</span></code>, the model showed oscillations around step 200. Both the format reward and CountdownORM reward dropped significantly:</p>
<p><a class="reference external" href="../../resources/grpo_countdown_1.png">Unstable Experiment Graph</a></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ÁâàÊùÉÊâÄÊúâ 2024, Ascend„ÄÇ</p>
  </div>

  Âà©Áî® <a href="https://www.sphinx-doc.org/">Sphinx</a> ÊûÑÂª∫Ôºå‰ΩøÁî®ÁöÑ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">‰∏ªÈ¢ò</a>
    Áî± <a href="https://readthedocs.org">Read the Docs</a> ÂºÄÂèë.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>