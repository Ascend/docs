

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Qwen3 Best Practices &mdash; ÊòáËÖæÂºÄÊ∫ê  ÊñáÊ°£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Á¥¢Âºï" href="../../../../../../genindex.html" />
    <link rel="search" title="ÊêúÁ¥¢" href="../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../index.html" class="icon icon-home">
            ÊòáËÖæÂºÄÊ∫ê
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="ÊêúÁ¥¢ÊñáÊ°£" aria-label="ÊêúÁ¥¢ÊñáÊ°£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="ÂØºËà™ËèúÂçï">
              <p class="caption" role="heading"><span class="caption-text">üèÅ ÂºÄÂßã‰ΩøÁî®</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ascend/quick_install.html">Âø´ÈÄüÂÆâË£ÖÊòáËÖæÁéØÂ¢É</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üèóÔ∏è  Âü∫Á°ÄËÆæÊñΩ‰∏éÊ°ÜÊû∂</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üß† ËÆ≠ÁªÉ‰∏éÂæÆË∞ÉÊ°ÜÊû∂</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üöÄ Êé®ÁêÜ‰∏éÊúçÂä°</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üé® Â§öÊ®°ÊÄÅ„ÄÅÂ∫îÁî®‰∏éËØÑÊµã</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ÁßªÂä®ÁâàÂØºËà™ËèúÂçï" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../index.html">ÊòáËÖæÂºÄÊ∫ê</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="È°µÈù¢ÂØºËà™">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Qwen3 Best Practices</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../_sources/sources/_generated/sources/ms-swift/source_en/BestPractices/Qwen3-Best-Practice.md.txt" rel="nofollow"> Êü•ÁúãÈ°µÈù¢Ê∫êÁ†Å</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="qwen3-best-practices">
<h1>Qwen3 Best Practices<a class="headerlink" href="#qwen3-best-practices" title="Link to this heading">ÔÉÅ</a></h1>
<p>Discussion: <a class="reference external" href="https://github.com/modelscope/ms-swift/issues/4030">issue 4030</a></p>
<p>Qwen Documentation: <a class="reference external" href="https://qwen.readthedocs.io/en/latest/training/ms_swift.html">https://qwen.readthedocs.io/en/latest/training/ms_swift.html</a></p>
<section id="inference">
<h2>Inference<a class="headerlink" href="#inference" title="Link to this heading">ÔÉÅ</a></h2>
<p>Thinking mode:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--infer_backend<span class="w"> </span>vllm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&lt;&lt;&lt; who are you?
&lt;think&gt;
Okay, the user is asking &quot;who are you?&quot; Let me start by introducing myself as Qwen, the large language model developed by Alibaba Cloud. I should mention my capabilities, like answering questions, creating content, and engaging in conversations. But I need to keep it concise. Also, the user might want to know how I can assist them. Maybe I should ask how I can help them today. Let me check if there&#39;s anything else important to include. Oh, I should make sure the tone is friendly and approachable. Alright, that should cover it.
&lt;/think&gt;

Hello! I am Qwen, a large language model developed by Alibaba Cloud. I can assist with a wide range of tasks, such as answering questions, creating content, writing stories, coding, and more. How can I help you today? üòä
&lt;&lt;&lt; clear
&lt;&lt;&lt; who are you? /no_think
&lt;think&gt;

&lt;/think&gt;

I am Qwen, a large language model developed by Alibaba Cloud. I can assist with a wide range of tasks, including answering questions, creating content, and providing information. How can I help you today?
</pre></div>
</div>
<p>Non-thinking mode:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--response_prefix</span></code> indicates that the model's output will continue after the prefix. It is equivalent to setting enable_thinking to False.</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--infer_backend<span class="w"> </span>vllm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--response_prefix<span class="w"> </span><span class="s1">&#39;&lt;think&gt;\n\n&lt;/think&gt;\n\n&#39;</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&lt;&lt;&lt; who are you?
&lt;think&gt;

&lt;/think&gt;

I am Qwen, a large-scale language model developed by Alibaba Cloud. I am designed to assist with a wide range of tasks, including answering questions, creating content, and providing information. How can I assist you today?
</pre></div>
</div>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Link to this heading">ÔÉÅ</a></h2>
<p>Before starting training, please ensure that your environment is properly configured.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>ms-swift<span class="w"> </span>-U
pip<span class="w"> </span>install<span class="w"> </span>transformers

pip<span class="w"> </span>install<span class="w"> </span>deepspeed<span class="w"> </span><span class="c1"># for multi-GPU training</span>
pip<span class="w"> </span>install<span class="w"> </span>liger-kernel<span class="w"> </span><span class="c1"># to save GPU memory resources</span>
pip<span class="w"> </span>install<span class="w"> </span>flash-attn<span class="w"> </span>--no-build-isolation<span class="w">  </span><span class="c1"># required for packing</span>
</pre></div>
</div>
</section>
<section id="supervised-fine-tuning-sft">
<h2>Supervised Fine-Tuning (SFT)<a class="headerlink" href="#supervised-fine-tuning-sft" title="Link to this heading">ÔÉÅ</a></h2>
<section id="data-preparation">
<h3>Data Preparation<a class="headerlink" href="#data-preparation" title="Link to this heading">ÔÉÅ</a></h3>
<p>When using ms-swift for SFT, the custom dataset format is as follows (the <code class="docutils literal notranslate"><span class="pre">system</span></code> field is optional). You can organize it in JSON, JSONL, or CSV format. Specify <code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">&lt;dataset_path&gt;</span></code> in the training script. For a complete guide on dataset formats, refer to the <a class="reference internal" href="../Customization/Custom-dataset.html"><span class="doc">Custom Dataset Documentation</span></a>.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># General format
{&quot;messages&quot;: [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;&lt;system-prompt&gt;&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&lt;query1&gt;&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;&lt;response1&gt;&quot;}
]}
# Format with thinking process
{&quot;messages&quot;: [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Where is the capital of Zhejiang?&quot;},
    {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;Thought: ...\n\nAnswer:\nThe capital of Zhejiang is Hangzhou.&quot;}
]}
</pre></div>
</div>
<p>If you want to train using data without the thinking chain while preserving the model's reasoning ability, you can use one of the following methods to minimize the impact of fine-tuning:</p>
<p><strong>Option 1</strong>: [Recommended] During training, specify <code class="docutils literal notranslate"><span class="pre">--loss_scale</span> <span class="pre">ignore_empty_think</span></code>, which will ignore the loss calculation for <code class="docutils literal notranslate"><span class="pre">'&lt;think&gt;\n\n&lt;/think&gt;\n\n'</span></code>, thus avoiding the loss of reasoning capability. The training script can be found <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo1.sh">here</a>. This method also works for models like DeepSeek-R1. The custom dataset format is as follows:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Where is the capital of Zhejiang?&quot;</span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;think&gt;\n\n&lt;/think&gt;\n\nThe capital of Zhejiang is Hangzhou.&quot;</span><span class="p">}</span>
<span class="p">]}</span>
</pre></div>
</div>
<p><strong>Option 2</strong>: Add <code class="docutils literal notranslate"><span class="pre">/no_think</span></code> to the query in the dataset to avoid losing the reasoning capability. The training script can be found <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/think_model/qwen3_demo2.sh">here</a>. The custom dataset format is as follows:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Where is the capital of Zhejiang? /no_think&quot;</span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;think&gt;\n\n&lt;/think&gt;\n\nThe capital of Zhejiang is Hangzhou.&quot;</span><span class="p">}</span>
<span class="p">]}</span>
</pre></div>
</div>
<p>You can use the following command to obtain a distilled reasoning dataset. During training, you can mix it with datasets that do not contain chain-of-thought (CoT) data to further mitigate the loss of reasoning ability:</p>
<ul class="simple">
<li><p>The choice of <code class="docutils literal notranslate"><span class="pre">--val_dataset</span></code> is arbitrary. The reasoning results saved to <code class="docutils literal notranslate"><span class="pre">result_path</span></code> can be specified directly in training via <code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">distill_dataset.jsonl</span></code>.</p></li>
<li><p>This approach is also applicable to other reasoning models, such as deepseek-r1.</p></li>
</ul>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4 * 80GiB</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-32B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--infer_backend<span class="w"> </span>vllm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--val_dataset<span class="w"> </span><span class="s1">&#39;AI-ModelScope/alpaca-gpt4-data-en#5000&#39;</span><span class="w"> </span><span class="s1">&#39;AI-ModelScope/alpaca-gpt4-data-zh#5000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_gpu_memory_utilization<span class="w"> </span><span class="m">0</span>.9<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_tensor_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--write_batch_size<span class="w"> </span><span class="m">1000</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--result_path<span class="w"> </span>distill_dataset.jsonl
</pre></div>
</div>
</section>
<section id="minute-self-awareness-fine-tuning">
<h3>30-Minute Self-Awareness Fine-Tuning<a class="headerlink" href="#minute-self-awareness-fine-tuning" title="Link to this heading">ÔÉÅ</a></h3>
<p>This section demonstrates how to perform self-awareness fine-tuning on Qwen3-8B within 30 minutes. A GPU with at least 22GB of VRAM is required and can run on the free computing resources provided by ModelScope, such as the A10 instance.</p>
<p>After training, the model will no longer identify itself as a &quot;Qwen&quot; trained by &quot;Tongyi Lab,&quot; but rather as a &quot;swift-robot&quot; trained by &quot;swift.&quot;</p>
<p>If you need to train in an offline environment, you can manually download the model and dataset, and specify <code class="docutils literal notranslate"><span class="pre">--model</span> <span class="pre">&lt;model-path&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">&lt;dataset-dir&gt;</span></code>. The dataset is available on the <a class="reference external" href="https://modelscope.cn/datasets/swift/self-cognition">ModelScope Hub</a>. You can view the preprocessing function for the <code class="docutils literal notranslate"><span class="pre">swift/self-cognition</span></code> dataset <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/36fdf381e5e88cb8a71c9d69c1d8936a989318cc/swift/llm/dataset/dataset/llm.py#L882">here</a>.</p>
<p>For explanations of the parameters used in the training script, please refer to the <a class="reference internal" href="../Instruction/Command-line-parameters.html"><span class="doc">Command Line Arguments Documentation</span></a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># GPU Memory Usage: 22GB</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>lora<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;swift/Qwen3-SFT-Mixin#2000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">              </span><span class="s1">&#39;swift/self-cognition:qwen3#600&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_rank<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lora_alpha<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--target_modules<span class="w"> </span>all-linear<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">2048</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_author<span class="w"> </span>swift<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model_name<span class="w"> </span>swift-robot
</pre></div>
</div>
<p>After fine-tuning, you can test the results using the following script. Note that the <code class="docutils literal notranslate"><span class="pre">--adapters</span></code> part should be modified to point to the final saved checkpoint directory:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>infer<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/vx-xxx/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--stream<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--temperature<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_new_tokens<span class="w"> </span><span class="m">2048</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>&lt;&lt;&lt; who are you?
&lt;think&gt;
Okay, the user asked, &quot;who are you?&quot; I need to introduce myself. Let me start by stating my name, swift-robot. Then, I should mention that I&#39;m an AI assistant developed by swift. I should explain my purpose, which is to provide information and assistance. I should also highlight my capabilities, like answering questions, generating text, and engaging in conversation. It&#39;s important to keep the tone friendly and approachable. Maybe add something about being here to help and encourage the user to ask anything. Let me check if I covered all the key points: name, developer, purpose, capabilities, and a welcoming statement. Yeah, that should do it. Now, let me put that into a concise and friendly response.
&lt;/think&gt;

Hello! I am swift-robot, an artificial intelligence assistant developed by swift. My purpose is to provide information and assistance to users like you. I can answer questions, generate text, and engage in conversations on a wide range of topics. I am here to help, so feel free to ask me anything you need!
</pre></div>
</div>
<p>By default, ms-swift uses the ModelScope community to download models and datasets. If you want to use the HuggingFace community instead, you need to additionally specify <code class="docutils literal notranslate"><span class="pre">--use_hf</span> <span class="pre">true</span></code>.</p>
<p>Merge LoRA weights:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>swift<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--merge_lora<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
<p>Push the model to ModelScope/HuggingFace:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># If pushing full weights, change `--adapters` to `--model`.</span>
<span class="c1"># You can find your ModelScope hub_token here: https://modelscope.cn/my/myaccesstoken</span>
swift<span class="w"> </span><span class="nb">export</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--adapters<span class="w"> </span>output/checkpoint-xxx<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--push_to_hub<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--hub_model_id<span class="w"> </span><span class="s1">&#39;&lt;hub-model-id&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--hub_token<span class="w"> </span><span class="s1">&#39;&lt;hub-token&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_hf<span class="w"> </span><span class="nb">false</span>
</pre></div>
</div>
<p>If you want to perform training on multiple GPUs, the following example provides a multi-GPU training setup:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4 * 60GB</span>
<span class="c1"># You can run the experiment by setting `--dataset AI-ModelScope/alpaca-gpt4-data-en`</span>
<span class="c1"># Note: If you specify `--packing true`, you must also set `--attn_impl flash_attn`</span>

<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;&lt;your-dataset&gt;&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">100</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_only_model<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deepspeed<span class="w"> </span>zero3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_liger_kernel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attn_impl<span class="w"> </span>flash_attn
</pre></div>
</div>
</section>
</section>
<section id="reinforcement-learning-rl">
<h2>Reinforcement Learning (RL)<a class="headerlink" href="#reinforcement-learning-rl" title="Link to this heading">ÔÉÅ</a></h2>
<p>ms-swift supports RLHF methods such as DPO, GRPO, DAPO, PPO, KTO, and GKD. This section will focus on using ms-swift for GRPO training on Qwen3-8B. For more information about GRPO, refer to the <a class="reference internal" href="../Instruction/GRPO/GetStarted/GRPO.html"><span class="doc">GRPO documentation</span></a>. Additional RLHF training scripts can be found in <a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/rlhf">examples/train/rlhf</a>.</p>
<section id="environment-setup">
<h3>Environment Setup<a class="headerlink" href="#environment-setup" title="Link to this heading">ÔÉÅ</a></h3>
<p>In addition to installing the dependencies related to ms-swift mentioned above, you also need to install the following:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;math_verify&quot;</span>
pip<span class="w"> </span>install<span class="w"> </span><span class="nv">vllm</span><span class="o">==</span><span class="m">0</span>.8.5.post1
</pre></div>
</div>
</section>
<section id="id1">
<h3>Data Preparation<a class="headerlink" href="#id1" title="Link to this heading">ÔÉÅ</a></h3>
<p>The dataset format used for GRPO training with ms-swift is similar to that of SFT, but it does not require the final assistant's response part. If accuracy is used as the reward, an additional <code class="docutils literal notranslate"><span class="pre">solution</span></code> column is required to calculate accuracy.</p>
<p>Example dataset format:</p>
<div class="highlight-jsonl notranslate"><div class="highlight"><pre><span></span>{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me tomorrow&#39;s weather&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is 1 + 1?&quot;}, {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;It equals 2&quot;}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What about adding 1?&quot;}]}
{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is your name?&quot;}]}
</pre></div>
</div>
<p>For data preparation for other RLHF algorithms, please refer to the <a class="reference external" href="../Customization/Custom-dataset.md#rlhf">Custom Dataset Documentation</a>.</p>
<p>Notes on dataset requirements:</p>
<ul class="simple">
<li><p><strong>Reward Function Calculation</strong>: The dataset format depends on the reward function being used. Additional columns may be needed to support specific reward calculations. For example:</p>
<ul>
<li><p>When using built-in <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> or <code class="docutils literal notranslate"><span class="pre">cosine</span></code> rewards, the dataset must include a <code class="docutils literal notranslate"><span class="pre">solution</span></code> column to calculate the accuracy of responses.</p></li>
<li><p>Other columns in the dataset will be passed as <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code> to the reward function for further customization.</p></li>
</ul>
</li>
<li><p><strong>Custom Reward Functions</strong>: To customize the reward function according to your specific needs, refer to: <a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/grpo/plugin">External Reward Plugin</a>. This plugin provides examples and templates for implementing custom reward functions.</p></li>
</ul>
<p>We use AI-MO/NuminaMath-TIR as the dataset and compute the accuracy-based reward for model responses.</p>
<p>During training, we utilize vLLM to accelerate the sampling process.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 70G*8</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3,4,5,6,7<span class="w"> </span><span class="se">\</span>
<span class="nv">NPROC_PER_NODE</span><span class="o">=</span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>rlhf<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--rlhf_type<span class="w"> </span>grpo<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-8B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--tuner_type<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;AI-MO/NuminaMath-TIR#5000&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--torch_dtype<span class="w"> </span>bfloat16<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_train_epochs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_train_batch_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--per_device_eval_batch_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--learning_rate<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_total_limit<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--logging_steps<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>output<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--gradient_accumulation_steps<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--warmup_ratio<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_completion_length<span class="w"> </span><span class="m">4096</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--reward_funcs<span class="w"> </span>accuracy<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--num_generations<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_vllm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_gpu_memory_utilization<span class="w"> </span><span class="m">0</span>.4<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sleep_level<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--offload_model<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--offload_optimizer<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--deepspeed<span class="w"> </span>zero3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_tensor_parallel_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--temperature<span class="w"> </span><span class="m">1</span>.0<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--top_p<span class="w"> </span><span class="m">0</span>.85<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--log_completions<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--overlong_filter<span class="w"> </span><span class="nb">true</span>
</pre></div>
</div>
</section>
</section>
<section id="megatron-swift">
<h2>Megatron-SWIFT<a class="headerlink" href="#megatron-swift" title="Link to this heading">ÔÉÅ</a></h2>
<p>Best practice reference for single-node 8xH20 LoRA training with Qwen3-235B-A22B-Instruct-250718: https://github.com/modelscope/ms-swift/pull/5033.</p>
<p>ms-swift introduces Megatron parallelism techniques to accelerate CPT/SFT/DPO/GRPO for large models. Supported models can be found in the <a class="reference internal" href="../Instruction/Supported-models-and-datasets.html"><span class="doc">Supported Models and Datasets Document</span></a>.</p>
<p>For environment setup, refer to the <a class="reference internal" href="../Megatron-SWIFT/Quick-start.html"><span class="doc">Megatron-SWIFT Training Documentation</span></a>.</p>
<p>We will use Alibaba Cloud DLC to launch training. The training environment consists of two nodes equipped with 8x 80GiB A800 GPUs each. For more information on multi-node launching, see <a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/multi-node">here</a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># https://help.aliyun.com/zh/pai/user-guide/general-environment-variables</span>
<span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span><span class="s1">&#39;expandable_segments:True&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NNODES</span><span class="o">=</span><span class="nv">$WORLD_SIZE</span><span class="w"> </span><span class="se">\</span>
<span class="nv">NODE_RANK</span><span class="o">=</span><span class="nv">$RANK</span><span class="w"> </span><span class="se">\</span>
megatron<span class="w"> </span>sft<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-30B-A3B-Base<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_safetensors<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset<span class="w"> </span><span class="s1">&#39;liucong/Chinese-DeepSeek-R1-Distill-data-110k-SFT&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--load_from_cache_file<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--split_dataset_ratio<span class="w"> </span><span class="m">0</span>.01<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--pipeline_model_parallel_size<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--expert_model_parallel_size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_permute_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_grouped_gemm<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_shared_expert_overlap<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--moe_aux_loss_coeff<span class="w"> </span>1e-3<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--micro_batch_size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--global_batch_size<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--packing<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_granularity<span class="w"> </span>full<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_method<span class="w"> </span>uniform<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--recompute_num_layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--train_iters<span class="w"> </span><span class="m">2000</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_iters<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--finetune<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--cross_entropy_loss_fusion<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr<span class="w"> </span>1e-5<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--lr_warmup_fraction<span class="w"> </span><span class="m">0</span>.05<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--min_lr<span class="w"> </span>1e-6<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--output_dir<span class="w"> </span>megatron_output/Qwen3-30B-A3B-Base<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--eval_steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save_steps<span class="w"> </span><span class="m">200</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_length<span class="w"> </span><span class="m">8192</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataloader_num_workers<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--dataset_num_proc<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_optim<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--no_save_rng<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--sequence_parallel<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--attention_backend<span class="w"> </span>flash
</pre></div>
</div>
<p>Training loss chart (partial):</p>
<img width="910" alt="Image" src="https://github.com/user-attachments/assets/9fe393aa-8299-4659-aa2f-be5d44f0730b" /><p>Effect screenshot:</p>
<img width="1066" alt="Image" src="https://github.com/user-attachments/assets/1a924130-1954-43e9-9093-b019aeef5949" /><p>The custom dataset format is the same as that used in <code class="docutils literal notranslate"><span class="pre">swift</span> <span class="pre">sft</span></code>. For details, see the previous sections. Simply specify <code class="docutils literal notranslate"><span class="pre">--dataset</span> <span class="pre">&lt;dataset_path&gt;</span></code>.</p>
<p>A comparison of training speed and GPU memory usage when performing full-parameter fine-tuning of the Qwen3-30B-A3B model using <code class="docutils literal notranslate"><span class="pre">megatron</span> <span class="pre">sft</span></code> and <code class="docutils literal notranslate"><span class="pre">swift</span> <span class="pre">sft</span></code> is shown below:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th></th>
<th>Megatron-LM</th>
<th>DeepSpeed-ZeRO2</th>
<th>DeepSpeed-ZeRO3</th>
</tr>
</thead>
<tbody>
<tr>
<td>ËÆ≠ÁªÉÈÄüÂ∫¶</td>
<td>9.6s/it</td>
<td>-</td>
<td>91.2s/it</td>
</tr>
<tr>
<td>ÊòæÂ≠ò‰ΩøÁî®</td>
<td>16 * 60GiB</td>
<td>OOM</td>
<td>16 * 80GiB</td>
</tr>
</tbody>
</table></section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ÁâàÊùÉÊâÄÊúâ 2024, Ascend„ÄÇ</p>
  </div>

  Âà©Áî® <a href="https://www.sphinx-doc.org/">Sphinx</a> ÊûÑÂª∫Ôºå‰ΩøÁî®ÁöÑ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">‰∏ªÈ¢ò</a>
    Áî± <a href="https://readthedocs.org">Read the Docs</a> ÂºÄÂèë.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>