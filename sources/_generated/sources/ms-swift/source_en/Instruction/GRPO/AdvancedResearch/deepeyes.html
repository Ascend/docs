

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>DeepEyes: Incentivizing &#34;Thinking with Images&#34; via Reinforcement Learning &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">DeepEyes: Incentivizing &quot;Thinking with Images&quot; via Reinforcement Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../../_sources/sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/deepeyes.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="deepeyes-incentivizing-thinking-with-images-via-reinforcement-learning">
<h1>DeepEyes: Incentivizing &quot;Thinking with Images&quot; via Reinforcement Learning<a class="headerlink" href="#deepeyes-incentivizing-thinking-with-images-via-reinforcement-learning" title="Link to this heading">ïƒ</a></h1>
<p><strong>Version Requirement</strong>: ms-swift&gt;=3.7</p>
<section id="principle-introduction">
<h2>Principle Introduction<a class="headerlink" href="#principle-introduction" title="Link to this heading">ïƒ</a></h2>
<p>The <a class="reference external" href="https://arxiv.org/abs/2505.14362">DeepEyes paper</a> proposes a method that enables models to &quot;think with images&quot; (image-assisted reasoning) by leveraging reinforcement learning. This approach achieves emergent model capabilities through end-to-end reinforcement learning, without requiring additional SFT (Supervised Fine-Tuning) steps. The model is equipped with built-in image localization capabilities and can actively invoke an &quot;image zoom-in tool&quot;: during inference, the model automatically selects specific regions within an image for zooming and cropping, and then chains the processed region information into downstream reasoning, thus achieving multi-step visual-text reasoning.</p>
<p><img alt="DeepEyes Overview" src="../../../../../../../../_images/deepeyes.png" /></p>
</section>
<section id="best-practices">
<h2>Best Practices<a class="headerlink" href="#best-practices" title="Link to this heading">ïƒ</a></h2>
<p><strong>Dataset Download and Registration</strong></p>
<p>Download the official DeepEyes training datasets locally:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># modelscope</span>
modelscope<span class="w"> </span>download<span class="w"> </span>--dataset<span class="w"> </span>Lixiang/ChenShawn-DeepEyes-Datasets-47k

<span class="c1"># huggingface</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>ChenShawn/DeepEyes-Datasets-47k<span class="w"> </span>--repo-type<span class="o">=</span>dataset
</pre></div>
</div>
<p>There are three parquet files in the dataset. Register them in the <code class="docutils literal notranslate"><span class="pre">swift/dataset/data/dataset_info.json</span></code> file. For each, rename the <code class="docutils literal notranslate"><span class="pre">prompt</span></code> column to <code class="docutils literal notranslate"><span class="pre">messages</span></code>:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;ms_dataset_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;path/to/data_0.1.2_visual_toolbox_v2.parquet&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;columns&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;messages&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;ms_dataset_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;path/to/data/data_thinklite_reasoning_acc.parquet&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;columns&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;messages&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;ms_dataset_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;path/to/data/data_v0.8_visual_toolbox_v2.parquet&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;columns&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;messages&quot;</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
</pre></div>
</div>
<p>For registering the reward function and tool call logic locally as used in the paper, you can refer to the <a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/grpo/plugin/deepeyes/deepeyes_plugin.py">DeepEyes implementation example</a>.</p>
<p><strong>Deploying the Evaluation Model</strong></p>
<p>The reward function in DeepEyes relies on a generative reward model to compare model outputs with ground-truth answers. For efficiency, it is recommended to deploy the reward model as a service.</p>
<p>Assuming you use the Qwen2.5-VL-72B-Instruct model for evaluation, refer to the following deployment command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># 4*80G</span>
<span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1,2,3<span class="w"> </span><span class="se">\</span>
swift<span class="w"> </span>deploy<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen2.5-VL-72B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--infer_backend<span class="w"> </span>vllm<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_tensor_parallel_size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<p>In the plugin file, you can use the OpenAI interface to call the model; see the <a class="reference external" href="../DeveloperGuide/reward_model.md#external-deployment">Reward Model documentation</a>.</p>
<p>The complete training script can be found at https://github.com/modelscope/ms-swift/tree/main/examples/train/grpo/plugin/deepeyes/deepeyes.sh</p>
</section>
<section id="implementation-details">
<h2>Implementation Details<a class="headerlink" href="#implementation-details" title="Link to this heading">ïƒ</a></h2>
<p>The <a class="reference external" href="https://github.com/modelscope/ms-swift/tree/main/examples/train/grpo/plugin/deepeyes/deepeyes_plugin.py">DeepEyes implementation example</a>, which references the <a class="reference external" href="https://github.com/Visual-Agent/DeepEyes/blob/main/verl/utils/reward_score/vl_agent.py">official implementation</a>, provides sample code for a DeepEyes training plugin, covering the logic of the reward function and multi-turn interaction calls.</p>
<p><strong>Dataset Info</strong> is shown below:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Dataset File Name</th>
<th>data_source</th>
<th>Scoring Function</th>
<th>Tool Call</th>
</tr>
</thead>
<tbody>
<tr>
<td>data_v0.8_visual_toolbox_v2.parquet</td>
<td>chart</td>
<td>vl_agent.compute_score</td>
<td>True (image_zoom_in_tool)</td>
</tr>
<tr>
<td>data_0.1.2_visual_toolbox_v2.parquet</td>
<td>vstar</td>
<td>vl_agent.compute_score</td>
<td>True (image_zoom_in_tool)</td>
</tr>
<tr>
<td>data_thinklite_reasoning_acc.parquet</td>
<td>thinklite_eureka</td>
<td>vl_agent.compute_score_math</td>
<td>False</td>
</tr>
</tbody>
</table><p><strong>Note</strong>: When processing image inputs, multimodal large models may perform preprocessing (such as cropping or resizing limited by the <code class="docutils literal notranslate"><span class="pre">max_pixels</span></code> parameter). When using the image zoom-in tool (<code class="docutils literal notranslate"><span class="pre">image_zoom_in_tool</span></code>), the model will output the cropped bbox based on the input image. Therefore, it is necessary to ensure the image fed into the tool has already been preprocessed. The following example shows how this is implemented in the Qwen2.5-VL series:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">qwen_vl_utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">fetch_image</span>
<span class="c1"># At this point, images have not yet been preprocessed</span>
<span class="n">infer_request</span><span class="o">.</span><span class="n">images</span>
<span class="c1"># Load as PIL.Image and apply cropping (same as using the MAX_PIXELS environment variable)</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">fetch_image</span><span class="p">({</span><span class="s1">&#39;image&#39;</span><span class="p">:</span> <span class="n">load_pil_image</span><span class="p">(</span><span class="n">infer_request</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="mi">0</span><span class="p">])})</span>
</pre></div>
</div>
<p><strong>Tool Reward</strong></p>
<p>According to the paper, if the final answer is correct and the trajectory uses at least one tool, a tool reward is given. To prevent the model from generating invalid tool calls, we determine this based on the number of images, not just on the presence of <code class="docutils literal notranslate"><span class="pre">&lt;tool_call&gt;</span></code> tokens.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tool_reward</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">num_image</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">acc_reward</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mf">0.0</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>