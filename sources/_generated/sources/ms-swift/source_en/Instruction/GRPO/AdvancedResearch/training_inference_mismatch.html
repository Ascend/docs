

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training-Inference-Mismatch &mdash; æ˜‡è…¾å¼€æº  æ–‡æ¡£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="ç´¢å¼•" href="../../../../../../../../genindex.html" />
    <link rel="search" title="æœç´¢" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../../../index.html" class="icon icon-home">
            æ˜‡è…¾å¼€æº
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="æœç´¢æ–‡æ¡£" aria-label="æœç´¢æ–‡æ¡£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="å¯¼èˆªèœå•">
              <p class="caption" role="heading"><span class="caption-text">ğŸ å¼€å§‹ä½¿ç”¨</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../ascend/quick_install.html">å¿«é€Ÿå®‰è£…æ˜‡è…¾ç¯å¢ƒ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ—ï¸  åŸºç¡€è®¾æ–½ä¸æ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ§  è®­ç»ƒä¸å¾®è°ƒæ¡†æ¶</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸš€ æ¨ç†ä¸æœåŠ¡</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">ğŸ¨ å¤šæ¨¡æ€ã€åº”ç”¨ä¸è¯„æµ‹</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ç§»åŠ¨ç‰ˆå¯¼èˆªèœå•" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">æ˜‡è…¾å¼€æº</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="é¡µé¢å¯¼èˆª">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Training-Inference-Mismatch</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../../_sources/sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/AdvancedResearch/training_inference_mismatch.md.txt" rel="nofollow"> æŸ¥çœ‹é¡µé¢æºç </a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="training-inference-mismatch">
<h1>Training-Inference-Mismatch<a class="headerlink" href="#training-inference-mismatch" title="Link to this heading">ïƒ</a></h1>
<p><strong>Version Requirement</strong>: ms-swift&gt;=3.11</p>
<p><strong>TL;DR</strong>: While GRPO introduces vLLM to accelerate the sampling process, it also introduces Training-Inference Mismatch issues that may affect training stability. This document explains the background, causes, and solutions to this problem.</p>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Link to this heading">ïƒ</a></h2>
<section id="basic-assumptions-of-grpo">
<h3>Basic Assumptions of GRPO<a class="headerlink" href="#basic-assumptions-of-grpo" title="Link to this heading">ïƒ</a></h3>
<p>The training objective of GRPO (Group Relative Policy Optimization) can be expressed as:</p>
<p>$$
\mathcal{L}<em>{\text{GRPO}} = - \mathbb{E}</em>{y \sim \pi_\theta} \left[ \min \left( r_t(\theta) \hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) \hat{A}_t \right) \right]
$$</p>
<p>Where:</p>
<ul class="simple">
<li><p>$r_t(\theta) = \frac{\pi_\theta(y_t|x, y_{&lt;t})}{\pi_{\theta_{\text{old}}}(y_t|x, y_{&lt;t})}$ is the importance sampling ratio</p></li>
<li><p>$\hat{A}_t$ is the advantage function, calculated based on reward and group baseline</p></li>
<li><p>$\epsilon$ is the clipping parameter</p></li>
</ul>
<p><strong>Core Assumption</strong>: Samples $y$ are drawn from the policy $\pi_\theta$. In practice, this means:</p>
<ol class="simple">
<li><p>The rollout model and the training model (policy model) should be <strong>the same model</strong> $\pi_\theta$</p></li>
<li><p>The probability distributions of both models should be <strong>exactly identical</strong>, i.e., $\pi_{\text{rollout}} = \pi_\theta$</p></li>
</ol>
</section>
<section id="deviation-after-introducing-vllm">
<h3>Deviation After Introducing vLLM<a class="headerlink" href="#deviation-after-introducing-vllm" title="Link to this heading">ïƒ</a></h3>
<p>GRPO's training speed is largely constrained by the sampling process (rollout). To accelerate this, training frameworks introduce high-performance inference engines (such as vLLM) for sampling. The <strong>ideal assumption</strong> is that through weight synchronization, vLLM maintains consistency with the training model, i.e., $\pi_{\text{vLLM}} \equiv \pi_\theta$.</p>
<p>However, in practice, even with fully synchronized weights, due to differences in operator implementations, the probability distributions still deviate:</p>
<p>$$
\pi_{\text{vLLM}}(y|x) \neq \pi_\theta(y|x)
$$</p>
<p>At this point, the actual training objective becomes:</p>
<p>$$
\mathcal{L} = - \mathbb{E}<em>{y \sim \pi</em>{\text{vLLM}}} \left[ \min \left( r_t(\theta) \hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) \hat{A}_t \right) \right]
$$</p>
<p>Where samples come from $\pi_{\text{vLLM}}$, but gradients are computed based on $\pi_\theta$. This <strong>violates the algorithm's on-policy assumption</strong>, introducing training-inference mismatch issues and potentially causing performance degradation.</p>
</section>
</section>
<section id="solution">
<h2>Solution<a class="headerlink" href="#solution" title="Link to this heading">ïƒ</a></h2>
<p>To address training-inference mismatch, we can introduce <strong>Importance Sampling (IS)</strong> correction mechanisms.</p>
<section id="importance-sampling-correction">
<h3>Importance Sampling Correction<a class="headerlink" href="#importance-sampling-correction" title="Link to this heading">ïƒ</a></h3>
<p>The basic idea of importance sampling is: when samples come from distribution $q$ rather than target distribution $p$, we can correct the expectation calculation by introducing weights:</p>
<p>$$
\mathbb{E}<em>{x \sim p} [f(x)] = \mathbb{E}</em>{x \sim q} \left[ \frac{p(x)}{q(x)} \cdot f(x) \right]
$$</p>
<p>Applied to the GRPO scenario, the corrected loss function is:</p>
<p>$$
\mathcal{L}<em>{\text{corrected}} = - \mathbb{E}</em>{y \sim \pi_{\text{vLLM}}} \left[ w(x, y) \cdot \min \left( r_t(\theta) \hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) \hat{A}_t \right) \right]
$$</p>
<p>Where $w(x, y)$ is the importance sampling weight used to correct the distribution bias between vLLM and the training model.</p>
<p>Importance sampling weights can be computed and applied at different granularities:</p>
<ol class="simple">
<li><p><strong>Token-Level</strong></p></li>
</ol>
<p>Compute the importance sampling ratio at each token:</p>
<p>$$
w_{i,t}^{\text{token}} = \frac{\pi_\theta(y_{i,t}|x, y_{i,&lt;t})}{\pi_{\text{vLLM}}(y_{i,t}|x, y_{i,&lt;t})}
$$</p>
<ol class="simple">
<li><p><strong>Sequence-Level</strong></p></li>
</ol>
<p>Compute the sequence-level importance sampling ratio, then broadcast to each token:</p>
<p>$$
w_i^{\text{seq}} = \left[ \frac{\pi_\theta(y_i|x)}{\pi_{\text{vLLM}}(y_i|x)} \right]^{\frac{1}{|y_i|}} = \exp\left( \frac{1}{|y_i|} \sum_{t=1}^{|y_i|} \log \frac{\pi_\theta(y_{i,t}|x, y_{i,&lt;t})}{\pi_{\text{vLLM}}(y_{i,t}|x, y_{i,&lt;t})} \right)
$$</p>
</section>
<section id="stability-control-truncate-vs-mask">
<h3>Stability Control: Truncate vs. Mask<a class="headerlink" href="#stability-control-truncate-vs-mask" title="Link to this heading">ïƒ</a></h3>
<p>Excessively large importance sampling weights can cause gradient explosion and destabilize training. Therefore, weight control is necessary:</p>
<section id="truncate">
<h4>1. Truncate<a class="headerlink" href="#truncate" title="Link to this heading">ïƒ</a></h4>
<p>Truncate the importance sampling weight to the $[0, \tau]$ interval:</p>
<p>$$
w_{\text{truncate}} = \min(w, \tau)
$$</p>
<p>This method retains all samples but limits their influence.</p>
</section>
<section id="mask">
<h4>2. Mask<a class="headerlink" href="#mask" title="Link to this heading">ïƒ</a></h4>
<p>Discard token/sequence data where weights exceed the threshold:</p>
<p>$$
w_{\text{mask}} = \begin{cases}
w &amp; \text{if } w \leq \tau \
0 &amp; \text{otherwise}
\end{cases}
$$</p>
</section>
</section>
<section id="four-correction-modes">
<h3>Four Correction Modes<a class="headerlink" href="#four-correction-modes" title="Link to this heading">ïƒ</a></h3>
<p>Combining granularity and control strategies, there are four correction modes (selected via <code class="docutils literal notranslate"><span class="pre">--rollout_importance_sampling_mode</span></code> parameter):</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Mode</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>token_truncate</code></td>
<td>Token-level truncation</td>
</tr>
<tr>
<td><code>token_mask</code></td>
<td>Token-level masking</td>
</tr>
<tr>
<td><code>sequence_truncate</code></td>
<td>Sequence-level truncation</td>
</tr>
<tr>
<td><code>sequence_mask</code></td>
<td>Sequence-level masking</td>
</tr>
</tbody>
</table><p>The threshold is set via the <code class="docutils literal notranslate"><span class="pre">--rollout_importance_sampling_threshold</span></code> parameter.</p>
</section>
</section>
<section id="metrics">
<h2>Metrics<a class="headerlink" href="#metrics" title="Link to this heading">ïƒ</a></h2>
<p>To monitor the degree of training-inference mismatch during training, we add the following metrics to the logs (prefixed with <code class="docutils literal notranslate"><span class="pre">rollout_correction/</span></code>):</p>
<section id="kl-divergence">
<h3>1. KL Divergence<a class="headerlink" href="#kl-divergence" title="Link to this heading">ïƒ</a></h3>
<p>KL divergence measures the deviation between the rollout policy and the training policy. Both metrics estimate $\text{KL}(\pi_{\text{vLLM}} | \pi_\theta)$</p>
<p><strong>Direct estimator <code class="docutils literal notranslate"><span class="pre">kl</span></code></strong>:</p>
<p>$$
\text{KL}(\pi_{\text{vLLM}} | \pi_\theta) = \mathbb{E}<em>{\pi</em>{\text{vLLM}}}\left[ \log \frac{\pi_{\text{vLLM}}}{\pi_\theta} \right]
$$</p>
<p><strong>K3 estimator <code class="docutils literal notranslate"><span class="pre">k3_kl</span></code></strong>:</p>
<p>$$
\text{KL}(\pi_{\text{vLLM}} | \pi_\theta) \approx \mathbb{E}<em>{\pi</em>{\text{vLLM}}}\left[ \rho - \log \rho - 1 \right], \quad \rho = \frac{\pi_\theta}{\pi_{\text{vLLM}}}
$$</p>
<p>The K3 estimator is more numerically stable when KL values are small and is always non-negative.</p>
</section>
<section id="perplexity-ppl">
<h3>2. Perplexity (PPL)<a class="headerlink" href="#perplexity-ppl" title="Link to this heading">ïƒ</a></h3>
<p>Perplexity measures the model's prediction uncertainty for a sequence:</p>
<p>$$
\text{PPL} = \exp\left( -\frac{1}{|y|} \sum_{t=1}^{|y|} \log p(y_t) \right)
$$</p>
<p>Related metrics:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">training_ppl</span></code> / <code class="docutils literal notranslate"><span class="pre">training_log_ppl</span></code>: Training policy PPL and its logarithm</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rollout_ppl</span></code> / <code class="docutils literal notranslate"><span class="pre">rollout_log_ppl</span></code>: Rollout policy PPL and its logarithm</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_ppl_diff</span></code>: Log PPL difference, positive value means training policy assigns lower probability</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_ppl_abs_diff</span></code>: Absolute log PPL difference</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">log_ppl_diff_max</span></code> / <code class="docutils literal notranslate"><span class="pre">log_ppl_diff_min</span></code>: Max/min of log PPL difference</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ppl_ratio</span></code>: PPL ratio $\frac{\text{PPL}<em>{\text{training}}}{\text{PPL}</em>{\text{rollout}}}$</p></li>
</ul>
</section>
<section id="divergence-chi-squared-divergence">
<h3>3. Ï‡Â² Divergence (Chi-squared Divergence)<a class="headerlink" href="#divergence-chi-squared-divergence" title="Link to this heading">ïƒ</a></h3>
<p>Ï‡Â² divergence measures the variance of importance sampling weights:</p>
<p>$$
\chi^2(\pi_\theta | \pi_{\text{vLLM}}) = \mathbb{E}<em>{\pi</em>{\text{vLLM}}}\left[ \rho^2 \right] - 1, \quad \rho = \frac{\pi_\theta}{\pi_{\text{vLLM}}}
$$</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">chi2_token</span></code>: Token-level Ï‡Â² divergence, $\mathbb{E}[\rho_t^2] - 1$</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chi2_seq</span></code>: Sequence-level Ï‡Â² divergence (geometric mean based), $\mathbb{E}[\rho_{\text{geo}}^2] - 1$, where $\rho_{\text{geo}} = \exp(\frac{1}{T}\sum_t \log \rho_t)$</p></li>
</ul>
<p>Higher Ï‡Â² divergence indicates larger IS weight variance and less stable training. <code class="docutils literal notranslate"><span class="pre">chi2_seq</span></code> uses geometric mean instead of product, making it comparable in scale to <code class="docutils literal notranslate"><span class="pre">chi2_token</span></code>.</p>
</section>
<section id="effective-sample-size-ess">
<h3>4. Effective Sample Size (ESS)<a class="headerlink" href="#effective-sample-size-ess" title="Link to this heading">ïƒ</a></h3>
<p>Effective sample size measures the number of samples that actually contribute after importance sampling:</p>
<p>$$
\text{ESS} = \frac{1}{\mathbb{E}\left[\left(\frac{w}{\mathbb{E}[w]}\right)^2\right]}
$$</p>
<p>A larger ESS value (closer to 1) indicates more uniform importance sampling weight distribution and higher sample utilization efficiency. When all weights are equal (on-policy), ESS = 1; when weights differ significantly (severely off-policy), ESS becomes small.</p>
</section>
<section id="is-weight-statistics">
<h3>5. IS Weight Statistics<a class="headerlink" href="#is-weight-statistics" title="Link to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">is_weight_mean</span></code>: Average importance sampling weight, ideal value is 1.0</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">clipped_frac</span></code>: Fraction of samples that were truncated or masked</p></li>
</ul>
</section>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Link to this heading">ïƒ</a></h2>
<section id="logging-diagnostic-metrics-only">
<h3>Logging Diagnostic Metrics Only<a class="headerlink" href="#logging-diagnostic-metrics-only" title="Link to this heading">ïƒ</a></h3>
<p>If you only want to monitor the degree of training-inference mismatch without enabling importance sampling correction, you can set:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">log_rollout_offpolicy_metrics</span> <span class="n">true</span>
</pre></div>
</div>
<p>This will log all diagnostic metrics (KL, PPL, Ï‡Â², etc.) without modifying the loss function.</p>
</section>
<section id="enabling-importance-sampling-correction">
<h3>Enabling Importance Sampling Correction<a class="headerlink" href="#enabling-importance-sampling-correction" title="Link to this heading">ïƒ</a></h3>
<p>Enable the correction mechanism with the following parameters:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">rollout_importance_sampling_mode</span> <span class="p">(</span><span class="n">default</span> <span class="kc">None</span><span class="p">)</span>
<span class="o">--</span><span class="n">rollout_importance_sampling_threshold</span> <span class="p">(</span><span class="n">default</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>When <code class="docutils literal notranslate"><span class="pre">rollout_importance_sampling_mode</span></code> is set, diagnostic metrics are automatically logged without needing to set <code class="docutils literal notranslate"><span class="pre">log_rollout_offpolicy_metrics</span></code>.</p>
</section>
</section>
<section id="off-policy-sequence-masking">
<h2>Off-Policy Sequence Masking<a class="headerlink" href="#off-policy-sequence-masking" title="Link to this heading">ïƒ</a></h2>
<p>In addition to importance sampling correction, you can use <strong>Off-Policy Sequence Masking</strong> to address training-inference mismatch. This technique comes from the <a class="reference external" href="https://arxiv.org/abs/2512.02556">DeepSeek-V3.2 paper</a>.</p>
<section id="principle">
<h3>Principle<a class="headerlink" href="#principle" title="Link to this heading">ïƒ</a></h3>
<p>The core idea of Off-Policy Sequence Masking is: when the current policy deviates significantly from the old policy (rollout or old policy), directly discard (mask) that sequence from loss computation. This approach specifically targets <strong>sequences with negative advantage</strong>, as these are more likely to cause training instability when policy shift is large.</p>
<p>Specifically, for each sequence, compute:</p>
<p>$$
\delta_i = \frac{1}{|y_i|} \sum_{t=1}^{|y_i|} \bigl( \log \pi_{\text{old}}(y_{i,t}|x, y_{i,&lt;t}) - \log \pi_\theta(y_{i,t}|x, y_{i,&lt;t}) \bigr)
$$</p>
<p>Sequence $i$ will be masked when the following conditions are met (mean taken over completion tokens, i.e., where <code class="docutils literal notranslate"><span class="pre">completion_mask=1</span></code>):</p>
<ol class="simple">
<li><p>$\delta_i &gt; \tau$</p></li>
<li><p><strong>AND</strong> $\hat{A}_i &lt; 0$</p></li>
</ol>
<p>Where:</p>
<ul class="simple">
<li><p>$\pi_{\text{old}}$ preferentially uses <code class="docutils literal notranslate"><span class="pre">rollout_per_token_logps</span></code> (logprobs from rollout/behavior policy); if unavailable, falls back to <code class="docutils literal notranslate"><span class="pre">old_per_token_logps</span></code></p></li>
<li><p>$\tau$ is the user-set threshold (<code class="docutils literal notranslate"><span class="pre">--off_policy_sequence_mask_delta</span></code>, default None = disabled)</p></li>
</ul>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">ïƒ</a></h2>
<ol class="simple">
<li><p>https://yingru.notion.site/When-Speed-Kills-Stability-Demystifying-RL-Collapse-from-the-Training-Inference-Mismatch-271211a558b7808d8b12d403fd15edda</p></li>
<li><p>https://fengyao.notion.site/off-policy-rl</p></li>
<li><p>https://github.com/volcengine/verl/blob/main/verl/trainer/ppo/rollout_corr_helper.py</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2512.02556">DeepSeek-V3.2: Pushing the Frontier of Open Large Language Models</a></p></li>
</ol>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ç‰ˆæƒæ‰€æœ‰ 2024, Ascendã€‚</p>
  </div>

  åˆ©ç”¨ <a href="https://www.sphinx-doc.org/">Sphinx</a> æ„å»ºï¼Œä½¿ç”¨çš„ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">ä¸»é¢˜</a>
    ç”± <a href="https://readthedocs.org">Read the Docs</a> å¼€å‘.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>