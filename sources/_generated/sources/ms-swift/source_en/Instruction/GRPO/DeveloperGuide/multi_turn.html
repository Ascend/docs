

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" data-content_root="../../../../../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Multi-turn Training &mdash; ÊòáËÖæÂºÄÊ∫ê  ÊñáÊ°£</title>
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/css/theme.css?v=9edc463e" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/custom.css?v=f2aa3e58" />
      <link rel="stylesheet" type="text/css" href="../../../../../../../../_static/sphinx-design.min.css?v=95c83b7e" />

  
      <script src="../../../../../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../../../../../_static/documentation_options.js?v=7d86a446"></script>
      <script src="../../../../../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../../../../../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../../../../../../../_static/copybutton.js?v=f281be69"></script>
      <script src="../../../../../../../../_static/package_info.js?v=2b3ed588"></script>
      <script src="../../../../../../../../_static/statistics.js?v=da671b53"></script>
      <script src="../../../../../../../../_static/translations.js?v=beaddf03"></script>
      <script src="../../../../../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script src="../../../../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Á¥¢Âºï" href="../../../../../../../../genindex.html" />
    <link rel="search" title="ÊêúÁ¥¢" href="../../../../../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../../../../../index.html" class="icon icon-home">
            ÊòáËÖæÂºÄÊ∫ê
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="ÊêúÁ¥¢ÊñáÊ°£" aria-label="ÊêúÁ¥¢ÊñáÊ°£" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="ÂØºËà™ËèúÂçï">
              <p class="caption" role="heading"><span class="caption-text">üèÅ ÂºÄÂßã‰ΩøÁî®</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../ascend/quick_install.html">Âø´ÈÄüÂÆâË£ÖÊòáËÖæÁéØÂ¢É</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üèóÔ∏è  Âü∫Á°ÄËÆæÊñΩ‰∏éÊ°ÜÊû∂</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../accelerate/index.html">Accelerate</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../deepspeed/index.html">DeepSpeed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../kernels/index.html">kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../pytorch/index.html">PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../transformers/index.html">Transformers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üß† ËÆ≠ÁªÉ‰∏éÂæÆË∞ÉÊ°ÜÊû∂</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../LLaMA-Factory/index.html">LLaMA-Factory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../ms-swift/index.html">ms-swift</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../roll/index.html">ROLL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../torchtitan/index.html">TorchTitan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../trl/index.html">Transformer Reinforcement Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../VeOmni/index.html">VeOmni</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../verl/index.html">verl</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üöÄ Êé®ÁêÜ‰∏éÊúçÂä°</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../llama_cpp/index.html">Llama.cpp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../lm_deploy/index.html">LMDeploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../onnxruntime/index.html">ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sentence_transformers/index.html">Sentence Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sglang/index.html">SGLang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../torchchat/index.html">Torchchat</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üé® Â§öÊ®°ÊÄÅ„ÄÅÂ∫îÁî®‰∏éËØÑÊµã</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../Diffusers/index.html">Diffusers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../lm_evaluation/index.html">LM-Evalution-Harness</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../open_clip/index.html">open_clip</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../opencompass/index.html">OpenCompass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../opencv/index.html">OpenCV</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../sd_webui/index.html">Stable-Diffusion-WebUI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../timm/index.html">timm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../wenet/index.html">WeNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../../../whisper_cpp/index.html">Whisper.cpp</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="ÁßªÂä®ÁâàÂØºËà™ËèúÂçï" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../../../../index.html">ÊòáËÖæÂºÄÊ∫ê</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="È°µÈù¢ÂØºËà™">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Multi-turn Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../../../../../_sources/sources/_generated/sources/ms-swift/source_en/Instruction/GRPO/DeveloperGuide/multi_turn.md.txt" rel="nofollow"> Êü•ÁúãÈ°µÈù¢Ê∫êÁ†Å</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="multi-turn-training">
<h1>Multi-turn Training<a class="headerlink" href="#multi-turn-training" title="Link to this heading">ÔÉÅ</a></h1>
<p><strong>Note</strong> The multi-turn training logic was refactored in ms-swift 3.8.
If your ms-swift version is earlier than 3.8, please consult the documentation for that version.</p>
<p>In reinforcement-learning scenarios, the model may need to interact with the environment over multiple turns (e.g., tool calls).
This interactive training requires the model to carry out continuous reasoning based on the feedback from the environment.
This document explains in detail how to customise the multi-turn training workflow in GRPO training.</p>
<p>The figure below shows a typical multi-turn training process, where the model may perform several rollout rounds that include environment interaction, tool calls, and so on:</p>
<p><img alt="Multi-turn example" src="../../../../../../../../_images/grpo_multi_turn.png" /></p>
<section id="multiturnscheduler">
<h2>MultiTurnScheduler<a class="headerlink" href="#multiturnscheduler" title="Link to this heading">ÔÉÅ</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">MultiTurnScheduler</span></code> is an abstract base class that provides the default multi-turn dialogue-management logic.
Its workflow is illustrated below:</p>
<img src="https://raw.githubusercontent.com/modelscope/ms-swift/main/docs/resources/multiturn_pipeline.png" width="300" /><p>The scheduler is responsible for two core functions:</p>
<ul class="simple">
<li><p><strong>Termination check</strong> ‚Äî decide whether the current turn of inference should stop via <code class="docutils literal notranslate"><span class="pre">check_finished</span></code>.</p></li>
<li><p><strong>Inference request construction</strong> ‚Äî build the request object for the next turn via <code class="docutils literal notranslate"><span class="pre">step</span></code>.</p></li>
</ul>
<p>Key methods of the abstract base class <code class="docutils literal notranslate"><span class="pre">MultiTurnScheduler</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MultiTurnScheduler</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_turns</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_turns</span> <span class="o">=</span> <span class="n">max_turns</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">infer_request</span><span class="p">:</span> <span class="s1">&#39;RolloutInferRequest&#39;</span><span class="p">,</span> <span class="n">response_choice</span><span class="p">:</span> <span class="s1">&#39;ChatCompletionResponseChoice&#39;</span><span class="p">,</span>
             <span class="n">current_turn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Handle the transition between dialogue turns.</span>

<span class="sd">        Args:</span>
<span class="sd">            infer_request: current inference request</span>
<span class="sd">            response_choice: response of the current turn</span>
<span class="sd">            current_turn: current turn index (starting from 1)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, Any]: a dict containing the result of this turn</span>
<span class="sd">                - infer_request (required): the inference request for the next turn</span>
<span class="sd">                - response_token_ids (optional): token IDs of each rollout response</span>
<span class="sd">                - response_loss_mask (optional): loss mask of each rollout response</span>
<span class="sd">                - rollout_logprobs (optional): token logps of each rollout response</span>
<span class="sd">                - rollout_infos (optional): extra information</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">check_finished</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">infer_request</span><span class="p">:</span> <span class="s1">&#39;RolloutInferRequest&#39;</span><span class="p">,</span> <span class="n">response_choice</span><span class="p">:</span> <span class="s1">&#39;ChatCompletionResponseChoice&#39;</span><span class="p">,</span>
                       <span class="n">current_turn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Default termination logic for multi-turn rollout.</span>

<span class="sd">        Termination conditions:</span>
<span class="sd">        1. The response is truncated (finish_reason == &#39;length&#39;).</span>
<span class="sd">        2. The dialogue reaches the maximum number of turns (if max_turns is set).</span>

<span class="sd">        Args:</span>
<span class="sd">            infer_request: the inference request</span>
<span class="sd">            response_choice: response choice containing finish_reason</span>
<span class="sd">            current_turn: current turn index</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: True to stop, False to continue</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">response_choice</span><span class="o">.</span><span class="n">finish_reason</span> <span class="o">==</span> <span class="s1">&#39;length&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_turns</span> <span class="ow">and</span> <span class="n">current_turn</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_turns</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>
</pre></div>
</div>
<p>Arguments passed to <code class="docutils literal notranslate"><span class="pre">step</span></code> and <code class="docutils literal notranslate"><span class="pre">check_finished</span></code>:</p>
<ul class="simple">
<li><p><strong>infer_request</strong>: current inference request</p></li>
<li><p><strong>response_choice</strong>: inference result of the current turn</p></li>
<li><p><strong>current_turn</strong>: current turn index (starting from 1)</p></li>
</ul>
<details><summary>Input example (click to expand)</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">infer_request</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">RolloutInferRequest(</span>
<span class="sd">    messages=[</span>
<span class="sd">        {&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within &lt;think&gt; &lt;/think&gt; and &lt;answer&gt; &lt;/answer&gt; tags, respectively, i.e., &lt;think&gt; reasoning process here &lt;/think&gt;&lt;answer&gt; answer here &lt;/answer&gt;\n&#39;}, {&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;What is the value of $\\sqrt{36 \\times \\sqrt{16}}$?&#39;},</span>
<span class="sd">        {&#39;role&#39;: &#39;assistant&#39;, &#39;content&#39;: &#39;To find the value of \\(\\sqrt{36 \\times \\sqrt{16}}\\), we will break down the problem step-by-step.\n\nFirst, we need to evaluate the inner square root:\n\\[\n\\sqrt{16}\n\\]\nWe know that:\n\\[\n4^2 = 16 \\implies \\sqrt{16} = 4\n\\]\n\nNext, we substitute this result back into the original expression:\n\\[\n\\sqrt{36 \\times \\sqrt{16}} = \\sqrt{36 \\times 4}\n\\]\n\nNow, we need to evaluate the product inside the square root:\n\\[\n36 \\times 4 = 144\n\\]\n\nSo, the expression simplifies to:\n\\[\n\\sqrt{144}\n\\]\n\nFinally, we determine the square root of 144:\n\\[\n\\sqrt{144} = 12\n\\]\n\nThus, the value of \\(\\sqrt{36 \\times \\sqrt{16}}\\) is:\n\\[\n\\boxed{12}\n\\]&#39;}</span>
<span class="sd">    ],</span>
<span class="sd">    images=[],</span>
<span class="sd">    audios=[],</span>
<span class="sd">    videos=[],</span>
<span class="sd">    tools=None,</span>
<span class="sd">    objects={},</span>
<span class="sd">    data_dict={</span>
<span class="sd">        &#39;problem&#39;: &#39;What is the value of $\\sqrt{36 \\times \\sqrt{16}}$?&#39;,</span>
<span class="sd">        &#39;solution&#39;: &quot;To solve the problem, we need to evaluate the expression \\(\\sqrt{36 \\times \\sqrt{16}}\\).\n\nWe can break down the steps as follows:\n\n1. Evaluate the inner square root: \\(\\sqrt{16}\\).\n2. Multiply the result by 36.\n3. Take the square root of the product obtained in step 2.\n\nLet&#39;s compute this step by step using Python code for accuracy.\n```python\nimport math\n\n# Step 1: Evaluate the inner square root\ninner_sqrt = math.sqrt(16)\n\n# Step 2: Multiply the result by 36\nproduct = 36 * inner_sqrt\n\n# Step 3: Take the square root of the product\nfinal_result = math.sqrt(product)\nprint(final_result)\n```\n```output\n12.0\n```\nThe value of \\(\\sqrt{36 \\times \\sqrt{16}}\\) is /\\(\\boxed{12}\\).&quot;</span>
<span class="sd">        }</span>
<span class="sd">    )</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">response_choice</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">ChatCompletionResponseChoice(</span>
<span class="sd">    index=0,</span>
<span class="sd">    message=ChatMessage(</span>
<span class="sd">        role=&#39;assistant&#39;,</span>
<span class="sd">        content=&#39;To find the value of \\(\\sqrt{36 \\times \\sqrt{16}}\\), we will break down the problem step-by-step.\n\nFirst, we need to evaluate the inner square root:\n\\[\n\\sqrt{16}\n\\]\nWe know that:\n\\[\n4^2 = 16 \\implies \\sqrt{16} = 4\n\\]\n\nNext, we substitute this result back into the original expression:\n\\[\n\\sqrt{36 \\times \\sqrt{16}} = \\sqrt{36 \\times 4}\n\\]\n\nNow, we need to evaluate the product inside the square root:\n\\[\n36 \\times 4 = 144\n\\]\n\nSo, the expression simplifies to:\n\\[\n\\sqrt{144}\n\\]\n\nFinally, we determine the square root of 144:\n\\[\n\\sqrt{144} = 12\n\\]\n\nThus, the value of \\(\\sqrt{36 \\times \\sqrt{16}}\\) is:\n\\[\n\\boxed{12}\n\\]&#39;, tool_calls=None),</span>
<span class="sd">        finish_reason=&#39;stop&#39;,</span>
<span class="sd">        logprobs=None,</span>
<span class="sd">        messages=None)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># response_choice.messages will be copied at the end of multi-turn inference.</span>
</pre></div>
</div>
</details><br>
<br><p>The default <code class="docutils literal notranslate"><span class="pre">check_finished</span></code> logic stops inference in the following cases:</p>
<ul class="simple">
<li><p>The model reply is truncated, i.e. exceeds <code class="docutils literal notranslate"><span class="pre">max_completion_length</span></code>.</p></li>
<li><p>The number of inference turns exceeds the specified maximum.</p></li>
</ul>
<p>For the full default multi-turn rollout logic, see the <code class="docutils literal notranslate"><span class="pre">run</span></code> method of the class.
You can override <code class="docutils literal notranslate"><span class="pre">run</span></code> to implement a completely custom workflow.</p>
</section>
<section id="setting-multi-turn-parameters">
<h2>Setting multi-turn parameters<a class="headerlink" href="#setting-multi-turn-parameters" title="Link to this heading">ÔÉÅ</a></h2>
<p>Specify the scheduler via <code class="docutils literal notranslate"><span class="pre">multi_turn_scheduler</span></code> in the <code class="docutils literal notranslate"><span class="pre">swift</span> <span class="pre">rollout</span></code> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>swift<span class="w"> </span>rollout<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen3-1.7B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--use_async_engine<span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--multi_turn_scheduler<span class="w"> </span>thinking_tips_scheduler<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_max_model_len<span class="w"> </span><span class="m">32768</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--vllm_gpu_memory_utilization<span class="w"> </span><span class="m">0</span>.8<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max_turns<span class="w"> </span><span class="m">3</span>
</pre></div>
</div>
<blockquote>
<div><p>With the <code class="docutils literal notranslate"><span class="pre">external_plugins</span></code> argument you can register your own local scheduler with ms-swift.
Refer to the <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/grpo/plugin/plugin.py">plugin code</a>.</p>
</div></blockquote>
<p>A full multi-turn training script can be found <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/grpo/external/vllm_multi_turn.sh">here</a>.</p>
<p>For multi-turn rollout we use <code class="docutils literal notranslate"><span class="pre">AsyncEngine</span></code> to perform efficient batched asynchronous sampling.
AsyncEngine reduces compute bubbles in multi-turn inference:</p>
<img src="https://raw.githubusercontent.com/modelscope/ms-swift/main/docs/resources/asyncengine.png" width="400" /><p>Use the <code class="docutils literal notranslate"><span class="pre">use_async_engine</span></code> argument in the <code class="docutils literal notranslate"><span class="pre">rollout</span></code> command to specify the engine type (async is the default).</p>
<blockquote>
<div><p>Note: The async engine and the custom multi-turn interaction logic below are currently only supported in server mode. For multi-turn interaction logic in colocate mode, please refer to the _colocate_multi_turn_infer method in RolloutTrainerMixin.</p>
</div></blockquote>
</section>
<section id="advanced-topics">
<h2>Advanced topics<a class="headerlink" href="#advanced-topics" title="Link to this heading">ÔÉÅ</a></h2>
<section id="customising-the-interaction-logic">
<h3>Customising the interaction logic<a class="headerlink" href="#customising-the-interaction-logic" title="Link to this heading">ÔÉÅ</a></h3>
<p>In the default logic we treat the whole multi-turn rollout as one trajectory when computing the loss.
This assumes the model‚Äôs history is not modified during interaction.</p>
<p>In some scenarios you may need to dynamically change the history during rollout (e.g., compressing context).
In that case each turn should be treated as a separate trajectory.</p>
<p>A common scenario is for ‚Äúthinking‚Äù models: during real inference the model keeps only the last reasoning step and discards previous ones.</p>
<p>For such cases override the <code class="docutils literal notranslate"><span class="pre">run</span></code> method in your scheduler to return the result for each rollout turn individually.
The built-in <code class="docutils literal notranslate"><span class="pre">ThinkingModelTipsScheduler</span></code> shows how to fully customise multi-turn inference by overriding <code class="docutils literal notranslate"><span class="pre">run()</span></code>.
See the implementation in <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/swift/rollout/multi_turn.py">multi_turn.py</a>.</p>
<p><strong>NOTE</strong>: In this scenario, the data for a single trajectory is split into multiple records. When computing rewards, you must assign the same reward to every record that belongs to the same trajectory.</p>
<p>The complete trajectory can be accessed via <code class="docutils literal notranslate"><span class="pre">trajectory_inputs</span></code> in <code class="docutils literal notranslate"><span class="pre">kwargs</span></code>.</p>
<p>For a concrete implementation, see the <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/grpo/plugin/plugin.py">MultiTurnThinkingTips class</a></p>
</section>
<section id="multimodal-data-override">
<h3>Multimodal Data Override<a class="headerlink" href="#multimodal-data-override" title="Link to this heading">ÔÉÅ</a></h3>
<p>In multimodal, multi-turn interactions, you may need to dynamically add, delete, or modify multimodal data during the conversation and ensure these changes are synchronized to the trainer.</p>
<p>Implementation: Use <code class="docutils literal notranslate"><span class="pre">rollout_infos</span></code> to override the original multimodal content in the dataset by specifying the corresponding keys.</p>
<p>Supported override keys: images, audios, videos.</p>
<p>For details, see <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/grpo/plugin/deepeyes/deepeyes_plugin.py#L403-L404">DeepEyes Scheduler</a>.</p>
</section>
<section id="returning-response-token-ids">
<h3>Returning response token IDs<a class="headerlink" href="#returning-response-token-ids" title="Link to this heading">ÔÉÅ</a></h3>
<p>In the default workflow the scheduler returns text, the trainer re-encodes it to token IDs for training.
To avoid this extra encoding, have the scheduler return <code class="docutils literal notranslate"><span class="pre">response_token_ids</span></code> directly.</p>
<p>Steps:</p>
<ul class="simple">
<li><p>Read the <code class="docutils literal notranslate"><span class="pre">token_ids</span></code> attribute from <code class="docutils literal notranslate"><span class="pre">response_choice</span></code> to obtain the sequence.</p></li>
<li><p>Include <code class="docutils literal notranslate"><span class="pre">response_token_ids</span></code> in the dict returned by <code class="docutils literal notranslate"><span class="pre">step</span></code> / <code class="docutils literal notranslate"><span class="pre">run</span></code>; the trainer can then use them directly.</p></li>
</ul>
<p>For a concrete implementation, refer to the <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/swift/rollout/multi_turn.py">ThinkingModelTipsScheduler class</a></p>
</section>
<section id="loss-mask">
<h3>Loss mask<a class="headerlink" href="#loss-mask" title="Link to this heading">ÔÉÅ</a></h3>
<p>When the environment or a tool call returns content that becomes part of the model response, you may want to mask it so the model is not penalised on externally generated tokens.</p>
<p>You can set the loss mask in two ways.</p>
<p><strong>1. Using <code class="docutils literal notranslate"><span class="pre">loss_scale</span></code></strong></p>
<p>ms-swift provides the <code class="docutils literal notranslate"><span class="pre">loss_scale</span></code> parameter to scale or mask parts of the response.
For example, <code class="docutils literal notranslate"><span class="pre">--loss_scale</span> <span class="pre">last_round</span></code> zeroes out the loss for all but the last round.
Custom <code class="docutils literal notranslate"><span class="pre">loss_scale</span></code> can also be implemented; see the <a class="reference external" href="../../../Customization/Pluginization.md#customizing-loss-scale">customisation guide</a>.</p>
<blockquote>
<div><p>Note: In GRPO, <code class="docutils literal notranslate"><span class="pre">loss_scale</span></code> serves only as a mask; it does not scale the loss.</p>
</div></blockquote>
<p><strong>2. Using <code class="docutils literal notranslate"><span class="pre">loss_mask</span></code></strong></p>
<p>In <code class="docutils literal notranslate"><span class="pre">step</span></code> or <code class="docutils literal notranslate"><span class="pre">run</span></code>, set <code class="docutils literal notranslate"><span class="pre">response_loss_mask</span></code> to define a custom mask.
This requires returning <code class="docutils literal notranslate"><span class="pre">response_token_ids</span></code>; the mask must be the same length.
When <code class="docutils literal notranslate"><span class="pre">response_loss_mask</span></code> is provided, <code class="docutils literal notranslate"><span class="pre">loss_scale</span></code> is ignored.</p>
<p>For how to return response_loss_mask, see the <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/examples/train/grpo/plugin/plugin.py">ToolCallScheduler class</a></p>
</section>
<section id="reward-function-related-tips">
<h3>Reward-function related tips<a class="headerlink" href="#reward-function-related-tips" title="Link to this heading">ÔÉÅ</a></h3>
<p><strong>Accessing multi-turn rollout information in a reward function</strong></p>
<p>Return a <code class="docutils literal notranslate"><span class="pre">rollout_infos</span></code> object from <code class="docutils literal notranslate"><span class="pre">step</span></code> / <code class="docutils literal notranslate"><span class="pre">run</span></code>, then read it from <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> in the reward function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Scheduler</span><span class="p">():</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">infer_request</span><span class="p">:</span> <span class="s1">&#39;RolloutInferRequest&#39;</span><span class="p">,</span> <span class="n">response_choice</span><span class="p">:</span> <span class="s1">&#39;ChatCompletionResponseChoice&#39;</span><span class="p">,</span>
             <span class="n">current_turn</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="o">...</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;infer_request&#39;</span><span class="p">:</span> <span class="n">infer_request</span><span class="p">,</span> <span class="s1">&#39;rollout_infos&#39;</span><span class="p">:</span> <span class="n">extra_dict</span><span class="p">}</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RewardFunction</span><span class="p">():</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">completions</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">infos</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;rollout_infos&#39;</span><span class="p">,</span> <span class="p">{})</span>
        <span class="o">...</span>
</pre></div>
</div>
</section>
<section id="accessing-additional-dataset-information-in-scheduler">
<h3>Accessing additional dataset information in scheduler<a class="headerlink" href="#accessing-additional-dataset-information-in-scheduler" title="Link to this heading">ÔÉÅ</a></h3>
<p>Set <code class="docutils literal notranslate"><span class="pre">--vllm_server_pass_dataset</span></code> on the training side to pass other dataset columns to the scheduler.
They can be read from <code class="docutils literal notranslate"><span class="pre">infer_request.data_dict</span></code>.</p>
</section>
<section id="training-inference-mismatch">
<h3>Training-Inference-Mismatch<a class="headerlink" href="#training-inference-mismatch" title="Link to this heading">ÔÉÅ</a></h3>
<p>Swift &gt;= 3.11 supports returning rollout logprobs from the vLLM side to address training-inference mismatch issues. For details, please refer to this <a class="reference internal" href="../AdvancedResearch/training_inference_mismatch.html"><span class="doc">document</span></a>.</p>
<p>In multi-turn training, if <code class="docutils literal notranslate"><span class="pre">rollout_importance_sampling_mode</span></code> is enabled, the framework automatically collects log probabilities from each rollout turn to correct off-policy issues.</p>
<p><strong>Default Behavior</strong>:</p>
<ul class="simple">
<li><p>When using the default <code class="docutils literal notranslate"><span class="pre">run</span></code> method, the framework automatically extracts log probabilities from <code class="docutils literal notranslate"><span class="pre">response_choice.logprobs</span></code></p></li>
<li><p>These logprobs are passed to the trainer along with <code class="docutils literal notranslate"><span class="pre">response_token_ids</span></code> and <code class="docutils literal notranslate"><span class="pre">response_loss_mask</span></code></p></li>
</ul>
<p><strong>Notes for Custom Schedulers</strong>:</p>
<p>If you modify the response in your <code class="docutils literal notranslate"><span class="pre">step</span></code> method (e.g., truncation, adding content), you need to return the corresponding <code class="docutils literal notranslate"><span class="pre">rollout_logprobs</span></code>:</p>
<p><strong>Key Rules</strong>:</p>
<ul class="simple">
<li><p>The length of <code class="docutils literal notranslate"><span class="pre">rollout_logprobs</span></code> should equal the count of 1s in <code class="docutils literal notranslate"><span class="pre">response_loss_mask</span></code></p></li>
<li><p>For tokens with <code class="docutils literal notranslate"><span class="pre">loss_mask=0</span></code> (e.g., user-added prompts, tool return results), no logprobs are needed</p></li>
<li><p>If <code class="docutils literal notranslate"><span class="pre">step</span></code> does not return <code class="docutils literal notranslate"><span class="pre">rollout_logprobs</span></code>, the framework will automatically extract them from <code class="docutils literal notranslate"><span class="pre">response_choice.logprobs</span></code></p></li>
</ul>
<p><strong>When Overriding the <code class="docutils literal notranslate"><span class="pre">run</span></code> Method</strong>:</p>
<p>If you completely override the <code class="docutils literal notranslate"><span class="pre">run</span></code> method, you need to manually collect and pass <code class="docutils literal notranslate"><span class="pre">rollout_logprobs</span></code></p>
<p>For implementation, please refer to <a class="reference external" href="https://github.com/modelscope/ms-swift/blob/main/swift/rollout/multi_turn.py">here</a></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; ÁâàÊùÉÊâÄÊúâ 2024, Ascend„ÄÇ</p>
  </div>

  Âà©Áî® <a href="https://www.sphinx-doc.org/">Sphinx</a> ÊûÑÂª∫Ôºå‰ΩøÁî®ÁöÑ 
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">‰∏ªÈ¢ò</a>
    Áî± <a href="https://readthedocs.org">Read the Docs</a> ÂºÄÂèë.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>